{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "988bbc05",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "mr\n",
    "\n",
    "# Lattice word problems\n",
    "\n",
    "https://link.springer.com/chapter/10.1007/10721975_15 An Algebra of Resolution . \n",
    "https://opus.bibliothek.uni-augsburg.de/opus4/frontdoor/deliver/index/docId/224/file/TB_2003_12.pdf Deriving tableau-based solutions to lattice word problems Georg Struth\n",
    "\n",
    "Horn clauses ~ lattice equational\n",
    "\n",
    "uniform word problem\n",
    "\n",
    "https://www.cs.upc.edu/~erodri/webpage/papers/lpar08max.pdf The Max-Atom Problem and its Relevance . difference logic extended with a max operation\n",
    "max(x,y) + k <= z\n",
    "\n",
    "https://sozeau.gitlabpages.inria.fr/www/research/publications/Bounded_Cumulative_Universe_Polymorphism_with_Algebraic_Universes-AIMXIX-241125.pdf - subtyping at the universe level.\n",
    "\n",
    "https://www.sciencedirect.com/science/article/pii/S0304397522000317?via%3Dihub Loop-checking and the uniform word problem for join-semilattices with an inflationary endomorphism. \"successor\" and join function. All terms of of the form join(x + k, ...) if you normalize by flattening all joins and pushing all succ as deep as possible. succ(join(x,y)) = join(succ(x), succ(y))\n",
    "\n",
    "s = t becomes kind of \n",
    "\n",
    "\"univform wqord problem for semilattice\"\n",
    "https://doc.sagemath.org/html/en/reference/combinat/sage/combinat/posets/lattices.html\n",
    "alan day ddoubling construction\n",
    "\n",
    "baked in lattices. That is kind of compelling yea? Like symbolic lattice values you learn about. merge = join.\n",
    "\n",
    "https://arxiv.org/abs/1311.2973 Locality and applications to subsumption testing and interpolation in EL and some of its extensions. Viorica Sofronie-Stokkermans Description logics\n",
    "\n",
    "https://groups.csail.mit.edu/tds/papers/Kanellakis/RTA85.pdf  Two applications of equational theories to database theory\n",
    "  Functional depedency problems are equal to uniform word problem for lattices\n",
    "\n",
    "Lorenzen is often quoted\n",
    "\n",
    "R.S. Freese, Finitely presented lattices: canonical forms and the covering relation.  \n",
    "https://math.hawaii.edu/~ralph/\n",
    "https://math.hawaii.edu/~ralph/books.html Free lattices book\n",
    "https://math.hawaii.edu/~ralph/Classes/649M/FreeLatChap.pdf\n",
    "https://www.uacalc.org/algorithms.html universal algerba calculator\n",
    "https://github.com/jipsen/Algebras-and-Logics/blob/main/files/index.html.md\n",
    "https://math.chapman.edu/~jipsen/mathstructures/lattices/ whitman's algorithm\n",
    "\n",
    "https://spot.colorado.edu/~kearnes/conf.html general algerba conferences\n",
    "\n",
    "https://www.math.uwaterloo.ca/~snburris/htdocs/MYWORKS/PAPERS/uwp.pdf Polynomial Time Uniform Word Problems - STANLEY BURRIS\n",
    "\n",
    "https://www.cs.ox.ac.uk/people/daniel.james/lattice.html A reflection-based proof tactic for lattices in Coq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48220d7e",
   "metadata": {},
   "source": [
    "# casting in knuckledragger\n",
    "type lattice\n",
    "lub\n",
    "multiple dispatch\n",
    "https://en.wikipedia.org/wiki/Multiple_dispatch\n",
    "ducktyping\n",
    "\n",
    "mro, c3\n",
    "\n",
    "https://link.springer.com/book/10.1007/978-1-4612-4138-6 Object-Oriented Programming A Unified Foundation castagna\n",
    "Luo coercion https://www.cs.rhul.ac.uk/home/zhaohui/SALT20.pdf typ theoretical sermantics of ocercions\n",
    "https://ncatlab.org/nlab/show/coercion\n",
    "\n",
    "https://belle.sourceforge.net/doc/subtypes.pdf PVS encoding into HOL hurd\n",
    "M. J. C. Gordon. Notes on PVS from a HOL perspective \n",
    "type(x : Bool) == x\n",
    "identiy function stating which things are considered to be type constraints.\n",
    "type(foo(x)) => type()\n",
    "\n",
    "\n",
    "forall([x,y,z], And(type(), ) => type(A[t]) ~~~~ x y z |- t : A judgement\n",
    "which part is t and which is A is unclear. Should be named only? But then why bother with type()?\n",
    "\n",
    "hastype(t,A) = A[t]  - has to be polymorphic, which stinks.\n",
    "\n",
    "\n",
    "What's the point of this?\n",
    "\n",
    "\n",
    "Maybe a universal datatype\n",
    "+ subtyping\n",
    "+ coercion into higher Universes.\n",
    "+ \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949cfb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Foo(x(x), y(x))"
      ],
      "text/plain": [
       "Foo(x(x), y(x))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "def cast_dt(dt : smt.DatatypeSortRef, e : smt.DatatypeRef) -> smt.DatatypeRef:\n",
    "    # also could if there is a single constructor with a single field matching the type, we could lift\n",
    "    # ambiguity?\n",
    "    dt1 = e.sort()\n",
    "    assert dt1.num_constructors() == 1\n",
    "    assert dt.num_constructors() == 1\n",
    "    constr, constr1 = dt.constructor(0), dt1.constructor(0)\n",
    "    assert constr.arity() <= constr1.arity()\n",
    "    args = []\n",
    "    for i in range(constr.arity()):\n",
    "        acc = dt.accessor(0, i)\n",
    "        args.append(getattr(e, acc.name()))\n",
    "    return constr(*args) \n",
    "\n",
    "Foo = kd.Struct(\"Foo\", (\"x\", smt.IntSort()), (\"y\", smt.IntSort()))\n",
    "Bar = kd.Struct(\"Bar\", (\"x\", smt.IntSort()), (\"y\", smt.IntSort()), (\"z\", smt.IntSort()))\n",
    "q = smt.Const(\"q\", Bar)\n",
    "cast_dt(Foo, x)\n",
    "\n",
    "\n",
    "kd.Struct(\"Monoid\", (\"e\", T), (\"mul\", smt.ArraySort(T,T,T)))\n",
    "kd.Struct(\"Group\", (\"inv\", smt.ArraySort(T,T)), inherit=[Monoid])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeef0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RefinedFun(NamedTuple):\n",
    "    f : Callable[[...], smt.ExprRef] # or ArrayRef or other callable\n",
    "    prop : kd.Proof # forall args, argsorts => \n",
    "    def __call__(self, *args, by=None):\n",
    "        pf = self.prop(*args)\n",
    "        if by is not None and smt.is_implies(pf.thm):\n",
    "            # inspect argument assumes here.\n",
    "            argpf = kd.prove(pf.thm.args(0), by=by)\n",
    "            return self.f(*args), kd.kernel.modus(argpf, pf)\n",
    "        return RefinedExpr(self.f(*args), self.prop(*args))\n",
    "def RefinedExpr(NamedTuple):\n",
    "    e : smt.ExprRef\n",
    "    prop : kd.Proof\n",
    "    def __call__(self, by=None):\n",
    "        pf = self.prop()\n",
    "        if by is not None and smt.is_implies(pf.thm):\n",
    "            argpf = kd.prove(pf.thm.args(0), by=by)\n",
    "            return self.e, kd.kernel.modus(argpf, pf)\n",
    "        return self.e, self.prop()\n",
    "    def __add__(self, other):\n",
    "        smt.And(self.prop, other.prop)\n",
    "    def __sub__(self, other):    \n",
    "\n",
    "class RefinedFuncDecl(smt.FuncDeclRef):\n",
    "\n",
    "class RefinedExpr(smt.ExprRef):\n",
    "\n",
    "\n",
    "\n",
    "# or just overload smt.FuncDeclRef.__call__\n",
    "# analgous to assumes. assumes should only go on\n",
    "\n",
    "FuncDeclRef.prop = None\n",
    "ExprRef.prop = None  # I already overload call\n",
    "\n",
    "# Could overload _everything_ to propagate prop via and_intro\n",
    "# And, Or,\n",
    "# but don't propagate assumes?\n",
    "\n",
    "# proofs by construction.\n",
    "\n",
    "# even without propagation, maybe manual prop association is useful.\n",
    "\n",
    "def has_prop(e,prop, by=[]):\n",
    "    pf = kd.prove(p)\n",
    "    e.prop = pf\n",
    "# screw it why not\n",
    "smt.IntVal(3).prop = kd.prove(3 > smt.IntVal(0))\n",
    "\n",
    "# it's a kind of super shallow existential / refinement type.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4df5757",
   "metadata": {},
   "source": [
    "# Set Theoretic Type\n",
    "https://arxiv.org/abs/2306.06391 The Design Principles of the Elixir Type System\n",
    "https://www.irif.fr/~gc/papers/set-theoretic-types-2022.pdf\n",
    "https://www.irif.fr/~gc/papers/covcon-again.pdf  COVARIANCE AND CONTRAVARIANCE:\n",
    "A FRESH LOOK AT AN OLD ISSUE (A PRIMER IN ADVANCED TYPE SYSTEMS FOR LEARNING FUNCTIONAL PROGRAMMERS). Has a description of the type checking algorithm that almost seems reasonable.\n",
    "\n",
    "https://dl.acm.org/doi/abs/10.1145/3587216.3587220 Set-theoretic Types for Erlang 2022\n",
    "\n",
    "https://cs.stackexchange.com/questions/162744/what-is-practically-preventing-us-from-applying-set-theoretic-types-in-engineeri\n",
    "\n",
    "https://pnwamk.github.io/sst-tutorial/\n",
    "\n",
    "Castagna\n",
    "frisch\n",
    "\n",
    "https://lobste.rs/s/cw85yf/lazier_binary_decision_diagrams_bdds_for https://elixir-lang.org/blog/2025/12/02/lazier-bdds-for-set-theoretic-types/\n",
    "lazy bdds\n",
    "all elixir values are total ordered?\n",
    "\n",
    "https://luau.org/\n",
    "\n",
    "https://arxiv.org/pdf/1708.08021 Fast and Precise Type Checking for JavaScript Avik 2017\n",
    "\n",
    "Distinction between having interesection and union and having set-theoreitc types\n",
    "\n",
    "https://plum-umd.github.io/projects/rdl.html Ruby. Jeff foster\n",
    "\n",
    "https://hal.science/hal-05369012/ implementing set theoretic types\n",
    "\n",
    "in knuckeldragger what if we made it gradually typed.\n",
    "\n",
    "ty also uses this stuff. Bdds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e316f526",
   "metadata": {},
   "source": [
    "# gradual typing\n",
    "? as an unknown / dynamic type\n",
    "\n",
    "https://jsiek.github.io/home/WhatIsGradualTyping.html\n",
    "\n",
    "\"is compatible with\" judgement\n",
    "`? ~ T`\n",
    "not transitive\n",
    "\n",
    "? is imilar to `object` or top, except it aslso allows casts to any other type. so it's also kind of bottom\n",
    "\n",
    "\n",
    "https://dl.acm.org/doi/10.1145/3290329  Gradual typing: a new perspective\n",
    "\n",
    "https://www.cambridge.org/core/journals/journal-of-functional-programming/article/gradual-type-theory/2D5DC0E87301B1724C42B7E31F90DD6B Gradual type theory new licata ahmed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a15b97",
   "metadata": {},
   "source": [
    "# cardelli\n",
    "Amber subtyping Cardelli. Record Refinement / row subtyping\n",
    "\n",
    "\n",
    "from kdrag.contrib\n",
    "\n",
    "tapl\n",
    "\n",
    "https://courses.grainger.illinois.edu/cs421/fa2018/CS421A/resources/cardelli.pdf\n",
    "https://sdiehl.github.io/typechecker-zoo/\n",
    "https://news.ycombinator.com/item?id=41922081 row polymorphism\n",
    "\n",
    "\n",
    "\n",
    "iuf type variables worked, could return a sentinel FreshVar\n",
    "\n",
    "x == y constraints rather than\n",
    "\n",
    "\n",
    "Tuple syntax\n",
    "accessor notation\n",
    "if-then-else\n",
    "\n",
    "\n",
    "\n",
    "use transitive closure of cast() relation.\n",
    "Maximize generaslity?\n",
    "T = join(A,B).\n",
    "T <= A, T <= B. max T\n",
    "\n",
    "\n",
    "smt.SetSort(Type)\n",
    "Union, Intersection\n",
    "\n",
    "Types themselves might denote sets of terms. I am not internalizing terms though\n",
    "Kind of an interesting in between\n",
    "\n",
    "\n",
    "a shape (2,3) <= (1,2,3,10,20) braodcasting + padding. Hmm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcbc73e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Tree('app', [Tree(Token('RULE', 'num'), [Token('NUMBER', '42')])])",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     34\u001b[39m         \u001b[38;5;28;01mcase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01m_\u001b[39;00m:\n\u001b[32m     35\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(tree)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[43minfer_type\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m42\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36minfer_type\u001b[39m\u001b[34m(s)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mmatch\u001b[39;00m tree:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mcase\u001b[39;00m Tree(\u001b[33m\"\u001b[39m\u001b[33mstart\u001b[39m\u001b[33m\"\u001b[39m, [e]):\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexpr_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mcase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01m_\u001b[39;00m:\n\u001b[32m     35\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(tree)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mexpr_type\u001b[39m\u001b[34m(tree, ctx)\u001b[39m\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Type.Bool\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mcase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01m_\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(tree)\n",
      "\u001b[31mNotImplementedError\u001b[39m: Tree('app', [Tree(Token('RULE', 'num'), [Token('NUMBER', '42')])])"
     ]
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "from lark import Tree\n",
    "#import kdrag.parsers.microlean as microlean\n",
    "Type = kd.Inductive(\"Type\")\n",
    "Type.declare(\"Int\")\n",
    "Type.declare(\"Bool\")\n",
    "Type.declare(\"Real\")\n",
    "Type.declare(\"Seq\", (\"seq\", Type))\n",
    "#Type.declare(\"Fun\", (\"arg\", smt.SeqSort(Type), (\"ret\", Type)))\n",
    "Type.declare(\"Array\", (\"domain\", Type), (\"range\", Type))\n",
    "Type.declare(\"Datatype\", (\"dtname\", smt.StringSort()))\n",
    "Type.declare(\"BitVec\", (\"size\", smt.IntSort()))\n",
    "Type.declare(\"UnInterp\", (\"uname\", smt.StringSort()))\n",
    "Type = Type.create()\n",
    "kd.microlean.parser.parse(\"fun x => x\")\n",
    "\n",
    "\n",
    "def expr_type(tree, ctx):\n",
    "    match tree:\n",
    "        case Tree(\"num\", [n]):\n",
    "            return Type.Int\n",
    "        case Tree(\"true\", []):\n",
    "            return Type.Bool\n",
    "        case Tree(\"false\", []):\n",
    "            return Type.Bool\n",
    "        case _:\n",
    "            raise NotImplementedError(tree)\n",
    "\n",
    "def infer_type(s):\n",
    "    tree = kd.microlean.parser.parse(s)\n",
    "    match tree:\n",
    "        case Tree(\"start\", [e]):\n",
    "            return expr_type(e, {})\n",
    "        case _:\n",
    "            raise NotImplementedError(tree)\n",
    "infer_type(\"42\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb469b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def type_constr(tree, ctx):\n",
    "    constrs = []\n",
    "    def lookup_decl(name):\n",
    "        if name in ctx:\n",
    "            return ctx[name]\n",
    "    def lookup(ctx):\n",
    "\n",
    "def type_const(tree, ctx, constrs=None, expect=None):\n",
    "    if constrs is None:\n",
    "        constrs = []\n",
    "    match \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d926d06",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'smt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m Type = \u001b[43msmt\u001b[49m.Inductive(\u001b[33m\"\u001b[39m\u001b[33mType\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m Type.declare(\u001b[33m\"\u001b[39m\u001b[33mInt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m Type.declare(\u001b[33m\"\u001b[39m\u001b[33mBool\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'smt' is not defined"
     ]
    }
   ],
   "source": [
    "# use z3 as constraint solver. Everything does have to be ground...\n",
    "\n",
    "#Type.declare(\"Tuple\", (\"elems\", smt.List(Type)))\n",
    "#Type.declare(\"NamedSubsort\", (\"name\", smt.StringSort()), (\"T\", Type))\n",
    "\n",
    "{\n",
    "    Type.Int : smt.IntSort(),\n",
    "    Type.Bool : smt.BoolSort(),\n",
    "    Type.Real : smt.RealSort(),\n",
    "    Type.Seq : lambda t: smt.SeqSort(t),\n",
    "}\n",
    "\n",
    "def to_sort(t):\n",
    "    if t.eq(Type.Int):\n",
    "        return smt.IntSort()\n",
    "    elif t.eq(Type.Bool):\n",
    "        return smt.BoolSort()\n",
    "    elif t.decl() == Type.Real: \n",
    "        return smt.RealSort()\n",
    "    elif t.decl() == Type.Seq:\n",
    "        return smt.SeqSort(to_sort(t.arg(0)))\n",
    "    elif t.decl() == Type.Fun:\n",
    "        return smt.ArraySort(smt.SeqSort(to_sort(t.arg(0))), to_sort(t.arg(1)))\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Cannot convert type {t} to sort\")\n",
    "\n",
    "def from_sort(s : smt.SortRef):\n",
    "    if isinstance(s, smt.DatatypeRef):\n",
    "        return Type.Datatype(s.name())\n",
    "    elif isinstance(s, smt.SeqSortRef)\n",
    "    elif isisntance(s, smt.ArraySortRef)\n",
    "    if s == smt.IntSort():\n",
    "        return Type.Int\n",
    "    elif s == smt.BoolSort():\n",
    "\n",
    "\n",
    "def type_constrs(tree):\n",
    "    t = smt.FreshConst(Type) # prefgix\n",
    "    tree.sort = t\n",
    "\n",
    "castable = smt.Function(\"castable\", Type, Type, smt.BoolSort())\n",
    "smt.TransitiveClousre(castable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a992fe76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed030c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# but castable table can also contain named/opaque Set -> Set functions\n",
    "castable = {\n",
    "    (int, smt.IntSort()),\n",
    "    (int, smt.RealSort()),\n",
    "    (float, smt.RealSort()),\n",
    "    \n",
    "}\n",
    "\n",
    "# simple non dependent subclasses like \n",
    "def DefineSubClass(name, args, body):\n",
    "    S = kd.define_const(name, smt.Lambda(args, body))\n",
    "    castable[(S, body.sort())] = kd.Id(body.sort())\n",
    "\n",
    "def DeclareSubSort(S,T):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "orig_cast = SortRef.cast\n",
    "cast_table = {}\n",
    "def cast(T, x):\n",
    "    if isinstance(x, smt.ExprRef):\n",
    "        S = x.sort()\n",
    "        if T == x.sort():\n",
    "            return x\n",
    "        f = cast_table.get((T,S))\n",
    "        if f is not None:\n",
    "            return f(x)\n",
    "    return orig_cast(T, x)\n",
    "\n",
    "def add_cast(T : smt.SortRef, S : smt.SortRef, f):\n",
    "    if (T,S) in cast:\n",
    "        raise Exception(\"Already castable\", T,S)\n",
    "    else:\n",
    "        # Transitively close the table.\n",
    "        dcast = {(T,S,f)}\n",
    "        while True:\n",
    "            new = set()\n",
    "            for T,S,f in dcast:\n",
    "                for S1,U,g in cast_table:\n",
    "                    if S == S1 and (T,U) not in cast_table:\n",
    "                        h = lambda x: g(f(x))\n",
    "                        cast_table[(T,U)] = h\n",
    "                        new.add((T,U,h))\n",
    "            if new:\n",
    "                dcast = new\n",
    "            else:\n",
    "                return\n",
    "\n",
    "class TransDict():\n",
    "    # a transitively closed dicionary\n",
    "    def __init__(self):\n",
    "        self.data = {}\n",
    "    def __setitem__(self):\n",
    "    def __getitem__(self):\n",
    "    def get(self, key)\n",
    "    def get_upper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd96b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtype = {}\n",
    "def is_subtype(T, S):\n",
    "    # lookup in subtype table\n",
    "\n",
    "def add_subtype(T, S, **kwargs):\n",
    "    dom = T.domain()\n",
    "    assert S.domain() == dom\n",
    "    # cast T to S?\n",
    "    x = smt.FreshConst(dom)\n",
    "    pf = kd.prove(smt.ForAll([x], T[x], S[x]), **kwargs)\n",
    "    subtype[(T,S)] = pf\n",
    "    # transtively close subtypes?\n",
    "\n",
    "# heterogenous vs homogenous subtyping. Hmm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45938419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['lambda', ['x'], 'x']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kdrag.parsers.sexp as sexp\n",
    "sexp.parse(\"(lambda (x) x)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717616c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tree(Token('RULE', 'start'), [Tree('fun_', [Tree(Token('RULE', 'binders'), [Tree('infer_binder', [Token('NAME', 'x')])]), Tree('app', [Tree(Token('RULE', 'const'), [Token('NAME', 'x')])])])])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kdrag.parsers.microlean as lean\n",
    "lean.parser.parse(\"fun x => x\")\n",
    "\n",
    "\n",
    "def check_type(tree, sort):\n",
    "\n",
    "\n",
    "def infer_type(tree):\n",
    "\n",
    "\n",
    "def type_constrs(tree):\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102c06e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d731a9b",
   "metadata": {},
   "source": [
    "# subtype\n",
    "\n",
    "https://dl.acm.org/doi/pdf/10.1145/3736112.3736141 Structuring Arrays with Algebraic Shapes\n",
    "\n",
    "\n",
    "https://arxiv.org/html/2508.00482v1 semantic subtyping for maps in erlang\n",
    "https://www.irif.fr/~gc/papers/icalp-ppdp05.pdf A Gentle Introduction to Semantic Subtyping castagna\n",
    "\n",
    "\n",
    "Pottier's thesis is a nexus point.\n",
    "\n",
    "\n",
    "https://arxiv.org/abs/1905.06546 first class subtypes. yallop and dolan\n",
    "\n",
    "\n",
    "Biuniification\n",
    "\n",
    "I should implement a hinldey milner. On some level I think of it as what happens naturally as you use prolog to perform type checking.\n",
    "But it also has a flavor of CLP where there is a side carried constraint store.\n",
    "\n",
    "It's interesting that the two subjects are \n",
    "\n",
    "Try elpi.\n",
    "\n",
    "\n",
    "pottier. constraint graph\n",
    "simple essence\n",
    "\n",
    "\n",
    "Parse python and hindley milner it?\n",
    "\n",
    "Use relationship to second order logic?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "https://en.wikipedia.org/wiki/Bounded_quantification#F-bounded_quantification\n",
    "\n",
    "https://en.wikipedia.org/wiki/Hindley%E2%80%93Milner_type_system\n",
    "\n",
    "https://www.youtube.com/watch?v=NkAt9eApGSw\n",
    "\n",
    "https://counterexamples.org/title.html\n",
    "\n",
    "https://okmij.org/ftp/ML/generalization.html\n",
    "regions.\n",
    "What about using a vector based union find?\n",
    "\n",
    "\n",
    "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tldi10-vytiniotis.pdf Let should not be generalized\n",
    "\n",
    "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=dbe447bae9782dac976de8ef028f3324c53d6414 type inference and equational theoires\n",
    "\n",
    "\n",
    "https://bernsteinbear.com/blog/type-inference/\n",
    "\n",
    "\n",
    "Type checking as a programming language.\n",
    "hm()\n",
    "Typeclass prolog is known to be a way to program at the typelevel.\n",
    "\n",
    "Undecidable typechecking becomes reasonable.\n",
    "\n",
    "\n",
    "```\n",
    "type schema = var list * \n",
    "```\n",
    "\n",
    "\n",
    "https://okmij.org/ftp/Haskell/AlgorithmsH.html#teval interpreting types as abstract values\n",
    "\n",
    "https://byorgey.wordpress.com/2021/09/08/implementing-hindley-milner-with-the-unification-fd-library/\n",
    "\n",
    "Didier Remy and Pottier in ATAPL https://pauillac.inria.fr/~fpottier/publis/emlti-final.pdf essence of hinldye milder\n",
    "\n",
    "\n",
    "Can I just yolo making an inequality union\n",
    "\n",
    "For lattices `a <= b` is the same thing as `a = join(a,b)`. Lattices are an equational theory.\n",
    "It is an extensible theory too. Are finitely presented lattices solvable? https://www.jstor.org/stable/2042634 Yes. Hmm. In marche there was ACI. Is that a lattice theory?\n",
    "This is kind of just another view on mainting the sets of things you're less than and greater to. The obvious thing.\n",
    "Basically transiitive cloure.\n",
    "\n",
    "monotonicity means f(a cup b) = f(a) cup f(b)\n",
    "The analog of group invariant.\n",
    "\n",
    "\n",
    "What about extensible groups? No, that is the word problem.\n",
    "\n",
    "What about free kleene algebra? Ought to be ok.\n",
    "Hmm. What about adding KAT to egraph as a theory.\n",
    "\n",
    "\n",
    "Even bottom up has a search character if subvariant. Hmm. You can jump to any of your upper or lower bounds depending if you're \n",
    "contra covariant.\n",
    "The applier only knows this and should decide to expand upward or not.\n",
    "\n",
    "The top level of \n",
    "a  <= b  implicitly says that all lowers of a are below uppers of b. So <= is kind of covariant also in first are and contra in second at top level of rule.\n",
    "\n",
    "\n",
    "\n",
    "Flattening foo(bar(X)) to foo(Y), bar(X,Y). And then having the ability to implcitily mediate by other relations.\n",
    "\n",
    "foo(Y), eq(Y,Y1), bar(X,Y1)\n",
    "\n",
    "foo(Y), le(Y,Y1), bar(X,Y1)\n",
    "\n",
    "\n",
    "subsumption ordering if we have non ground terms in our termbank. Foall vs exists is covariant vs contratvariant.\n",
    "\n",
    "\n",
    "lattice is kind of equational theory that is normalizable.\n",
    "\n",
    "in EMT, non normalizability iasn't that bad. You just miss stuiff.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98259bc",
   "metadata": {},
   "source": [
    "## Inequality Union Find\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e39e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LEFindRebuild(parents={}, upper=defaultdict(<class 'set'>, {1: {2}, 2: {3}}))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786e9f62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf4d31ef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06182e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LEFind(parents={3: 1, 1: 2}, upper=defaultdict(<class 'set'>, {2: {1, 3}, 1: {2, 3}, 3: set()}))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a581a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LEFind(parents={3: 1, 1: 2}, upper=defaultdict(<class 'set'>, {2: {3}, 1: {2}, 3: {1}}))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class LEFind():\n",
    "    parents : dict\n",
    "    upper : defaultdict(set)\n",
    "    #lower : defaultdict(set)\n",
    "    def __init__(self):\n",
    "        self.parents = {}\n",
    "        self.upper = defaultdict(set)\n",
    "        #self.lower = defaultdict(set)\n",
    "    def assert_le(self, x, y):\n",
    "        x,y = self.find(x), self.find(y)\n",
    "        if x == y:\n",
    "            return\n",
    "        elif self.is_le(y, x):\n",
    "            self.parents[x] = y\n",
    "            #self.union(x, y)\n",
    "        elif not self.is_le(x, y): # avoid redundant additions.\n",
    "            #self.lower[y].add(x)\n",
    "            self.upper[x].add(y)\n",
    "    def union(self, x, y):\n",
    "        x, y = self.find(x), self.find(y)\n",
    "        if x != y:\n",
    "            # self.assert_le(x,y); self.assert_le(y,x)  # make union subservient to assert_le?\n",
    "            self.upper[y].add(x)\n",
    "            #self.assert_le(y, x)\n",
    "            for z in self.le_set(x): # union find dict action. We merge their upper sets.\n",
    "                self.assert_le(y, z)\n",
    "            for z in self.le_set(y): # union find dict action. We merge their upper sets.\n",
    "                self.assert_le(x, z)\n",
    "            #self.parents[x] = y\n",
    "                #self.upper[y].add(z)\n",
    "    def find(self, x):\n",
    "        while x in self.parents:\n",
    "            x = self.parents[x]\n",
    "        return x\n",
    "    def is_le(self, x, y):\n",
    "        x, y = self.find(x), self.find(y)\n",
    "        todo = [x]\n",
    "        seen = set([x])\n",
    "        while todo:\n",
    "            x = todo.pop()\n",
    "            for x in self.upper[x]:\n",
    "                x = self.find(x)\n",
    "                if x == y:\n",
    "                    return True\n",
    "                elif x in seen:\n",
    "                    continue\n",
    "                else:\n",
    "                    seen.add(x)\n",
    "                    todo.append(x)\n",
    "        #self.upper[x] = seen\n",
    "        return False\n",
    "\n",
    "    def le_set(self, x): # \"le_find\" splits into two functions since it isn't as cheap anymore.\n",
    "        x = self.find(x)\n",
    "        todo = [x]\n",
    "        seen = set([x]) # or could even set seen = self.upper[x]\n",
    "        while todo:\n",
    "            x = todo.pop()\n",
    "            for x in self.upper[x]:\n",
    "                x = self.find(x) # \"path compression\" would modify in place and \n",
    "                if x in seen:\n",
    "                    continue\n",
    "                else:\n",
    "                    seen.add(x)\n",
    "                    todo.append(x)\n",
    "        #self.upper[x] = seen\n",
    "        return seen\n",
    "    #def rebuild(self):\n",
    "    #    for s in self.upper.items():\n",
    "    #        s = {self.find(x) for x in s}\n",
    "\n",
    "le = LEFind()\n",
    "le.assert_le(1, 2)\n",
    "le.assert_le(2, 3)\n",
    "assert le.le_set(1) == {1, 2, 3}\n",
    "assert le.le_set(2) == {2, 3}\n",
    "assert le.le_set(3) == {3}\n",
    "assert le.is_le(1,3)\n",
    "assert not le.is_le(3,1)\n",
    "le.union(1,3)\n",
    "le\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5032a26e",
   "metadata": {},
   "source": [
    "Type checking hindley milner the python ast. But how do I represent anything?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bcabf31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], Arr(c!4, Arr(c!5, c!4)))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "from kdrag.all import *\n",
    "Type = smt.DeclareSort(\"Type\")\n",
    "Arr = smt.Function(\"Arr\", Type, Type, Type)\n",
    "Bool = smt.Const(\"Bool\", Type)\n",
    "Int = smt.Const(\"Int\", Type)\n",
    "\n",
    "def infer(env, t : ast.AST) -> tuple[list[smt.BoolRef], smt.ExprRef]:\n",
    "    match t:\n",
    "        case ast.Lambda(ast.arguments(args=[x]), body):\n",
    "            A = smt.FreshConst(Type)\n",
    "            env1 = {x.arg : A, **env}\n",
    "            constrs, B = infer(env1, body)\n",
    "            return constrs, Arr(A,B)\n",
    "        case ast.Call(func, [x]):\n",
    "            c1, AB = ftyinfer(env, func)\n",
    "            c2, A = infer(env, x)\n",
    "            assert AB.decl() == Arr\n",
    "            return c1 + c2 + [AB.arg(0) == A], AB.arg(1)\n",
    "            \"\"\"for t, x in zip(fty, args):\n",
    "                c, t1 = infer(env, x)\n",
    "                constrs.append((t, t1))\n",
    "                constrs.extend(c)\n",
    "            return constrs, fty.res\n",
    "            \"\"\"\n",
    "        case ast.Name(id=v):\n",
    "            return [], env[v]\n",
    "        case _:\n",
    "            raise NotImplementedError(f\"Unsupported AST node: {ast.dump(t)}\")\n",
    "\n",
    "def infer1(t : str):\n",
    "    return infer({}, ast.parse(t, mode=\"eval\").body)\n",
    "\n",
    "infer1(\"lambda x: x\")\n",
    "infer1(\"lambda x: lambda y: x\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90321261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Module(body=[Expr(value=Lambda(args=arguments(posonlyargs=[], args=[arg(arg='x')], kwonlyargs=[], kw_defaults=[], defaults=[]), body=BinOp(left=Name(id='x', ctx=Load()), op=Add(), right=Constant(value=1))))], type_ignores=[])\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "ast.dump(ast.parse(\"lambda x: x + 1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8c6bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/test.ml\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/test.ml\n",
    "#use \"topfind\";;\n",
    "#require \"core.kernel\";;\n",
    "print_endline \"Hello, World!\";;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f13cd059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such package: core.kernel\n",
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "! ocaml /tmp/test.ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0c19593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/test\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/test\n",
    "#!/usr/bin/env cabal\n",
    "{- cabal:\n",
    "build-depends:\n",
    "  base >=4.19.0.0,\n",
    "  haskell-say ^>=1.0.0.0\n",
    "-}\n",
    "\n",
    "import HaskellSay (haskellSay)\n",
    "\n",
    "main :: IO ()\n",
    "main = haskellSay \"Hello, Haskell!\"\n",
    "\n",
    "\n",
    "-- https://cabal.readthedocs.io/en/stable/getting-started.html#running-a-single-file-haskell-script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e35c3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ________________________________________________________\n",
      " /                                                        \\\n",
      "| Hello, Haskell!                                          |\n",
      " \\____       _____________________________________________/\n",
      "      \\    /\n",
      "       \\  /\n",
      "        \\/\n",
      "  _____   _____\n",
      "  \\    \\  \\    \\\n",
      "   \\    \\  \\    \\\n",
      "    \\    \\  \\    \\\n",
      "     \\    \\  \\    \\  \\-----------|\n",
      "      \\    \\  \\    \\  \\          |\n",
      "       \\    \\  \\    \\  \\---------|\n",
      "       /    /  /     \\\n",
      "      /    /  /       \\  \\-------|\n",
      "     /    /  /    ^    \\  \\      |\n",
      "    /    /  /    / \\    \\  \\ ----|\n",
      "   /    /  /    /   \\    \\\n",
      "  /____/  /____/     \\____\\\n"
     ]
    }
   ],
   "source": [
    "! cabal run /tmp/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478dbbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not a good combinator, but writing all this junk is quite labrosome.\n",
    "def declare_theory(ts):\n",
    "    ms = []\n",
    "    for t in ts:\n",
    "        name = t[0]\n",
    "        typs = t[1:]\n",
    "        ms.append(smt.Function(name, *typs))\n",
    "    return ms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fc6d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.all import *\n",
    "Term = DeclareSort(\"Term\")\n",
    "Var = DeclareSort(\"Var\")\n",
    "\n",
    "lam = smt.Function(\"lam\", smt.ArraySort(Var, Term), Term)\n",
    "var = smt.Function(\"var\", Var, Term)\n",
    "app = smt.Function(\"app\", Term, Term, Term)\n",
    "\n",
    "tt = smt.Const(\"tt\", Term)\n",
    "\n",
    "ForAll([x,t], app(lam(x, var(x), t)) == t)\n",
    "\n",
    "Type = DeclareSort(\"Type\")\n",
    "Bool = smt.Const(\"Bool\", Type)\n",
    "Arr = smt.Function(\"Arr\", Type, Type, Type)\n",
    "Unit = smt.Const(\"Unit\", Type)\n",
    "\n",
    "TEnv = smt.ArraySort(Var, Type)\n",
    "G = smt.Const(\"G\", TEnv)\n",
    "hastype = smt.Function(\"hastype\", TEnv, Term, Type, smt.BoolSort()) # Gamma |- t : A\n",
    "tt_unit = kd.axiom(smt.ForAll([G], hastype(G, tt,Unit)))\n",
    "kd.QForAll([G,t,A,B, v], hastype(Store(G,v,A), l(v), B),   \n",
    "                hastype(G, lam(l), Arr(A,B))\n",
    ")\n",
    "kd.QForAll([G, f, t,A,B],\n",
    "    hastype(G, f, Arr(A,B)), hastype(G, t, A),\n",
    "    hastype(G, app(f, t), B)\n",
    ")\n",
    "\n",
    "injBool = smt.Function(\"injBool\", smt.BoolSort(), Term)\n",
    "hastype(G, t, Bool), castBool(injBool(t)) == t # castbool is a partial function.\n",
    "\n",
    "#smt.ForAll(tvs, hastype())\n",
    "\n",
    "# HM as a proof producing procedure.\n",
    "def hm(vs, tenv, t : smt.ExprRef):\n",
    "    decl = t.decl()\n",
    "    if t.eq(tt):\n",
    "        return Unit, [], tt_unit(tenv)\n",
    "    elif decl == lam:\n",
    "        (v,),body = open_binder(lam.arg(0))\n",
    "        a = smt.FreshConst(Type)\n",
    "        vs.append(v)\n",
    "        tenv1 = hm({vs, **tenv, v: a}, body)\n",
    "    elif decl == var:\n",
    "        return tenv[t.arg(0)] \n",
    "    elif decl == app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9e3a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 2), (1, 3), (2, 3)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge = {(1,2), (2,3)}\n",
    "path = set()\n",
    "for i in range(10):\n",
    "    # path(x,y) :- edge(x,y).\n",
    "    path |= edge\n",
    "    # path(x,z) :- edge(x,y), path(y,z).\n",
    "    path |= {(x,z) for x,y in edge for (y1,z) in path if y == y1}\n",
    "print(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02adf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n",
      "arr(_4308,_4308)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'truth': False}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from janus_swi import *\n",
    "query_once(\"writeln('Hello world!')\")\n",
    "\n",
    "\n",
    "janus.consult(\"hm\", \"\"\n",
    "\"\"\"\n",
    "%:- library(assoc).\n",
    "%typeof(Env, lam(X, T), arr(A, B)) :- put_assoc(X, Env, A, Env1), typeof(Env1, T, B).\n",
    "typeof(Env, lam(X, T), arr(A, B)) :- typeof([X-A | Env], T, B).\n",
    "typeof(Env, var(X), Ty) :- member(X-Ty, Env).\n",
    "typeof(_, true, bool).\n",
    "typeof(_, false, bool).\n",
    "\"\"\")\n",
    "\n",
    "assert query_once(\"typeof(_, true, bool)\")[\"truth\"]\n",
    "assert query_once(\"typeof(_, false, bool)\")[\"truth\"]\n",
    "query_once(\"typeof(_, lam(x, var(x)), _T), writeln(_T)\")\n",
    "query_once(\"typeof(_, lam(x, var(y)), _T), writeln(_T)\") # hmm succeeds in unspecified context That's interesting.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "philzook58.github.io",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
