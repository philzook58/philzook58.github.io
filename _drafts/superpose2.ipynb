{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Techniques\n",
    "\n",
    "https://leanprover.zulipchat.com/#narrow/channel/458659-Equational/topic/A.20magma.20of.20order.20.3C.2013.20-.20for.20Equation2531.3F/near/475021693 \n",
    "\" think others will document much better strategies. My method is very much like mining: the computer digs through large quantities of rock, and I try to direct it to veins that might have precious material.\n",
    "\n",
    "When I want to disprove the implication X -> Y, I usually use Prover9 and Mace4 in tandem. I set a small search space, typically up to 6x6 optables. Mace4 can quickly cover 2x2, 3x3, but starts slowing down as it reaches 5x5 or 6x6 (depending on the equations X and Y, this could happen earlier or later).\n",
    "\n",
    "Next, I introduce additional conditions that might be relevant, such as requiring the structure to have some good endomorphism (perhaps relevant to the equation), or that the magma operation preserves some added structure (e.g., a digraph, partial order, or another algebraic operation). Cancellativity itself started out as one of these, but it worked often enough that I decided to do an exhaustive search, which eventually led to the 5x5 enumeration.\n",
    "\n",
    "As I add assumptions, I monitor two things:\n",
    "\n",
    "Can Prover9 prove the implication X -> Y given my additional assumptions? If yes, there can't be a counterexample like this, so I move on to a weaker assumption.\n",
    "How quickly does Mace4 exhaust the search space for different sizes (it helpfully reports when it moves on from 3x3 to 4x4 etc.).\n",
    "The goal is to set up a scenario where:\n",
    "\n",
    "Prover9 cannot find a proof of X -> Y after some reasonable time (checking the proof trace helps see if it's even trying anything useful);\n",
    "But Mace4 quickly handles the small search spaces.\n",
    "When both conditions hold, I crank the table size N up to a large value, and usually, a counterexample appears shortly after. This is how I got the 13x13 example: when I tried commutativity, Mace4 started churning through the small tables really fast, but Prover9 was not finding a proof. I increased N, and the 13x13 table appeared within a second (which is unusually fast)\"\n",
    "\n",
    "\n",
    "https://arxiv.org/abs/1808.04251 Michael Kinyon https://mathstodon.xyz/@ProfKinyon/114530006893268867 The hints / wtachnlisti n eprover.  It puts priority on anything that subsumes something in previous proof. There is a difference between this and egraph sketches in that the egraph sketch is the more general thing, but here the derived clauses are more general.\n",
    "Hmm. So maybe get ground proof. Throw into eprover / prover9 with sketches, that'll find interesting lemmas?\n",
    "Randomization tweaking parameters all over the place. some kind of stochastic or other search.\n",
    "\n",
    "\n",
    "\n",
    "https://matryoshka-project.github.io/pubs/vukmirovic_msc_thesis.pdf Implementation of Lambda-Free Higher-Order Superposition\n",
    "\n",
    "https://www.cs.unm.edu/~mccune/mace4/mace4.pdf mace4 manual. Model enumeration\n",
    "\n",
    "\n",
    "Even the knuth bendix implementation can probably do constrained knuth bendix. If rules carry constraints, I could just collect them. Overlap narrowins that are unsat don't have to be considered.\n",
    "The constrained part of the rewriting is perhaps a pain.\n",
    "\n",
    "https://www.philipzucker.com/superpose_datalog/\n",
    "How do we get more imperative control?\n",
    "\n",
    "Functional programs\n",
    "Call graph\n",
    "Prolog\n",
    "Datalog\n",
    "\n",
    "binary integers a la minikaren?\n",
    "https://arxiv.org/pdf/cs/0604054 New results on rewrite-based satisfiability\n",
    "procedures\n",
    "\n",
    "\n",
    "Clause priority.\n",
    "Using Lambda.\n",
    "Progress and preservation via inductionless induction?\n",
    "Deep embedding of other logics. Logikey.\n",
    "\"People\" love using \n",
    "\n",
    "typing\n",
    "gats\n",
    "negation\n",
    "\n",
    "\n",
    "equality sautration\n",
    "E as a simplification engine\n",
    "\n",
    "Transpilation from egglog syntax to tptp\n",
    "\n",
    "\n",
    "Boolean algerba sheffer stroke robbins problem cody\n",
    "\n",
    "\n",
    "Chaining resolution for refinement\n",
    "Ganzinger slides on chaining\n",
    "birewriting levy and agusty\n",
    "\n",
    "Non ground 2-SAT is more like completion? At least there are 2 things.\n",
    "\n",
    "E as E-unifier\n",
    "\n",
    "\n",
    "Antidifferentiation\n",
    "\n",
    "vampire for QBF\n",
    "\n",
    "Quasiquotation and staging.\n",
    "qfoo(a,b)\n",
    "\n",
    "eval(qfoo(A,B)) = foo(eval(A), eval(B))\n",
    "\n",
    "If I wanted to estyablish ski combinators terminate on a particulat example, that would have search because locus of control is no specified.\n",
    "\n",
    "\n",
    "Hmm. I commented that SAT solvers \"discover\" a good order in the form of their trail?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GATs\n",
    "One of my appraoches was to use minikarne for typechecking or inserting the appropraite well typedness conditions ahead of time.\n",
    "\n",
    "I suspect that eprover /ordered resolution can simulate prolog / datalog given a term ordering that reflects strata or call graph conditions.\n",
    "\n",
    "https://www.philipzucker.com/superpose_datalog/\n",
    "\n",
    "GATs as a congruence proof system\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "Gamma |- q : A\n",
    "--------------\n",
    "Gamma, q : A |- ?\n",
    "\n",
    "rewriting in context?\n",
    "\n",
    "\n",
    "Gamma |- p = q : B\n",
    "---------------------\n",
    "Gamma |- t[p/q] : A[p/q]\n",
    "\n",
    "Gamma |- s : A   Gamma |- t : A\n",
    "----------------------------\n",
    "Gamma |- t = s : A\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "Models of GATs are families of sets\n",
    "A(_)  {  b :  set() }  \n",
    "T : {  v!0, v!1}\n",
    "\n",
    "\n",
    "bidirectional typing as a prolog/datalog program. Maybe getting the term ordering... They're mutually recursive... Hmm.\n",
    "synth(X) = T -> check(X, T) = true\n",
    "check(X, synth(X)) = true. (? what about if synth can't return?)\n",
    "\n",
    "Moding and resolution and term orders... How to think about that one?\n",
    "Modes and ordered rewriting. Kind of saying we're working in ground mode... Hmm.\n",
    "elf / LF and modes  / termination \n",
    "https://www.cs.cmu.edu/~fp/papers/esop96.pdf\n",
    "\n",
    " :- typeof(t, T)\n",
    "t = t2 :- keq(t, t2, T).\n",
    "keq(t, t2, T) :- typeof(t, T), typeof(t2, T), t = t2.\n",
    "keq(t, t2, T) <=> typeof(t, T), typeof(t2, T), t != t2.\n",
    "\n",
    "goal\n",
    "\n",
    "\n",
    " > typeof\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/counter.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/counter.p\n",
    "\n",
    "cnf(ax1, axiom, counter(s(X), M, N) = counter(X, M, N)).\n",
    "%cnf(ax1, axiom, counter(s(X), M, N) = counter(X, P, Q)). % chaosing P,Q is still terminating... but eprover doesn't\n",
    "cnf(ax2, axiom, counter(X, s(M), N) = counter(X, M, N)).\n",
    "cnf(ax3, axiom, counter(X, M, s(N)) = counter(X, M, N)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/counter.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/counter.p\n",
    "\n",
    "%fof(ax1, axiom, ![X,M,N] : (counter(s(X), M, N) <=> counter(X, M, N))).\n",
    "fof(ax1, axiom, ![X,M,N,P,Q] : (counter(s(X), M, N) <=> counter(X, P, Q))).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/counter.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/counter.p\n",
    "\n",
    "cnf(ax1, axiom,   counter(X, s(s(M))) = counter(s(X), M))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnf(ax1, axiom, (counter(X1,s(s(X2)))=counter(s(X1),X2)), file('/tmp/counter.p', ax1)).\n",
      "{\n",
      "   {\n",
      "      ordertype:               KBO6\n",
      "      to_weight_gen:           none\n",
      "      to_prec_gen:             none\n",
      "      rewrite_strong_rhs_inst: false\n",
      "      to_pre_prec:             \"\"\n",
      "      conj_only_mod:           0\n",
      "      conj_axiom_mod:          0\n",
      "      axiom_only_mod:          0\n",
      "      skolem_mod:              0\n",
      "      defpred_mod:             0\n",
      "      force_kbo_var_weight:    false\n",
      "      to_pre_weights:          \"\"\n",
      "      to_const_weight:         0\n",
      "      to_defs_min:             false\n",
      "      lit_cmp:                 1\n",
      "      lam_w:                   20\n",
      "      db_w:                    10\n",
      "      ho_order_kind:           lfho\n",
      "   }\n",
      "   no_preproc:                     false\n",
      "   eqdef_maxclauses:               20000\n",
      "   eqdef_incrlimit:                20\n",
      "   formula_def_limit:              24\n",
      "   sine:                           \"None\"\n",
      "   add_goal_defs_pos:             false\n",
      "   add_goal_defs_neg:             false\n",
      "   add_goal_defs_subterms:        false\n",
      "   heuristic_name:                Default\n",
      "   heuristic_def:                 \"\"\n",
      "   prefer_initial_clauses:         false\n",
      "   selection_strategy:             NoSelection\n",
      "   pos_lit_sel_min:                0\n",
      "   pos_lit_sel_max:                9223372036854775807\n",
      "   neg_lit_sel_min:                0\n",
      "   neg_lit_sel_max:                9223372036854775807\n",
      "   all_lit_sel_min:                0\n",
      "   all_lit_sel_max:                9223372036854775807\n",
      "   weight_sel_min:                 0\n",
      "   select_on_proc_only:            false\n",
      "   inherit_paramod_lit:            false\n",
      "   inherit_goal_pm_lit:            false\n",
      "   inherit_conj_pm_lit:            false\n",
      "   enable_eq_factoring:            true\n",
      "   enable_neg_unit_paramod:        true\n",
      "   enable_given_forward_simpl:     true\n",
      "   pm_type:                        ParamodPlain\n",
      "   ac_handling:                    1\n",
      "   ac_res_aggressive:              true\n",
      "   forward_context_sr:             false\n",
      "   forward_context_sr_aggressive:  false\n",
      "   backward_context_sr:            false\n",
      "   forward_subsumption_aggressive: false\n",
      "   forward_demod:                  2\n",
      "   prefer_general:                 false\n",
      "   condensing:                     false\n",
      "   condensing_aggressive:          false\n",
      "   er_varlit_destructive:          false\n",
      "   er_strong_destructive:          false\n",
      "   er_aggressive:                  false\n",
      "   split_clauses:                  0\n",
      "   split_method:                   0\n",
      "   split_aggressive:               false\n",
      "   split_fresh_defs:               true\n",
      "   diseq_decomposition             0\n",
      "   diseq_decomp_maxarity           9223372036854775807\n",
      "   rw_bw_index_type:               FP7\n",
      "   pm_from_index_type:             FP7\n",
      "   pm_into_index_type:             FP7\n",
      "   sat_check_grounding:            NoGrounding\n",
      "   sat_check_step_limit:           9223372036854775807\n",
      "   sat_check_size_limit:           9223372036854775807\n",
      "   sat_check_ttinsert_limit:       9223372036854775807\n",
      "   sat_check_normconst:            false\n",
      "   sat_check_normalize:            false\n",
      "   sat_check_decision_limit:       10000\n",
      "   filter_orphans_limit:           9223372036854775807\n",
      "   forward_contract_limit:         9223372036854775807\n",
      "   delete_bad_limit:               9223372036854775807\n",
      "   mem_limit:                      0\n",
      "   watchlist_simplify:             true\n",
      "   watchlist_is_static:            false\n",
      "   use_tptp_sos:                   false\n",
      "   presat_interreduction:          false\n",
      "   detsort_bw_rw:                  false\n",
      "   detsort_tmpset:                 false\n",
      "   arg_cong:                       all\n",
      "   neg_ext:                        off\n",
      "   pos_ext:                        off\n",
      "   ext_rules_max_depth:            -1\n",
      "   inverse_recognition:            false\n",
      "   replace_inj_defs:               false\n",
      "   lift_lambdas:                  true\n",
      "   lambda_to_forall:              true\n",
      "   unroll_only_formulas:          true\n",
      "   elim_leibniz_max_depth:        -1\n",
      "   prim_enum_mode:                pragmatic\n",
      "   prim_enum_max_depth:           -1\n",
      "   inst_choice_max_depth:         -1\n",
      "   local_rw:                      false\n",
      "   prune_args:                    false\n",
      "   preinstantiate_induction:      false\n",
      "   fool_unroll:                   true\n",
      "   func_proj_limit:               0\n",
      "   imit_limit:                    0\n",
      "   ident_limit:                   0\n",
      "   elim_limit:                    0\n",
      "   unif_mode:                     single\n",
      "   pattern_oracle:                true\n",
      "   fixpoint_oracle:               true\n",
      "   max_unifiers:                  4\n",
      "   max_unif_steps:                256\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho /tmp/counter.p --output-level=6 --print-strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   {\n",
      "      ordertype:               LPO4\n",
      "      to_weight_gen:           none\n",
      "      to_prec_gen:             none\n",
      "      rewrite_strong_rhs_inst: false\n",
      "      to_pre_prec:             \"counter>s\"\n",
      "      conj_only_mod:           0\n",
      "      conj_axiom_mod:          0\n",
      "      axiom_only_mod:          0\n",
      "      skolem_mod:              0\n",
      "      defpred_mod:             0\n",
      "      force_kbo_var_weight:    false\n",
      "      to_pre_weights:          \"\"\n",
      "      to_const_weight:         0\n",
      "      to_defs_min:             false\n",
      "      lit_cmp:                 1\n",
      "      lam_w:                   20\n",
      "      db_w:                    10\n",
      "      ho_order_kind:           lfho\n",
      "   }\n",
      "   no_preproc:                     false\n",
      "   eqdef_maxclauses:               20000\n",
      "   eqdef_incrlimit:                20\n",
      "   formula_def_limit:              24\n",
      "   sine:                           \"None\"\n",
      "   add_goal_defs_pos:             false\n",
      "   add_goal_defs_neg:             false\n",
      "   add_goal_defs_subterms:        false\n",
      "   heuristic_name:                Default\n",
      "   heuristic_def:                 \"\"\n",
      "   prefer_initial_clauses:         false\n",
      "   selection_strategy:             NoSelection\n",
      "   pos_lit_sel_min:                0\n",
      "   pos_lit_sel_max:                9223372036854775807\n",
      "   neg_lit_sel_min:                0\n",
      "   neg_lit_sel_max:                9223372036854775807\n",
      "   all_lit_sel_min:                0\n",
      "   all_lit_sel_max:                9223372036854775807\n",
      "   weight_sel_min:                 0\n",
      "   select_on_proc_only:            false\n",
      "   inherit_paramod_lit:            false\n",
      "   inherit_goal_pm_lit:            false\n",
      "   inherit_conj_pm_lit:            false\n",
      "   enable_eq_factoring:            true\n",
      "   enable_neg_unit_paramod:        true\n",
      "   enable_given_forward_simpl:     true\n",
      "   pm_type:                        ParamodPlain\n",
      "   ac_handling:                    1\n",
      "   ac_res_aggressive:              true\n",
      "   forward_context_sr:             false\n",
      "   forward_context_sr_aggressive:  false\n",
      "   backward_context_sr:            false\n",
      "   forward_subsumption_aggressive: false\n",
      "   forward_demod:                  2\n",
      "   prefer_general:                 false\n",
      "   condensing:                     false\n",
      "   condensing_aggressive:          false\n",
      "   er_varlit_destructive:          false\n",
      "   er_strong_destructive:          false\n",
      "   er_aggressive:                  false\n",
      "   split_clauses:                  0\n",
      "   split_method:                   0\n",
      "   split_aggressive:               false\n",
      "   split_fresh_defs:               true\n",
      "   diseq_decomposition             0\n",
      "   diseq_decomp_maxarity           9223372036854775807\n",
      "   rw_bw_index_type:               FP7\n",
      "   pm_from_index_type:             FP7\n",
      "   pm_into_index_type:             FP7\n",
      "   sat_check_grounding:            NoGrounding\n",
      "   sat_check_step_limit:           9223372036854775807\n",
      "   sat_check_size_limit:           9223372036854775807\n",
      "   sat_check_ttinsert_limit:       9223372036854775807\n",
      "   sat_check_normconst:            false\n",
      "   sat_check_normalize:            false\n",
      "   sat_check_decision_limit:       10000\n",
      "   filter_orphans_limit:           9223372036854775807\n",
      "   forward_contract_limit:         9223372036854775807\n",
      "   delete_bad_limit:               9223372036854775807\n",
      "   mem_limit:                      0\n",
      "   watchlist_simplify:             true\n",
      "   watchlist_is_static:            false\n",
      "   use_tptp_sos:                   false\n",
      "   presat_interreduction:          false\n",
      "   detsort_bw_rw:                  false\n",
      "   detsort_tmpset:                 false\n",
      "   arg_cong:                       all\n",
      "   neg_ext:                        off\n",
      "   pos_ext:                        off\n",
      "   ext_rules_max_depth:            -1\n",
      "   inverse_recognition:            false\n",
      "   replace_inj_defs:               false\n",
      "   lift_lambdas:                  true\n",
      "   lambda_to_forall:              true\n",
      "   unroll_only_formulas:          true\n",
      "   elim_leibniz_max_depth:        -1\n",
      "   prim_enum_mode:                pragmatic\n",
      "   prim_enum_max_depth:           -1\n",
      "   inst_choice_max_depth:         -1\n",
      "   local_rw:                      false\n",
      "   prune_args:                    false\n",
      "   preinstantiate_induction:      false\n",
      "   fool_unroll:                   true\n",
      "   func_proj_limit:               0\n",
      "   imit_limit:                    0\n",
      "   ident_limit:                   0\n",
      "   elim_limit:                    0\n",
      "   unif_mode:                     single\n",
      "   pattern_oracle:                true\n",
      "   fixpoint_oracle:               true\n",
      "   max_unifiers:                  4\n",
      "   max_unif_steps:                256\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho /tmp/counter.p --term-ordering=LPO4 --precedence=\"counter>s\" /tmp/counter.p  --print-strategy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order.GR\n",
      "Order.NGE\n",
      "Order.NGE\n",
      "Order.NGE\n",
      "Order.NGE\n",
      "Order.GR\n"
     ]
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "T = smt.DeclareSort(\"T\")\n",
    "s = smt.Function(\"s\", T,T)\n",
    "counter = smt.Function(\"counter\", T,T,T,T)\n",
    "x,y,z,m,n = smt.Consts(\"x y z m n\", T)\n",
    "\n",
    "print(rw.lpo([x,m,n,y,z], counter(s(x),m,n), counter(x,m,n)))\n",
    "print(rw.lpo([x,m,n,y,z], counter(s(x),m,n), counter(x,s(y),s(z))))\n",
    "print(rw.lpo([x,m,n,y,z], counter(s(x),m,z), counter(x, s(s(m)), z)))\n",
    "print(rw.lpo([x,m,n,y,z], counter(x, s(s(m)), z), counter(s(x),m,z)))\n",
    "print(rw.kbo([x,m,n,y,z], counter(s(x),m,z), counter(x, s(s(m)), z)))\n",
    "print(rw.kbo([x,m,n,y,z], counter(x, s(s(m)), z), counter(s(x),m,z)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolution\n",
    "\n",
    "\n",
    "Do we advance?\n",
    "https://www.philipzucker.com/superpose_datalog/\n",
    "https://www.philipzucker.com/resolution1/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knuth bendix style\n",
    "def overlap(a : Rule, b : Rule):\n",
    "    # overlap of two rules\n",
    "\n",
    "def orient(c : Clause):\n",
    "    # find largest atom\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clause(vs=(A!108, B!109, C!110), pos=[path(A!108, C!110)], neg=[edge(A!108, B!109), path(B!109, C!110)]), Clause(vs=(A!111, B!112), pos=[path(A!111, B!112)], neg=[edge(A!111, B!112)]), Clause(vs=(), pos=(edge(a, b),), neg=()), Clause(vs=(), pos=(edge(b, c),), neg=())]\n",
      "c1 Clause(vs=(A!108, B!109, C!110), pos=[path(A!108, C!110)], neg=[edge(A!108, B!109), path(B!109, C!110)])\n",
      "c2 Clause(vs=(A!108, B!109, C!110), pos=[path(A!108, C!110)], neg=[edge(A!108, B!109), path(B!109, C!110)])\n",
      "res [Clause(vs=[B!109, C!110!115, B!109!114, A!108!113], pos=(edge(B!109!114, B!109), path(B!109, C!110!115), edge(A!108!113, B!109!114)), neg=(path(A!108!113, C!110!115),))]\n",
      "c1 Clause(vs=(A!108, B!109, C!110), pos=[path(A!108, C!110)], neg=[edge(A!108, B!109), path(B!109, C!110)])\n",
      "c2 Clause(vs=(A!111, B!112), pos=[path(A!111, B!112)], neg=[edge(A!111, B!112)])\n",
      "res []\n",
      "c1 Clause(vs=(A!108, B!109, C!110), pos=[path(A!108, C!110)], neg=[edge(A!108, B!109), path(B!109, C!110)])\n",
      "c2 Clause(vs=(), pos=(edge(a, b),), neg=())\n",
      "res []\n",
      "c1 Clause(vs=(A!108, B!109, C!110), pos=[path(A!108, C!110)], neg=[edge(A!108, B!109), path(B!109, C!110)])\n",
      "c2 Clause(vs=(), pos=(edge(b, c),), neg=())\n",
      "res []\n",
      "c1 Clause(vs=(A!111, B!112), pos=[path(A!111, B!112)], neg=[edge(A!111, B!112)])\n",
      "c2 Clause(vs=(A!108, B!109, C!110), pos=[path(A!108, C!110)], neg=[edge(A!108, B!109), path(B!109, C!110)])\n",
      "res [Clause(vs=[B!109, C!110, A!108], pos=(edge(B!109, C!110), edge(A!108, B!109)), neg=(path(A!108, C!110),))]\n",
      "c1 Clause(vs=(A!111, B!112), pos=[path(A!111, B!112)], neg=[edge(A!111, B!112)])\n",
      "c2 Clause(vs=(A!111, B!112), pos=[path(A!111, B!112)], neg=[edge(A!111, B!112)])\n",
      "res []\n",
      "c1 Clause(vs=(A!111, B!112), pos=[path(A!111, B!112)], neg=[edge(A!111, B!112)])\n",
      "c2 Clause(vs=(), pos=(edge(a, b),), neg=())\n",
      "res []\n",
      "c1 Clause(vs=(A!111, B!112), pos=[path(A!111, B!112)], neg=[edge(A!111, B!112)])\n",
      "c2 Clause(vs=(), pos=(edge(b, c),), neg=())\n",
      "res []\n",
      "c1 Clause(vs=(), pos=(edge(a, b),), neg=())\n",
      "c2 Clause(vs=(A!108, B!109, C!110), pos=[path(A!108, C!110)], neg=[edge(A!108, B!109), path(B!109, C!110)])\n",
      "res [Clause(vs=[C!110], pos=(path(b, C!110),), neg=(path(a, C!110),))]\n",
      "c1 Clause(vs=(), pos=(edge(a, b),), neg=())\n",
      "c2 Clause(vs=(A!111, B!112), pos=[path(A!111, B!112)], neg=[edge(A!111, B!112)])\n",
      "res [Clause(vs=[], pos=(), neg=(path(a, b),))]\n",
      "c1 Clause(vs=(), pos=(edge(a, b),), neg=())\n",
      "c2 Clause(vs=(), pos=(edge(a, b),), neg=())\n",
      "res []\n",
      "c1 Clause(vs=(), pos=(edge(a, b),), neg=())\n",
      "c2 Clause(vs=(), pos=(edge(b, c),), neg=())\n",
      "res []\n",
      "c1 Clause(vs=(), pos=(edge(b, c),), neg=())\n",
      "c2 Clause(vs=(A!108, B!109, C!110), pos=[path(A!108, C!110)], neg=[edge(A!108, B!109), path(B!109, C!110)])\n",
      "res [Clause(vs=[C!110], pos=(path(c, C!110),), neg=(path(b, C!110),))]\n",
      "c1 Clause(vs=(), pos=(edge(b, c),), neg=())\n",
      "c2 Clause(vs=(A!111, B!112), pos=[path(A!111, B!112)], neg=[edge(A!111, B!112)])\n",
      "res [Clause(vs=[], pos=(), neg=(path(b, c),))]\n",
      "c1 Clause(vs=(), pos=(edge(b, c),), neg=())\n",
      "c2 Clause(vs=(), pos=(edge(a, b),), neg=())\n",
      "res []\n",
      "c1 Clause(vs=(), pos=(edge(b, c),), neg=())\n",
      "c2 Clause(vs=(), pos=(edge(b, c),), neg=())\n",
      "res []\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from kdrag.all import *\n",
    "\n",
    "def clause_of_expr(e : smt.ExprRef):\n",
    "    #e = smt.Tactic(\"nnf\")(e)[0]\n",
    "    #e = e.simplify()\n",
    "    #print(e)\n",
    "    if isinstance(e, smt.QuantifierRef) and e.is_forall():\n",
    "        vs, body = kd.utils.open_binder(e)\n",
    "    else:\n",
    "        vs = []\n",
    "        body = e\n",
    "    cnf = smt.Tactic(\"tseitin-cnf\")(body)[0]\n",
    "    assert len(cnf) == 1\n",
    "    cnf = cnf[0]\n",
    "    if smt.is_or(cnf):\n",
    "        children = cnf.children()\n",
    "        pos = [c for c in children if not smt.is_not(c)]\n",
    "        neg = [c.arg(0) for c in children if smt.is_not(c)]\n",
    "    else:\n",
    "        pos = (cnf,)\n",
    "        neg = ()\n",
    "    return Clause(tuple(vs), pos, neg)\n",
    "\n",
    "@dataclass\n",
    "class Clause():\n",
    "    vs : tuple[smt.ExprRef, ...]\n",
    "    pos : tuple[smt.ExprRef, ...]\n",
    "    neg : tuple[smt.ExprRef, ...]\n",
    "    def freshen(self):\n",
    "        vs = tuple(smt.FreshConst(v.sort(), prefix=v.decl().name()) for v in self.vs)\n",
    "        pos = tuple(smt.substitute(t, *zip(self.vs, vs)) for t in self.pos)\n",
    "        neg = tuple(smt.substitute(t, *zip(self.vs, vs)) for t in self.neg)\n",
    "        return Clause(vs, pos, neg)\n",
    "    def to_expr(self):\n",
    "        return smt.ForAll(vs, smt.Or(*(self.pos + [smt.Not(p) for p in self.neg])))\n",
    "\n",
    "\n",
    "def subst(lit, s):\n",
    "    return smt.substitute(lit, *s.items())\n",
    "\n",
    "def computeResolvents(clause1: Clause, clause2: Clause):\n",
    "    res = []\n",
    "    if any(v2.eq(v1) for v1 in clause1.vs for v2 in clause2.vs):\n",
    "        clause2 = clause2.freshen()\n",
    "    vs = clause1.vs + clause2.vs\n",
    "    for i, lit1 in enumerate(clause1.pos):\n",
    "        for j, lit2 in enumerate(clause2.neg):\n",
    "            s = kd.utils.unify(vs, lit1 , lit2)\n",
    "            if s is None:\n",
    "                continue\n",
    "            newvs = list(set(vs) - set(s.keys()))\n",
    "            new_clause = Clause(newvs, tuple(subst(lit,s) for lit in clause1.neg) + tuple(subst(lit,s) for lit in clause2.neg if not lit.eq(lit2)), tuple(subst(lit,s) for lit in clause1.pos if not lit.eq(lit1)) + tuple(subst(lit,s) for lit in clause2.pos))\n",
    "            res.append(new_clause)\n",
    "    return res\n",
    "\n",
    "a,b,c,d = smt.Ints(\"a b c d\")\n",
    "edge = smt.Function(\"edge\", smt.IntSort(), smt.IntSort(), smt.BoolSort())\n",
    "path = smt.Function(\"path\", smt.IntSort(), smt.IntSort(), smt.BoolSort())\n",
    "clauses = [\n",
    "kd.QForAll([a,b,c], edge(a,b), path(b,c), path(a,c)),\n",
    "kd.QForAll([a,b], edge(a,b), path(a,b)),\n",
    "edge(a,b),\n",
    "edge(b,c)\n",
    "]\n",
    "\n",
    "#for c in clauses:\n",
    "#    vs, body = kd.utils.open_binder_unhygienic(c)\n",
    "#    print(smt.Tactic(\"tseitin-cnf\")(body)[0][0])\n",
    "\n",
    "clauses = [clause_of_expr(c) for c in clauses]\n",
    "print(clauses)\n",
    "for c1 in clauses:\n",
    "    for c2 in clauses:\n",
    "        resolvents = computeResolvents(c1, c2)\n",
    "        print(\"c1\", c1)\n",
    "        print(\"c2\", c2)\n",
    "        print(\"res\", resolvents)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "[[&forall;a : path(a, b!2(a)) &or; edge(a, b!2(a))]]"
      ],
      "text/plain": [
       "[[ForAll(a, Or(path(a, b!2(a)), edge(a, b!2(a))))]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smt.Tactic(\"nnf\")(smt.ForAll([a], smt.Exists([b], smt.Or(path(a,b), edge(a,b)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeFactors(clause : Clause):\n",
    "    res = []\n",
    "    for i, lit1 in enumerate(clause.pos):\n",
    "        for j, lit2 in enumerate(clause.neg):\n",
    "            s = kd.utils.unify(clause.vs, lit1 , lit2)\n",
    "            if s is None:\n",
    "                continue\n",
    "            new_clause = Clause(clause.vs, tuple(subst(lit,s) for lit in clause.pos if lit != lit1), tuple(subst(lit,s) for lit in clause.neg if lit != lit2))\n",
    "            res.append(new_clause)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolution\n",
    "Given clause\n",
    "https://www.philipzucker.com/resolution1/\n",
    "https://github.com/eprover/PyRes/blob/master/saturation.py\n",
    "\n",
    "Do we want to store our clauses packed (as a single z3expr) or unpacked (as python structure)?\n",
    "\n",
    "Hmm pyres has literal selection even without ordering. These ideas are separate\n",
    "\n",
    "\n",
    "Subsumption vs generation. If you are chasing saturation, super powerful subsumption also feels important. A full theorem prover call is maximally (?) powerful subsumption. But if you were generated from the processed set in any way, this call must show subsumption... hmm. Theorem prover call to some weaker logic?\n",
    "You could recursviely call yourself i suppose?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.all import *\n",
    "from typing import NamedTuple\n",
    "\n",
    "class Clause(NamedTuple):\n",
    "    vs: list[smt.ExprRef]\n",
    "    neg: list[smt.ExprRef]\n",
    "    # selected: list[smt.ExprRef] could further split pos,neg into selected and unselected\n",
    "    pos: list[smt.ExprRef]\n",
    "\n",
    "def resolve(vs, clause1, clause2):\n",
    "\n",
    "\n",
    "def given():\n",
    "    processed = {}\n",
    "    unprocessed = []\n",
    "    while unprocessed:\n",
    "        givenclause = unprocessed.pop()\n",
    "        if givenclause.is_empty():\n",
    "            return False\n",
    "        \n",
    "        # delete tautologies\n",
    "        s = Solver()\n",
    "        s.set(\"timeout\",0.1)\n",
    "        s.add(Not(givenclause))\n",
    "        if s.check() == unsat:\n",
    "            continue\n",
    "        # forward subsumption. Does processed clause cover (imply) given?\n",
    "        if givenclause in processed:\n",
    "            continue\n",
    "        # backward subsumption. does given cover processed clause?\n",
    "\n",
    "\n",
    "\n",
    "        vs, body = kd.utils.open_binders(clause)\n",
    "        unprocessed.extend(allfactors(givenclause))\n",
    "        for clause2 in processed:\n",
    "            allresolvants(givenclause, clause2)\n",
    "        self.processed.add(givenclause)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tableau\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ILP\n",
    "\n",
    "Dyckhoff rules?\n",
    "Hmm. If I use | ~ as inference rules\n",
    "vs using as sequent |-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/intuit.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/intuit.p\n",
    "\n",
    "\n",
    "cnf(and_intro, axiom, ~p(P) | ~p(Q) | p(and(P,Q))).\n",
    "cnf(and_elim1, axiom, ~p(and(P,Q)) | p(P) ).\n",
    "cnf(and_elim2, axiom, ~p(and(P,Q)) | p(Q) ).\n",
    "\n",
    "% speical behavior is triggered by \n",
    "% and(P,Q) = and(Q,P)\n",
    "% and(P,and(Q,R)) = and(and(P,Q),R)\n",
    "\n",
    "\n",
    "%cnf(true_ctx, axiom, ~p(a)).\n",
    "%cnf(true_ctx, axiom, p(b)).\n",
    "%cnf(goal, axiom, p(and(a,b))).\n",
    "\n",
    "cnf(or_intro1, axiom, ~p(P) | p(or(P,Q))).\n",
    "cnf(or_intro2, axiom, ~p(Q) | p(or(P,Q))).\n",
    "cnf(or_elim, axiom, ~p(or(P,Q)) | ~p(impl(P,C)) | ~p(impl(Q,C)) | p(C)).\n",
    "\n",
    "cnf(impl_intro, axiom, ~p(P) | p(impl(Q,P))).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to do a search over paramter space of which helper lemmas nd solver paramters work best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/intuit.p\n",
    "\n",
    "\n",
    "cnf(and_intro, axiom, ~seq(Gam, P) | ~seq(Gam, Q) | p(Gam, and(P,Q))).\n",
    "cnf(and_elim1, axiom, ~p(and(P,Q)) | p(P) ).\n",
    "cnf(and_elim2, axiom, ~p(and(P,Q)) | p(Q) ).\n",
    "\n",
    "\n",
    "%cnf(true_ctx, axiom, ~p(a)).\n",
    "%cnf(true_ctx, axiom, p(b)).\n",
    "%cnf(goal, axiom, p(and(a,b))).\n",
    "\n",
    "cnf(or_intro1, axiom, ~p(P) | p(or(P,Q))).\n",
    "cnf(or_intro2, axiom, ~p(Q) | p(or(P,Q))).\n",
    "cnf(or_elim, axiom, ~p(or(P,Q)) | ~p(impl(P,C)) | ~p(impl(Q,C)) | p(C)).\n",
    "\n",
    "%cnf(impl_intro, axiom, ~seq(Gam + A, P) | seq(Gam, impl(Q,P))).\n",
    "% any invertible rules we can treat via = (?)\n",
    "% or seq() = seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Preprocessing class: FSSSSMSSSSSNFFN.\n",
      "# Configuration: G-E--_302_C18_F1_URBAN_RG_S04BN\n",
      "# No SInE strategy applied\n",
      "# Search class: FHUNF-FFSF22-SFFFFFNN\n",
      "# Configuration: SAT001_MinMin_p005000_rr_RG\n",
      "# Initializing proof state\n",
      "# Scanning for AC axioms\n",
      "#\n",
      "#cnf(i_0_11, plain, (p(or(X2,X1))|~p(X1))).\n",
      "#\n",
      "#cnf(i_0_9, plain, (p(X2)|~p(and(X1,X2)))).\n",
      "#\n",
      "#cnf(i_0_8, plain, (p(X1)|~p(and(X1,X2)))).\n",
      "#\n",
      "#cnf(i_0_10, plain, (p(or(X1,X2))|~p(X1))).\n",
      "#\n",
      "#cnf(i_0_7, plain, (p(and(X1,X2))|~p(X2)|~p(X1))).\n",
      "#\n",
      "#cnf(i_0_12, plain, (p(X3)|~p(or(X1,X2))|~p(impl(X2,X3))|~p(impl(X1,X3)))).\n",
      "# Presaturation interreduction done\n",
      "#\n",
      "#cnf(i_0_11, plain, (p(or(X1,X2))|~p(X2))).\n",
      "#\n",
      "#cnf(i_0_9, plain, (p(X1)|~p(and(X2,X1)))).\n",
      "#\n",
      "#cnf(i_0_8, plain, (p(X1)|~p(and(X1,X2)))).\n",
      "#\n",
      "#cnf(i_0_10, plain, (p(or(X1,X2))|~p(X1))).\n",
      "#\n",
      "#cnf(i_0_7, plain, (p(and(X1,X2))|~p(X2)|~p(X1))).\n",
      "#\n",
      "#cnf(i_0_12, plain, (p(X1)|~p(or(X2,X3))|~p(impl(X3,X1))|~p(impl(X2,X1)))).\n",
      "#\n",
      "#cnf(i_0_15, plain, (p(X1)|~p(impl(X3,X1))|~p(impl(X2,X1))|~p(X3))).\n",
      "#\n",
      "# No proof found!\n",
      "# SZS status Satisfiable\n"
     ]
    }
   ],
   "source": [
    "!eprover-ho --auto  /tmp/intuit.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Program\n",
    "Programming Resolution\n",
    "--precedence=\"append>and>eq>true>false>nil>cons\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/list.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/list.p\n",
    "\n",
    "cnf(nil, axiom, nil != cons(X,Y)). % also innjectivty of cons? cons(X,Y) = cons(A,B) | X != Y | A != B.  % A != X | B != Y | cons(A,B) = cons(X,Y)\n",
    "cnf(true_false, axiom, true != false). % use built in $true $false?\n",
    "cnf(xy, axiom, x != y). % arbitrary elements x,y. They are constructors. data Foo = A | B\n",
    "\n",
    "\n",
    "cnf(and_true, axiom, and(true, X) = X).\n",
    "cnf(and_false, axiom, and(false, X) = false).\n",
    "cnf(and_false2, axiom, and(X, false) = false).\n",
    "\n",
    "cnf(eq_nil, axiom, eq(nil, nil) = true).\n",
    "cnf(eq_cons, axiom, eq(cons(A, B), nil) = false).\n",
    "cnf(eq_cons2, axiom, eq(nil, cons(A, B)) = false).\n",
    "cnf(eq_cons3, axiom, eq(cons(A, B), cons(C, D)) = and(eq(A, C), eq(B, D))).\n",
    "\n",
    "cnf(app_base, axiom, append(nil, X) = X).\n",
    "cnf(app_cons, axiom, append(cons(H, T), X) = cons(H, append(T, X))).\n",
    "\n",
    "cnf(rev_nil, axiom, rev(nil) = nil).\n",
    "cnf(rev_cons, axiom, rev(cons(H, T)) = append(rev(T), cons(H, nil))).\n",
    "\n",
    "\n",
    "cnf(append_nil, axiom, append(X, nil) = X).\n",
    "\n",
    "cnf(append_assoc, axiom, append(append(X, Y), Z) = append(X, append(Y, Z))).\n",
    "\n",
    "% The two subcases of induction on X\n",
    "%cnf(append_assoc_nil, axiom, append(append(nil, Y), Z) = append(nil, append(Y, Z))).\n",
    "\n",
    "% yes, well I suppose since this needs the induction lemma...? It needs that in context to saturate\n",
    "% feels like cheating though.\n",
    "%cnf(append_assoc_cons, axiom, append(append(cons(H, T), Y), Z) = append(cons(H,T), append(Y, Z))).\n",
    "\n",
    "% goes forever. because it needs assoc done first?\n",
    "\n",
    "cnf(rev_app, axiom, rev(append(X, Y)) = append(rev(Y), rev(X))).\n",
    "%cnf(rev_app_nil, axiom, rev(append(nil, Y)) = append(rev(Y), rev(nil))).\n",
    "%cnf(rev_app_cons, axiom, rev(append(cons(H, T), Y)) = append(rev(Y), rev(cons(H, T)))).\n",
    "\n",
    "\n",
    "% this also needs the rev_app lemma first. Huh.\n",
    "cnf(rev_rev, axiom, rev(rev(X)) = X).\n",
    "%cnf(rev_rev_nil, axiom, rev(rev(nil)) = nil).\n",
    "%cnf(rev_rev_cons, axiom, rev(rev(cons(H, T))) = cons(H,T)).\n",
    "\n",
    "\n",
    "\n",
    "%cnf(rev_app, axiom, rev(append(x, y)) != append(rev(y), rev(x))).\n",
    "\n",
    "\n",
    "%fof(rev_app, conjecture, ![X,Y]: rev(append(X, Y)) = append(rev(Y), rev(X))).\n",
    "\n",
    "% eq(append(rev(X), rev(Y)), rev(append(X, Y))) = true.\n",
    "\n",
    "% yes shows unsat\n",
    "%cnf(rev_app, axiom, rev(append(X, Y)) = rev(X)).\n",
    "\n",
    "\n",
    "% I can also execute\n",
    "% query1 = foo(x,y,z) did not work so good. Why? Ahh, I missed putting x,y in the ordering. It should have yelled at me?\n",
    "%cnf(query1, axiom, query1(rev(cons(x, cons(y, nil))))).\n",
    "cnf(query1, axiom, query1 = rev(cons(x, cons(y, nil)))). % the evlauated form is in the saturated database. But X = rev(cons(x,..)) won't work because itself could be an answer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnf(nil, axiom, (nil!=cons(X1,X2)), file('/tmp/list.p', nil)).\n",
      "cnf(true_false, axiom, (true!=false), file('/tmp/list.p', true_false)).\n",
      "cnf(and_true, axiom, (and(true,X1)=X1), file('/tmp/list.p', and_true)).\n",
      "cnf(and_false, axiom, (and(false,X1)=false), file('/tmp/list.p', and_false)).\n",
      "cnf(and_false2, axiom, (and(X1,false)=false), file('/tmp/list.p', and_false2)).\n",
      "cnf(eq_nil, axiom, (eq(nil,nil)=true), file('/tmp/list.p', eq_nil)).\n",
      "cnf(eq_cons, axiom, (eq(cons(X1,X2),nil)=false), file('/tmp/list.p', eq_cons)).\n",
      "cnf(eq_cons2, axiom, (eq(nil,cons(X1,X2))=false), file('/tmp/list.p', eq_cons2)).\n",
      "cnf(eq_cons3, axiom, (eq(cons(X1,X2),cons(X3,X4))=and(eq(X1,X3),eq(X2,X4))), file('/tmp/list.p', eq_cons3)).\n",
      "cnf(app_base, axiom, (append(nil,X1)=X1), file('/tmp/list.p', app_base)).\n",
      "cnf(app_cons, axiom, (append(cons(X1,X2),X3)=cons(X1,append(X2,X3))), file('/tmp/list.p', app_cons)).\n",
      "cnf(rev_nil, axiom, (rev(nil)=nil), file('/tmp/list.p', rev_nil)).\n",
      "cnf(rev_cons, axiom, (rev(cons(X1,X2))=append(rev(X2),cons(X1,nil))), file('/tmp/list.p', rev_cons)).\n",
      "cnf(append_nil, axiom, (append(X1,nil)=X1), file('/tmp/list.p', append_nil)).\n",
      "cnf(append_assoc, axiom, (append(append(X1,X2),X3)=append(X1,append(X2,X3))), file('/tmp/list.p', append_assoc)).\n",
      "cnf(rev_app, axiom, (rev(append(X1,X2))=append(rev(X2),rev(X1))), file('/tmp/list.p', rev_app)).\n",
      "cnf(rev_rev, axiom, (rev(rev(X1))=X1), file('/tmp/list.p', rev_rev)).\n",
      "cnf(query1, axiom, (query1=rev(cons(x,cons(y,nil)))), file('/tmp/list.p', query1)).\n",
      "cnf(c_0_19, plain, (nil!=cons(X1,X2)),inference(fof_simplification, [status(thm)],[c_0_1])).\n",
      "cnf(c_0_20, plain, (true!=false),inference(fof_simplification, [status(thm)],[c_0_2])).\n",
      "{\n",
      "   {\n",
      "      ordertype:               LPO4\n",
      "      to_weight_gen:           none\n",
      "      to_prec_gen:             none\n",
      "      rewrite_strong_rhs_inst: false\n",
      "      to_pre_prec:             \"query1>rev>append>eq>and>true>false>nil>cons>x>y\"\n",
      "      conj_only_mod:           0\n",
      "      conj_axiom_mod:          0\n",
      "      axiom_only_mod:          0\n",
      "      skolem_mod:              0\n",
      "      defpred_mod:             0\n",
      "      force_kbo_var_weight:    false\n",
      "      to_pre_weights:          \"\"\n",
      "      to_const_weight:         0\n",
      "      to_defs_min:             false\n",
      "      lit_cmp:                 1\n",
      "      lam_w:                   20\n",
      "      db_w:                    10\n",
      "      ho_order_kind:           lfho\n",
      "   }\n",
      "   no_preproc:                     false\n",
      "   eqdef_maxclauses:               20000\n",
      "   eqdef_incrlimit:                20\n",
      "   formula_def_limit:              24\n",
      "   sine:                           \"None\"\n",
      "   add_goal_defs_pos:             false\n",
      "   add_goal_defs_neg:             false\n",
      "   add_goal_defs_subterms:        false\n",
      "   heuristic_name:                Default\n",
      "   heuristic_def:                 \"\"\n",
      "   prefer_initial_clauses:         false\n",
      "   selection_strategy:             SelectLargestNegLit\n",
      "   pos_lit_sel_min:                0\n",
      "   pos_lit_sel_max:                9223372036854775807\n",
      "   neg_lit_sel_min:                0\n",
      "   neg_lit_sel_max:                9223372036854775807\n",
      "   all_lit_sel_min:                0\n",
      "   all_lit_sel_max:                9223372036854775807\n",
      "   weight_sel_min:                 0\n",
      "   select_on_proc_only:            false\n",
      "   inherit_paramod_lit:            false\n",
      "   inherit_goal_pm_lit:            false\n",
      "   inherit_conj_pm_lit:            false\n",
      "   enable_eq_factoring:            true\n",
      "   enable_neg_unit_paramod:        true\n",
      "   enable_given_forward_simpl:     true\n",
      "   pm_type:                        ParamodPlain\n",
      "   ac_handling:                    1\n",
      "   ac_res_aggressive:              true\n",
      "   forward_context_sr:             false\n",
      "   forward_context_sr_aggressive:  false\n",
      "   backward_context_sr:            false\n",
      "   forward_subsumption_aggressive: false\n",
      "   forward_demod:                  2\n",
      "   prefer_general:                 false\n",
      "   condensing:                     false\n",
      "   condensing_aggressive:          false\n",
      "   er_varlit_destructive:          false\n",
      "   er_strong_destructive:          false\n",
      "   er_aggressive:                  false\n",
      "   split_clauses:                  0\n",
      "   split_method:                   0\n",
      "   split_aggressive:               false\n",
      "   split_fresh_defs:               true\n",
      "   diseq_decomposition             0\n",
      "   diseq_decomp_maxarity           9223372036854775807\n",
      "   rw_bw_index_type:               FP7\n",
      "   pm_from_index_type:             FP7\n",
      "   pm_into_index_type:             FP7\n",
      "   sat_check_grounding:            NoGrounding\n",
      "   sat_check_step_limit:           9223372036854775807\n",
      "   sat_check_size_limit:           9223372036854775807\n",
      "   sat_check_ttinsert_limit:       9223372036854775807\n",
      "   sat_check_normconst:            false\n",
      "   sat_check_normalize:            false\n",
      "   sat_check_decision_limit:       10000\n",
      "   filter_orphans_limit:           9223372036854775807\n",
      "   forward_contract_limit:         9223372036854775807\n",
      "   delete_bad_limit:               9223372036854775807\n",
      "   mem_limit:                      0\n",
      "   watchlist_simplify:             true\n",
      "   watchlist_is_static:            false\n",
      "   use_tptp_sos:                   false\n",
      "   presat_interreduction:          false\n",
      "   detsort_bw_rw:                  false\n",
      "   detsort_tmpset:                 false\n",
      "   arg_cong:                       all\n",
      "   neg_ext:                        off\n",
      "   pos_ext:                        off\n",
      "   ext_rules_max_depth:            -1\n",
      "   inverse_recognition:            false\n",
      "   replace_inj_defs:               false\n",
      "   lift_lambdas:                  true\n",
      "   lambda_to_forall:              true\n",
      "   unroll_only_formulas:          true\n",
      "   elim_leibniz_max_depth:        -1\n",
      "   prim_enum_mode:                pragmatic\n",
      "   prim_enum_max_depth:           -1\n",
      "   inst_choice_max_depth:         -1\n",
      "   local_rw:                      false\n",
      "   prune_args:                    false\n",
      "   preinstantiate_induction:      false\n",
      "   fool_unroll:                   true\n",
      "   func_proj_limit:               0\n",
      "   imit_limit:                    0\n",
      "   ident_limit:                   0\n",
      "   elim_limit:                    0\n",
      "   unif_mode:                     single\n",
      "   pattern_oracle:                true\n",
      "   fixpoint_oracle:               true\n",
      "   max_unifiers:                  4\n",
      "   max_unif_steps:                256\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho  --print-saturated   --generated-limit=1000 --output-level=6 --print-strategy --literal-selection-strategy=\"SelectLargestNegLit\" --term-ordering=\"LPO4\" --precedence=\"query1>rev>append>eq>and>true>false>nil>cons>x>y\" /tmp/list.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inductionless induction.\n",
    "Very fishy feeling.\n",
    "\n",
    "Cyclic proofs\n",
    "http://www0.cs.ucl.ac.uk/staff/J.Brotherston/slides/PARIS_FLoC_07_18_part1.pdf\n",
    "\n",
    "https://cstheory.stackexchange.com/questions/15078/why-is-there-a-need-for-cyclic-proofs\n",
    "http://www0.cs.ucl.ac.uk/staff/J.Brotherston/TABLEAUX05/cyclic_proofs_folind.pdf\n",
    "\n",
    "Handbook chapter\n",
    "\n",
    "What about something that isn't a single obvious induction?\n",
    "Would we make new terms that somehow make the termination or induction explicit?\n",
    "A version of the algorithm that carries variants and make the theorem that the two (with and without erased variants) are equal.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/eval.p\n",
    "\n",
    "\n",
    "cnf(eval_append_nil, axiom, eval(append(nil, X)) =  nil).\n",
    "cnf(eval_append_cons, axiom, eval(append(cons(H, T), X)) = cons(H, eval(append(T, X)))).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prolog\n",
    "SLD resolution https://en.wikipedia.org/wiki/SLD_resolution\n",
    "Model elimination loveland 1968 1978\n",
    "PTTP A Prolog technology theorem\n",
    "prover: a new exposition and\n",
    "implementation in Prolog* - stickel\n",
    "\n",
    "https://www.doc.ic.ac.uk/~rak/papers/sl.pdf Sl resolution kowalski\n",
    "https://link.springer.com/article/10.1007/BF00244355 sequent style model elimination\n",
    "\n",
    "https://cs.uwaterloo.ca/~david/cl/\n",
    "\n",
    "Computational logic\n",
    "https://cs.uwaterloo.ca/~david/cl/sld-gallier.pdf Sld gallier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Complete failure to saturate but the functional program is fine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /tmp/add.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/add.p\n",
    "cnf(zero, axiom, zero != succ(X)).\n",
    "cnf(add_zero, axiom, add(zero, X) = X).\n",
    "cnf(add_succ, axiom, add(succ(X), Y) = succ(add(X, Y)))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnf(zero, axiom, (zero!=succ(X1)), file('/tmp/add.p', zero)).\n",
      "cnf(add_zero, axiom, (add(zero,X1)=X1), file('/tmp/add.p', add_zero)).\n",
      "cnf(add_succ, axiom, (add(succ(X1),X2)=succ(add(X1,X2))), file('/tmp/add.p', add_succ)).\n",
      "cnf(c_0_4, plain, (zero!=succ(X1)),inference(fof_simplification, [status(thm)],[c_0_1])).\n",
      "# Initializing proof state\n",
      "cnf(c_0_5, plain, (succ(X1)!=zero), c_0_-9223372036854775800,['eval']).\n",
      "cnf(c_0_6, plain, (add(zero,X1)=X1), c_0_-9223372036854775799,['eval']).\n",
      "cnf(c_0_7, plain, (add(succ(X1),X2)=succ(add(X1,X2))), c_0_-9223372036854775798,['eval']).\n",
      "# Scanning for AC axioms\n",
      "cnf(c_0_8, plain, (add(zero,X1)=X1), c_0_6,['new_given']).\n",
      "cnf(c_0_9, plain, (add(succ(X1),X2)=succ(add(X1,X2))), c_0_7,['new_given']).\n",
      "cnf(c_0_10, plain, (succ(X1)!=zero), c_0_5,['new_given']).\n",
      "cnf(c_0_11, plain, (add(zero,X1)=X1), c_0_8,['final']).\n",
      "cnf(c_0_12, plain, (add(succ(X1),X2)=succ(add(X1,X2))), c_0_9,['final']).\n",
      "cnf(c_0_13, plain, (succ(X1)!=zero), c_0_10,['final']).\n",
      "\n",
      "# No proof found!\n",
      "# SZS status Satisfiable\n",
      "# Processed positive unit clauses:\n",
      "cnf(c_0_11, plain, (add(zero,X1)=X1)).\n",
      "cnf(c_0_12, plain, (add(succ(X1),X2)=succ(add(X1,X2)))).\n",
      "\n",
      "# Processed negative unit clauses:\n",
      "cnf(c_0_13, plain, (succ(X1)!=zero)).\n",
      "\n",
      "# Processed non-unit clauses:\n",
      "\n",
      "# Unprocessed positive unit clauses:\n",
      "\n",
      "# Unprocessed negative unit clauses:\n",
      "\n",
      "# Unprocessed non-unit clauses:\n",
      "\n",
      "\n",
      "# Parsed axioms                        : 3\n",
      "# Removed by relevancy pruning/SinE    : 0\n",
      "# Initial clauses                      : 3\n",
      "# Removed in clause preprocessing      : 0\n",
      "# Initial clauses in saturation        : 3\n",
      "# Processed clauses                    : 3\n",
      "# ...of these trivial                  : 0\n",
      "# ...subsumed                          : 0\n",
      "# ...remaining for further processing  : 3\n",
      "# Other redundant clauses eliminated   : 0\n",
      "# Clauses deleted for lack of memory   : 0\n",
      "# Backward-subsumed                    : 0\n",
      "# Backward-rewritten                   : 0\n",
      "# Generated clauses                    : 0\n",
      "# ...of the previous two non-redundant : 0\n",
      "# ...aggressively subsumed             : 0\n",
      "# Contextual simplify-reflections      : 0\n",
      "# Paramodulations                      : 0\n",
      "# Factorizations                       : 0\n",
      "# NegExts                              : 0\n",
      "# Equation resolutions                 : 0\n",
      "# Disequality decompositions           : 0\n",
      "# Total rewrite steps                  : 0\n",
      "# ...of those cached                   : 0\n",
      "# Propositional unsat checks           : 0\n",
      "#    Propositional check models        : 0\n",
      "#    Propositional check unsatisfiable : 0\n",
      "#    Propositional clauses             : 0\n",
      "#    Propositional clauses after purity: 0\n",
      "#    Propositional unsat core size     : 0\n",
      "#    Propositional preprocessing time  : 0.000\n",
      "#    Propositional encoding time       : 0.000\n",
      "#    Propositional solver time         : 0.000\n",
      "#    Success case prop preproc time    : 0.000\n",
      "#    Success case prop encoding time   : 0.000\n",
      "#    Success case prop solver time     : 0.000\n",
      "# Current number of processed clauses  : 3\n",
      "#    Positive orientable unit clauses  : 2\n",
      "#    Positive unorientable unit clauses: 0\n",
      "#    Negative unit clauses             : 1\n",
      "#    Non-unit-clauses                  : 0\n",
      "# Current number of unprocessed clauses: 0\n",
      "# ...number of literals in the above   : 0\n",
      "# Current number of archived formulas  : 0\n",
      "# Current number of archived clauses   : 0\n",
      "# Clause-clause subsumption calls (NU) : 0\n",
      "# Rec. Clause-clause subsumption calls : 0\n",
      "# Non-unit clause-clause subsumptions  : 0\n",
      "# Unit Clause-clause subsumption calls : 0\n",
      "# Rewrite failures with RHS unbound    : 0\n",
      "# BW rewrite match attempts            : 0\n",
      "# BW rewrite match successes           : 0\n",
      "# Condensation attempts                : 0\n",
      "# Condensation successes               : 0\n",
      "# Termbank termtop insertions          : 45\n",
      "# Search garbage collected termcells   : 2\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --print-saturated   --generated-limit=100 --output-level=6 --literal-selection-strategy=\"SelectLargestNegLit\" --term-ordering=\"LPO4\" --precedence=\"add>succ>zero\" /tmp/add.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/prolog.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/prolog.p\n",
    "\n",
    "cnf(succ_neq_zero, axiom, succ(X) != zero).\n",
    "%cnf(add_nil, axiom, add(zero, zero, zero)).\n",
    "cnf(add_zero, axiom, add(zero, X, X)).\n",
    "cnf(add_succ, axiom, add(succ(X), Y, succ(Z)) | ~add(X, Y, Z)).\n",
    "%cnf(add_succ, axiom, add(succ(X), succ(Y), succ(succ(Z))) | ~add(X, Y, Z)).\n",
    "%cnf(add_succ, axiom, add(X, zero, X))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   {\n",
      "      ordertype:               KBO6\n",
      "      to_weight_gen:           none\n",
      "      to_prec_gen:             none\n",
      "      rewrite_strong_rhs_inst: false\n",
      "      to_pre_prec:             \"\"\n",
      "      conj_only_mod:           0\n",
      "      conj_axiom_mod:          0\n",
      "      axiom_only_mod:          0\n",
      "      skolem_mod:              0\n",
      "      defpred_mod:             0\n",
      "      force_kbo_var_weight:    false\n",
      "      to_pre_weights:          \"\"\n",
      "      to_const_weight:         0\n",
      "      to_defs_min:             false\n",
      "      lit_cmp:                 1\n",
      "      lam_w:                   20\n",
      "      db_w:                    10\n",
      "      ho_order_kind:           lfho\n",
      "   }\n",
      "   no_preproc:                     false\n",
      "   eqdef_maxclauses:               20000\n",
      "   eqdef_incrlimit:                20\n",
      "   formula_def_limit:              24\n",
      "   sine:                           \"None\"\n",
      "   add_goal_defs_pos:             false\n",
      "   add_goal_defs_neg:             false\n",
      "   add_goal_defs_subterms:        false\n",
      "   heuristic_name:                Default\n",
      "   heuristic_def:                 \"\"\n",
      "   prefer_initial_clauses:         false\n",
      "   selection_strategy:             NoSelection\n",
      "   pos_lit_sel_min:                0\n",
      "   pos_lit_sel_max:                9223372036854775807\n",
      "   neg_lit_sel_min:                0\n",
      "   neg_lit_sel_max:                9223372036854775807\n",
      "   all_lit_sel_min:                0\n",
      "   all_lit_sel_max:                9223372036854775807\n",
      "   weight_sel_min:                 0\n",
      "   select_on_proc_only:            false\n",
      "   inherit_paramod_lit:            false\n",
      "   inherit_goal_pm_lit:            false\n",
      "   inherit_conj_pm_lit:            false\n",
      "   enable_eq_factoring:            true\n",
      "   enable_neg_unit_paramod:        true\n",
      "   enable_given_forward_simpl:     true\n",
      "   pm_type:                        ParamodPlain\n",
      "   ac_handling:                    1\n",
      "   ac_res_aggressive:              true\n",
      "   forward_context_sr:             false\n",
      "   forward_context_sr_aggressive:  false\n",
      "   backward_context_sr:            false\n",
      "   forward_subsumption_aggressive: false\n",
      "   forward_demod:                  2\n",
      "   prefer_general:                 false\n",
      "   condensing:                     false\n",
      "   condensing_aggressive:          false\n",
      "   er_varlit_destructive:          false\n",
      "   er_strong_destructive:          false\n",
      "   er_aggressive:                  false\n",
      "   split_clauses:                  0\n",
      "   split_method:                   0\n",
      "   split_aggressive:               false\n",
      "   split_fresh_defs:               true\n",
      "   diseq_decomposition             0\n",
      "   diseq_decomp_maxarity           9223372036854775807\n",
      "   rw_bw_index_type:               FP7\n",
      "   pm_from_index_type:             FP7\n",
      "   pm_into_index_type:             FP7\n",
      "   sat_check_grounding:            NoGrounding\n",
      "   sat_check_step_limit:           9223372036854775807\n",
      "   sat_check_size_limit:           9223372036854775807\n",
      "   sat_check_ttinsert_limit:       9223372036854775807\n",
      "   sat_check_normconst:            false\n",
      "   sat_check_normalize:            false\n",
      "   sat_check_decision_limit:       10000\n",
      "   filter_orphans_limit:           9223372036854775807\n",
      "   forward_contract_limit:         9223372036854775807\n",
      "   delete_bad_limit:               9223372036854775807\n",
      "   mem_limit:                      0\n",
      "   watchlist_simplify:             true\n",
      "   watchlist_is_static:            false\n",
      "   use_tptp_sos:                   false\n",
      "   presat_interreduction:          false\n",
      "   detsort_bw_rw:                  false\n",
      "   detsort_tmpset:                 false\n",
      "   arg_cong:                       all\n",
      "   neg_ext:                        off\n",
      "   pos_ext:                        off\n",
      "   ext_rules_max_depth:            -1\n",
      "   inverse_recognition:            false\n",
      "   replace_inj_defs:               false\n",
      "   lift_lambdas:                  true\n",
      "   lambda_to_forall:              true\n",
      "   unroll_only_formulas:          true\n",
      "   elim_leibniz_max_depth:        -1\n",
      "   prim_enum_mode:                pragmatic\n",
      "   prim_enum_max_depth:           -1\n",
      "   inst_choice_max_depth:         -1\n",
      "   local_rw:                      false\n",
      "   prune_args:                    false\n",
      "   preinstantiate_induction:      false\n",
      "   fool_unroll:                   true\n",
      "   func_proj_limit:               0\n",
      "   imit_limit:                    0\n",
      "   ident_limit:                   0\n",
      "   elim_limit:                    0\n",
      "   unif_mode:                     single\n",
      "   pattern_oracle:                true\n",
      "   fixpoint_oracle:               true\n",
      "   max_unifiers:                  4\n",
      "   max_unif_steps:                256\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --print-saturated --print-strategy --generated-limit=10 /tmp/prolog.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnf(succ_neq_zero, axiom, (succ(X1)!=zero), file('/tmp/prolog.p', succ_neq_zero)).\n",
      "cnf(add_zero, axiom, (add(zero,X1,X1)), file('/tmp/prolog.p', add_zero)).\n",
      "cnf(add_succ, axiom, (add(succ(X1),succ(X2),succ(succ(X3)))|~add(X1,X2,X3)), file('/tmp/prolog.p', add_succ)).\n",
      "cnf(c_0_4, plain, (succ(X1)!=zero),inference(fof_simplification, [status(thm)],[c_0_1])).\n",
      "cnf(c_0_5, plain, (add(succ(X1),succ(X2),succ(succ(X3)))|~add(X1,X2,X3)),inference(fof_simplification, [status(thm)],[c_0_3])).\n",
      "# Initializing proof state\n",
      "cnf(c_0_6, plain, (succ(X1)!=zero), c_0_-9223372036854775799,['eval']).\n",
      "cnf(c_0_7, plain, (add(zero,X1,X1)), c_0_-9223372036854775798,['eval']).\n",
      "cnf(c_0_8, plain, (add(succ(X1),succ(X2),succ(succ(X3)))|~add(X1,X2,X3)), c_0_-9223372036854775797,['eval']).\n",
      "# Scanning for AC axioms\n",
      "cnf(c_0_9, plain, (add(zero,X1,X1)), c_0_7,['new_given']).\n",
      "cnf(c_0_10, plain, (add(succ(X1),succ(X2),succ(succ(X3)))|~add(X1,X2,X3)), c_0_8,['new_given']).\n",
      "cnf(c_0_11, plain, (succ(X1)!=zero), c_0_6,['new_given']).\n",
      "cnf(c_0_12, plain, (add(zero,X1,X1)), c_0_9,['final']).\n",
      "cnf(c_0_13, plain, (succ(X1)!=zero), c_0_11,['final']).\n",
      "cnf(c_0_14, plain, (add(succ(X1),succ(X2),succ(succ(X3)))|~add(X1,X2,X3)), c_0_10,['final']).\n",
      "\n",
      "# No proof found!\n",
      "# SZS status Satisfiable\n",
      "# Processed positive unit clauses:\n",
      "cnf(c_0_12, plain, (add(zero,X1,X1))).\n",
      "\n",
      "# Processed negative unit clauses:\n",
      "cnf(c_0_13, plain, (succ(X1)!=zero)).\n",
      "\n",
      "# Processed non-unit clauses:\n",
      "cnf(c_0_14, plain, (add(succ(X1),succ(X2),succ(succ(X3)))|~add(X1,X2,X3))).\n",
      "\n",
      "# Unprocessed positive unit clauses:\n",
      "\n",
      "# Unprocessed negative unit clauses:\n",
      "\n",
      "# Unprocessed non-unit clauses:\n",
      "\n",
      "\n",
      "# Parsed axioms                        : 3\n",
      "# Removed by relevancy pruning/SinE    : 0\n",
      "# Initial clauses                      : 3\n",
      "# Removed in clause preprocessing      : 0\n",
      "# Initial clauses in saturation        : 3\n",
      "# Processed clauses                    : 3\n",
      "# ...of these trivial                  : 0\n",
      "# ...subsumed                          : 0\n",
      "# ...remaining for further processing  : 3\n",
      "# Other redundant clauses eliminated   : 0\n",
      "# Clauses deleted for lack of memory   : 0\n",
      "# Backward-subsumed                    : 0\n",
      "# Backward-rewritten                   : 0\n",
      "# Generated clauses                    : 0\n",
      "# ...of the previous two non-redundant : 0\n",
      "# ...aggressively subsumed             : 0\n",
      "# Contextual simplify-reflections      : 0\n",
      "# Paramodulations                      : 0\n",
      "# Factorizations                       : 0\n",
      "# NegExts                              : 0\n",
      "# Equation resolutions                 : 0\n",
      "# Disequality decompositions           : 0\n",
      "# Total rewrite steps                  : 0\n",
      "# ...of those cached                   : 0\n",
      "# Propositional unsat checks           : 0\n",
      "#    Propositional check models        : 0\n",
      "#    Propositional check unsatisfiable : 0\n",
      "#    Propositional clauses             : 0\n",
      "#    Propositional clauses after purity: 0\n",
      "#    Propositional unsat core size     : 0\n",
      "#    Propositional preprocessing time  : 0.000\n",
      "#    Propositional encoding time       : 0.000\n",
      "#    Propositional solver time         : 0.000\n",
      "#    Success case prop preproc time    : 0.000\n",
      "#    Success case prop encoding time   : 0.000\n",
      "#    Success case prop solver time     : 0.000\n",
      "# Current number of processed clauses  : 3\n",
      "#    Positive orientable unit clauses  : 1\n",
      "#    Positive unorientable unit clauses: 0\n",
      "#    Negative unit clauses             : 1\n",
      "#    Non-unit-clauses                  : 1\n",
      "# Current number of unprocessed clauses: 0\n",
      "# ...number of literals in the above   : 0\n",
      "# Current number of archived formulas  : 0\n",
      "# Current number of archived clauses   : 0\n",
      "# Clause-clause subsumption calls (NU) : 0\n",
      "# Rec. Clause-clause subsumption calls : 0\n",
      "# Non-unit clause-clause subsumptions  : 0\n",
      "# Unit Clause-clause subsumption calls : 0\n",
      "# Rewrite failures with RHS unbound    : 0\n",
      "# BW rewrite match attempts            : 0\n",
      "# BW rewrite match successes           : 0\n",
      "# Condensation attempts                : 0\n",
      "# Condensation successes               : 0\n",
      "# Termbank termtop insertions          : 65\n",
      "# Search garbage collected termcells   : 5\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --print-saturated --generated-limit=10 --output-level=6 --literal-selection-strategy=\"NoSelection\" --term-ordering=\"LPO4\" --precedence=\"add>succ>zero\" /tmp/prolog.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prolog parse\n",
    "\n",
    "\n",
    "A surface lanmguage that exposes term orderings? LPO by precedence of appearance. Or by callgraph.\n",
    "Use aprove to get good ordering first? Slothrop\n",
    "\n",
    "\n",
    "It would also be cool to make an egglog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query [add(s(s(z)), s(z), X)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[add(z, Y, Y),\n",
       " Implies(And(add(s(X), Y, s(Z)), add(X, Y, Z)),\n",
       "         add(s(X), Y, s(Z)))]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lark import Lark, Transformer\n",
    "\n",
    "# Define the Prolog grammar\n",
    "prolog_grammar = r\"\"\"\n",
    "    start: _statement*\n",
    "\n",
    "    _statement: fact\n",
    "             | rule\n",
    "             | query\n",
    "\n",
    "    fact: predicate \".\"\n",
    "    rule: predicate \":-\" predicate_list \".\"\n",
    "    query: \"?-\" predicate_list \".\"\n",
    "\n",
    "    predicate_list: predicate (\",\" predicate)* // inlined\n",
    "\n",
    "    predicate: IDENTIFIER \"(\" term_list? \")\"\n",
    "    term_list: term (\",\" term)* // inlined\n",
    "\n",
    "    term: IDENTIFIER    -> const          // constants or functors\n",
    "        | VARIABLE      -> var          // variables\n",
    "        | IDENTIFIER \"(\" term_list \")\" -> fun_app  // recursive terms (e.g., s(X))\n",
    "\n",
    "    VARIABLE: /[A-Z][A-Za-z0-9_]*/  // Variables start with uppercase\n",
    "    IDENTIFIER: /[a-z][A-Za-z0-9_]*/  // Constants and function names start with lowercase\n",
    "\n",
    "    %import common.WS\n",
    "    %ignore WS\n",
    "\"\"\"\n",
    "parser = Lark(prolog_grammar, start=\"start\", parser=\"lalr\")\n",
    "\n",
    "ex1 = \"\"\"add(z,Y,Y).\n",
    "add(s(X),Y,s(Z)) :- add(X,Y,Z).\n",
    "?- add(s(s(z)),s(z),X).\"\"\"\n",
    "t = parser.parse(ex1)\n",
    "#print(t.pretty())\n",
    "\n",
    "import z3\n",
    "Term = z3.DeclareSort(\"Term\")\n",
    "\n",
    "\n",
    "def interp_term(t):\n",
    "    token = t.data\n",
    "    if token == \"const\":\n",
    "        return z3.Const(t.children[0], Term)\n",
    "    elif token == \"var\":\n",
    "        return z3.Const(t.children[0], Term)\n",
    "    elif token == \"fun_app\":\n",
    "        args = t.children[1].children\n",
    "        sortlist = [Term] * (len(args) + 1)\n",
    "        f = Function(t.children[0], *sortlist)\n",
    "        return f(*[interp_term(a) for a in args])\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected term {t}\")\n",
    "\n",
    "def interp_pred(t):\n",
    "    assert t.data == \"predicate\"\n",
    "    name = t.children[0]\n",
    "    args = [interp_term(a) for a in t.children[1].children]\n",
    "    return Function(name, *([Term]*len(args)), z3.BoolSort())(*args)\n",
    "\n",
    "from z3 import *\n",
    "def interp(t):\n",
    "    assert t.data == \"start\"\n",
    "    clauses = []\n",
    "    for stmt in t.children:\n",
    "        if stmt.data == \"fact\":\n",
    "            clauses.append(interp_pred(stmt.children[0]))\n",
    "        elif stmt.data == \"rule\":\n",
    "            head = interp_pred(stmt.children[0])\n",
    "            predlist = stmt.children[1]\n",
    "            \n",
    "            assert predlist.data == \"predicate_list\"\n",
    "            body = [interp_pred(p) for p in [stmt.children[0]] + stmt.children[1].children ]\n",
    "            clauses.append(z3.Implies(And(*body), head))\n",
    "        elif stmt.data == \"query\":\n",
    "            q = [interp_pred(p) for p in stmt.children[0].children]\n",
    "            print(\"query\", q)\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected statement {stmt}\")\n",
    "    return clauses\n",
    "\n",
    "#print(t.pretty())       \n",
    "interp(t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cnf\n",
    "\n",
    "\n",
    "https://github.com/inpefess/tptp-lark-parser/blob/master/tptp_lark_parser/resources/TPTP.lark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "  cnf_annotated\n",
      "    test\n",
      "    axiom\n",
      "    disjunction\n",
      "      poslit\n",
      "        pred_app\n",
      "          foo\n",
      "          arguments\n",
      "            const\ta\n",
      "      disjunction\n",
      "        poslit\n",
      "          pred_const\tbar\n",
      "        disjunction\n",
      "          poslit\n",
      "            pred_app\n",
      "              biz\n",
      "              arguments\n",
      "                var\tX\n",
      "  cnf_annotated\n",
      "    test\n",
      "    axiom\n",
      "    disjunction\n",
      "      poslit\n",
      "        pred_app\n",
      "          foo\n",
      "          arguments\n",
      "            const\ta\n",
      "      disjunction\n",
      "        eq\n",
      "          const\tbar\n",
      "          const\tfum\n",
      "        disjunction\n",
      "          neglit\n",
      "            pred_app\n",
      "              biz\n",
      "              arguments\n",
      "                var\tX\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grammar = \"\"\"\n",
    "start                : cnf_annotated* \n",
    "cnf_annotated        : \"cnf\" \"(\" NAME \",\" FORMULA_ROLE \",\" cnf_formula \")\"  \".\"\n",
    "\n",
    "FORMULA_ROLE         : \"axiom\" \n",
    "\n",
    "?cnf_formula          : disjunction | \"(\" disjunction \")\"\n",
    "disjunction         : literal (\"|\" cnf_formula)*\n",
    "literal              : atomic_formula -> poslit \n",
    "                    | \"~\" atomic_formula -> neglit\n",
    "                    | term \"!=\" term  -> diseq\n",
    "                    | term \"=\" term -> eq\n",
    "\n",
    "atomic_formula       : NAME \"(\" arguments \")\"  -> pred_app\n",
    "                      | NAME -> pred_const\n",
    "\n",
    "arguments            : term (\",\" term)*\n",
    "\n",
    "term                :  NAME -> const\n",
    "            |        | UPPER_WORD -> var\n",
    "                    ||  NAME \"(\" arguments \")\" -> fun_app\n",
    "\n",
    "\n",
    "NAME                 : LOWER_WORD\n",
    "UPPER_WORD           : UPPER_ALPHA ALPHA_NUMERIC*\n",
    "LOWER_WORD           : LOWER_ALPHA ALPHA_NUMERIC*\n",
    "\n",
    "\n",
    "NUMERIC              : \"0\"..\"9\"\n",
    "LOWER_ALPHA          : \"a\"..\"z\"\n",
    "UPPER_ALPHA          : \"A\"..\"Z\"\n",
    "ALPHA_NUMERIC        : (LOWER_ALPHA | UPPER_ALPHA | NUMERIC | \"_\") \n",
    "\n",
    "%import common.WS\n",
    "%ignore WS\n",
    "\"\"\"\n",
    "\n",
    "parser = Lark(grammar, start=\"start\", parser=\"lalr\")\n",
    "\n",
    "t = parser.parse(\"cnf(test,axiom, foo(a) | (bar | biz(X))). cnf(test,axiom, foo(a) | (bar = fum | ~biz(X))).\")\n",
    "print(t.pretty())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Embed\n",
    "\n",
    "Self interpreter\n",
    "prolog interpreter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/mi.pl\n",
    "mi((X,Y)) :- mi(X), mi(Y).\n",
    "mi((X;Y)) :- mi(X); mi(Y).\n",
    "mi(X) :- clause(X,Body), mi(Body).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/seq.p\n",
    "\n",
    "% using AC to represent set contexts\n",
    "% union vs  finite set combine.\n",
    "% singleton(a) vs a. Not really a reason to make a distinction (?)\n",
    "% well it allows us to differentiate pattern matching on subset vs singleton\n",
    "cnf(union_assoc, axiom, u(u(A,B), C) = u(A, u(B,C))).\n",
    "cnf(union_comm, axiom, u(A,B) = u(B,A)).\n",
    "cnf(union_idem, axiom, u(A,A) = A).\n",
    "% a different union idem axiom.\n",
    "cnf(union_single_idem, axiom, u(s(A), s(A)) = s(A)).\n",
    "cnf(union_single, axiom, u(A,B) != s(C)). % typing condition I guess? Hmm.\n",
    "\n",
    "\n",
    "\n",
    "tff(type, u : ctx > ctx > ctx)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cnf(ax, axiom, ~elem(A,Gam) | \n",
    "        %--------------------\n",
    "               seq(Gam, A)).\n",
    "%cnf(and_R, axiom, \n",
    "%    ~seq(Gam, u(A,Delta)) | ~seq(Gam, u(B, Delta)) |\n",
    "%    % -----------------------------------------------\n",
    "%           seq(Gam, u(A,B,and(A,B), Delta1, Delta2))).\n",
    "%cnf(and_I, )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolution 2\n",
    "Ground resolution\n",
    "Ordered Ground Resolution\n",
    "\n",
    "Ground paramodulation\n",
    "Ground superposition\n",
    "\n",
    "https://events.model.in.tum.de/mod23/lectures.html Jasmin Blanchettes lectures\n",
    "https://matryoshka-project.github.io/pubs/satur_report.pdf A Comprehensive Framework for\n",
    "Saturation Theorem Proving\n",
    "\n",
    "\n",
    "https://www.sciencedirect.com/science/article/pii/0168007288900152 Second Order monadic term unification is decidable.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "def ground_size(t):\n",
    "        match t:\n",
    "            case (t1,args):\n",
    "                return 1 + sum(map, ground_size, args)\n",
    "def ground_kbo(t1,t2):\n",
    "    s1 = ground_size(t1)\n",
    "    s2 = ground_size(t2)\n",
    "    if s1 < s2:\n",
    "        return True\n",
    "    if s1 > s2:\n",
    "        return False\n",
    "    elif s1 == s2:\n",
    "        if t1[0] < t2[0]:\n",
    "            return True\n",
    "        elif t1[0] > t2[0]:\n",
    "            return False\n",
    "        elif t1[0] == t2[0]:\n",
    "            for i in range(1,len(t1)):\n",
    "                if t1[i] < t2[i]:\n",
    "                    return True\n",
    "                elif t1[i] > t2[i]:\n",
    "                    return False\n",
    "            return False\n",
    "    \n",
    "egraph = []\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Clause():\n",
    "    hyps: frozenset[Any]\n",
    "    concs: frozenset[Any]\n",
    "\n",
    "def maxlit(c : Clause):\n",
    "    return max(max(c.concs), max(c.hyps))\n",
    "\n",
    "```\n",
    "\n",
    "Some ideas about  hash consing.\n",
    "Could store more data in the nodes.\n",
    "numpy it or flatten it\n",
    "range queries with stdlib bisect\n",
    "We could uniquely label vars by depth first ordering. But then if they go in a frozenset, this becomes confusing.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "@dataclass(frozen=True)\n",
    "class Term():\n",
    "    pass\n",
    "@dataclass(frozen=True)\n",
    "class Fn(Term):\n",
    "    name: str\n",
    "    args: tuple[Any, ...] = ()\n",
    "    def __repr__(self):\n",
    "        if len(self.args) == 0:\n",
    "            return self.name\n",
    "        return f\"{self.name}({', '.join(map(repr, self.args))})\"\n",
    "    def __eq__(self, other, perm=[]):\n",
    "        if not isinstance(other, Fn) or self.name != other.name or len(self.args) != len(other.args):\n",
    "            return False\n",
    "        for x,y in zip(self.args, other.args):\n",
    "            if not x.__eq__(y,perm):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    \n",
    "@dataclass(frozen=True)\n",
    "class Var(Term):\n",
    "    name: str\n",
    "    def __repr__(self):\n",
    "        return \"?\" + self.name\n",
    "    def __eq__(self, other, perm=[]):\n",
    "        if not isinstance(other, Var):\n",
    "            return False\n",
    "        for x,y in perm:\n",
    "            if x == self.name:\n",
    "                return y == other.name\n",
    "            if y == other.name:\n",
    "                return x == self.name\n",
    "        perm.append((self.name, other.name))\n",
    "        return True\n",
    "    def __hash__(self):\n",
    "        # The name is not alpha invariant so can't naively be part of the hash\n",
    "        return 19\n",
    "\n",
    "def f(x):\n",
    "    return Fn(\"f\", (x,))\n",
    "def bar(x,y):\n",
    "    return Fn(\"bar\", (x,y))\n",
    "x,y,z = map(Var, \"xyz\")\n",
    "\n",
    "print(f\"{f(x) == f(f(x))=}\")\n",
    "print(f\"{f(x) == f(y)=}\")\n",
    "print(f\"{bar(x,y) == bar(x,x)=}\")\n",
    "print(f\"{bar(x,x) == bar(y,y)=}\")\n",
    "\n",
    "print(f\"{hash(bar(x,y))=} {hash(bar(x,y))=}\")\n",
    "\n",
    "print(f\"{set([ bar(x,x), bar(y,y), bar(y,x), bar(x,y) ])=}\")\n",
    "\n",
    "```\n",
    "\n",
    "    f(x) == f(f(x))=False\n",
    "    f(x) == f(y)=True\n",
    "    bar(x,y) == bar(x,x)=False\n",
    "    bar(x,x) == bar(y,y)=True\n",
    "    hash(bar(x,y))=-2698517946957590065 hash(bar(x,y))=-2698517946957590065\n",
    "    set([ bar(x,x), bar(y,y), bar(y,x), bar(x,y) ])={bar(?y, ?x), bar(?x, ?x)}\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "import lark\n",
    "from lark import v_args\n",
    "@dataclass(frozen=True)\n",
    "class Fact():\n",
    "    head: Fn\n",
    "    def __repr__(self):\n",
    "        return f\"{self.head}.\"\n",
    "@dataclass(frozen=True)\n",
    "class Rule():\n",
    "    head: Fn\n",
    "    body: tuple[Fn, ...]\n",
    "    def __repr__(self):\n",
    "        return f\"{self.head} :- {', '.join(map(repr, self.body))}.\"\n",
    "\n",
    "grammar = \"\"\"\n",
    "?start : decl* \n",
    "?decl :  fact | rule\n",
    "?fact : term \".\"\n",
    "?rule : term \":-\" term (\",\" term)* \".\"\n",
    "?term : NAME \"(\" term (\",\" term)* \")\" -> fn\n",
    "      | \"?\" NAME -> var\n",
    "      | NAME -> const\n",
    "%import common.CNAME -> NAME\n",
    "%import common.WS\n",
    "%ignore WS\n",
    "\"\"\"\n",
    "class Transformer(lark.Transformer):\n",
    "    fn = v_args(inline=True)(lambda self, n, *a: Fn(n, a))\n",
    "    const = v_args(inline=True)(Fn)\n",
    "    var = v_args(inline=True)(Var)\n",
    "    fact = v_args(inline=True)(Fact)\n",
    "    rule = v_args(inline=True)(lambda self, head, *body: Rule(head, body))\n",
    "    start = list\n",
    "\n",
    "datalog_parser = lark.Lark(grammar, parser=\"lalr\", transformer=Transformer())\n",
    "\n",
    "datalog_parser.parse(\"f(x). f(x) :- bar, biz(?X).\")[1]\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    f(x) :- bar, biz(?X).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "# nominal?\n",
    "@dataclass(frozen=True)\n",
    "class Atom():\n",
    "    name:str\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "import bisect\n",
    "\n",
    "class SortedListWithLE:\n",
    "    def __init__(self):\n",
    "        self._list = []\n",
    "\n",
    "    def insert(self, value):\n",
    "        bisect.insort_left(self._list, value)\n",
    "\n",
    "    def search_le(self, value):\n",
    "        index = bisect.bisect_right(self._list, value)\n",
    "        if index:\n",
    "            return self._list[index - 1]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "# Example usage:\n",
    "sl = SortedListWithLE()\n",
    "sl.insert(5)\n",
    "sl.insert(3)\n",
    "sl.insert(7)\n",
    "sl.insert(1)\n",
    "sl.insert(4)\n",
    "sl.insert(6)\n",
    "sl.insert(9)\n",
    "\n",
    "print(sl.search_le(2))  # Output: 1\n",
    "print(sl.search_le(5))  # Output: 5\n",
    "print(sl.search_le(8))  # Output: 7\n",
    "\n",
    "```\n",
    "\n",
    "    1\n",
    "    5\n",
    "    7\n",
    "\n",
    "\n",
    "Prolog has all the bits and pieces. WHy can't I just use prolog as my loigcal framework?\n",
    "Prolog is a pretty powerful metalanguage. Bindings are going to stink.\n",
    "Amy Felty. Could also try using elpi\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "# https://www.swi-prolog.org/pldoc/doc_for?object=section(%27packages/janus.html%27)\n",
    "import janus_swi as janus\n",
    "#janus.consult(\"/tmp/trs.pl\")\n",
    "janus.consult(\"path\", \"\"\"\n",
    "edge(a,b).\n",
    "edge(b,c).    \n",
    "edge(c,d).\n",
    "\n",
    ":- table path/2.\n",
    "path(X,Y) :- edge(X,Y).\n",
    "path(X,Y) :- edge(X,Z), path(Z,Y).\n",
    "\"\"\")\n",
    "#ans = janus.query_once(\"normal_form([f(x) ==> g(x)], f(x), _Res), term_to_list(_Res,Res).\")\n",
    "#ans['Res']\n",
    "list(janus.query(\"path(a,Y).\"))\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    [{'truth': True, 'Y': 'c'},\n",
    "     {'truth': True, 'Y': 'b'},\n",
    "     {'truth': True, 'Y': 'd'}]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "janus.consult(\"sequent\", \"\"\"\\\n",
    "% unify with occurs check\n",
    "theorem(refl, [], A = A, assume). % name, hyps, concs, reason\n",
    "              \n",
    "cnf(refl,axiom,[A = A]). % this basically is what tptp _is_\n",
    "\n",
    "% could reify stuff too. The sequent becomes a clause.\n",
    "% A == A.            \n",
    "              \n",
    "% modus takes in the _names_ of two theorems and returns a new theorem.\n",
    "modus(a,b,X) :- var(X), theorem(a, S, C, _), theorem(b, C, D, _), gensym(X), asserta(theorem(X, S, D, modus(a,b))). \n",
    "              % ammusingly call on the reason would basically prove the thing again.\n",
    "reflect(C) :- C, gensym(X), asserta(theorem(X,[],C)).\n",
    "\n",
    "\"\"\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
