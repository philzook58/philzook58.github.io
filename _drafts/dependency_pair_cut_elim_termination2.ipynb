{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trs_of_z3():\n",
    "    pass\n",
    "\n",
    "measures = []\n",
    "\n",
    "def fixpoint(name, args, body), measure=None):\n",
    "    subcalls = {}\n",
    "    def q(*x):\n",
    "        subcalls.add(x)\n",
    "        return Function(name, map(lambda z: z.sort(), args))(*x)\n",
    "    body(q)\n",
    "\n",
    "# it's kind of an axiom schema / definitional schema again\n",
    "def fixpoint(name, args, body), measure=None, by=[]):\n",
    "    subcalls = {}\n",
    "    def q(*x):\n",
    "        f = Function(name, map(lambda z: z.sort(), args))\n",
    "        lemma(measure(), by=by)\n",
    "        return \n",
    "    body = body(q)\n",
    "    defns.append(name, body)\n",
    "    # but also return custom induction principle.using subcalls?\n",
    "# when I define an inductive, it should return a well founded ordering relation? (subterm?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Cut elimination -> The subformula property\n",
    "The subformula property is by inspection of the cut-free rules.\n",
    "\n",
    "\n",
    "Reducing the worst redex is doing something akin to a multiset order. We replace the worst redex with many copies of slightly smaller redexes.\n",
    "\n",
    "\n",
    "If I had a term like representation of my proofs, I could write down rewrite systems for them\n",
    "\n",
    "Related to justified smt.\n",
    "Related to datalog for inverse method.\n",
    "\n",
    "Combinators?\n",
    "Cylindrical algerba?  wait, related to cad?\n",
    "\n",
    "https://okmij.org/ftp/tagless-final/ski.pdf\n",
    "typeof( Gam, t, s, e)\n",
    "\n",
    "What is S. https://blog.plover.com/math/combinator-s.html\n",
    "\"substitution\" apprently wrong.\n",
    "(f x) (g x) --> S f g x\n",
    "It's kind of a way of fusing two uses. Akin to dup.\n",
    "It's also kind of \"env carrying\" apply https://gist.github.com/buzzdecafe/6261503\n",
    "It's `<*>` / `ap`. specialzied to Reader\n",
    "composition of binary and unary function.\n",
    "\n",
    "\n",
    " [The Combinator S - Waldmann]\n",
    "\n",
    "\n",
    "Hoekstra's thesis is great\n",
    "B is compose\n",
    "\n",
    "T swap. T x y z = x z y\n",
    "\n",
    "Are combinators already the \"assocaited\" form of catuerogy combinators?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('app',\n",
       " ('app',\n",
       "  ('S',),\n",
       "  ('app', ('app', ('S',), ('app', ('K',), ('S',))), ('app', ('K',), ('I',)))),\n",
       " ('app', ('K',), ('I',)))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from z3 import *\n",
    "\n",
    "#type Arr[A,B] = Callable[A,B]\n",
    "def compile(t):\n",
    "    match t:\n",
    "        case \"app\", e1,e2:\n",
    "            return (\"app\", compile(e1), compile(e2))\n",
    "        case \"lam\", x, e:\n",
    "            return abstract(x, compile(e))\n",
    "        case _:\n",
    "            return t\n",
    "def abstract(x, e):\n",
    "    \"\"\"abstract x from e. No inner lambdas\"\"\"\n",
    "    match e:\n",
    "        case (\"app\", e1, e2):\n",
    "            return (\"app\", (\"app\", (\"S\",), abstract(x,e1)), abstract(x,e2))\n",
    "        case (\"var\", x):\n",
    "            return (\"I\",)\n",
    "        case _:\n",
    "            return (\"app\", (\"K\",), e)\n",
    "\n",
    "def lam(x,e):\n",
    "    return (\"lam\", x, e)\n",
    "def app(e1,e2):\n",
    "    return (\"app\", e1, e2)\n",
    "def var(x):\n",
    "    return (\"var\", x)\n",
    "def vars(xs):\n",
    "    return [var(x) for x in xs.split()]\n",
    "\n",
    "x,y,z,x1,x2,x3 = vars(\"x y z x1 x2 x3\")\n",
    "#lam(y, app(lam(x, app(var(x), var(x))), v))\n",
    "compile(lam(x, lam(y, app(var(y), var(x)))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klop Terese https://en.wikipedia.org/wiki/Jan_Willem_Klop https://janwillemklop.com/\n",
    "PM A\n",
    "\n",
    "http://joerg.endrullis.de/\n",
    "http://joerg.endrullis.de/teaching/\n",
    "\n",
    "Braids\n",
    "\n",
    "\n",
    "clock lambda calc.  http://joerg.endrullis.de/research/clocked-lambda-calculus/\n",
    "terese\n",
    "\n",
    "cycle rewriting - strings in loops. A fun idea https://arxiv.org/abs/1609.07065 transforming into string rewriting\n",
    "\n",
    "Zantema https://en.wikipedia.org/wiki/Hans_Zantema https://www.win.tue.nl/~hzantema/ar.html automated rerasoning lectures\n",
    "https://www.win.tue.nl/~hzantema/isr19.html infinitary rewriting\n",
    "\n",
    "infinitary rewriteing.  http://joerg.endrullis.de/trs/11_infinitary_rewriting.pdf/0000_slide.html infinite term is map from positions to symbol. Hmmm. That's reaosdbnable http://joerg.endrullis.de//assets/papers/infinitary-highlights-2012.pdf\n",
    "A metric. 2^-p highest p;osition whenre they differ. Hmm.\n",
    "cauchy convergent. Terms gets closer to each other.\n",
    "Transfinite reductions\n",
    "f(x,x) -> f(a,b)\n",
    "a -> c(a)\n",
    "b -> c(b)\n",
    "f(a,b) can rewrite to f(c(c(...)), c(c(...))) and then the top rule can fire. Cool\n",
    "CIRC https://dl.acm.org/doi/abs/10.5555/1770730.1770757 streambox\n",
    "\n",
    "https://drops.dagstuhl.de/storage/00lipics/lipics-vol015-rta2012/v20120508-organizer-final/LIPIcs.RTA.2012.69/LIPIcs.RTA.2012.69.pdf\n",
    "Infinitary term graph rewriting\n",
    "\n",
    "infinitary rewriting is good for streams. Does it havve automata like notions? Minimization?\n",
    "\n",
    "I supopse for finite term rewriting, a similar metric could be defined, or we could start from the leaves, hash consing. 2^-p such that p is highest hieight where a term exists not in the other.\n",
    "\n",
    "matrix interpretations. Consider a dscirete linear transition system.\n",
    "SDP?\n",
    "\n",
    "sqauirer homology perspective. draft book klop\n",
    "univelance allows stream equality. Is there a term rewriting version of univalence?\n",
    "\n",
    "\n",
    "acyclic DFA obviosly terminate. Is that obvious when converted to a term rewriting system? Yeah probably. Just assign topological order weight to states.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmlschema\n",
    "schemaurl = \"https://raw.githubusercontent.com/TermCOMP/TPDB/master/xml/xtc.xsd\"\n",
    "my_schema = xmlschema.XMLSchema(schemaurl)\n",
    "fileurl = \"https://raw.githubusercontent.com/TermCOMP/TPDB/master/TRS_Standard/Der95/01.xml\"\n",
    "mytrs = my_schema.to_dict(fileurl)\n",
    "def pretty_term(term):\n",
    "    if \"var\" in term:\n",
    "        return \"?\" + term[\"var\"]\n",
    "    if \"funapp\" in term:\n",
    "        t = term[\"funapp\"]\n",
    "        return t[\"name\"] + \"(\" + \", \".join(pretty_term(arg) for arg in t.get(\"arg\", [])) + \")\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid term\", term)\n",
    "def pretty(trs):\n",
    "    #trs = trs[\"trs\"]\n",
    "    for rule in trs[\"rules\"][\"rule\"]:\n",
    "        #print(rule)\n",
    "        print(pretty_term(rule[\"lhs\"]), \"=>\", pretty_term(rule[\"rhs\"]))\n",
    "    for rule in trs[\"rules\"]:\n",
    "        print(rule)\n",
    "\n",
    "    #for key, value in trs.items():\n",
    "    #    print(key)\n",
    "    #    #print(value)\n",
    "pretty(mytrs[\"trs\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://xsdata.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://cl-informatik.uibk.ac.at/isr24/ rewriting school. Seems like all the good topics\n",
    "https://link.springer.com/book/10.1007/978-3-031-43369-6 frontiers of combining systems\n",
    "\n",
    "polynomial interpretations\n",
    "matrix interpretations\n",
    "SAT/LP solver for termination\n",
    "dealing wiht the xml format\n",
    "How does the frontend deal with things\n",
    "\n",
    "There is rewriting modulo equations, realtive rewriting, innermost rewriting, conditional rewriting, outermost rewriting, higher order rewriting hrs, cycle rewriting, string rewriting. How are these dealt with?\n",
    "\n",
    "Confluence checking CSI\n",
    "https://en.wikipedia.org/wiki/Cycle_detection\n",
    "\n",
    "Java. Hmm.\n",
    "eBPF\n",
    "\n",
    "https://maude.cs.uiuc.edu/tools/mta/\n",
    "https://maude.cs.uiuc.edu/tools/itp/hendrix-thesis.pdf\n",
    "hendrix thesis. Equational tree automata\n",
    "\n",
    "Well founded induction\n",
    "\n",
    "if foo(s(x)) -> foo(x) is a well founded definition, then there is intrinisically a valid induction hypothesis in there\n",
    "Is extracting the piece related the dependency pairs?\n",
    "How to deal with completeness check? Default to some dummy value? Well, it isn't a problem. One can't prove what the value is on other pieces. We do want confluence though. To make sure we don't have foo(x) == true /\\ foo(x) == false\n",
    "\n",
    "higher order. sizechangetool  https://github.com/Deducteam/SizeChangeTool wanda \n",
    "\n",
    "## Dependency Pairs\n",
    "https://www.jaist.ac.jp/~hirokawa/publications/04rta.pdf\n",
    "\"let us start with some easy observations. If a TRS R is not terminating\n",
    "then there must be a minimal non-terminating term, minimal in the sense that\n",
    "all its proper subterms are terminating. Let us denote the set of all minimal\n",
    "non-terminating terms by T∞.\"\n",
    "\n",
    "Kind of copy the meta and the object level\n",
    "\n",
    "https://github.com/NikolajBjorner/ShonanArtOfSAT/blob/main/AkihisaYamada-slides.pdf\n",
    "he proof system in the slides has no base case\n",
    "Also R is just carried the whole way through\n",
    "I'd guess (empty, R) is the base cas\n",
    "\n",
    "Find constructor discipline in the rewirte system\n",
    "```\n",
    "let rec simplify t = \n",
    "    match t with\n",
    "    | Plus(x, S(y)) -> simplify S(Plus(x, y))\n",
    "    | Plus(Z, y) -> simplify y\n",
    "    | Mul (x, S(y)) -> simplify Plus(x, Mul(x, y))\n",
    "\n",
    "    | _ -> t\n",
    "\n",
    "let simplify1 t = \n",
    "    match t with\n",
    "    | Plus(x, S(y)) -> S(Plus(x, y))\n",
    "    | Plus(Z, y) -> y\n",
    "    | Mul (x, S(y)) -> Plus(x, Mul(x, y))\n",
    "\n",
    "    | _ -> t\n",
    "\n",
    "let simplify = \n",
    "    |\n",
    "    |\n",
    "\n",
    "-- Nontermination comes from calling simplify1 infinitely many times not from simplify1 itself\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "-- rework into\n",
    "\n",
    "let rec add x y = match x with\n",
    "    | Z -> y\n",
    "    | S(x) -> S(add x y) \n",
    "\n",
    "\n",
    "let rec mul \n",
    "\n",
    "let simplify1 = match t with\n",
    " | Add(x,y) -> add x y\n",
    " | Mul(x,y) -> mul x y\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "smart constructors\n",
    "final vs initial. A final style which has semantics in terms of asts but is quasi normalizing (we're not worried about confluence here). You can't let the thing just rip, because it won't terminate. Well you could with counter.\n",
    "\n",
    "let add x y = match x, y with\n",
    "    | Z, y -> y\n",
    "    | S(x), y -> succ(add x y) vs Succ(add x y) vs succ Add(x,y)\n",
    "\n",
    "\n",
    "defunctionalization\n",
    "\n",
    "https://discord.com/channels/905485733425475626/905485734071369730/1310354032300265512\n",
    "\"\n",
    "I did not come away understanding anything about them except its some kind of divide and conquer methodology for termination. Where you don’t need strict ordering\n",
    "\n",
    "Turn a rewrite problem into a head rewrite problem\n",
    "The Bjørner slides explains this\n",
    "I thought they did a fine job\n",
    "Basically a decompilation phase\n",
    "Turn a rewrite system back into a functional program\n",
    "\n",
    "Slide 2?\n",
    "Hmm, that’s an intriguing analogy\n",
    "I think decompilation may be underdiscussed for PL purposes\n",
    "\n",
    "Maybe\n",
    "\n",
    "There was something about that in vm compute considerations\n",
    "How do you go to byte code to normalize and then return to a term\n",
    "Slash krivine machine whatevers\n",
    "\n",
    "Yeah seems like an interesting topic, I guess\n",
    "Adjacent to my NbE hobby horse\n",
    "\n",
    "Or maybe one could ask how to decompile a fol atp proof into dependent typed one\n",
    "A perspective anyway\n",
    "Analogy\n",
    "I guess talia had some tactic decompilation something something in her proof repair thing\n",
    "\n",
    "Yes\n",
    "I don't think I ever worked out the details\n",
    "Leo seemed skeptical at the time\n",
    "But he is about a lot\n",
    "\n",
    "Compiling a functional program into a term rewriting system looks like nothing\n",
    "How could decompilation look like anything\n",
    "\n",
    "Define functions by blocks of mutual recursion\n",
    "\n",
    "Is mutual recursion definition an explicit term?\n",
    "\n",
    "In e.g. Lean\n",
    "\n",
    "Lean or ocaml has tons of sugar and features\n",
    "I would have identified the core of first order functional programming as being term rewriting \n",
    "But we are making a distinction now\n",
    "Where is the distinction\n",
    "(or functional programs as orthogonal term rewrite systems) \n",
    "Or maybe functional programs as rewrite systems with explicit evaluation rewrite ordering restrictions\n",
    "Evaluation contexts and such\n",
    "I suppose I could write a functional program that kind of mirrors the term rewrite system. Instead of having a monolithic “simplify” function, have one per head\n",
    "\n",
    "Well it could be blocks of mutually defined recursion\n",
    "And I guess what you're allowed to match on\n",
    "Whether you allow non-linear patterns\n",
    "Idk it's a jugement call\n",
    "philzook — Today at 4:40 PM\n",
    "I’m not sure how to think syntactically about blocks of mutual recursion. Or even syntactically think about definitions. Seems kind of meta or higher order\n",
    "Dis association — Today at 4:41 PM\n",
    "Whatever your abstract machine doesn't support\n",
    "philzook — Today at 4:42 PM\n",
    "So I could separate out rules the are nondeterministic or not obeying constructor discipline from the ones that do?\n",
    "Dis association — Today at 4:43 PM\n",
    "Yes, that's often step 1 of a termination analysis\n",
    "philzook — Today at 4:43 PM\n",
    "Hmmm…\n",
    "Dis association — Today at 4:44 PM\n",
    "Non-linearity is horrible\n",
    "And forget about conditional rewriting\n",
    "So fiddly\n",
    "At any rate, I find it compelling to turn a rewrite system into a pair P, R with P being \"mandatory steps\"\n",
    "Basically things you know must happen infinitely often if you diverge\n",
    "\n",
    "hmmm\n",
    "Well i'm intrigued at the idea of slowly moving the term rewriting system up to the metalevel\n",
    "Seem like a useful thing to do anyway, since it'll be a speed boost\n",
    "Maybe it's kind of incrementally moving from an initial style to a final style.\n",
    "let rec add x y =   vs Add(x,y)\n",
    "let simplify t = ... vs let rec add xy = ... and mul x y = ... \n",
    "It is like decompilation in that you can always decompile assembly into one big ass dispatch loop per instruction, but it's nice to recover block structure \n",
    "and only dispatch at block boundaries or back edges or something\n",
    "Or recover structured loops\n",
    "\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "https://www.sciencedirect.com/science/article/pii/S0304397599002078 Termination of term rewriting using dependency pairs\n",
    "Dependency pairs  fraemwork http://cl-informatik.uibk.ac.at/users/thiemann/paper/LPAR04DPFramework.pdf\n",
    "\n",
    "https://drops.dagstuhl.de/storage/00lipics/lipics-vol131-fscd2019/LIPIcs.FSCD.2019.9/LIPIcs.FSCD.2019.9.pdf Dependency Pairs Termination in Dependent Type Theory Modulo Rewriting\n",
    "\n",
    "Wanda \n",
    "\n",
    "\"Dependency pairs aren't that mysterious:\n",
    "Plus(x, S(y)) -> S(Plus(x, y))\n",
    "gives the pair\n",
    "Plus(x, S(y)) -> Plus(x, y)\n",
    "which intuitively is the only bit we really care about re termination.\n",
    "This is the \"ignore the context\" bit you were mentioning.\n",
    "\"\n",
    "\n",
    "\"\n",
    "Dependency pairs: not that tough an idea\n",
    "take a rewrite system R = { l -> r }\n",
    "Define G to be like R, but with every possible subterm of each right hand side\n",
    "so if G is f(x, y) -> g(f(y, x), y) then G is f(x, y) -> g(f(y, x), y) and f(x, y) -> f(y, x)\n",
    "now only allow G steps at the root, and then some arbitrary number of R steps not at the root\n",
    "the theorem is that termination of R <=> there is no infinite reduction of G-root + R non-root steps\n",
    "the idea is that G \"focuses\" the reductions on each possible subterm, ignoring the context\n",
    "now you only need to care about possible infinite sequences of G steps (with in-between R steps)\n",
    "\n",
    "Seems worse\n",
    "G is bigger than r\n",
    "\n",
    "yes but\n",
    "you can observe that some G steps may not follow another G step\n",
    "e.g.\n",
    "times(x, S(y)) -> plus(x, times(x, y))\n",
    "the G steps are times(x, S(y)) -> plus(x, times(x, y)) and times(x, S(y)) -> times(x, y)\n",
    "but there is no outer times rule for times after the first step!\n",
    "so the only \"loop\" for times is the second one\n",
    "the idea is that you can treat each \"mutual recursion\" rules individually\n",
    "often to make this explicit they rename the G head symbols\n",
    "so G is actually TIMES(x, S(y)) -> PLUS(x, times(x, y)) and TIMES(x, S(y)) -> TIMES(x, y)\n",
    "which feels different\n",
    "there's  only one rules that can lead to infinite TIMES steps\n",
    "\n",
    "But we still have all of R\n",
    "\n",
    "but what you need to show is termination of alternating G/R steps\n",
    "so if you prove that there can't be infinitely many G steps you're golden\n",
    "you'll see that in AproVE that's what they're trying to do\n",
    "\"remove\" G rules\n",
    "in practice you replace \"non-trivial\" inner terms by some fresh var \n",
    "so TIMES(x, S(y)) -> PLUS(x, z)\n",
    "that means any plus rule can fire at this point\n",
    "but a PLUS rule can't reach a TIMES rule, so you can prove first termination of PLUS then termination of TIMES\n",
    "but read the paper it's well-written\n",
    "\n",
    "Plus doesnt depend on times. Is that not sufficient to see they can be treated hierarchically?\n",
    "I cant show plus terminates then leave its rules out and show times terminates?\n",
    "How could termination checking possibly work in coq then\n",
    "\n",
    "Yes you can, but in TRSes things are not generally so modular\n",
    "\"depends on\" is basically what the dependency pair relation captures\n",
    "you can have crazy rules like plus(x, x) -> times(2, x)\n",
    "does that terminate?\n",
    "anyways\n",
    "\n",
    "I’m suspicious.\"\n",
    "\n",
    "simplification pair \n",
    "reduction order\n",
    "order eakly, delete strict pieces\n",
    "SCC dependency graph\n",
    "\n",
    "\n",
    "https://aprove.informatik.rwth-aachen.de/download\n",
    "\n",
    "https://matryoshka-project.github.io/wait2018/ WAIT Workshop on Automated (Co)inductive Theorem Proving\n",
    "HipSpec https://www.cse.chalmers.se/~jomoa/papers/hipspec-atx.pdf\n",
    "https://dmg.tuwien.ac.at/hetzl/teaching/d_vierling.pdf The limits of automated\n",
    "inductive theorem provers 2023 thesis\n",
    "vampire has induction support. What does it look like?\n",
    "https://www.cse.chalmers.se/~jomoa/papers/cicm15-TIP.pdf tons of inductive problems https://github.com/tip-org\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A core method of termination is to solve for a term order that meets your needs.\n",
    "If you're given a pile of equations, you could need to make choices about which direction they should point.\n",
    "\n",
    "For string rewriting / string equations variables don't matter that much\n",
    "\n",
    "It may be useful to maxsat this termination rather than insist it simply works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cvxpy\n",
    "import z3\n",
    "from dataclasses import dataclass\n",
    "from collections import namedtuple\n",
    "\n",
    "Var = namedtuple(\"Var\", \"name\")\n",
    "Fn = namedtuple(\"Fn\", \"head args\")\n",
    "#(RULES\n",
    "#    plus(0,y) -> y\n",
    "#    plus(s(x),y) -> s(plus(x,y))\n",
    "#)\n",
    "rules = [\n",
    "    (Fn(\"f\", [Var(\"x\")]), Var(\"x\")),\n",
    "    (Fn(\"plus\", [Fn(\"s\", [Var(\"x\")]), Var(\"y\")]), Fn(\"s\", [Fn(\"plus\", [Var(\"x\"), Var(\"y\")])])),\n",
    "    (Fn(\"plus\", [Fn(\"0\", []), Var(\"y\")]), Var(\"x\")),\n",
    "]\n",
    "\n",
    "def weight(t):\n",
    "    if isinstance(t, Var):\n",
    "        return z3.Int(\"__varweight\")\n",
    "    elif isinstance(t, Fn):\n",
    "        return z3.Int(t.head) + sum(weight(a) for a in t.args)\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected term {t}\")\n",
    "\n",
    "s = z3.Solver()\n",
    "for (lhs,rhs) in rules:\n",
    "    s.add(weight(lhs) > weight(rhs))\n",
    "print(s)\n",
    "s.check()\n",
    "#m = s.model()\n",
    "#m\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LinTerm(dict):\n",
    "    \"\"\" Linear terms like 1 + 2x + 3y implemented as dictionary {None: 1, \"x\": 2, \"y\": 3}\"\"\"\n",
    "    def __add__(self, other):\n",
    "        if isinstance(other, dict): # vector addition\n",
    "            res = LinTerm(self)\n",
    "            for k,v in other.items():\n",
    "                res[k] = res.get(k, z3.IntVal(0)) + v\n",
    "        else: # scalar addition\n",
    "            res = LinTerm(self)\n",
    "            print(\"here\", other)\n",
    "            res[None] = res.get(None, z3.IntVal(0)) + other\n",
    "            return res\n",
    "        return res\n",
    "    def __mul__(self,other): #scalar multiplication\n",
    "        if isinstance(other, dict):\n",
    "            raise ValueError(\"Multiplication of linear terms not supported\")\n",
    "        res = LinTerm()\n",
    "        for k,v in self.items():\n",
    "            res[k] = v * other\n",
    "        return res\n",
    "    def __rmul__(self,other):\n",
    "        return self * other\n",
    "    def __radd__(self,other):\n",
    "        return self + other\n",
    "    def str(self):\n",
    "        return \" + \".join([f\"{v} * {k}\" for k,v in self.items()])\n",
    "    def repr(self):\n",
    "        return \" + \".join([f\"{v} * {k}\" for k,v in self.items()])\n",
    "    def __lt__(self,other):\n",
    "        if not isinstance(other, dict):\n",
    "            raise ValueError(\"Comparison of linear terms not supported\")\n",
    "        return z3.And([self.get(k,z3.IntVal(0)) < other.get(k,z3.IntVal(0)) for k in set(self.keys()).union(other.keys())])\n",
    "\n",
    "\n",
    "def poly_interp(head):\n",
    "    def res(*args):\n",
    "        arity = str(len(args))\n",
    "        print(\"here\")\n",
    "        print(z3.Int(head + \"_\" + arity + \"_\" + str(0)))\n",
    "        for i,a in enumerate(args):\n",
    "            print(a)\n",
    "            print( a * z3.Int(head + \"_\" + arity + \"_\" + str(i)) + z3.Int(head + \"_\" + arity))\n",
    "        return sum(a * z3.Int(head + \"_\" + arity + \"_\" + str(i)) for (i,a) in enumerate(args)) + z3.Int(head + \"_\" + arity) \n",
    "    return res\n",
    "\n",
    "def weight(t):\n",
    "    if isinstance(t, Var):\n",
    "        return LinTerm({t.name: 1})\n",
    "    elif isinstance(t, Fn):\n",
    "        return poly_interp(t.head)(*map(weight, t.args))\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected term {t}\")\n",
    "\n",
    "s = z3.Solver()\n",
    "for (lhs,rhs) in rules:\n",
    "    s.add(weight(lhs) > weight(rhs))\n",
    "s.check()\n",
    "s.model()\n",
    "\n",
    "def pp(model):\n",
    "    interp = {}\n",
    "    for d in model.decls():\n",
    "        v = model[d]\n",
    "        match d.name().split(\"_\"):\n",
    "            case (head,arity):\n",
    "                interp[head] = interp.get(head, LinTerm()) + {None: v}\n",
    "            case (head,arity,i):\n",
    "                interp[head] = interp.get(head, LinTerm()) + {\"x\" + str(i): v}\n",
    "\n",
    "        return interp\n",
    "pp(s.model())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer transition systems\n",
    "\n",
    "# cond -> rhs\n",
    "x,y,z = z3.Ints(\"x y z\")\n",
    "vars = (x,y,z)\n",
    "rules = [\n",
    "    (x >= 0, (x - 1, y, z)),\n",
    "    (y >= 0, (x, y - 1, z)),\n",
    "]\n",
    "\n",
    "# linear measure ax + by + cz\n",
    "a,b,c = z3.Ints(\"a b c\")\n",
    "\n",
    "for constr, (x1,y1,z1) in rules:\n",
    "    s.add(z3.ForAll([x,y,z], z3.Implies(constr, a*x + b*y + c*z > a*x1 + b*y1 + c*z1)))\n",
    "s.check()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "lexer = [\n",
    "    (r\"\\s+\", None),\n",
    "    (r\"\\d+\", \"INT\"),\n",
    "    (r\"\\w+\", \"ID\"),\n",
    "    (\"RULES\", \"RULES\"),\n",
    "    (\"VAR\", \"VAR\")\n",
    "    (r\"\\(\", \"LPAREN\"),\n",
    "    (r\"\\)\", \"RPAREN\"),\n",
    "    (r\"->\", \"ARROW\"),\n",
    "]\n",
    "\n",
    "re.compiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " lexicographic vector measure. f(x) > f(x1) or f(x) == f(x1) and g(x) > g(x1)\n",
    " It's all easy enough to state. The quantifier gives me unease though.\n",
    " CEGAR it?\n",
    " I mean actually a single exaple problem would be nice\n",
    " https://aprove.informatik.rwth-aachen.de/interface/v-AProVE2023/itrs\n",
    " https://aprove.informatik.rwth-aachen.de/interface/v-AProVE2023/inttrs\n",
    "\n",
    " koat and loat are like this right?\n",
    " https://arxiv.org/pdf/2202.04546.pdf https://koat.verify.rwth-aachen.de/\n",
    "\n",
    " polygonal loops\n",
    "\n",
    " f(x,y,z) -> f(x + 1, y - 2)  is a integer transition system.\n",
    " changing the top symbol is a way of adding finite state to this.\n",
    "\n",
    " https://koat.verify.rwth-aachen.de/\n",
    " https://aprove.informatik.rwth-aachen.de/interface/v-koat/c a secret koat web demo oooh\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial interpretation does give a weight to each symbol, but also gives a weighting to each possible subterm. That rules.\n",
    "\n",
    "iteratively apply to prune.\n",
    "\n",
    "right ground systems have decidable termination.\n",
    "ground systems also have \n",
    "\n",
    "for knuckledragger.\n",
    "- critical pair checker. No critical pairs = confluent. foo(a,b) = bar(b,c) should be unsat\n",
    "- termin checker = polynomial interp. structurally decreasing is good, but we can do better. Build in integers\n",
    "- completeness checker = could just give default value? Isn't unsound persay.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nat = z3.Datatype(\"Nat\")\n",
    "Nat.declare(\"zero\")\n",
    "Nat.declare(\"s\", (\"pred\", Nat))\n",
    "Nat = Nat.create()\n",
    "\n",
    "plus = z3.Function(\"plus\", Nat, Nat, Nat)\n",
    "x,y = z3.Consts(\"x y\", Nat)\n",
    "defns = [\n",
    "    z3.ForAll([x], plus(Nat.zero, x) == x),\n",
    "    z3.ForAll([x,y], plus(Nat.s(x), y) == Nat.s(plus(x,y)))\n",
    "]\n",
    "\n",
    "# more split up and easier to check.\n",
    "# defining fun sym. pat vars, pattern, rhs\n",
    "defns2 = plus, [\n",
    "    ([x], (Nat.zero, x), x),\n",
    "    ([x,y], (Nat.s(x), y), Nat.s(plus(x,y)))\n",
    "]\n",
    "\n",
    "def check_defn(defns):\n",
    "    for defn in defns:\n",
    "        assert defn.is_forall()\n",
    "        for v in defn.num_vars()\n",
    "            defn.var_name(v)\n",
    "    defn.body()\n",
    "    # check symbol undefined \n",
    "    # quantifier free\n",
    "\n",
    "    # check top symbol on lhs is same\n",
    "\n",
    "    # check no overlap\n",
    "\n",
    "    # check termination\n",
    "\n",
    "def check_thm():\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(defns[0])\n",
    "defn = defns[1]\n",
    "#defn.weight()\n",
    "dir(defn)\n",
    "b = defn.body()\n",
    "#dir(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subterms(t):\n",
    "    if isinstance(t, Var):\n",
    "        return\n",
    "    yield t\n",
    "    if isinstance(t, Fn):\n",
    "        for a in t.args:\n",
    "            yield from subterms(a)\n",
    "\n",
    "def capital(t):\n",
    "    \"\"\"replace head symbol with new thing. Why?\"\"\"\n",
    "    if isinstance(t, Fn):\n",
    "        return Fn(t.head.capitalize(), t.args)\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected term {t}\")\n",
    "    \n",
    "def dependency_pairs(lhs,rhs):\n",
    "    for t in subterms(rhs):\n",
    "        yield (lhs,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/prolog.pl\n",
    "%query: append(b,f,f)\n",
    "append(nil,L,L).\n",
    "append(cons(X,Xs),Ys,cons(X, Zs)) :- append(Xs,Ys,Zs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! java -ea -cp ~/Documents/solvers/aprove.jar aprove.CommandLineInterface.PrologFrontendMain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! java -ea -cp ~/Documents/solvers/aprove.jar aprove.CommandLineInterface.PrologFrontendMain /tmp/prolog.pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(VAR T17 T18)\n",
    "(PAIRS\n",
    "  F1_IN(cons(T17, T18)) -> U1^1(f1_in(T18), cons(T17, T18))\n",
    "  F1_IN(cons(T17, T18)) -> F1_IN(T18)\n",
    ")\n",
    "(RULES\n",
    "  f1_in(nil) -> f1_out1\n",
    "  f1_in(cons(T17, T18)) -> U1(f1_in(T18), cons(T17, T18))\n",
    "  U1(f1_out1, cons(T17, T18)) -> f1_out1\n",
    ")\n",
    "(Q\n",
    ")\n",
    "(EDGES\n",
    "    2 -> 1\n",
    "    2 -> 2\n",
    ")\n",
    "(MINIMAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/hask.hs\n",
    "{-# htermination (foldr1 :: (a -> a -> a) -> (List a) -> a) #-}\n",
    "\n",
    "\n",
    "import qualified Prelude\n",
    "\n",
    "\n",
    "data MyBool = MyTrue | MyFalse\n",
    "\n",
    "data List a = Cons a (List a) | Nil\n",
    "\n",
    "\n",
    "foldr1 :: (a -> a -> a) -> (List a) -> a\n",
    "\n",
    "foldr1 f (Cons x Nil) = x\n",
    "\n",
    "foldr1 f (Cons x xs) = f x (foldr1 f xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! java -ea -cp ~/Documents/solvers/aprove.jar aprove.CommandLineInterface.HaskellFrontendMain  /tmp/hask.hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(VAR vx3 vx40 vx410 vx411 h)\n",
    "(PAIRS\n",
    "  new_foldr1(vx3, Cons(vx40, Cons(vx410, vx411)), h) -> new_foldr1(vx3, Cons(vx410, vx411), h)\n",
    ")\n",
    "(RULES\n",
    ")\n",
    "(Q\n",
    ")\n",
    "(EDGES\n",
    "    1 -> 1\n",
    ")\n",
    "(MINIMAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Termination is the question of whether some dynamical system will always eventually stop.\n",
    "The \"dyanamical system\" in question is usually a term rewriting system (rules describing simplifying or evaluating exressions like `x + 0 -> x` or `append(cons(a,x), y) -> cons(append(x,y))`). The state here is the current term and the dynamics are described by the rules. There are an infinite number of posssible terms/states to consider here. What is there to do?\n",
    "\n",
    "An old notion of termination is that of a fixed point. The differential equation `y' = -y` has solutions $y = C e ^ {-x}$. We can see that this is a decaying solution heading to `y = 0`. We could also find this fixed point by finding where `'y = 0` which mean `y = 0`.\n",
    "Lyapunov functions are certificates for regions of decay.\n",
    "\n",
    "It perhaps helps to consider a system with a finite number of states. It then is clearly more tractable to consider the question of whether a system will eventually get stuck. If we think about it, this is equivalent to just checking if there is a loop in the transition graph.\n",
    "\n",
    "For infinite state systems the problem is more tricky. We can't exhaustively be sure there are no loops by just checking each state.\n",
    "\n",
    "Termination is important in mathematics and program analysis. If you alow a non-terminating definition of a function into your logical system\n",
    "For program analysis, if you can guarantee some loop doesn't terminate, you can ignore whatever comes after it. If you can guarantee it always terminates, you can perhaps lift code that comes after to before the loop or rearrange call sites. A guaranteed terminating piece of pure code behaves more like an ideal mathematical function and is more easy to reason and manipulate correctly. If a compiler can't reason, it is not allowed to perform optimizatins and may emit pessimistic code. This may produce better code from a compiler. Having some exact bounds of the maximum number of iterations may unlock even more. For some loops (like fixed parameter for loops) this may be very easy to do, for some nasty while loop it may not.\n",
    "For verification purposes, it may be desirable to state and prove that a function always returns an answer with such and such result.\n",
    "\n",
    "There is a class of solver called a termination checker\n",
    "\n",
    "The core notion of a measure is some natural number that goes down and is bounded below by zero, like the length of a list. With enough squinting, other termination certificates are generalizations of this intuitive idea.\n",
    "\n",
    "The idea of a well-founded relation is in essence trying to just define what it means for something to eventually always stop and our basic notion of something that always stops is a decreasing natural number.\n",
    "\n",
    "<https://cstheory.stackexchange.com/questions/34316/is-there-a-good-notion-of-non-termination-and-halting-proofs-in-type-theory>\n",
    "\n",
    "`zero = cons(0,zero)` is \"ok\". It has a model N -> N? Maybe non terminating definitions can interfere with the foundation axiom in some bad way. or `fact(n) = n == 0? 1 : n * fact(n-1)` when `n < 0` runs off to infinity, but maybe some ordinal or hyperinteger model can handle it?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
