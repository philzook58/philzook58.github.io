{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/salykova/matmul.c https://salykova.github.io/matmul-cpu\n",
    "https://github.com/flame/blis\n",
    "\n",
    "https://github.com/DeepWok/mase\n",
    "\n",
    "\n",
    "So what would a minimal tensor compiler, scheduling guy look like?\n",
    "I need to output C++ code / Cuda / C++ simd ionstrinsics\n",
    "Oleg style C\n",
    "\n",
    "Could dynlink in the kernel. Or is it easier to just subprocess it?\n",
    "use that pytorch compile thing https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html\n",
    "https://cppyy.readthedocs.io/en/latest/index.html\n",
    "\n",
    "Ideas:\n",
    "Blur\n",
    "Will melt - deform, \n",
    "wave\n",
    "heat\n",
    "reaction diffusion\n",
    "coulomb\n",
    "polybench problems?\n",
    "\n",
    "Arguably, computer perf is good for the environment.\n",
    "\n",
    "\n",
    "- https://commit.csail.mit.edu/papers/2021/vegen.pdf  VeGen: A Vectorizer Generator for SIMD and Beyond\n",
    "- https://github.com/GiorgioZacharo/AccelSeeker https://ieeexplore.ieee.org/abstract/document/8988767 Compiler-Assisted Selection of Hardware Acceleration Candidates from Application Source Code\n",
    "- https://dl.acm.org/doi/10.1145/3580394 Trireme: Exploration of Hierarchical Multi-level Parallelism for Hardware Acceleration\n",
    "- https://devashreetrip.github.io/publication/FARSI_TECS_CameraReady.pdf FARSI: An Early-stage Design Space Exploration\n",
    "Framework to Tame the Domain-specific System-on-chip\n",
    "Complexity\n",
    "- ithermal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/SYCL\n",
    "https://en.wikipedia.org/wiki/Standard_Portable_Intermediate_Representation\n",
    "https://en.wikipedia.org/wiki/Vulkan\n",
    "\n",
    "https://www.cs.tufts.edu/~nr/pubs/gentileset.pdf\n",
    "\n",
    "\n",
    "ACM ConferencesACM Conferences\n",
    "Lightweight, Modular Verification for WebAssembly-to-Native Instruction Selection | Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1 (25 kB)\n",
    "https://dl.acm.org/doi/10.1145/3617232.3624862\n",
    "\n",
    "\n",
    "https://dl.acm.org/doi/pdf/10.1145/2400682.2400716\n",
    "\n",
    "https://arxiv.org/pdf/1905.10434\n",
    "\n",
    "ACM ConferencesACM Conferences\n",
    "Vector instruction selection for digital signal processors using program synthesis | Proceedings of the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems (13 kB)\n",
    "https://dl.acm.org/doi/10.1145/3503222.3507714\n",
    "\n",
    "https://arxiv.org/pdf/2207.00257 code movement on loop-invariant code between CPU/GPU translation units (edited) \n",
    "\n",
    "https://wsmoses.com/academic/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.diva-portal.org/smash/get/diva2:1806967/FULLTEXT01.pdf Omelette intervals for daisy\n",
    "\n",
    "https://only.rs/assets/papers/COS539Report.pdf CatsTail: Packet programs synthesis via Equality Saturation. P4 equality sautration\n",
    "\n",
    "https://ieeexplore.ieee.org/document/10444787 A Tensor Algebra Compiler for Sparse Differentiation\n",
    "\n",
    "https://arxiv.org/abs/2403.14242 E-Syn: E-Graph Rewriting with Technology-Aware Cost Functions for Logic Synthesis\n",
    "\n",
    "http://www.paramathic.com/wp-content/uploads/2024/04/REV_PLDI_rev2.pdf SpEQ: Translation of Sparse Codes using Equivalences\n",
    "\n",
    "https://arxiv.org/abs/2404.05431 Simplifying MBA Expression Using E-Graphs\n",
    "\n",
    "https://arxiv.org/abs/2404.08106  KestRel: Relational Verification Using E-Graphs for Program Alignment\n",
    "\n",
    "https://arxiv.org/pdf/2404.08751 Performant Dynamically Typed E-Graphs in Pure Julia. Opttifloat.\n",
    "\n",
    "https://www.sosy-lab.org/research/pub/2023-Draft.LemmaCalc.pdf Quick Theory Exploration for Algebraic Data Types via Program Transformations\n",
    "\n",
    "https://uwspace.uwaterloo.ca/handle/10012/20590 Programmatic Representation of Quantum Many Body Systems\n",
    "\n",
    "https://michel.steuwer.info/files/publications/2024/EGRAPHS-2024.pdf slotted egraph\n",
    "\n",
    "https://ieeexplore.ieee.org/abstract/document/10549954?casa_token=osGlQxs8m0cAAAAA:lBVQ_DaNHuu58QIc8WE2lOQ1InlvHENufwmDWPGmpnP3npNxFLJx7LrzFgWto2lqz2Bd1ULd5PrJgQ ROVER: RTL Optimization via Verified E-Graph Rewriting\n",
    "\n",
    "\n",
    "https://mastodon.social/@grosser/112693804018663392  Falcon: A Scalable Analytical Cache Model\n",
    "\n",
    "presburger\n",
    "\n",
    " Pluto, PoCC, Polly, Graphite, PolyOpt, PPCG, and Polygeist.  https://github.com/vincentloechner/PolyhedralCompilers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(body):\n",
    "    return \"int main(){\" + body + \"return 0;}\"\n",
    "\n",
    "def type_of_shape(shape):\n",
    "    if len(shape) == 1:\n",
    "        return \"vector<int>\"\n",
    "    else:\n",
    "        return \"vector<vector<int>>\"\n",
    "\n",
    "def numpy_const(x):\n",
    "     return f\"{type_of_shape(x.shape)} {x.name} = {x.to_string(\"\n",
    "\n",
    "def matrix_multiply(a,b):\n",
    "     = a.shape\n",
    "     = b.shape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.31046626,  0.65844833,  0.07906275,  1.9617434 ,  1.42294726,\n",
       "         0.20204498,  0.40687659,  0.67967967, -0.00870005],\n",
       "       [ 3.54828591,  2.34538197,  1.96419394,  5.37431379,  3.33590376,\n",
       "        -0.35761729,  1.02769102,  1.11851864, -0.26513445],\n",
       "       [ 3.62105505,  3.27176744,  1.72605773,  1.19710883, -1.33067401,\n",
       "        -0.06654727, -1.01015221, -2.05987732, -2.42009655],\n",
       "       [ 3.4558572 ,  3.17985693,  0.49590552, -0.97296426, -2.69173456,\n",
       "         0.80930476,  1.9448902 ,  0.4162344 ,  1.06708111],\n",
       "       [ 0.57190069,  1.78356123, -1.51150129, -1.48969576,  1.1230824 ,\n",
       "         2.50065244,  3.24586681,  3.49688147,  3.71579744],\n",
       "       [ 0.88945686,  4.93068064,  0.60081222, -2.11282168,  1.36769066,\n",
       "         2.35703195,  0.41602892,  0.7976928 ,  0.03607092],\n",
       "       [ 0.66529984,  2.29259899,  0.81820352,  0.40120943,  1.66383995,\n",
       "        -0.56748654, -0.60277451,  2.2396351 ,  0.91317627],\n",
       "       [ 0.66636054, -0.10556659, -0.32316119,  0.95568744,  1.23081266,\n",
       "        -2.90894993, -1.28331082,  2.88038446,  2.00651862],\n",
       "       [ 1.96458533,  2.28375555,  0.9000126 ,  0.98802625, -0.03171931,\n",
       "        -3.40004844, -2.5444537 ,  1.00855292,  1.48019104]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "img = np.random.randn(10,10)\n",
    "\n",
    "def blurx(x):\n",
    "    return x[1:,:] + x[:-1,:]  \n",
    "def blury(x):\n",
    "    return x[:,1:] + x[:,:-1]  \n",
    "    #return np.convolve(x, [0.1, 0.8, 0.1], mode='same')\n",
    "img\n",
    "blury(blurx(img))\n",
    "\n",
    "def extend_x(img):\n",
    "    return np.concatenate([img, img[-1:,:]], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML compiler\n",
    "https://arxiv.org/abs/2311.10800a The Next 700 ML-Enabled Compiler Optimizations https://compilers.cse.iith.ac.in/publications/mlcompilerbridge/\n",
    "CGO \n",
    "https://github.com/IITH-Compilers/IR2Vec \n",
    "\n",
    "https://github.com/zwang4/awesome-machine-learning-in-compilers\n",
    "https://github.com/merrymercy/awesome-tensor-compilers\n",
    "\n",
    "autotuning\n",
    "https://zwang4.github.io/publications/pieee18.pdf survey of ml for compilers. Autotuning. Iterative compilation.\n",
    "\n",
    "https://arxiv.org/abs/2002.03794 deep learning compiler a ocmprehensive surfvey\n",
    "glow tvm xla. Polyhedral IRs \n",
    "\n",
    "https://dl.acm.org/doi/10.1145/3408974 Achieving high-performance the functional way: a functional pearl on expressing high-performance optimizations as rewrite strategies\n",
    "\n",
    "https://www.youtube.com/watch?v=f2NEU1ENt6A&t=3s  Verified Tensor-Program Optimization Via High-Level Scheduling Rewrites \n",
    "\n",
    "Verifying and Improving Halideâ€™s Term Rewriting System with Program Synthesis https://www.youtube.com/watch?v=rcGZwLYnK_M&ab_channel=ACMSIGPLAN https://dl.acm.org/doi/10.1145/3428234. z3 + coq. They nmodel halide rewrite rules. Cegis for given term order. Huh\n",
    "\n",
    "\n",
    "WHat about my numpy knuckeldragger.\n",
    "Breaking up domain into tiles. How to model? HOL of index sets?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "Z3Exception",
     "evalue": "b'Sort mismatch at argument #1 for function (declare-fun or (Bool Bool) Bool) supplied sort is (Array Int Bool)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZ3Exception\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m d1 \u001b[38;5;241m=\u001b[39m Lambda([x], And(x \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, x \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m16\u001b[39m))\n\u001b[1;32m     12\u001b[0m d2 \u001b[38;5;241m=\u001b[39m Lambda([x], And(x \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m, x \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m32\u001b[39m))\n\u001b[0;32m---> 13\u001b[0m prove(d \u001b[38;5;241m==\u001b[39m (d1 \u001b[38;5;241m|\u001b[39m d2))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/z3/z3.py:1600\u001b[0m, in \u001b[0;36mBoolRef.__or__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1599\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__or__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m-> 1600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/z3/z3.py:1952\u001b[0m, in \u001b[0;36mOr\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   1950\u001b[0m args \u001b[38;5;241m=\u001b[39m _coerce_expr_list(args, ctx)\n\u001b[1;32m   1951\u001b[0m _args, sz \u001b[38;5;241m=\u001b[39m _to_ast_array(args)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BoolRef(\u001b[43mZ3_mk_or\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_args\u001b[49m\u001b[43m)\u001b[49m, ctx)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/z3/z3core.py:1926\u001b[0m, in \u001b[0;36mZ3_mk_or\u001b[0;34m(a0, a1, a2, _elems)\u001b[0m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mZ3_mk_or\u001b[39m(a0, a1, a2, _elems\u001b[38;5;241m=\u001b[39mElementaries(_lib\u001b[38;5;241m.\u001b[39mZ3_mk_or)):\n\u001b[1;32m   1925\u001b[0m   r \u001b[38;5;241m=\u001b[39m _elems\u001b[38;5;241m.\u001b[39mf(a0, a1, a2)\n\u001b[0;32m-> 1926\u001b[0m   \u001b[43m_elems\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1927\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/z3/z3core.py:1554\u001b[0m, in \u001b[0;36mElementaries.Check\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m   1552\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_error_code(ctx)\n\u001b[1;32m   1553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mOK:\n\u001b[0;32m-> 1554\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mException(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_error_message(ctx, err))\n",
      "\u001b[0;31mZ3Exception\u001b[0m: b'Sort mismatch at argument #1 for function (declare-fun or (Bool Bool) Bool) supplied sort is (Array Int Bool)'"
     ]
    }
   ],
   "source": [
    "from  z3 import *\n",
    "dom = ArraySort(IntSort(), BoolSort())\n",
    "vec = ArraySort(IntSort(), RealSort())\n",
    "x = Const('x', IntSort())\n",
    "ExprRef.__and__ = lambda self, other: Lambda([x], And(self[x], other[x]))\n",
    "ExprRef.__or__ = lambda self, other: Lambda([x], Or(self[x], other[x]))\n",
    "ExprRef.__add__ = lambda self, other: Lambda([x], self[x] + other[x])\n",
    "\n",
    "a,b = Consts(\"a b\", vec)\n",
    "d = Lambda([x], And(x >= 0, x < 32))\n",
    "d1 = Lambda([x], And(x >= 0, x < 16))\n",
    "d2 = Lambda([x], And(x >= 16, x < 32))\n",
    "prove(d == (d1 | d2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Egraph\n",
    "\n",
    "\n",
    "tensat - TASO\n",
    "glenside\n",
    "\n",
    "Spore\n",
    "etc.\n",
    "\n",
    "https://egraphs.org/meeting/2024-04-18-sparse-tensor-diff Amir Shaikhha - A Tensor Algebra Compiler for Sparse Differentiation.\n",
    "Max had one\n",
    "Thomas Koehler RISE\n",
    "\n",
    "https://dl.acm.org/doi/10.1145/3620665.3640392 SEER mlir\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "twee experimensz\n",
    "3z\n",
    "\n",
    "## diospyros \n",
    "\n",
    "\n",
    "Vec4Add\n",
    "Vec4Mul\n",
    "Vec2Add \n",
    "Vec2Mul\n",
    "\n",
    "Duplicate out the rules.\n",
    "\n",
    "Generatying simd code and running it\n",
    "Maybe gdb isn't crazy.\n",
    "\n",
    "Samuel Thomas\n",
    "\n",
    "scalar -> vector\n",
    "\n",
    "Kind of a compiler, but also kind of a deocmpiler.\n",
    "fully unroll concrete loops\n",
    "concrete 4d 2d vectors\n",
    "Return vector results\n",
    "0 packing sometimes needed\n",
    "x + y + z\n",
    "\n",
    "rule phasing - scalrar -> scalar, scalar -> vector, vector -> vector\n",
    "Automatic discovery via ruler\n",
    "\n",
    "schedling egraphs vs egraphs for scheduling. Hmm. Is it a conicience\n",
    "\n",
    "Yihong is doing egraphs for halide\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking\n",
    "I should probably know what it is I want to do manually first\n",
    "benchamrking infra... hmm.\n",
    "https://github.com/google/benchmark\n",
    "https://github.com/google/benchmark/blob/main/docs/user_guide.md\n",
    "https://github.com/google/benchmark/blob/main/docs/tools.md compare\n",
    "\n",
    "https://quick-bench.com/\n",
    "https://perfbench.com/\n",
    "https://github.com/chronoxor/CppBenchmark\n",
    "https://github.com/sharkdp/hyperfine\n",
    "\n",
    "https://ashvardanian.com/posts/google-benchmark/\n",
    "\n",
    "Oh it outputs json or scv. hmm\n",
    "https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/54db51700fabe094cbf7f11f5195d2bd/benchmark.ipynb\n",
    "pytorch benchmark\n",
    "timeit.Timer\n",
    "torch.utils.benchamrk.TImer\n",
    "Callgrind\n",
    "\n",
    "\n",
    "\n",
    "uttotuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/bench.cpp\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/bench.cpp\n",
    "#include <benchmark/benchmark.h>\n",
    "\n",
    "static void BM_StringCreation(benchmark::State& state) {\n",
    "  for (auto _ : state)\n",
    "    std::string empty_string;\n",
    "}\n",
    "// Register the function as a benchmark\n",
    "BENCHMARK(BM_StringCreation);\n",
    "\n",
    "// Define another benchmark\n",
    "static void BM_StringCopy(benchmark::State& state) {\n",
    "  std::string x = \"hello\";\n",
    "  for (auto _ : state)\n",
    "    std::string copy(x);\n",
    "}\n",
    "BENCHMARK(BM_StringCopy);\n",
    "\n",
    "BENCHMARK_MAIN();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23T11:57:08-04:00\n",
      "Running /tmp/mybenchmark\n",
      "Run on (8 X 3900 MHz CPU s)\n",
      "CPU Caches:\n",
      "  L1 Data 48 KiB (x4)\n",
      "  L1 Instruction 32 KiB (x4)\n",
      "  L2 Unified 512 KiB (x4)\n",
      "  L3 Unified 8192 KiB (x1)\n",
      "Load Average: 2.59, 2.10, 1.96\n",
      "***WARNING*** CPU scaling is enabled, the benchmark real time measurements may be noisy and will incur extra overhead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Benchmark                  Time             CPU   Iterations\n",
      "------------------------------------------------------------\n",
      "BM_StringCreation       3.53 ns         3.53 ns    189533532\n",
      "BM_StringCopy           8.32 ns         8.32 ns     81841079\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "g++ /tmp/bench.cpp -std=c++11 -isystem ~/Downloads/benchmark/include \\\n",
    "  -L ~/Downloads/benchmark/build/src -lbenchmark -lpthread -o /tmp/mybenchmark\n",
    "/tmp/mybenchmark # --benchmark_out_format=json --benchmark_out=/tmp/bench.json\n",
    "# compare.py benchmarks /tmp/mybenchmark /tmp/mybenckmark2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TVM\n",
    "Relay - functional and statically typed ir\n",
    "Offer laide liuke interfrace te tesnro exprwsssion s\n",
    "https://www.youtube.com/watch?v=JmWWAnHBDx0&ab_channel=HarvardCS249R%3AIntrotoTinyML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLIR\n",
    "\n",
    "mlir is top evle mdule.\n",
    "list of regions\n",
    "list of blocks\n",
    "list of operations\n",
    "\n",
    "linked lists.\n",
    "\n",
    "https://mlir.llvm.org/doxygen/mlir-c_2IR_8h.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/mlir.cpp\n",
    "mlirOperationGetNumRegions\n",
    "mlirOPerationGetRegion\n",
    "\n",
    "mlirRegionGetFirstBLock\n",
    "mlirRegionGetNextInRegion\n",
    "\n",
    "MlirContext context = mlirContectCreate()\n",
    "\n",
    "modukle = mlirOPerationCreateParse(cotext, mlirStringRefCreateFromCStrig(\"contents of module\"), mlirStrngRefCreateFromCString(\"FILENAME\"))\n",
    "\n",
    "MlirRegion body = mlirOPerationGetFirstRegion(module)\n",
    "mlirRegionGetFirstBlock(body)\n",
    "mlirSDymblTabeGetVisibilityAttritbuteName()\n",
    "publicVisibility = mlirStringRefCreateFromCString(\"public\")\n",
    "\n",
    "for(MlirOperation op = mlirBlockGetFirstOPeration() ; !mlirOPerationisNull(op); op = mlirOperationGetNextInBlock(op)){\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C API https://mlir.llvm.org/docs/CAPI/\n",
    "Ownership model\n",
    "\n",
    "Mlir<Type> mlir<Type>Create(mlirContextRef context, ...);\n",
    "caller owns result and must destroy or transfer\n",
    "\n",
    "\n",
    "operation states\n",
    "\n",
    "list of owned regions\n",
    "\n",
    "works for any dialect but may be slow because of string name lookup\n",
    "\n",
    "does not call the build function\n",
    "does not verify\n",
    "\n",
    "creatingf type\n",
    "no generic fromat unlike operations\n",
    "requires defining additional functions\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/mlir.c\n",
    "#include \"mlir-c/IR.h\"\n",
    "\n",
    "MlirContext = mlirContextCreate()\n",
    "MlirOperationState strate = mlirOPerationStateGet()\n",
    "\n",
    "\n",
    "mlirOPertationDestroy(op)\n",
    "mlirContextDestroy(context)\n",
    "\n",
    "\n",
    "#ifdef __cpluplus\n",
    "extern \"C\" {\n",
    "#endif\n",
    "\n",
    "MLIR_DECLARE_CAPI_DIALECT_REGISTRATION(\n",
    "    Transform, transform\n",
    ")\n",
    "\n",
    "MLIR_CAPI_EXPORTED\n",
    "\n",
    "using interfaces\n",
    "\n",
    "mutating IR from C\n",
    "\n",
    "#include \"ml9ir-C/pass.h\"\n",
    "\n",
    "void run PassPipeline(MLIr COntext context, MLirOperation module){\n",
    "    MlirPassManager pm = mlirPassManagerCreateOnOperation(context, mlirStringRefCreateFromCString(\"builtin.module\"));\n",
    "    MlirOpPassManager opm = mlirPassManagerGetOpPassmanager(pm);\n",
    "    char *error = 0;\n",
    "    mlirParsePassPipeline(opm, mlirCreateStringRefFromCString(\"canonicalize, cse, transform.canonicalize\", appendError, error);\n",
    "    if mlirLogicalResultisFauilure(result)){\n",
    "\n",
    "    }\n",
    "}\n",
    "\n",
    "You need to regsiter passes and stuff with context before you use it.\n",
    "mlirRegsiterTranbsformCSE()\n",
    "mlirResgiterTransdformsCSE()\n",
    "mlirResgiter....\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "strcuct MlirExternalPassCallabcks{\n",
    "    void *(construct) // Pass::Pass\n",
    "    void *(destruct) // Pass::~Pass\n",
    "    initialize // Pass::initialize(Mlircontext *)\n",
    "    clone // Pass::clonePass()\n",
    "    run // Pass::runOnOperation()\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mlir from python\n",
    "https://mlir.llvm.org/docs/Bindings/Python/\n",
    "\n",
    "\n",
    "MLir resgitration merchanism is hard\n",
    "everything must be linked into one big library\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"PYTHONPATH\"] = os.path.abspath(\"/home/philip/Downloads/llvm-project/build/tools/mlir/python_packages/mlir_core\") + \":\" + os.environ.get(\"PYTHONPATH\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/philip/Downloads/llvm-project/build/tools/mlir/python_packages/mlir_core\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mlir._mlir_libs._site_initialize.<locals>.Context object at 0x76a2403c7650>\n",
      "module {\n",
      "  func.func @doofadd(%arg0: i32, %arg1: i32) -> i32 {\n",
      "    %0 = arith.addi %arg0, %arg1 : i32\n",
      "    return %0 : i32\n",
      "  }\n",
      "}\n",
      "\n",
      "module {\n",
      "  func.func @doofadd(%arg0: i32, %arg1: i32) -> i32 {\n",
      "    %0 = arith.addi %arg0, %arg1 : i32\n",
      "    return %0 : i32\n",
      "  }\n",
      "}\n",
      "\n",
      "yo func.func @doofadd(%arg0: i32, %arg1: i32) -> i32 {\n",
      "  %0 = arith.addi %arg0, %arg1 : i32\n",
      "  return %0 : i32\n",
      "}\n",
      "func.func @doofadd(%arg0: i32, %arg1: i32) -> i32 {\n",
      "  %0 = arith.addi %arg0, %arg1 : i32\n",
      "  return %0 : i32\n",
      "}\n",
      "\"doofadd\"\n",
      "<mlir._mlir_libs._mlir.ir.OpAttributeMap object at 0x76a248369950>\n",
      "\"doofadd\"\n",
      "^bb0(%arg0: i32, %arg1: i32):\n",
      "  %0 = arith.addi %arg0, %arg1 : i32\n",
      "  func.return %0 : i32\n",
      "\n",
      "heyo %0 = arith.addi %arg0, %arg1 : i32\n",
      "Value(<block argument> of type 'i32' at index: 0)\n",
      "^bb0(%arg0: i32, %arg1: i32):\n",
      "  %0 = arith.addi %arg0, %arg1 : i32\n",
      "  func.return %0 : i32\n",
      "\n",
      "Value(<block argument> of type 'i32' at index: 1)\n",
      "^bb0(%arg0: i32, %arg1: i32):\n",
      "  %0 = arith.addi %arg0, %arg1 : i32\n",
      "  func.return %0 : i32\n",
      "\n",
      "heyo func.return %0 : i32\n",
      "Value(%0 = arith.addi %arg0, %arg1 : i32)\n",
      "%0 = arith.addi %arg0, %arg1 : i32\n"
     ]
    }
   ],
   "source": [
    "import mlir\n",
    "from mlir import ir\n",
    "\n",
    "with ir.Context() as ctx:\n",
    "    print(ctx)\n",
    "    ctx.load_all_available_dialects()\n",
    "    module = ir.Module.parse(\"\"\"\n",
    "\n",
    "module {\n",
    "  func.func @doofadd(%arg0: i32, %arg1: i32) -> i32 {\n",
    "    %sum = arith.addi %arg0, %arg1 : i32\n",
    "    return %sum : i32\n",
    "  }\n",
    "}\n",
    "\n",
    "\"\"\", context=ctx)\n",
    "    print(module)\n",
    "    print(module.operation)\n",
    "    print(\"yo\", module.operation.regions[0].blocks[0].operations[0]) #.attributes\n",
    "    for region in module.operation.regions:\n",
    "        for block in region.blocks:\n",
    "            for op in block.operations:\n",
    "                print(op)\n",
    "                print(op.name)\n",
    "                print(op.attributes)\n",
    "                print(op.attributes[\"sym_name\"])\n",
    "                for b in op.regions:\n",
    "                    for b1 in b.blocks:\n",
    "                        print(b1)\n",
    "                        for o1 in b1.operations:\n",
    "                            print(\"heyo\", o1)\n",
    "                            for oper in o1.operands:\n",
    "                                print(oper)\n",
    "                                print(oper.owner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class OpOperand in module mlir._mlir_libs._mlir.ir:\n",
      "\n",
      "class OpOperand(builtins.object)\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, /, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |\n",
      " |  __new__(*args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |\n",
      " |  operand_number\n",
      " |      (self) -> int\n",
      " |\n",
      " |  owner\n",
      " |      (self) -> object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir(ir)\n",
    "import mlir.dialects as dialects\n",
    "#help(dialects.func.FuncOp)\n",
    "#help(ir.Operation)\n",
    "help(ir.OpOperand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"builtin.module\"() ({\n",
      "  \"func.func\"() <{function_type = () -> (), sym_name = \"main\"}> ({\n",
      "  }) : () -> ()\n",
      "}) : () -> ()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mlir.ir import Context, Module\n",
    "from mlir.dialects import builtin\n",
    "\n",
    "with Context():\n",
    "  # with ir.UnknownLoc():\n",
    "  module = Module.create(loc=ir.Location.unknown())\n",
    "  with ir.InsertionPoint(module.body), ir.Location.unknown():\n",
    "    func = dialects.func.FuncOp(\"main\", ([], []))\n",
    "    # func = Operation.create(\"func.func\" ,...)\n",
    "print(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlir.passmanager as pm\n",
    "pm.PassManager.parse(\"builtin.module(canonicalize,cse)\")\n",
    "pm.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlir import ir\n",
    "\n",
    "def traverse_ir(op : ir.operation):\n",
    "    for region in op.regions:\n",
    "        for block in region.blocks:\n",
    "            for nested in block.operations:\n",
    "                print(nested.attributes[\"my_attr\"])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "drop mlir prefix\n",
    "use properties\n",
    "use containers\n",
    "objects nullablke in C return None\n",
    "\n",
    "\n",
    "mlir.ir\n",
    "mlir.dialects.linalg\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlir import ir\n",
    "with ir.Context():\n",
    "    top_level = ir.Module.parse(\"...\", context=ctx) # can be derived from surrounding context manager\n",
    "    body = top_level.regions[0]\n",
    "    body_block = body.blocks[0]\n",
    "    for op in block_body.operation:\n",
    "        viasibility = op.attributers[\"syum_visisbilty\"]\n",
    "        if visibility is None: continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://github.com/raviqqe/melior?tab=readme-ov-file\n",
    "\n",
    "https://mlir.llvm.org/docs/Bindings/Python/\n",
    "\n",
    "https://mlir.llvm.org/docs/Tutorials/Toy/Ch-1/\n",
    "\n",
    "\n",
    "\n",
    "https://myhsu.xyz/llvm-sched-model-1/ llvm scheduling model\n",
    "https://myhsu.xyz/llvm-sched-model-1.5/\n",
    "\n",
    "https://arxiv.org/abs/2002.11054  MLIR: A Compiler Infrastructure for the End of Moore's Law\n",
    "\n",
    "Ok. so I could get llvm via a docker?\n",
    "\n",
    "mlir-opt - lots of useful bits and pieces\n",
    "\n",
    "front end?\n",
    "lean mlir\n",
    "\n",
    "mlir \n",
    "\n",
    "https://circt.llvm.org/docs/Dialects/\n",
    "\n",
    "comb\n",
    "smt https://youtu.be/gZdHrve9p40?si=4fpesyX4cIGCe9M1 https://circt.llvm.org/docs/Dialects/SMT/ \n",
    "builtin\n",
    "llvm\n",
    "emitc\n",
    "affine\n",
    "math\n",
    "polynomial\n",
    "linalg\n",
    "vector\n",
    "memref\n",
    "verif https://circt.llvm.org/docs/Dialects/Verif/\n",
    "transform dialect https://arxiv.org/pdf/2404.19350 https://mlir.llvm.org/docs/Tutorials/transform/ChH/ Chapter H: Reproducing Halide Schedule https://mlir.llvm.org/docs/Tutorials/transform/\n",
    "sparse\n",
    "https://llvm.github.io/clangir/\n",
    "\n",
    "mlir-tv https://github.com/aqjune/mlir-tv\n",
    "https://link.springer.com/chapter/10.1007/978-3-031-13188-2_19\n",
    "\n",
    "mlir graph rewriting\n",
    "mlir egraph. eclass nodes? graph rewriting embedding\n",
    "mlir proof trees\n",
    "mlir verification conditions. dafny style mlir\n",
    "mlir grobner basis. polynomial division\n",
    "dependently typed mlir\n",
    "mlir unison constraint compiling\n",
    "mlir datalog\n",
    " \n",
    "https://mlir.llvm.org/docs/PDLL/\n",
    "https://www.jeremykun.com/2024/08/04/mlir-pdll/\n",
    "pdl - inline in file!!\n",
    "pddl - higher level\n",
    "\n",
    "https://blog.trailofbits.com/2024/06/21/eurollvm-2024-trip-report/\n",
    "binary analysis via bolt\n",
    "\n",
    "vast https://blog.trailofbits.com/2023/06/15/finding-bugs-with-mlir-and-vast/\n",
    "macroni https://github.com/trailofbits/macroni\n",
    "https://github.com/Jezurko/potato potato points to analysis\n",
    "\n",
    "jsir dialect\n",
    "direct to mir avoiding llvm\n",
    "\n",
    "mojo\n",
    "\n",
    "mlir has a pass to lift cfg to regions?\n",
    "\n",
    "https://github.com/iree-org/iree \n",
    "\n",
    "enzyme\n",
    "\n",
    "https://github.com/makslevental/mlir-python-extras\n",
    "https://github.com/spcl/pymlir - lark parse into mirrored thing\n",
    "https://mlir.llvm.org/OpenMeetings/2023-12-21-PyDSL.pdf pydsl\n",
    "https://github.com/SRI-CSL/filia\n",
    "https://arxiv.org/pdf/2307.16080 nelli https://github.com/makslevental/nelli hmm. archived.\n",
    "Maybe these techniques could be useful for z3 reification.\n",
    "Rewrite AST + rewrite bytecode + overloading\n",
    "\n",
    "exocompiler and others.\n",
    "https://cap.csail.mit.edu/sites/default/files/research-pdfs/Codon-%20A%20Compiler%20for%20High-Performance%20Pythonic%20Applications%20and%20DSLs.pdf codon converts to llvm\n",
    "https://github.com/exaloop/codon\n",
    "\n",
    "https://mlir.llvm.org/docs/Dialects/Linalg/OpDSL/ linalg pyt\n",
    "tensor comphrehensions https://arxiv.org/pdf/1802.04730\n",
    "\n",
    "torch-mlir\n",
    "mhlo tf tflite tensorflow\n",
    "TOSA\n",
    "https://mlir.llvm.org/doxygen/namespacemlir_1_1presburger.html\n",
    "https://acohen.gitlabpages.inria.fr/impact/impact2022/papers/paper9.pdf Bringing Presburger Arithmetic to MLIR with FPL\n",
    "\n",
    "openssef hardcening\n",
    "\n",
    "riscemu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir /tmp/llvmplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/llvmplay/CMakelists.txt\n",
    "cmake_minimum_required(VERSION 3.10)\n",
    "project(llvmplay)\n",
    "set(CMAKE_CXX_STANDARD 17)\n",
    "add_executable(llvmplay main.cpp)\n",
    "find_package(LLVM REQUIRED CONFIG)\n",
    "message(STATUS \"Found LLVM ${LLVM_PACKAGE_VERSION}\")\n",
    "message(STATUS \"Using LLVMConfig.cmake in: ${LLVM_DIR}\")\n",
    "include_directories(${LLVM_INCLUDE_DIRS})\n",
    "add_definitions(${LLVM_DEFINITIONS})\n",
    "llvm_map_components_to_libnames(llvm_libs support core irreader)\n",
    "target_link_libraries(llvmplay ${llvm_libs})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/llvmplay/main.cpp\n",
    "#include <iostream>\n",
    "#include <llvm/IR/LLVMContext.h>\n",
    "#include <llvm/IR/Module.h>\n",
    "#include <llvm/IR/Function.h>\n",
    "#include <llvm/IR/IRBuilder.h>\n",
    "#include <llvm/IR/Verifier.h>\n",
    "#include <llvm/Support/raw_ostream.h>\n",
    "#include <llvm/IR/Type.h>\n",
    "#include <llvm/IR/DerivedTypes.h>\n",
    "#include <llvm/IR/GlobalVariable.h>\n",
    "#include <llvm/IR/Constant.h>\n",
    "#include <llvm/IR/Constants.h>\n",
    "#include <llvm/IR/Instructions.h>\n",
    "#include <llvm/IR/BasicBlock.h>\n",
    "#include <llvm/IR/Value.h>\n",
    "#include <llvm/IR/TypeBuilder.h>\n",
    "#include <llvm/IR/IRPrintingPasses.h>\n",
    "#include <llvm/IR/PassManager.h>\n",
    "#include <llvm/IR/LegacyPassManager.h>\n",
    "#include <llvm/IR/CallingConv.h>\n",
    "#include <llvm/IR/InlineAsm.h>\n",
    "#include <llvm/IR/Attributes.h>\n",
    "#include <llvm/IR/Argument.h>\n",
    "#include <llvm/IR/GlobalValue.h>\n",
    "#include <llvm/IR/GlobalObject.h>\n",
    "#include <llvm/IR/ConstantFolder.h>\n",
    "#include <llvm/IR/ConstantRange.h>\n",
    "#include <llvm/IR/ConstantData.h>\n",
    "#include <llvm/IR/ConstantExpr.h>\n",
    "#include <llvm/IR/ConstantInt.h>\n",
    "#include <llvm/IR/ConstantFP.h>\n",
    "#include <llvm/IR/ConstantArray.h>\n",
    "#include <llvm/IR/ConstantStruct.h>\n",
    "#include <llvm/IR/ConstantVector.h>\n",
    "#include <llvm/IR/ConstantPointerNull.h>\n",
    "\n",
    "\n",
    "using namespace llvm;\n",
    "\n",
    "int main() {\n",
    "    LLVMContext context;\n",
    "    Module* module = new Module(\"top\", context);\n",
    "    IRBuilder<> builder(context);\n",
    "    \n",
    "    // Create the main function\n",
    "    FunctionType* main_type = FunctionType::get(builder.getVoidTy(), false);\n",
    "    Function* main_func = Function::Create(main_type, Function::ExternalLinkage, \"main\", module);\n",
    "    BasicBlock* entry = BasicBlock::Create(context, \"entry\", main_func);\n",
    "    builder.SetInsertPoint(entry);\n",
    "    \n",
    "    // Create the return value\n",
    "    builder.CreateRetVoid();\n",
    "    \n",
    "    // Print the IR\n",
    "    module->print(outs(), nullptr);\n",
    "    delete module;\n",
    "    return 0;\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script\n",
    "cd /tmp/llvmplay\n",
    "cmake .\n",
    "make\n",
    "./llvmplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/example.mlir\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/example.mlir\n",
    "module {\n",
    "  pdl.pattern : pattern benefit(1) {\n",
    "    // Match an operation \"foo\" and replace it with \"bar\"\n",
    "    %input = pdl.operand : !pdl.type\n",
    "    %op = pdl.operation \"foo\"(%input) : (!pdl.type) -> !pdl.type\n",
    "    pdl.replace %op with (%input) -> (%result : !pdl.type) {\n",
    "      %result = pdl.operation \"bar\"(%input) : (!pdl.type) -> !pdl.type\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Example usage of the \"foo\" operation\n",
    "  func.func @test_func(%arg0: i32) -> i32 {\n",
    "    %0 = \"foo\"(%arg0) : (i32) -> i32\n",
    "    return %0 : i32\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m/tmp/example.mlir:2:17: \u001b[0m\u001b[0;1;31merror: \u001b[0m\u001b[1mcustom op 'pdl.pattern' expected 'benefit'\n",
      "\u001b[0m  pdl.pattern : pattern benefit(1) {\n",
      "\u001b[0;1;32m                ^\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! mlir-opt-20 --pass-pipeline=\"pdl-apply\" /tmp/example.mlir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/custom.op\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/custom.op\n",
    "module {\n",
    "  func.func @example(%arg0: i32) -> i32 {\n",
    "    %0 = \"my_custom.op\"(%arg0) : (i32) -> i32\n",
    "    return %0 : i32\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module {\n",
      "  func.func @example(%arg0: i32) -> i32 {\n",
      "    %0 = \"my_custom.op\"(%arg0) : (i32) -> i32\n",
      "    return %0 : i32\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! mlir-opt-20 /tmp/custom.op -allow-unregistered-dialect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /tmp/Dockerfile.llvm\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/Dockerfile.llvm\n",
    "# Use a base image with Ubuntu\n",
    "FROM ubuntu:22.04\n",
    "\n",
    "# Set non-interactive mode for APT\n",
    "ENV DEBIAN_FRONTEND=noninteractive\n",
    "\n",
    "# Install required tools and the LLVM APT repository\n",
    "RUN apt-get update && apt-get install -y \\\n",
    "    wget \\\n",
    "    gnupg2 \\\n",
    "    software-properties-common \\\n",
    "    && wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - \\\n",
    "    && wget https://apt.llvm.org/llvm.sh \\\n",
    "    && chmod +x llvm.sh \\\n",
    "    && ./llvm.sh all\n",
    "\n",
    "# Install additional dependencies (optional)\n",
    "RUN apt-get install -y \\\n",
    "    build-essential \\\n",
    "    cmake \\\n",
    "    python3 \\\n",
    "    python3-pip \\\n",
    "    && apt-get clean \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Set environment variables for LLVM\n",
    "ENV LLVM_DIR=/usr/lib/llvm-20\n",
    "ENV PATH=${LLVM_DIR}/bin:$PATH\n",
    "ENV LD_LIBRARY_PATH=${LLVM_DIR}/lib:$LD_LIBRARY_PATH\n",
    "\n",
    "# Set up a work directory\n",
    "WORKDIR /workspace\n",
    "\n",
    "# Default command to run in the container\n",
    "CMD [\"/bin/bash\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build -t llvm-dev-env -f /tmp/Dockerfile.llvm /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/mlirsimple.mlir\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/mlirsimple.mlir\n",
    "// simple_example.mlir\n",
    "func @main() {\n",
    "  %0 = \"std.constant\"() {value = 42 : i32} : () -> i32\n",
    "  return\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmlir\u001b[49m\u001b[38;5;241m-\u001b[39mopt \u001b[38;5;241m/\u001b[39mtmp\u001b[38;5;241m/\u001b[39mmlirsimple\u001b[38;5;241m.\u001b[39mmlir \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m-\u001b[39mconvert\u001b[38;5;241m-\u001b[39mstd\u001b[38;5;241m-\u001b[39mto\u001b[38;5;241m-\u001b[39mllvm \u001b[38;5;66;03m#| llc -o /tmp/mlirsimple.o\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mlir' is not defined"
     ]
    }
   ],
   "source": [
    "mlir-opt /tmp/mlirsimple.mlir --convert-std-to-llvm #| llc -o /tmp/mlirsimple.o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmlir\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlir'"
     ]
    }
   ],
   "source": [
    "import mlir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() {\n",
    "  # Define a variable `a` with shape <2, 3>, initialized with the literal value.\n",
    "  # The shape is inferred from the supplied literal.\n",
    "  var a = [[1, 2, 3], [4, 5, 6]];\n",
    "\n",
    "  # b is identical to a, the literal tensor is implicitly reshaped: defining new\n",
    "  # variables is the way to reshape tensors (element count must match).\n",
    "  var b<2, 3> = [1, 2, 3, 4, 5, 6];\n",
    "\n",
    "  # transpose() and print() are the only builtin, the following will transpose\n",
    "  # a and b and perform an element-wise multiplication before printing the result.\n",
    "  print(transpose(a) * transpose(b));\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### patterm taching\n",
    "\n",
    "\n",
    "increasing complexity / runtime overhead.\n",
    "\n",
    "IR walk. vuistor based\n",
    "pattern walk driver\n",
    " - top to bottom traversal\n",
    "- greedy rewrite\n",
    "- trasnform dialect\n",
    "- dialect convesion\n",
    "\n",
    "Operation *toplevel;\n",
    "WalkResult result = toplevel->walk([](Operation *op) {\n",
    "op->dump();\n",
    "return WalkResult::advance(); // optional. advance, skip, interrupt\n",
    "})\n",
    "\n",
    "// can only visit funcops\n",
    "WalkResult result = toplevel->walk([](FuncOp *op) {\n",
    "op->dump();\n",
    "return WalkResult::advance(); // optional. advance, skip, interrupt\n",
    "})\n",
    "// FunctionOpInterace\n",
    "\n",
    "toplevel->walk<Order, IterATOR>\n",
    "// Walkorder::PostOrder, prorder\n",
    "// ForwardIteratro, ForwardDomianceIterator, ReverseIterator, ReverseDomainceIterator\n",
    "\n",
    "https://mlir.llvm.org/docs/PatternRewriter/\n",
    "OpRewritePatttern<airth::AddIOp>\n",
    "matchAndRewrite(op, rewriter){\n",
    "lhs = getConstantintVal(op.getLHS());\n",
    "rhs = getConstantintVal(op.getRHS());\n",
    "if !lhes || !rhs reyutnr failure();\n",
    "rewriter. replaceOpwithNewOp<arith::COnstant::OP>\n",
    "\n",
    "rewriter.replace()\n",
    "rewriter.eraseOp()\n",
    "\n",
    "\n",
    "return success();\n",
    "}\n",
    "\n",
    "\n",
    "Pattern walk driver\n",
    "\n",
    "RewritePatternSet patterns(ctx);\n",
    "pattersn.add<AddFoldPattern, SubFoldPattenr, MulFoldPatterm>(ctx);\n",
    "\n",
    "Operations * op;\n",
    "walkAndApplyPatterns(opm  std::move(patterns))\n",
    "\n",
    "Greedy Pattern driver\n",
    "applyPattersnAndFoldGreedily\n",
    "\n",
    "apply all ops in a scope until fixed point.\n",
    "apply folders. (smart constructors defined for operation)\n",
    "simplify regions\n",
    "cse constants\n",
    "m,erge idntical blocks\n",
    "remove dead dce.\n",
    "Wokrlist implementation\n",
    "Ops may be revisisted\n",
    "no guartnateed order of traversal\n",
    "\n",
    "\n",
    "\n",
    "pdll \n",
    "\n",
    "pdl interpreter\n",
    "\n",
    "\n",
    "canonicalziation pattersns. simplifyt oir bring into canonical form\n",
    "https://mlir.llvm.org/docs/Canonicalization/\n",
    "OpName::getCaonincalizePatterns\n",
    "\n",
    "\n",
    "max iteraitons is set to 10 by default\n",
    "Do not depend on caonical form for correctness\n",
    "\n",
    "Canonizlier uses greedy\n",
    "\n",
    "ir should verify after pattern application\n",
    "populate...Patterns\n",
    "\n",
    "https://discourse.llvm.org/t/rfc-update-to-general-design-section-of-operation-canonicalizations-in-mlir/79355\n",
    "\n",
    "MLIR_ENABLE_EXPENSIVE_PATTERN_API_CHECKS\n",
    "LLVM_USE_SANIT^IZER=\"Address\"\n",
    "\n",
    "\n",
    "prefer walk over pattern driver.\n",
    "\n",
    "dialect conversion\n",
    "https://llvm.org/devmtg/2024-10/slides/techtalk/Springer-Pattern-Based-IR-Rewriting-in-MLIR.pdf\n",
    "TypeConverter\n",
    "ConversionPattern\n",
    "Do not have to retain types.\n",
    "Normal rewriters retain same type\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transform / linalg\n",
    "Can I use them raw?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pymlir\n",
    "lark based solution. Lower key.\n",
    "What does xdsl even do? It seems so ocmplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module {\n",
      "  func.func @toy_func(%tensor: tensor<2x3xf64>) -> tensor<3x2xf64> {\n",
      "    %t_tensor = \"toy.transpose\"(%tensor) {inplace = true} : (tensor<2x3xf64>) -> tensor<3x2xf64>\n",
      "    return %t_tensor : tensor<3x2xf64>\n",
      "  }\n",
      "}\n",
      "module {\n",
      "  func.func @toy_func(%tensor: tensor<2x3xf64>) -> tensor<3x2xf64> {\n",
      "    %t_tensor = \"toy.transpose\"(%tensor) {inplace = true} : (tensor<2x3xf64>) -> tensor<3x2xf64>\n",
      "    return %t_tensor : tensor<3x2xf64>\n",
      "  }\n",
      "}\n",
      "MLIRFile(definitions=[], modules=[Module(name=None, attributes=None, region=Region(body=[Block(label=None, body=[Operation(result_list=None, op=Function(name=SymbolRefId(value='toy_func'), args=[NamedArgument(name=SsaId(value='tensor', op_no=None), type=RankedTensorType(dimensions=[Dimension(value=2), Dimension(value=3)], element_type=FloatType(type=<FloatTypeEnum.f64: 'f64'>)), attributes=None)], result_types=RankedTensorType(dimensions=[Dimension(value=3), Dimension(value=2)], element_type=FloatType(type=<FloatTypeEnum.f64: 'f64'>)), attributes=None, region=Region(body=[Block(label=None, body=[Operation(result_list=[OpResult(value=SsaId(value='t_tensor', op_no=None), count=None)], op=GenericOperation(name=StringLiteral(value='toy.transpose'), args=[SsaId(value='tensor', op_no=None)], successors=None, regions=None, attributes=AttributeDict(values=[AttributeEntry(name='inplace', value=BoolAttr(value=True))]), type=FunctionType(argument_types=[RankedTensorType(dimensions=[Dimension(value=2), Dimension(value=3)], element_type=FloatType(type=<FloatTypeEnum.f64: 'f64'>))], result_types=[RankedTensorType(dimensions=[Dimension(value=3), Dimension(value=2)], element_type=FloatType(type=<FloatTypeEnum.f64: 'f64'>))])), location=None), Operation(result_list=None, op=ReturnOperation(match=1, values=[SsaId(value='t_tensor', op_no=None)], types=[RankedTensorType(dimensions=[Dimension(value=3), Dimension(value=2)], element_type=FloatType(type=<FloatTypeEnum.f64: 'f64'>))]), location=None)])]), location=None), location=None)])]), location=None)])\n"
     ]
    }
   ],
   "source": [
    "import mlir\n",
    "ast3 = mlir.parse_string('''\n",
    "module {\n",
    "  func.func @toy_func(%tensor: tensor<2x3xf64>) -> tensor<3x2xf64> {\n",
    "    %t_tensor = \"toy.transpose\"(%tensor) { inplace = true } : (tensor<2x3xf64>) -> tensor<3x2xf64>\n",
    "    return %t_tensor : tensor<3x2xf64>\n",
    "  }\n",
    "}\n",
    "''')\n",
    "\n",
    "ast3\n",
    "ast3.dump()\n",
    "repr(ast3)\n",
    "print(ast3.pretty())\n",
    "print(ast3.dump())\n",
    "print(ast3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module {\n",
      "  func.func @hello_world(%a: f64, %b: f64) {\n",
      "    %_pymlir_ssa = addf %a , %b : f64\n",
      "    return %_pymlir_ssa : f64\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import mlir.builder\n",
    "\n",
    "builder = mlir.builder.IRBuilder()\n",
    "mlirfile = builder.make_mlir_file()\n",
    "module = mlirfile.default_module\n",
    "\n",
    "with builder.goto_block(builder.make_block(module.region)):\n",
    "    hello = builder.function(\"hello_world\")\n",
    "    block = builder.make_block(hello.region)\n",
    "    builder.position_at_entry(block)\n",
    "\n",
    "    x, y = builder.add_function_args(hello, [builder.F64, builder.F64], ['a', 'b'])\n",
    "\n",
    "    adder = builder.addf(x, y, builder.F64)\n",
    "    builder.func.ret([adder], [builder.F64])\n",
    "\n",
    "print(mlirfile.dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xDSL\n",
    "https://xdsl.dev/\n",
    "\n",
    "smt dialect\n",
    "pddl rewriting\n",
    "egraph basic\n",
    "pcode to xdsl.\n",
    "\n",
    "https://www.lopoukhine.com/winter-school/\n",
    "\n",
    "%zero = arith.constant 0 : index\n",
    "%one = arith.constant 1 : index\n",
    "\n",
    "%res = scf.for %i = %one to \n",
    "\n",
    "scf for https://mlir.llvm.org/docs/Dialects/SCFDialect/#scffor-scfforop\n",
    "\n",
    "interpreter.register_implementation\n",
    "\n",
    "def run_func(module: ModuleOp, name: str, args: tuple[Any, ...]):\n",
    "    from xdsl.interpreter import Interpreter\n",
    "    from xdsl.interpreters import scf, arith, func\n",
    "\n",
    "    interpreter = Interpreter(module)\n",
    "    interpreter.register_implementations(scf.ScfFunctions)\n",
    "    interpreter.register_implementations(arith.ArithFunctions)\n",
    "    interpreter.register_implementations(func.FuncFunctions)\n",
    "\n",
    "    res = interpreter.call_op(name, args)\n",
    "\n",
    "    if len(res) == 1:\n",
    "        res = res[0]\n",
    "\n",
    "    return res\n",
    "\n",
    "ctx = MLContext()\n",
    "ctx.load_dialect(builtin.Builtin)\n",
    "ctx.load_dialect(func.Func)\n",
    "ctx.load_dialect(scf.Scf)\n",
    "ctx.load_dialect(arith.Arith)\n",
    "\n",
    "builtin diaslect\n",
    "\n",
    "\n",
    "mymodule.walk()\n",
    "\n",
    "\n",
    "xdsl.ir.core.Dialect\n",
    "xdsl.diALECTS.BUILTIN\n",
    "Dialect.split_name\n",
    "\n",
    "ir core https://github.com/xdslproject/xdsl/blob/main/xdsl/ir/core.py\n",
    "\n",
    "parent_op\n",
    ".parent\n",
    "\n",
    "\n",
    "\n",
    "https://github.com/orgs/xdslproject/projects/23 eqsat\n",
    "\n",
    "https://github.com/oluwatimilehin/mlir-sat\n",
    "https://github.com/opencompl/xdsl-smt\n",
    "Builder\n",
    "\n",
    "moduleOp()\n",
    "Builder(InsertPoiont.at_end)\n",
    "FuncOp(\"main)\n",
    "build.insert\n",
    "\n",
    "general rationale for mlir rwerite https://mlir.llvm.org/docs/Rationale/RationaleGenericDAGRewriter/\n",
    "match_and_rewrite_op\n",
    " GreedyRewritePatternApplier(AddZeroPattern(), MulTwoPattern())\n",
    " GreedyRewritePatternApplier(AddZeroPattern(), MulTwoPattern())\n",
    " \n",
    " \n",
    " can define \n",
    " tablgen can define patterns\n",
    " pdll - pattern definition language\n",
    " xdsl some support for pdl\n",
    "\n",
    "\n",
    " xdsl-tblgen\n",
    "\n",
    " https://github.com/ftynse/mlir-tutorial-docker\n",
    " RUN cmake --build build -t mlir-opt mlir-translate mlir-transform-opt mlir-cpu-runner check-mlir || true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xdsl.ir import *\n",
    "from xdsl.irdl import *\n",
    "from xdsl.dialects.builtin import *\n",
    "from xdsl.dialects.arith import *\n",
    "from xdsl.dialects.scf import *\n",
    "from xdsl.pattern_rewriter import *\n",
    "\n",
    "\n",
    "@irdl_attr_definition\n",
    "class Bag(ParametrizedAttribute):\n",
    "    name = \"sql.bag\"\n",
    "    schema: ParameterDef[Attribute]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printer = Printer()\n",
    "printer.print_attribute(Bag([i32]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xdsl.irdl import attr_def, result_def\n",
    "\n",
    "\n",
    "@irdl_op_definition\n",
    "class Table(IRDLOperation):\n",
    "    name = \"sql.table\"\n",
    "    table_name: StringAttr = attr_def(StringAttr)\n",
    "    result_bag: OpResult = result_def(Bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Table.build(attributes={\"table_name\": StringAttr(\"T\")}, result_types=[Bag([(i32)])])\n",
    "printer.print_op(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = ModuleOp([t])\n",
    "print(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@irdl_op_definition\n",
    "class Selection(IRDLOperation):\n",
    "    name = \"sql.selection\"\n",
    "    input_bag: Operand = operand_def(Bag)\n",
    "    filter: Region = region_def()\n",
    "    result_bag: OpResult = result_def(Bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exo\n",
    "https://exo-lang.dev/\n",
    "\n",
    "https://www.proquest.com/openview/87a41aefc3eaa9033b6342ee83b4d892/1?pq-origsite=gscholar&cbl=18750&diss=y exo in reinking thesis\n",
    "\n",
    "https://arxiv.org/pdf/2411.07211 exo 2\n",
    "its installable?\n",
    "https://github.com/exo-lang/exo\n",
    "\n",
    "https://github.com/exo-lang/exo/tree/main/examples\n",
    "https://github.com/exo-lang/exo/tree/main/examples/avx2_matmul\n",
    "\n",
    "Reminds me a lot of that C rewritng thing Thomas had \n",
    "\n",
    "scheduling things are rewrites. The rewrites take a lot of parameters.\n",
    "\n",
    "Some interesting looking unification algorithms in rewrite engine. Arith aware and bool aware?\n",
    "(unification? Not pattern match?)\n",
    "\n",
    "https://github.com/exo-lang/exo/blob/main/src/exo/core/LoopIR.py\n",
    "\n",
    "```python\n",
    "\n",
    "LoopIR = ADT(\n",
    "    \"\"\"\n",
    "module LoopIR {\n",
    "    proc = ( name    name,\n",
    "             fnarg*  args,\n",
    "             expr*   preds,\n",
    "             stmt*   body,\n",
    "             instr?  instr,\n",
    "             srcinfo srcinfo )\n",
    "\n",
    "    instr  = ( string c_instr,\n",
    "               string c_global )\n",
    "\n",
    "    fnarg  = ( sym     name,\n",
    "               type    type,\n",
    "               mem?    mem,\n",
    "               srcinfo srcinfo )\n",
    "\n",
    "    stmt = Assign( sym name, type type, expr* idx, expr rhs )\n",
    "         | Reduce( sym name, type type, expr* idx, expr rhs )\n",
    "         | WriteConfig( config config, string field, expr rhs )\n",
    "         | Pass()\n",
    "         | If( expr cond, stmt* body, stmt* orelse )\n",
    "         | For( sym iter, expr lo, expr hi, stmt* body, loop_mode loop_mode )\n",
    "         | Alloc( sym name, type type, mem mem )\n",
    "         | Free( sym name, type type, mem mem )\n",
    "         | Call( proc f, expr* args )\n",
    "         | WindowStmt( sym name, expr rhs )\n",
    "         attributes( srcinfo srcinfo )\n",
    "\n",
    "    loop_mode = Seq()\n",
    "                | Par()\n",
    "\n",
    "    expr = Read( sym name, expr* idx )\n",
    "         | Const( object val )\n",
    "         | USub( expr arg )  -- i.e.  -(...)\n",
    "         | BinOp( binop op, expr lhs, expr rhs )\n",
    "         | Extern( extern f, expr* args )\n",
    "         | WindowExpr( sym name, w_access* idx )\n",
    "         | StrideExpr( sym name, int dim )\n",
    "         | ReadConfig( config config, string field )\n",
    "         attributes( type type, srcinfo srcinfo )\n",
    "\n",
    "    -- WindowExpr = (base : Sym, idx : [ Pt Expr | Interval Expr Expr ])\n",
    "    w_access = Interval( expr lo, expr hi )\n",
    "             | Point( expr pt )\n",
    "             attributes( srcinfo srcinfo )\n",
    "\n",
    "    type = Num()\n",
    "         | F16()\n",
    "         | F32()\n",
    "         | F64()\n",
    "         | INT8()\n",
    "         | UINT8()\n",
    "         | UINT16()\n",
    "         | INT32()\n",
    "         | Bool()\n",
    "         | Int()\n",
    "         | Index()\n",
    "         | Size()\n",
    "         | Stride()\n",
    "         | Error()\n",
    "         | Tensor( expr* hi, bool is_window, type type )\n",
    "         -- src       - type of the tensor from which the window was created\n",
    "         -- as_tensor - tensor type as if this window were simply a tensor \n",
    "         --             itself\n",
    "         -- window    - the expression that created this window\n",
    "         | WindowType( type src_type, type as_tensor,\n",
    "                       sym src_buf, w_access *idx )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def rank_k_reduce_6x16(K: size, A: f32[6, K] @ DRAM, B: f32[K, 16] @ DRAM,\n",
      "                       C: f32[6, 16] @ DRAM):\n",
      "    for i in seq(0, 6):\n",
      "        for j in seq(0, 16):\n",
      "            for k in seq(0, K):\n",
      "                C[i, j] += A[i, k] * B[k, j]\n"
     ]
    }
   ],
   "source": [
    "from exo import *\n",
    "\n",
    "@proc\n",
    "def rank_k_reduce_6x16(\n",
    "    K: size, A: f32[6, K] @ DRAM, B: f32[K, 16] @ DRAM, C: f32[6, 16] @ DRAM\n",
    "):\n",
    "    for i in seq(0, 6):\n",
    "        for j in seq(0, 16):\n",
    "            for k in seq(0, K):\n",
    "                C[i, j] += A[i, k] * B[k, j]\n",
    "\n",
    "print(rank_k_reduce_6x16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def rank_k_reduce_6x16_scheduled(K: size, A: f32[6, K] @ DRAM,\n",
      "                                 B: f32[K, 16] @ DRAM, C: f32[6, 16] @ DRAM):\n",
      "    for k in seq(0, K):\n",
      "        for i in seq(0, 6):\n",
      "            for j in seq(0, 16):\n",
      "                C[i, j] += A[i, k] * B[k, j]\n"
     ]
    }
   ],
   "source": [
    "from exo import proc\n",
    "from exo.platforms.x86 import *\n",
    "from exo.stdlib.scheduling import *\n",
    "\n",
    "# In this example, we want the computation to be \"output stationary\", which means,\n",
    "# we want to preallocate all the output registers at the start.\n",
    "avx = rename(rank_k_reduce_6x16, \"rank_k_reduce_6x16_scheduled\")\n",
    "avx = reorder_loops(avx, \"j k\")\n",
    "avx = reorder_loops(avx, \"i k\")\n",
    "\n",
    "print(avx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def rank_k_reduce_6x16_scheduled(K: size, A: f32[6, K] @ DRAM,\n",
      "                                 B: f32[K, 16] @ DRAM, C: f32[6, 16] @ DRAM):\n",
      "    C_reg: f32[6, 16] @ DRAM\n",
      "    for i0 in seq(0, 6):\n",
      "        for i1 in seq(0, 16):\n",
      "            C_reg[i0, i1] = C[i0, i1]\n",
      "    for k in seq(0, K):\n",
      "        for i in seq(0, 6):\n",
      "            for jo in seq(0, 2):\n",
      "                for ji in seq(0, 8):\n",
      "                    C_reg[i, ji + 8 * jo] += A[i, k] * B[k, ji + 8 * jo]\n",
      "    for i0 in seq(0, 6):\n",
      "        for i1 in seq(0, 16):\n",
      "            C[i0, i1] = C_reg[i0, i1]\n",
      "=============Optimized Matmul==============\n",
      "def rank_k_reduce_6x16_scheduled(K: size, A: f32[6, K] @ DRAM,\n",
      "                                 B: f32[K, 16] @ DRAM, C: f32[6, 16] @ DRAM):\n",
      "    C_reg: f32[6, 2, 8] @ AVX2\n",
      "    for i0 in seq(0, 6):\n",
      "        for i2 in seq(0, 2):\n",
      "            mm256_loadu_ps(C_reg[i0, i2, 0:8], C[i0, 8 * i2:8 + 8 * i2])\n",
      "    for k in seq(0, K):\n",
      "        B_reg: f32[2, 8] @ AVX2\n",
      "        for io in seq(0, 2):\n",
      "            mm256_loadu_ps(B_reg[io, 0:8], B[k, 8 * io:8 + 8 * io])\n",
      "        for i in seq(0, 6):\n",
      "            A_reg: f32[8] @ AVX2\n",
      "            mm256_broadcast_ss(A_reg[0:8], A[i, k:1 + k])\n",
      "            for jo in seq(0, 2):\n",
      "                mm256_fmadd_ps(C_reg[i, jo, 0:8], A_reg[0:8], B_reg[jo, 0:8])\n",
      "    for i0 in seq(0, 6):\n",
      "        for i2 in seq(0, 2):\n",
      "            mm256_storeu_ps(C[i0, 8 * i2:8 + 8 * i2], C_reg[i0, i2, 0:8])\n"
     ]
    }
   ],
   "source": [
    "# The staging of C will cause us to consume 12 out of the 16 vector registers\n",
    "avx = divide_loop(avx, \"for j in _: _\", 8, [\"jo\", \"ji\"], perfect=True)\n",
    "avx = stage_mem(avx, \"for k in _:_\", \"C[0:6, 0:16]\", \"C_reg\")\n",
    "avx = simplify(avx)\n",
    "\n",
    "print(avx)\n",
    "# Reshape C_reg so we can map it into vector registers\n",
    "avx = divide_dim(avx, \"C_reg:_\", 1, 8)\n",
    "avx = repeat(divide_loop)(avx, \"for i1 in _: _\", 8, [\"i2\", \"i3\"], perfect=True)\n",
    "avx = simplify(avx)\n",
    "\n",
    "# Map C_reg operations to vector instructions\n",
    "avx = set_memory(avx, \"C_reg:_\", AVX2)\n",
    "avx = replace_all(avx, mm256_loadu_ps)\n",
    "avx = replace_all(avx, mm256_storeu_ps)\n",
    "avx = simplify(avx)\n",
    "\n",
    "# Now, the rest of the compute needs to work with the constraint that the\n",
    "# we only have 4 more registers to work with here.\n",
    "\n",
    "# B is easy, it is just two vector loads\n",
    "avx = stage_mem(avx, \"for i in _:_\", \"B[k, 0:16]\", \"B_reg\")\n",
    "avx = simplify(avx)\n",
    "avx = divide_loop(avx, \"for i0 in _: _ #1\", 8, [\"io\", \"ii\"], perfect=True)\n",
    "avx = divide_dim(avx, \"B_reg:_\", 0, 8)\n",
    "avx = set_memory(avx, \"B_reg:_\", AVX2)\n",
    "avx = simplify(avx)\n",
    "avx = replace_all(avx, mm256_loadu_ps)\n",
    "avx = simplify(avx)\n",
    "\n",
    "# The final part is staging A. We will be using up two more vector registers.\n",
    "avx = bind_expr(avx, \"A[i, k]\", \"A_reg\")\n",
    "avx = expand_dim(avx, \"A_reg\", 8, \"ji\")\n",
    "avx = lift_alloc(avx, \"A_reg\", n_lifts=2)\n",
    "avx = fission(avx, avx.find(\"A_reg[ji] = _\").after(), n_lifts=2)\n",
    "avx = remove_loop(avx, \"for jo in _: _\")\n",
    "avx = set_memory(avx, \"A_reg:_\", AVX2)\n",
    "avx = replace_all(avx, mm256_broadcast_ss)\n",
    "\n",
    "# Replace the FMA instructions to AVX2 instructions\n",
    "avx = replace_all(avx, mm256_fmadd_ps)\n",
    "avx = simplify(avx)\n",
    "\n",
    "print(\"=============Optimized Matmul==============\")\n",
    "print(avx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# taco\n",
    "http://tensor-compiler.org/\n",
    "https://github.com/tensor-compiler/taco build and install\n",
    "\n",
    "http://simit-lang.org/  https://fredrikbk.com/\n",
    "graphit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tiramisu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mosaic\n",
    "https://github.com/manya-bansal/mosaic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Halide\n",
    "https://halide-lang.org/tutorials/\n",
    "https://www.proquest.com/openview/87a41aefc3eaa9033b6342ee83b4d892/1?pq-origsite=gscholar&cbl=18750&diss=y  The Design and Implementation of User-Schedulable Languages by Alexander Julian Reinking. Thesis 2022\n",
    "\n",
    "https://dl.acm.org/doi/10.1145/3306346.3322967  Learning to optimize halide with tree search and random programs\n",
    "\n",
    "- Hydride\n",
    "- Halide\n",
    "\n",
    "- SpEQ - http://www.paramathic.com/wp-content/uploads/2024/04/REV_PLDI_rev2.pdf\n",
    "- Exo: https://dl.acm.org/doi/abs/10.1145/3519939.3523446\n",
    "- Mosaic: https://manya-bansal.github.io/papers/pldi23main-p107-final.pdf\n",
    "\n",
    "- taco\n",
    "- glenside\n",
    "- mlir\n",
    "- \n",
    "Maaz Bin Safeer Ahmad, Alexander J Root, Andrew Adams, Shoaib Kamil, and Alvin Cheung. Vector instruction selection for digital signal processors using program synthesis.\n",
    "\n",
    "Sebastian Buchwald, Andreas Fried, and Sebastian Hack. Synthesizing an instruction selection rule library from semantic specifications.\n",
    "\n",
    "Yishen Chen, Charith Mendis, Michael Carbin, and Saman Amarasinghe. Vegen: a vectorizer generator for simd and beyond\n",
    "\n",
    "Zhengyang Liu, Stefan Mada, and John Regehr. Minotaur: A simd-oriented synthesizing superoptimizer\n",
    "\n",
    "Alexander J Root, Maaz Bin Safeer Ahmad, Dillon Sharlet, Andrew Adams, Shoaib Kamil, and Jonathan Ragan-Kelley. Fast instruction selection for fast digital signal processing.\n",
    "\n",
    "Alexander James Root. Optimizing Vector Instruction Selection for Digital Signal Processing. PhD thesis, Massachusetts Institute of Technology, 2022\n",
    "\n",
    "Samuel Thomas and James Bornholt. Automatic generation of vectorizing compilers for customizable digital signal processors. 2024.\n",
    "\n",
    "Alexa VanHattum, Rachit Nigam, Vincent T Lee, James Bornholt, and Adrian Sampson. Vectorization for digital signal processors via equality saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/halide.cpp\n",
    "\n",
    "Func blur_3x3(Func input) {\n",
    "  Func blur_x, blur_y;\n",
    "  Var x, y, xi, yi;\n",
    "\n",
    "  // The algorithm - no storage or order\n",
    "  blur_x(x, y) = (input(x-1, y) + input(x, y) + input(x+1, y))/3;\n",
    "  blur_y(x, y) = (blur_x(x, y-1) + blur_x(x, y) + blur_x(x, y+1))/3;\n",
    "\n",
    "  // The schedule - defines order, locality; implies storage\n",
    "  blur_y.tile(x, y, xi, yi, 256, 32)\n",
    "        .vectorize(xi, 8).parallel(y);\n",
    "  blur_x.compute_at(blur_y, x).vectorize(x, 8);\n",
    "\n",
    "  return blur_y;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kokkos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perf Ninja\n",
    "\n",
    "new book is coming out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Muratori\n",
    "Alright. I'm subscribed. Get my 9$ a month qworth!\n",
    "\n",
    "It was really interesting seeing casey muratoi \n",
    "https://www.computerenhance.com/p/the-case-of-the-missing-increment\n",
    "\n",
    "https://github.com/cmuratori/computer_enhance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coarse Schuedling\n",
    "Task Graphs\n",
    "Task scheduling\n",
    "Tasks\n",
    "\n",
    "https://arxiv.org/html/2403.07120v1 Comparing Task Graph Scheduling Algorithms: An Adversarial Approach\n",
    "https://github.com/ANRGUSC/saga\n",
    "\n",
    "https://iris-programming.github.io/pdf/exhet2023.pdf Tiling Framework for Heterogeneous Computing of Matrix-Based\n",
    "Tiled Algorithms. \n",
    "IRIS https://iris-programming.github.io/\n",
    "\n",
    "https://link.springer.com/content/pdf/10.1007/s00500-020-05152-8.pdf A load balance multi-scheduling model for OpenCL kernel tasks\n",
    "in an integrated cluster\n",
    "\n",
    "https://inria.hal.science/hal-04146714/document\n",
    "A generic scheduler to foster data locality for GPU and\n",
    "out-of-core task-based applications\n",
    "StarPU\n",
    "https://starpu.gitlabpages.inria.fr/ A Unified Runtime System for Heterogeneous Multicore Architectures\n",
    "\n",
    "https://dl.acm.org/doi/fullHtml/10.1145/3624062.3624244  CHARM-SYCL: New Unified Programming Environment for Multiple Accelerator Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Array Langs\n",
    "\n",
    "https://dl.acm.org/doi/10.1145/3689774 AUTOMAP: Inferring Rank-Polymorphic Function Applications with Integer Linear Programming\n",
    "inserting maps and other operations in a minimal way using ILP to make type correct. Futhark people.\n",
    "\n",
    "Remora\n",
    "https://futhark-lang.org/blog/2022-10-03-futhark-on-arraycast.html\n",
    "\n",
    "https://sac-home.org/index single assignemnt c\n",
    "\n",
    "\n",
    "If I try to design a rank polymorphic array language, what stops me?\n",
    "What insights do I need?\n",
    "\n",
    "type 'rank typ = \n",
    "\n",
    "\n",
    "https://mlochbaum.github.io/BQN/implementation/compile/intro.html\n",
    "https://mlochbaum.github.io/BQN/implementation/codfns.html#does-apl-need-a-type-system \n",
    "\n",
    "apl compilation\n",
    "ML-family (like Haskell): Futhark has size-dependent types and Dex has fully dependent types\n",
    "MLIR and XLA, low-level drivers of deep learning frameworks like TensorFlow\n",
    "\n",
    "https://www.snakeisland.com/apexup.htm\n",
    "https://github.com/Snektron/pareas gpu accelerated compiler\n",
    "https://github.com/melsman/apltail typed array intermeidtae language. https://elsman.com/pdf/array14_final.pdf . Seems very similar to remora\n",
    "\n",
    "https://dl.acm.org/doi/10.1145/3460944.3464310 Towards size-dependent types for array programming ARRAY 2021\n",
    "\n",
    "co-dfns - gpu compielr written in apl\n",
    "\n",
    "futhark\n",
    "\n",
    "dex https://github.com/google-research/dex-lang https://arxiv.org/pdf/2104.05372. https://scholar.google.com/scholar?start=10&hl=en&as_sdt=40000005&sciodt=0,22&cites=1188560884062516815&scipsc= reverse search\n",
    "\n",
    "https://ieeexplore.ieee.org/abstract/document/10046117/ Memory Optimizations in an Array Language\n",
    "\n",
    "I thought gibbons had some stuff https://www.cs.ox.ac.uk/people/jeremy.gibbons/publications/aplicative.pdf APLicative Programming with Naperian Functors\n",
    "\n",
    "haskell accelerate\n",
    "\n",
    "https://dl.acm.org/doi/abs/10.1145/3589246.3595372  Polymorphic Types with Polynomial Sizes array 2023\n",
    "\n",
    "\n",
    "\n",
    "C Barry Jay and Milan Sekanina. 1997. Shape checking of array programs 1997\n",
    "Kai Trojahner and Clemens Grelck. 2009. Dependently typed array programs donâ€™t go wrong. \n",
    "\n",
    "C.B. Jay. 1999. Denotational Semantics of Shape:: Past, Present and Future. \n",
    "C.Barry Jay. 1995. A semantics for shape. \n",
    "\n",
    "Ok what if we take numpy as our runtime.\n",
    "\n",
    "Bailly LHenriksen TElsman MKeller GWestrick S(2023)Shape-Constrained Array Programming with Size-Dependent Types  https://dl.acm.org/doi/10.1145/3609024.3609412 2023\n",
    "\n",
    "records with rank polymorphism https://dl.acm.org/doi/10.1145/3315454.3329961 2019\n",
    "\n",
    "Hattori MKobayashi NSato R(2023)Gradual Tensor Shape Checking \n",
    "\n",
    "https://www.khoury.northeastern.edu/~pete/research/array-2018.html Rank Polymorphism Viewed as a Constraint Problem\n",
    "\n",
    "\n",
    "\n",
    "Oleg\n",
    "https://okmij.org/ftp/meta-programming/tutorial/daxpy.html#preview  axpy using codegen\n",
    "https://okmij.org/ftp/Computation/ARPL.html array programming\n",
    "zf fun ~ Set(A) * A >> B\n",
    "array ~ Set(SeqInt) * Seq(Int) >> R \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remora\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Futhark\n",
    "import via futhark-py\n",
    "https://futhark-lang.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp(e, env):\n",
    "    match e:\n",
    "        case (\"const\", x):\n",
    "            return env[x]\n",
    "        case (\"zeros\", shape):\n",
    "            return np.zeros(shape)\n",
    "        case (\"slice\", a, i, j):\n",
    "            return interp(a,env)[i:j]\n",
    "        case (\"dot\", a, b):\n",
    "            return np.dot(interp(a,env), interp(b,env))\n",
    "        case (\"sum\", a):\n",
    "            return np.sum(interp(a, env))\n",
    "        case (\"add\", a, b):\n",
    "            return interp(a,env) + interp(b,env)\n",
    "        case _:\n",
    "            raise ValueError(f\"Unknown expression {e}\")\n",
    "\n",
    "def dot(a,b):\n",
    "    return (\"dot\", a, b)\n",
    "def add(a,b):\n",
    "    return (\"add\", a, b)\n",
    "def zeros(shape):\n",
    "    return (\"zeros\", shape)\n",
    "def const(x):\n",
    "    return (\"const\", x)\n",
    "def slice(a, i, j):\n",
    "    return (\"slice\", a, i, j)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.tuplize.<locals>.wrapper(*args, **kwargs)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "class TuplizeAST(ast.NodeTransformer):\n",
    "    def visit_For(self,node):\n",
    "        print(node)\n",
    "        #return (\"for\", i, n)\n",
    "def tuplize(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        source_code = inspect.getsource(func)\n",
    "        tree = ast.parse(source_code)\n",
    "        normalizer = NormalizeAST()\n",
    "        return normalizer.visit(tree)\n",
    "    return wrapper\n",
    "\n",
    "@tuplize\n",
    "def mysum(a):\n",
    "    acc = 0\n",
    "    for i in range(len(a)):\n",
    "        acc += a[i]\n",
    "    return acc\n",
    "mysum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "@tuplize\n",
    "def myconv(a,b):\n",
    "    n = len(a)\n",
    "    m = len(b)\n",
    "    c = np.zeros(n+m-1)\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            c[i+j] += a[i]*b[j]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# einsum\n",
    "einsum is a good exmpale of a dsl to be scheudled and compiled\n",
    "\n",
    "glenside\n",
    "tensor comprehensions\n",
    "\n",
    "With particular built in tensors we can express other stuff like convlution, blurs, etc.\n",
    "\n",
    "\n",
    "\n",
    "true einstein notation has pairs of indices.\n",
    "\n",
    "\n",
    "what if xs can be dense or sparse.\n",
    "\n",
    "Done at runtime or compile time.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k', 'j', 'i'} [('ij', array([[ 0,  1,  2],\n",
      "       [ 3,  4,  5],\n",
      "       [ 6,  7,  8],\n",
      "       [ 9, 10, 11]])), ('jk', array([[0, 1],\n",
      "       [2, 3],\n",
      "       [4, 5]]))]\n",
      "{'i': 4, 'j': 3, 'k': 2}\n",
      "[[1], [0, 1], [0]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'str' and 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 31\u001b[0m\n\u001b[1;32m     26\u001b[0m b \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m6\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     28\u001b[0m my_einsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mij,jk->ik\u001b[39m\u001b[38;5;124m\"\u001b[39m, [a,b])\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEinSum\u001b[39;00m():\n\u001b[1;32m     32\u001b[0m     inputs: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m]]\n\u001b[1;32m     33\u001b[0m     output: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m]\n",
      "Cell \u001b[0;32mIn[8], line 34\u001b[0m, in \u001b[0;36mEinSum\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m inputs: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m]]\n\u001b[1;32m     33\u001b[0m output: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m]\n\u001b[0;32m---> 34\u001b[0m arrs: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEinSum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m \u001b[38;5;241m|\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray]\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'str' and 'type'"
     ]
    }
   ],
   "source": [
    "def my_einsum(s, xs):\n",
    "    s = s.strip()\n",
    "    inputs, output = s.split(\"->\")\n",
    "    inputs = inputs.split(\",\")\n",
    "    assert len(inputs) == len(xs)\n",
    "    indices = set(\"\".join(inputs))\n",
    "    print(indices, list(zip(inputs, xs)))\n",
    "    shape = {}\n",
    "    for input, x in zip(inputs, xs):\n",
    "        for i, n in zip(input, x.shape):\n",
    "            #print(input, x, i, n)\n",
    "            if i in shape:\n",
    "                assert shape[i] == n\n",
    "            else:\n",
    "                shape[i] = n\n",
    "    print(shape)\n",
    "    hyperedges = [[j for j,axes in enumerate(inputs) if i in axes]  for i in indices]\n",
    "    print(hyperedges)\n",
    "\n",
    "\n",
    "    #env = {i : n }\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "a = np.arange(12).reshape(4,3)\n",
    "b = np.arange(6).reshape(3,2)\n",
    "\n",
    "my_einsum(\"ij,jk->ik\", [a,b])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "symbolic einsum\n",
    "In some sense we are refactoring an einsum tree\n",
    "\n",
    "extended einsum includes reshape operations.\n",
    "\n",
    "\n",
    "einsum could be canonized via sorting\n",
    "The output order is real (?) and the order of \n",
    "\n",
    "symmettry of indices.\n",
    "Anti symmettry\n",
    "Sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'type' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEinSum\u001b[39;00m():\n\u001b[1;32m      2\u001b[0m     inputs: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m]]\n\u001b[1;32m      3\u001b[0m     output: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m]\n",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m, in \u001b[0;36mEinSum\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m inputs: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m]]\n\u001b[1;32m      3\u001b[0m output: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m arrs: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEinSum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m \u001b[38;5;241m|\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray]\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'type' and 'str'"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "class EinSum():\n",
    "    inputs: list[list[Any]]\n",
    "    # they actually should be zipped together.\n",
    "    # inputs: list[tuple[list[Any], str | \"EinSym\" | np.ndarray]]\n",
    "    output: list[Any]\n",
    "    arrs: list[str | \"EinSum\" | np.ndarray]\n",
    "    #def reshape():\n",
    "    #def \n",
    "    def indices(self):\n",
    "        # set of all indices. Useful for \"freevar\" side condition to know what needs renaming.\n",
    "        pass\n",
    "    def rename(self, old, new):\n",
    "        # dummy index renaming\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poylyhedral\n",
    "https://github.com/bondhugula/pluto  Pluto: An automatic polyhedral parallelizer and locality optimizer\n",
    "https://github.com/periscop/cloog  he CLooG Code Generator in the Polyhedral Model\n",
    "\n",
    "https://github.com/VERIMAG-Polyhedra/VPL verified polyuhedral library\n",
    "https://github.com/verif-scop/PolCert?tab=readme-ov-file A verified polyhedral scheduling validator in Coq.\n",
    "https://github.com/Ekdohibs/PolyGen PolyGen is a code generator for the polyhedral model, written and proved in Coq."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# buildit\n",
    "\n",
    "metaocaml style metAPEROGRAMMINBG for C++\n",
    "python analog could work?\n",
    "thermometer continuations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finch\n",
    "https://github.com/finch-tensor\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
