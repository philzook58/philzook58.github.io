{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://people.cs.nott.ac.uk/psztxa/publ/fomus19.pdf altelnkirch note\n",
    "\n",
    "https://eprints.nottingham.ac.uk/41385/1/th.pdf  Type theory in a type theory with\n",
    "quotient inductive types kaposi thesis\n",
    "\n",
    "Winterhalter thesis\n",
    "\n",
    "https://drops.dagstuhl.de/storage/00lipics/lipics-vol131-fscd2019/LIPIcs.FSCD.2019.25/LIPIcs.FSCD.2019.25.pdf  Gluing for Type Theory\n",
    "\n",
    "abstract and concrerte type theories - uemeura https://eprints.illc.uva.nl/id/document/12150\n",
    "\n",
    "artin gluing is a way to put two cetagories together\n",
    "Logical relations\n",
    "\n",
    "\n",
    "LF\n",
    "\n",
    "https://www.danielgratzer.com/papers/type-theory-book.pdf\n",
    "programming in martin lof type theory\n",
    "hott book\n",
    "egbert hott book\n",
    "\n",
    "Cody's notes https://www.kleene.church/tt-notes\n",
    "\n",
    "https://logic.berkeley.edu/logic@UCB/Rathjen_logic@UCB.pdf On relating type theories to (intuitionistic) set theories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# identity types\n",
    "\n",
    "Families.\n",
    "parameters vs indices\n",
    "https://golem.ph.utexas.edu/category/2022/07/identity_types_in_context.html\n",
    "https://cs.stackexchange.com/questions/20100/what-are-the-difference-between-and-consequences-of-using-type-parameters-and-ty\n",
    "https://homotopytypetheory.org/2011/04/10/just-kidding-understanding-identity-elimination-in-homotopy-type-theory/\n",
    "\n",
    "P(a,refla)\n",
    "P selects where to rewrite.\n",
    "\n",
    "\n",
    "A refinment version?\n",
    "p : EqInfo | eq(p, a, b)\n",
    "\n",
    "pattern matching and unification problems. How to compiler dependent matcvhes to \n",
    "\n",
    "\n",
    "Constructors internalize meta notions.\n",
    "sigma types tinernalize things that can happen in a context.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Terms sort is not that different from ZF.\n",
    "https://ncatlab.org/nlab/show/subsingleton\n",
    "\n",
    "Consider other congruence relations. Combinators on them?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TERMS = smt.DeclareSort(\"TERMS\") # Constructions\n",
    "TYPE = set_.Set(TERMS) # Is type judgement\n",
    "elem = smt.Function(\"elem\", TERMS, smt.SetSort(TERMS)) # has type judgement\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantics of type theory\n",
    "\n",
    "https://cms.sic.saarland/semantics_ws2122/materials/\n",
    "\n",
    "https://cstheory.stackexchange.com/questions/17668/resources-for-mathematicians-hoping-to-learn-more-computer-science\n",
    "\n",
    "https://people.mpi-sws.org/~dreyer/courses/catlogic/jacobs.pdf catgeorical logic and type theory bart jacobs\n",
    "\n",
    "practical foundatiosn - taylor\n",
    "\n",
    "https://www.lfcs.inf.ed.ac.uk/reports/92/ECS-LFCS-92-208/  An introduction to fibrations, topos theory, the effective topos and modest sets\n",
    "\n",
    "https://ncatlab.org/nlab/show/categorical+semantics+of+dependent+type+theory\n",
    "Ok. \n",
    "sets pointing into their \"type\" sets considered as subsets of them.\n",
    "Then there are squares that \n",
    "type families Ai  project into their indexing space (?). Yeah, I guess so.\n",
    "\n",
    "\n",
    "Categories with families. Cody says related to explicit substituion calculus like lambda sigma.\n",
    "\n",
    "Substitutions as a category\n",
    "\n",
    "GATs involved somehow.\n",
    "\n",
    "Maybe the first step is to deeply understand lawvere theories. https://en.wikipedia.org/wiki/Lawvere_theory\n",
    "https://ncatlab.org/nlab/show/Lawvere+theory\n",
    " How do you combinatorify equational/algebraic or first order logic?\n",
    "term = morphism from unit?\n",
    "https://www.youtube.com/watch?v=IZcrASzCybs&ab_channel=SchmidCollege%2CChapmanUniversity evan patterson. standard hierachy at 41:10\n",
    "free substitutions vs substituions under a theory? Adding equations to the category of substitutions?\n",
    "\n",
    "Functor to set = model\n",
    "\n",
    "To turn n-arity into single arity we can use a prod construction. Just like we can make multiarg computer programs using tuples\n",
    "fst(prod(x,y)) = x\n",
    "snd(prod(x,y)) = y\n",
    "`assoc(prod(x,prod(y,z))) = prod(prod(x,y),z)` vs `prod(x,prod(y,z)) = prod(prod(x,y),z)`. fst and snd get confused if we make equal on the nose.\n",
    "So is this an an example of how to model higher structures that aren't \"equal on the nose\"?\n",
    "\n",
    "Another style\n",
    "prod2(x,y)\n",
    "prod3(x,y,z)\n",
    "\n",
    "negassoc(prod(prod(x,y),z)) = prod(x,prod(y,z))\n",
    "\n",
    "\n",
    "\n",
    "see fibers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hott\n",
    "\n",
    "https://ncatlab.org/nlab/show/categorical+semantics+of+dependent+type+theory\n",
    "https://www.cs.uoregon.edu/research/summerschool/summer14/rwh_notes/ssdt.pdf\n",
    "\n",
    "What is the name \n",
    "\n",
    "https://www.cs.cmu.edu/~rwh/courses/hott/ bob harper course\n",
    "\n",
    "https://mathstodon.xyz/@MartinEscardo/110890155815254064 escardo threads on hott\n",
    "\n",
    "https://www.youtube.com/@epitspringschoolonhomotopy6943 EPIT Spring School on Homotopy Type Theory 2021\n",
    "https://www.youtube.com/@jdchristensen123  HoTTEST 2022\n",
    "https://www.youtube.com/playlist?list=PL-47DDuiZOMCRDiXDZ1fI0TFLQgQqOdDa 2019 bauer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "TYPE = smt.DeclareSort(\"TYPE\")\n",
    "TERM = smt.DeclareSort(\"TERM\")\n",
    "\n",
    "@dataclass\n",
    "class Judgement():\n",
    "    ctx : list[tuple[smt.ExprRef, smt.ExprRef]]\n",
    "@dataclass\n",
    "class IsType(Judgement):\n",
    "    typ : smt.ExprRef\n",
    "    def __repr__(self):\n",
    "        return f\"{self.ctx} |- {self.typ} TYPE\"\n",
    "@dataclass\n",
    "class HasType(Judgement):\n",
    "    term : smt.ExprRef\n",
    "    typ : smt.ExprRef\n",
    "    def __repr__(self):\n",
    "        return f\"{self.ctx} |- {self.term} : {self.typ}\"\n",
    "@dataclass\n",
    "class EqType(Judgement):\n",
    "    typ1 : smt.ExprRef\n",
    "    typ2 : smt.ExprRef\n",
    "    def __repr__(self):\n",
    "        return f\"{self.ctx} |- {self.typ1} = {self.typ2}\"\n",
    "@dataclass\n",
    "class EqTerm(Judgement):\n",
    "    term1 : smt.ExprRef\n",
    "    term2 : smt.ExprRef\n",
    "    typ : smt.ExprRef\n",
    "    def __repr__(self):\n",
    "        return f\"{self.ctx} |- {self.term1} = {self.term2} : {self.typ}\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Array(T, Bool)"
      ],
      "text/plain": [
       "Array(T, Bool)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "T = smt.DeclareSort(\"T\")\n",
    "TSet = smt.SetSort(T)\n",
    "\n",
    "TSet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ncatlab.org/nlab/show/type+telescope\n",
    "https://www.pls-lab.org/en/telescope\n",
    "https://www.sciencedirect.com/science/article/pii/089054019190066B?ref=pdf_download&fr=RR-2&rr=92eb234868378fa9  Telescopic mappings in typed lambda calculus\n",
    "\n",
    "telescopes as trees?\n",
    "telescopes are ordered variables. grobner elmination tries to find a fopr of the polynomial like that. Gauss elimination.\n",
    "Triangular form. trinagular unfication. We're just playing mind jazz baby\n",
    "J Zucker\n",
    "\n",
    "T3elescope dot product. Terms are in the telescope. Dot product instantiations vairables. hmmm.\n",
    "`[1 , 2] . [x : x = 17, y : y + x = 14] =  1 = 17 /\\ 2 + 1 = 14` \n",
    "`[foo(a), bar(biz)] . [x : baz(x), y : edge(x,y)] = baz(foo(a)) /\\ edge(foo(a), bar(biz))`\n",
    "\n",
    "telescopic mappings are matrices?\n",
    "dot product is maybe like |=? \n",
    "\n",
    "telescopic mappings are instnation of the contex? They are substitutions. BUt then the telescope isn't\n",
    "Some kind of trinagular matrix? a stack of rows or a stack of columns?\n",
    "nested telescopes.\n",
    "x -> [y : B(y)]\n",
    "No whole hog. The substiution rule applied one by one? Subst + weaken.\n",
    "Add in new variable we're going to subst to. Then eliminate using subst old variable in terms of new.\n",
    "[x : A(x)] |- f(x) : Z(x) \n",
    "[y : B(y), x : A(x)] |- f(x) : Z(x) weaken\n",
    "[y : B(y)] |- f(g(y)) |- Z(g(y)) subst\n",
    "\n",
    "Gam, x : A, Del\n",
    "and\n",
    "Gam |- t : A \n",
    "\n",
    "Gam, Del[t/A]\n",
    "\n",
    "\n",
    "I guess telescope is a generalization of my `vs` list, which was a context, sure.\n",
    "If telescopes are a context, what is a ntext? :)\n",
    "\n",
    "\n",
    "\n",
    "def unify(telescope, t1 , t2, typ)\n",
    "def pmatch(telescope, p, t1, typ)\n",
    "\n",
    "\n",
    "You could have GAT rewriting logic. \n",
    "Gam |- t1 -> t2 : A.  asymmettric\n",
    "Gam |- A -> A1\n",
    "\n",
    "Gam |- T type is a fibration.\n",
    "\n",
    "predicates with variables in them are sets at the metalevel. Before we use comprehension / lambda to internalize them.\n",
    "\n",
    "If you have an equational theory of types, you could find an ordering the context that puts the thing you want to substitute last or first?\n",
    "\n",
    "definitional type equality is in a context. Not clear if I have to use kleene equality or no. Well, I need to quantify over the variables in scope...\n",
    "If I don't have function symbols, this is probably all in EPR?\n",
    "\n",
    "To say we have a iterative fibering of a surface is kind of like saying we have a fully projection sequence form.\n",
    "It's weird to say that we have this from the get go.\n",
    "block triangular form is almost as good.\n",
    "mappings between\n",
    "[x : R,  y : R | y = x**2 + 2]\n",
    "Does a telescope have anything to do with triangular form solutions / projection / gauss elimination / elimination / quantifer elim.   I could descibe a sphere as something like [x : R, y : R | x**2 + y**2 <= 1, z : R | z = 1 - x**2 - y**2] \n",
    "Or some robot configuration it's nice to have the kinematics straightened out. Or maybe something something cylindrical algerbaic decomposition\n",
    "I could decribe a triangular linear equation as  [x : R | x = 42, y : R | y = 3* x + 14, ...]\n",
    "Or fourier motzkin form as   [x : R | 1 < x < 7, y : R | x + y < 4 /\\ x + y < 17, ....]\n",
    "\n",
    "[ p : R^3|   p.x**2 + p.y**2 + p.z**2 = 1 ] converting this telescope into that above one is hard in general\n",
    "\n",
    "SympyTelescope. SolveSet.\n",
    "\n",
    "TERM and TYPE\n",
    "\n",
    "But what if they were the same? is TYPE = Set(TERM), this requires some kind of class -> set comprehension like thing. An internalization.\n",
    "TYPE1 = smt.SetSort(TYPE)\n",
    " and so on\n",
    "\n",
    "\n",
    "```\n",
    "# n are universe levels. Obviously they are not in the system. They are python integers\n",
    "def TYPE(n):\n",
    "    if n == 0:\n",
    "        return TERM \n",
    "    return smt.SetSort(TYPE(n-1))\n",
    "```\n",
    "\n",
    "is univalence statable?\n",
    "```\n",
    "def univalence(n):\n",
    "    return Iso(A == B, Iso(A,B)) # no. == is definitional equality. We want propositional equality (?) right?\n",
    "    retrun Iso(PropEq(A,B), Iso(A,B))\n",
    "\n",
    "def Iso(A,B):\n",
    "    #which for ismorphic stuff means same cardinality? But maybe less clear given we're recursing into an equality.\n",
    "    f,g = smt.Array(\"f g\", TYPE(n), TYPE(n))\n",
    "    smt.Exists([f,g], A[x] => B[f(x)], B[y] => A[g(y)], f(g(x)) == x, g(f(y)) == y)\n",
    "```\n",
    "\n",
    "finite models by encding up to universe level n. If it trivialize at some N, we're good to go? It stays trivial?\n",
    "\n",
    "I'm building a model of dependent type theory. I don't know if that proves it in the original system, that unsat means that there must be a judgement in dependent type theory. Can i extract such a judgement tree from an unsat core?\n",
    "\n",
    "\n",
    "\n",
    "lifting property\n",
    "unit ->  spiral\n",
    "|         |\n",
    "\\/        \\/\n",
    "interval -> circl\n",
    "\n",
    "we pick an \"inital condition\" for which layer we want to be on, that's what the upper and left edges do, then the r5est of the path is derivable.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Resolution_of_singularities\n",
    "\n",
    "\n",
    "co de bruijn telescopes.\n",
    "\n",
    "VMap = \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy\n",
    "\n",
    "class Telescope():\n",
    "    vs : list[sympy.Symbol]  # maybe if we want it in block solved form, list[tuple[sympy.Symbol, ...]]\n",
    "    typs : SolveSet\n",
    "\n",
    "class Shape(): #Fibration\n",
    "    ctx : Telescope   # base\n",
    "    typ : SolveSet # a constrjiat on the rewals\n",
    "\n",
    "class Point():\n",
    "    ctx : Telescope\n",
    "    t : sympy.Expr\n",
    "    typ : SolveSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gatexpr is like Gam |- t : A judgement. see cat_topos_free.ipynb\n",
    "TERM = smt.DeclareSort(\"TERM\")\n",
    "TYPE = smt.SetSort(TERM)\n",
    "\n",
    "@dataclass\n",
    "class TeleScope():\n",
    "    vs : list[smt.ExprRef]\n",
    "    typs : list[smt.BoolRef] # vs smt.ExprRef. Pre applied to vs or not?\n",
    "    def interp(self):\n",
    "        return smt.And(self.typs)\n",
    "        #return smt.And(typ(*self.vs[:i]) for i,typ in enumerate(self.typs))\n",
    "    def extend(self, typ): # C-ext\n",
    "        v = smt.FreshConst(TERM)\n",
    "        return v, Telescope(vs + [v], typs + [typ(v)]) # typ is a z3 or python lambda that can also contain previous variables.\n",
    "    # I guess I'm considering all type expressions to be valid.\n",
    "    # Gamma |- T type is not a judgement that is needed.\n",
    "    # if wqe capture \"variables\" not in scope somehow, they are considered to be constants.\n",
    "    # We have an open notion of constant\n",
    "    #def strengthen(self, n): ... # check nothing using variable n and then remove it. Is this weakening, or is this strengthening.\n",
    "    def weaken(self, posn, typ):\n",
    "        v = smt.FreshConst(TERM)\n",
    "        # maybe check typ does not contain any vs[posn:]. THis is just fancy extend\n",
    "        return v, Telescope(vs[:posn] + [v] + vs[posn+1:], typs[:posn] + [typ(v)] + typs[posn+1:])\n",
    "    def subst(self, v_or_posn, t : GatExpr):\n",
    "        assert t.ctx == self[:posn] # or alpha eq? and normalize?\n",
    "        assert t.typ == self.typs[posn]\n",
    "        tailtyps = [smt.substitute(typ  (v, t.t)) for typ in self.typs[posn+1]]\n",
    "        return Telescope(self.vs[:posn] self.vs[posn+1:], self.typs[:posn] + tailtyps)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GATExpr():\n",
    "    ctx : Telescope\n",
    "    t : smt.ExprRef # t.sort() == TERM\n",
    "    typ : smt.ExprRef # this is a typ.sort() == TYPE\n",
    "\n",
    "    def judge(self):\n",
    "        smt.ForAll(self.ctx.vs, self.ctx.interp(), self.typ[self.t])\n",
    "    def __eq__(self, other):\n",
    "        # either require to be in same context or reconcile them. (common prefix?)\n",
    "\n",
    "\n",
    "\n",
    "Ob = smt.Const(\"Ob\", TYPE)\n",
    "Hom = smt.Function(\"Hom\", Ob, Ob, TYPE)\n",
    "a,b,c = smt.Consts(\"a b c\", TERM)\n",
    "kd.axiom(Ob[a])\n",
    "kd.axiom(Ob[b])\n",
    "kd.axiom(Ob[c])\n",
    "f,g,h = smt.Consts(\"f g h\", TERM)\n",
    "id_ = smt.Function(\"id\", TERM, TERM)\n",
    "comp = smt.Function(\"comp\", TERM, TERM, TERM)\n",
    "kd.notation.matmul.register(TERM, comp)\n",
    "\n",
    "kd.axiom(kd.QForAll([a], Ob[a], Hom(a,a)[id_(a)])) # a : Ob |- id(a) : Hom(a,a)\n",
    "kd.axiom(kd.QForAll([a,b,c], Ob[a], Ob[b], Ob[c], Hom(a,b)[f], Hom(b,c)[g], Hom(a,c)[f @ g])) # a : ob, b : Ob, c : Ob, f : Hom(a,b), g : Hom(b,c) |- f . g : Hom(a,c) \n",
    "\n",
    "# hmm. Hom(a,b)[f] is there difference of those like the difference between indexes and parameters? Nooooo. Porb not.\n",
    "\n",
    "\n",
    "# equality rules\n",
    "kd.axiom(kd.QForAll([a,b], Ob[a], Ob[b], Hom(a,b)[f], f @ id_(a)) == f) # a : Ob, b : Ob, f : Hom(a,b) |- f. id(a) = f\n",
    "# other id\n",
    "# assoc comp\n",
    "\n",
    "# Ob[a] is a simple predicate. And i can do it ahead of time in z3 sort system. If I know these things don't intersect? \n",
    "# Injectivity of Type constructors?\n",
    "# This is an optimization though.\n",
    "\n",
    "\n",
    "# a : Ob, b : Ob, f : Hom(a,b) |- dom(f) = a\n",
    "# a : Ob, b : Ob, f : Hom(a,b) |- cod(f) = b\n",
    "\n",
    "# internalizing type. deep embedding GAT/ Martin Lof into GAT\n",
    "type0 = smt.Function(\"type0\", TYPE)\n",
    "type1 = smt.Function(\"type1\", TERM)\n",
    "eq = smt.Function(\"eq\", TERM, TERM, TERM) # \n",
    "eq1 = smt.Function(\"eq\", TERM, TERM, TYPE)\n",
    "eq2 = smt.Function(\"eq\", TYPE, TYPE, TERM) # eq1 is a judgement, eq2 is a term.\n",
    "eq3 = smt.Function(\"eq\", TYPE, TYPE, TYPE) # eq1 is a judgement, eq2 is a term.\n",
    "eq4 = smt.Function(\"eq\", TYPE, TERM, TYPE) # THe two inputs hsould at least match yeah?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, here's the idea with maps between contexts and substitutions. Say I've got a context x:A,y:B(x), and another x:C,y:D(x). Then a map from the first to the second should be a pair of terms x:A, y:B(x) |- c(x,y), d(x,y) - so the components can depend on every variable in the first context - but the types of these terms should be C and D(c(x,y)). So strictly speaking what you want are terms x:A, y:B(x) |- c(x,y) : C and x:A, y:B(x) |- d(x,y) : D(c(x,y)). Mutatis mutandis for more than two types, these give you a mapping between the contexts if you just think of each context as a dependent tuple type.\n",
    "They also give you a substitution mapping going in the other direction. Like if you have terms c, d as above, and some type T(x,y) in context x:C,y:D(x), then you can turn T into a type in context x:A, y:B(x) by substitution: x:A,y:B(x)|-T(c(x,y), d(x,y)).\n",
    "So this is an example of the general picture where a morphism in a base category between two objects X,Y induces a functor between the fiber categories above X,Y in the total category, going in the opposite direction. The contexts are objects of the base category, and the types in a given context are the objects in the fiber over that context.\n",
    "\n",
    "\n",
    "Put ticks on x’:C, y’:D(x’)\n",
    "\n",
    "\n",
    "Fair (edited) \n",
    "\n",
    "Is it c(x’,y’) ?\n",
    "4:32\n",
    "Or c(x,y)?\n",
    "\n",
    "\n",
    "The second. The arguments to c(x,y) have types A and B(x)\n",
    "\n",
    "\n",
    "See that’s the part that is non intuitive to me\n",
    "\n",
    "I’d have thought it should be c(x’,y’)\n",
    "\n",
    "Because I want to change out the x variables for x’ variablez\n",
    "\n",
    "Then I think you want a map from the context x':C,y'D(x') to x:A,y:B(x).\n",
    "\n",
    "Analogy: if I have a function from nats to reals, it turns predicates depending on reals into predicates depending on nats. If I have a map from context C to context C', it turns things that depend on C' (like types in that context) into things that depend on C.\n",
    "\n",
    "\n",
    "So i should actually be thinking of context mappings as functions, not substitutions\n",
    "\n",
    "Yeah. They're mappings, and mappings induce substitutions.\n",
    "\n",
    "And contexts actually have a semantics and arent just syntax\n",
    "\n",
    "Yeah. They're the base category. Concretely, you can even think about them as sets (of indices) if you're thinking about types in context as indexed families of sets.\n",
    "\n",
    "x : A, y : B(x) |- x’ := c(x,y) : C, y’ := d(x,y) : D(x’)\n",
    "\n",
    "I see, so in the semantics “free” single sorted herbrand model case, the “function” form is applying those terms to the input. This is not a very interesting thing to discuss, so it doesn’t show up in automated reasoning texts\n",
    "5:17\n",
    "And its tuples of terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{a: Lambda([x, y], x + y), b: Lambda([x, y], x - y), c: Lambda([x, y], x*y)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "from dataclasses import dataclass\n",
    "V = smt.ExprRef\n",
    "@dataclass\n",
    "class Mapping():\n",
    "    vs : list[V] # ctx. Gamma\n",
    "    ts : dict[V, smt.ExprRef] # labelled output\n",
    "    # x,y,z |- x' := f(x,y), y' := g(x,y), z' := h(x,y)\n",
    "    def __post_init__(self):\n",
    "        assert all(v.sort() == t.sort() for v,t in self.ts.items())\n",
    "    def apply(self, ts : dict[V, smt.ExprRef]):\n",
    "        assert all(v in self.vs for v in ts.keys())\n",
    "        return {v: smt.substitute(t, *[(v,ts[v]) for v in self.vs]) for v,t in self.ts.items()}\n",
    "    def __matmul__(self, other):\n",
    "        assert isinstance(other, Mapping)\n",
    "        return Mapping(other.vs, self.apply(other.ts))\n",
    "    def meaning(self):\n",
    "        return {l : smt.Lambda(self.vs, t) for l,t in self.ts.items()}\n",
    "\n",
    "x,y,z,a,b,c,p,q = smt.Ints(\"x y z a b c p q\")\n",
    "\n",
    "m1 = Mapping([x,y], {a : x + y, b : x - y, c : x * y})\n",
    "m2 = Mapping([a,b,c], {p : a + b, q : a})    \n",
    "\n",
    "x0 = {x : smt.IntVal(1), y : smt.IntVal(2)}\n",
    "m1.apply(x0)\n",
    "\n",
    "class Predicate(Mapping):\n",
    "    # ts should be a single\n",
    "    def __post_init__(self):\n",
    "        assert len(self.ts) == 1\n",
    "        assert all(v.sort() == smt.BoolSort() for v,t in self.ts.items())\n",
    "        super().__post_init__()\n",
    "\n",
    "m2 @ m1\n",
    "assert (m2 @ m1).apply(x0) == m2.apply(m1.apply(x0))\n",
    "\n",
    "m1.meaning()\n",
    "\n",
    "\n",
    "def unify(m1 : Mapping, m2 : Mapping):\n",
    "    assert m1.ts.keys() == m2.ts.keys()\n",
    "    todo = [(t, m2[l]) l,t in for m1.ts.items()]\n",
    "    subst = kd.utils.unify(todo)\n",
    "    vs = m1.vs + m2.vs - subst.keys()\n",
    "    return Mapping(vs, {v : subst[v] if v in subst else v for v in m1.vs} ), Mapping(vs, {v : subst[v] if v in subst else v  for v in m2.vs} )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PMapping():\n",
    "    vs : list[V] # ctx. Gamma\n",
    "    pre : list[smt.BoolRef] # pres over vs. could intertwine with vs\n",
    "    ts : dict[V, tuple[smt.ExprRef, smt.BoolRef]] # labelled output.\n",
    "    #post : list[smt.BoolRef] # post over with vs as vars. same length as ts.\n",
    "    # x,y,z |- x' := f(x,y), y' := g(x,y), z' := h(x,y)\n",
    "    def __post_init__(self):\n",
    "        assert all(v.sort() == t.sort() for v,t in self.ts.items())\n",
    "    def apply(self, ts : dict[V, smt.ExprRef]):\n",
    "        assert all(v in self.vs for v in ts.keys())\n",
    "        return {v: smt.substitute(t, *[(v,ts[v]) for v in self.vs]) for v,t in self.ts.items()}\n",
    "    def __matmul__(self, other):\n",
    "        assert isinstance(other, Mapping)\n",
    "        return Mapping(other.vs, self.apply(other.ts))\n",
    "    def meaning(self):\n",
    "        defined = smt.And(self.preds)\n",
    "        #return {l : smt.Lambda(self.vs, smt.If(defined, t, smt.FreshConst(t.sort()))) for l,t in self.ts.items()}\n",
    "        # relational semantics. Partial functions.\n",
    "        return {l : smt.Lambda(self.vs + [l], smt.Implies(defined, smt.And(l == t, post))) for l,(t,post) in self.ts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PMapping():\n",
    "    vs : list[tuple[V, smt.BoolRef]] # ctx. Gamma\n",
    "    ts : dict[V, tuple[smt.ExprRef, smt.BoolRef]] # labelled output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labelled term tuples. They themselves are kind of substitutions. Hmm. But like ground ones.\n",
    "\n",
    "Obviously, could use de bruijn indices and ordered tuples of terms instead.\n",
    "\n",
    "\n",
    "a telescope mapping is conceptually a function from gamma vars with preconditions given be types into post labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finset models of families\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle x \\in \\left\\{1, 2\\right\\}$"
      ],
      "text/plain": [
       "Contains(x, {1, 2})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sympy\n",
    "x,y,z = sympy.symbols(\"x y z\")\n",
    "sympy.ConditionSet(x, x > 0, sympy.S.Reals)\n",
    "sympy.Contains(x, sympy.UniversalSet)\n",
    "x in sympy.UniversalSet\n",
    "sympy.Contains(x, sympy.FiniteSet(1,2)) # in doesn't work. Needs to evlauates to Bool\n",
    "\n",
    "#def Arr(A,B):\n",
    "#def Pi(A,B):\n",
    "\n",
    "Contains(x, sympy.UniversalSet), Contains(y, FiniteSet(1,2)(x), Contains(z, FiniteSet(1,2)(x,y))\n",
    "                                          ImageSet().Contains()\n",
    "                                        \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def Te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Turnstile(*vs, body): # TeleForAll\n",
    "    acc = body\n",
    "    # TODO: maybe compress stretches of unquantified.\n",
    "    for v in reversed(vs):\n",
    "        if isinstance(v, tuple):\n",
    "            #acc = kd.QForAll([v[0]], v[1], acc) # this is more refinement style. Strictly speaking B can still contain x in other ways.\n",
    "            acc = kd.QForAll([v[0]], v[1][v[0]], acc)\n",
    "        else:\n",
    "            acc = kd.QForAll([v], acc)\n",
    "    return acc\n",
    "\n",
    "IntT = smt.K(smt.IntSort(), True)\n",
    "#Pos = smt.Lambda([x], x > 0)\n",
    "def GT(x):\n",
    "    return smt.Lambda([y], y > x)\n",
    "def Fin(n): # meta Fin\n",
    "    return smt.Lambda([x], smt.And(0 <= x, x < n))\n",
    "# Internal-ish Fin\n",
    "Fin = kd.define(\"Fin\", [n], smt.Lambda([x], smt.And(0 <= x, x < n)))\n",
    "#Fin2 = smt.Lambda([x], smt.Lambda([y], smt.And(0 <= x, x < 2))\n",
    "Turnstile([(x, Fin(3)), (y, Fin(x))], )\n",
    "\n",
    "type Type = smt.ArraySortRef\n",
    "def Pi(A : smt.ArraySortRef, B : smt.ArraySortRef) -> Type:\n",
    "    return smt.Lambda([f], kd.QForAll([x], A[x], B(x)(f[x])))\n",
    "def Arr(A : Type, B : Type) -> Type:\n",
    "    return smt.Lambda([f], kd.QForAll([x], A[x], B(f[x])))\n",
    "def Pair(A : Type, B : Type) -> Type:\n",
    "    return smt.Lambda([p], smt.And(p.is_pair, A(p[0]), B(p[1])))\n",
    "def Sigma(A : Type, B : Type) -> Type:\n",
    "    return smt.Lambda([p], smt.And(p.is_pair, A(p[0]), B(p[0])(p[1])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contracts? diualectica? Something something?\n",
    "# You needs both variance to do stuff.\n",
    "\n",
    "type Type = type[Gen, Callable[object, bool]]\n",
    "def Pi(A, B):\n",
    "    return lambda f: all(lambda x: A(x) and B(x)(f(x))) # can't really do this part.\n",
    "def Pi(A, B):\n",
    "    def check(f):\n",
    "        hypothesis.get(A[0])\n",
    "        # quick check property that pull from A, then B(f(x))\n",
    "    def gen():\n",
    "        return lambda x: gen(B(x))\n",
    "    return gen, check\n",
    "\n",
    "def Sigma()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({frozenset(), frozenset({False, True}), frozenset({()})})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Env((\"x\", A), (\"y\", B(\"x\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lambda x35243: x35243(1)'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "type Code = str\n",
    "def lam(f : Callable[[Code], Code]) -> Code:\n",
    "    x = \"x\" + str(random.randint(0, 100000))\n",
    "    return f\"lambda {x}: {f(x)}\"\n",
    "def app(f : Code, x : Code) -> Code:\n",
    "    return f\"{f}({x})\"\n",
    "def lit(x : Code) -> Code:\n",
    "    return f\" {x} \"\n",
    "lam(lambda x: f\"{x} + 1\")\n",
    "\n",
    "lam(lambda f: f\"{f}(1)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3           0 RESUME                   0\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 LOAD_CONST               1 (1)\n",
      "              6 BINARY_OP                0 (+)\n",
      "             10 RETURN_VALUE\n",
      "  4           0 RESUME                   0\n",
      "              2 LOAD_FAST                0 (y)\n",
      "              4 LOAD_CONST               1 (1)\n",
      "              6 BINARY_OP                0 (+)\n",
      "             10 RETURN_VALUE\n"
     ]
    }
   ],
   "source": [
    "import dis\n",
    "\n",
    "f = lambda x: x + 1\n",
    "f1 = lambda y: y + 1\n",
    "dis.dis(f)\n",
    "dis.dis(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction(opname='RESUME', opcode=151, arg=0, argval=0, argrepr='', offset=0, starts_line=3, is_jump_target=False, positions=Positions(lineno=3, end_lineno=3, col_offset=0, end_col_offset=0)) Instruction(opname='RESUME', opcode=151, arg=0, argval=0, argrepr='', offset=0, starts_line=5, is_jump_target=False, positions=Positions(lineno=5, end_lineno=5, col_offset=0, end_col_offset=0))\n",
      "Instruction(opname='LOAD_FAST', opcode=124, arg=0, argval='x', argrepr='x', offset=2, starts_line=None, is_jump_target=False, positions=Positions(lineno=3, end_lineno=3, col_offset=14, end_col_offset=15)) Instruction(opname='LOAD_FAST', opcode=124, arg=0, argval='y', argrepr='y', offset=2, starts_line=None, is_jump_target=False, positions=Positions(lineno=5, end_lineno=5, col_offset=15, end_col_offset=16))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def def_eq(f, f1):\n",
    "    # not alpha equiv\n",
    "    # could have some simlifying rewriting in here?\n",
    "    for i1,i2 in zip(dis.Bytecode(f), dis.Bytecode(f1)):\n",
    "        print(i1,i2)\n",
    "        if i1.opname != i2.opname or i1.arg != i2.arg or i1.argval != i2.argval:\n",
    "            return False\n",
    "    return True\n",
    "def_eq(f,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frozenset([x + y for x in Fin(5) for y in Fin(x)]) <= Fin(8) # x : Fin(5), y : Fin(x) |- x + y : Fin(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([x + y in Fin(8) for x in Fin(5) for y in Fin(x)])  # x : Fin(5), y : Fin(x) |- x + y : Fin(8)\n",
    "all([x + y in Fin(5 + y) for x in Fin(5) for y in Fin(x)]) \n",
    "\n",
    "all([frozendict({y : x + y for y in Fin(x)}) in Pi(Fin(x), lambda z: Fin(5 + z)) for x in Fin(5)])\n",
    "# x : Fin(5) |- fun y => y + x : forall z : Fin(x), Fin(5 + z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all([isinstance(Fin(x), frozenset) for x in Fin(5)]) # x : Fin(5) |- Fin(x) Type\n",
    "all([x + y == y + x for x in Fin(5) for y in Fin(x)]) # x : Fin(5), y : Fin(x) |- x + y = y + x # judge_eq? But I don't want x + y == y + x judgementally?\n",
    "# id(x + y) == id(y + x) or  \"x + y\" == \"y + x\" or \n",
    "all([Fin(x + y) == Fin(y + x) for x in Fin(5) for y in Fin(x)]) # x : Fin(5), y : Fin(x) |- Fin(x + y) = Fin(y + x) judge_eq ? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({frozendict.frozendict({'x': False, 'y': False}),\n",
       "           frozendict.frozendict({'x': False, 'y': True}),\n",
       "           frozendict.frozendict({'x': True, 'y': False}),\n",
       "           frozendict.frozendict({'x': True, 'y': True})})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# python contexts as Gamma? No this is more like env rho? But like all envs\n",
    "def foo():\n",
    "    #A = Bool\n",
    "    #y = iter(A)\n",
    "    ctxs = [] # Gamma? Interpretation of Gamma as a set of contexts.\n",
    "    def inner():\n",
    "        for x in Bool:\n",
    "            for y in Bool:\n",
    "                t = locals()\n",
    "                del t[\"ctxs\"]\n",
    "                ctxs.append(frozendict(t))\n",
    "                del t\n",
    "    inner()\n",
    "    return frozenset(ctxs)\n",
    "foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def app(f, x):\n",
    "    return f[x]\n",
    "def var(x):\n",
    "    return x\n",
    "tt = ()\n",
    "true = True\n",
    "false = False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step indexing.\n",
    "\n",
    "# gas parameter\n",
    "def Pi(A,B,gas):\n",
    "    # all steps < gas\n",
    "    Alist = list(functools.reduce(operator.or_, A(i) for i in range(gas)))\n",
    "    return frozenset(frozendict({k:v for k,v in zip(Alist, bvs)}) for bvs in itertools.product(*[B(a,gas) for a in Alist]))\n",
    "\n",
    "# generator style.\n",
    "# B is generator of families.\n",
    "def Pi(A,B):\n",
    "    Biter = B()\n",
    "    B.next() # B is one ahead of A\n",
    "    for An in A:\n",
    "        Bn = B.next()\n",
    "        yield frozenset(frozendict({k:v for k,v in zip(An, bvs)}) for bvs in itertools.product(*[Bn(a) for a in An]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp(e : smt.ExprRef, env) -> object:\n",
    "    if isinstance(e, smt.QuantifierRef):\n",
    "        assert e.is_lambda()\n",
    "        e.vars + env\n",
    "    if smt.is_select(e):\n",
    "        app(interp(e.arg(0)), interp(e.arg(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python vs z3 meta.\n",
    "ctx can be z3 meta ctx. Not refiied.\n",
    "Forall x y z, is analog of above for loops.\n",
    "\n",
    "forall x, B[x], forall y, A[x,y], ... C[t(x,y,z)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Term0 = smt.DeclareSort(\"Term0\")\n",
    "Term = smt.Datatype(\"Term\")\n",
    "Term.declare(\"TT\")\n",
    "Term.declare(\"BoolVal\", (\"bval\", smt.BoolSort()))\n",
    "Term.declare(\"IntVal\", (\"ival\", smt.IntSort()))\n",
    "Term.declare(\"PairVal\", (\"fst\", Term), (\"snd\", Term))\n",
    "Term.declare(\"OtherVal\", (\"val\", Term0)) # Functions, etc. We only separate out primitives for fun.\n",
    "\n",
    "Type = smt.SortSort(Term)\n",
    "Family = smt.ArraySort(Term, Type)\n",
    "Bool = smt.Lambda([t], t.is_BoolVal)\n",
    "Void = smt.Lambda([t], False)\n",
    "Unit = smt.Lambda([t], t.is_TT)\n",
    "\n",
    "Arr = smt.Function(\"Arr\", Type, Type, Type)\n",
    "apply = smt.Function(\"apply\", Term, Term, Term)\n",
    "lam = smt.Function(\"lam\", smt.ArraySort(Term, Term), Term)\n",
    "kd.axiom(kd.QForAll([a,b], apply(lam(a), b)) == a[b])\n",
    "# extensionality forall x, apply(t1, x) == apply(t2, x) == (t2 == t1)\n",
    "\n",
    "\n",
    "kd.define(\"Arr\", [A,B], smt.Lambda([t], smt.And(t.is_OtherVal, kd.QForAll([x], A[x], B[apply(t, x)]))))\n",
    "kd.define('Pi', [A,B], smt.Lambda([t], smt.And(t.is_OtherVal, kd.QForAll([x], A[x], B[x][apply(t, x)]))))\n",
    "def Pi(A, B):\n",
    "    return smt.Lambda([t], smt.And(t.is_OtherVal, kd.QForAll([x], A(x), B(x, apply(t, x)))))\n",
    "# comp = smt.Function(\"comp\", Type, Term)\n",
    "# This might be ok, but the reverse,   Term, Type or asking if Term in Term requires carefulness.\n",
    "\n",
    "lamB = smt.Function(\"lamB\", smt.ArraySort(smt.BoolSort(), Term), Term)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Univ = smt.Const(\"Univ0\", Type)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametricity\n",
    "Finite parametricity\n",
    "\n",
    "https://people.mpi-sws.org/~dreyer/tor/papers/wadler.pdf\n",
    "\n",
    "\n",
    "Paramatricity is an information hiding theorem about the type universe? We want to allow open universes / be non specific about exactly what's in the universe.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Binary_relation . Hmm Class vs set issues in relation algebra\n",
    "\n",
    "schmidt relational mathematics\n",
    "\n",
    "Sympyifying and that parametricity = noether thing. Hmm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({(frozendict.frozendict({True: False, False: False}),\n",
       "            frozendict.frozendict({True: False, False: False})),\n",
       "           (frozendict.frozendict({True: False, False: True}),\n",
       "            frozendict.frozendict({True: False, False: True})),\n",
       "           (frozendict.frozendict({True: True, False: False}),\n",
       "            frozendict.frozendict({True: True, False: False})),\n",
       "           (frozendict.frozendict({True: True, False: True}),\n",
       "            frozendict.frozendict({True: True, False: True}))})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bools = frozenset({(True, True), (False, False)})\n",
    "Unit = frozenset({((), ())})\n",
    "Void = frozenset()\n",
    "def Fin(n):\n",
    "    return frozenset({(i,i) for i in range(n)})\n",
    "\n",
    "\n",
    "# I am not sure this is right.\n",
    "# Alist is longer than just the naive length of single A. So I'm picking a dependence\n",
    "# maybe I do need to do cartisan product and then \n",
    "def Arr(A,B): # In B the product is already done.\n",
    "    Alist = list(A)\n",
    "    res = []\n",
    "    for bs in itertools.product(B, repeat=len(Alist)):\n",
    "        f,f1 = zip(*[((a,b), (a1,b1)) for ((a,a1), (b,b1)) in zip(Alist, bs)])\n",
    "        res.append((frozendict(f), frozendict(f1)))\n",
    "    #f,f1 = zip(*[(a,b), (a1,b1) for ((a,a1), (b,b1)) in zip(Alist, bs)] for bs in itertools.product(B, repeat=len(Alist)))\n",
    "    return frozenset(res)\n",
    "    #return frozenset(frozendict(data), frozendict()\n",
    "\n",
    "def breakup(B):\n",
    "    xs, ys = zip(*A)\n",
    "    return frozenset(xs), frozenset(ys)\n",
    "\n",
    "\n",
    "\n",
    "type Type = frozenset[tuple[object, object]]\n",
    "type Family = frozenset[tuple[Callable[object, Type0], Callable[object, Type0]]] # this is too many tuples? Type0 doesn't really let us express correlation.\n",
    "def Pi(A, B : Family):\n",
    "    Alist = list(A)\n",
    "    res = []\n",
    "    for bs in itertools.product(*[itertools.product((B0(x), B1(y)) for B0, B1 in B) for (x,y) in Alist]):\n",
    "    #for bs in itertools.product(*[itertools.product(B[0](x), B[1](y)) for (x,y) in Alist]):\n",
    "        f,f1 = zip(*[((a,b), (a1,b1)) for ((a,a1), (b,b1)) in zip(Alist, bs)])\n",
    "        res.append((frozendict(f), frozendict(f1)))\n",
    "    #f,f1 = zip(*[(a,b), (a1,b1) for ((a,a1), (b,b1)) in zip(Alist, bs)] for bs in itertools.product(B, repeat=len(Alist)))\n",
    "    return frozenset(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(frozenset({1, 2}), frozenset({1, 2, 3}))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# factor into smallest overapaproximation if you cartieana producted again\n",
    "def factor(A):\n",
    "    xs, ys = zip(*A)\n",
    "    return frozenset(xs), frozenset(ys)\n",
    "\n",
    "factor({(1,2), (2,3), (2,1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## monotonic\n",
    "type interpeted as monotnically increasing sets\n",
    "\n",
    "maybe is becomes more interesting.\n",
    "\n",
    "vs finite sets of monotinically evaluating objects.\n",
    "vs monotonically evaluating \n",
    "Motonically producing objects?\n",
    "\n",
    "\n",
    "FRP as model of intuionistic logic? Hmm. label realvbalue of when stuiff becomes true\n",
    "\n",
    "sets of pairs of (timestamp, value) # and take the earliest timestamp\n",
    "\n",
    "vs fix how many timesteps in advance.\n",
    "\n",
    "There's no reason to use generators really. Huh.\n",
    "\n",
    "I interpret a type into this? Feels weird.\n",
    "\n",
    "a growing egraph universe\n",
    "sorts are interpreted as subuniverses?\n",
    "Next step of universe could contain it's previous self.\n",
    "This was an angle on the finite set post.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozendict.frozendict({'x': 1, 'y': 2, 'z': 4})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "def tset(vs):\n",
    "    d = {}\n",
    "    for v,t in vs:\n",
    "        d[v] = min(d.get(v, float(\"inf\")), t)\n",
    "    return frozendict(d)\n",
    "\n",
    "tset([(\"x\",1), (\"y\",2), (\"x\", 3), (\"z\",4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, None), (None, None), (42, None), (42, None), (42, 'hello')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "def delay(t, v):\n",
    "    for i in range(t):\n",
    "        yield\n",
    "    yield v\n",
    "    #return v\n",
    "\n",
    "list(delay(4, 2))\n",
    "\n",
    "x = delay(4,3)\n",
    "next(x)\n",
    "next(x)\n",
    "next(x)\n",
    "next(x)\n",
    "next(x)\n",
    "\n",
    "\n",
    "def pair(x,y):\n",
    "    for i in x:\n",
    "        yield (i,None)\n",
    "    for j in y:\n",
    "        yield (i,j)\n",
    "list(pair(delay(2,42), delay(1, \"hello\")))\n",
    "\n",
    "def Pair(A,B):\n",
    "    return [pair(i,j) for i in A for j in B]\n",
    "def Pi(A,B):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Int at 0x736ae2208a00>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Int():\n",
    "    s = set()\n",
    "    i = 0\n",
    "    while True:\n",
    "        s.add(i)\n",
    "        yield frozenset(s)\n",
    "        i += 1\n",
    "\n",
    "Int()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impredicativity\n",
    "https://cstheory.stackexchange.com/questions/36043/impredicative-in-type-theory\n",
    "How do we read this answer? Full comprehension of some formula is allowable (?).\n",
    "indctive(S) = elem(emp,S) & forall x, elem(x,S), elem(succ(x), S)\n",
    "\n",
    "large eliminations\n",
    "\n",
    "exlcuded middle gets you prop resizing https://ncatlab.org/nlab/show/propositional+resizing\n",
    "\n",
    "\n",
    "\"A type signature for church encoded natural numbers is forall (A : Prop), (A -> A) -> A -> A.\n",
    "This signature quantifies over A : Prop hence if this type signature is in Prop then Prop is impredicative which is necessary to even define functions from the church nats to church nats. \n",
    "The alternatives to impredicative Prop would be either:\"  https://discord.com/channels/1128334405795061800/1324761377801502720/1326012154830393424\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proofs as categories\n",
    "single succedent singel conseqeunt\n",
    "\n",
    "```\n",
    " ...\n",
    "------\n",
    "A |- B\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "--------- id\n",
    " id(A) : A |- A\n",
    "```\n",
    "\n",
    "```\n",
    "f : A |- B   g :  B |- C\n",
    "------------------------- cut\n",
    "     comp(f,g) : A |- C\n",
    "```\n",
    "\n",
    "```\n",
    "------------------\n",
    " fst : A /\\ B |- A\n",
    "```\n",
    "\n",
    "```\n",
    "---------------\n",
    "snd :  A /\\ B |- B\n",
    "```\n",
    "\n",
    "```\n",
    "f : A |- B   g : C |- D\n",
    "------------------ par\n",
    "par(f,g) : A /\\ C |- B /\\ D\n",
    "```\n",
    "\n",
    "```\n",
    "----------- dup\n",
    "dup : A |- A /\\ A\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "   f : A /\\ B |- C\n",
    "-------------------------\n",
    "   curry(f) : A |- B -> C\n",
    "```\n",
    "\n",
    "```\n",
    "-----------------\n",
    "apply : A /\\ A -> B |- B\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# z3 subst catgegoyr\n",
    "\n",
    "https://ncatlab.org/nlab/show/substitution#CategoricalSemantics\n",
    "\n",
    "\n",
    "A cateogical presentrration of the nufnication algorithm.\n",
    "We break down the lawvere theory into par and do it piece by piece somehow.\n",
    "\n",
    "\n",
    "I guess pullback is kind of like unifying terms from two different unification var sets\n",
    "\n",
    "https://math.andrej.com/2012/09/28/substitution-is-pullback/\n",
    "predicates.\n",
    "https://en.wikipedia.org/wiki/Pullback\n",
    "\n",
    "substitution equationally\n",
    "We work with the entire system...\n",
    "```\n",
    "-- eq is equalizer morphism\n",
    "eq(f,f) = id(dom(f))  -- id rule\n",
    "eq(f,g) = eq(g,f)  -- kind of orient rule but all at once.\n",
    "eq(par(f,g),par(h,k)) = par(eq(f,h),eq(g,k))\n",
    "eq(comp(f,g), comp(h,k)) =?\n",
    " -- unify  f,h first, then unify \n",
    " eq(comp(f,g), h) = eq(f . ??, h) something?\n",
    "\n",
    "\n",
    "eq(id,f) =? \n",
    "```\n",
    "\n",
    "https://link.springer.com/chapter/10.1007/3-540-17162-2_139  A categorical unification algorithm\n",
    "Ryhdeheard and burstall\n",
    "Hmm. Coequalizer?\n",
    "\n",
    "Hmm. Yes the variables in the terms are associated with the CODOMINA of the subtitution.\n",
    "The domain of the substitution is a mere indexing basically and almost doesn't have a sense of being a variable.\n",
    "\n",
    "To be comparing vars in codomain like unification, it should be aa coequalizer\n",
    "\n",
    "{x -> f(x', y'), y -> g(x', y')}\n",
    "[f(v0,v1), g(v0,v1)]\n",
    "\n",
    "[f(p(q(a)))] is a concrete ground term. The codomain is implicit. It could be 0 vars (?)\n",
    "The domain is 1.\n",
    "\n",
    "A signature can be expressed as noting atomic elements [f(v0,v1)]  [g(v0)]. [mul(v0,v1)] [inv(v0)] []\n",
    "\n",
    "\n",
    "A particular open preciate is [even(succ(succ(v0)))]  a multi predicate is interpreted as conjunction?\n",
    "\n",
    "\n",
    "Raising nad lowering unneccesary variables.\n",
    "Projecting out variables as exists and forall\n",
    "duplicating variables ~ eq\n",
    "\n",
    "[v0, v0]  expsress {x -> x', y -> x'}  a merging substitution\n",
    "There is no duplicating susbtitution. {x -> x', x -> y'}\n",
    "\n",
    "vBool -> F(x)  . vInt -> succ(y) = vBool -> F(succ(y))\n",
    "post composition is substituion into predicate\n",
    "vBool -> F(x)  . vInt -> add(z,y) = vBool -> F(add(x,y)) this makes morew vairblwes.\n",
    "\n",
    "f(x,y) = x   is and equation saying the vInt -> f(x,y) is the same as raise(vInt -> x, vInt)\n",
    "\n",
    "\n",
    " `|-` \n",
    "\n",
    " https://www.cl.cam.ac.uk/~amp12/papers/catl/catl.pdf catehorical logic pitts\n",
    "\n",
    " https://www.youtube.com/watch?v=uQp-Pi5jSNk quantifiers as djoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from z3 import *\n",
    "\n",
    "Ctx = list[SortRef]\n",
    "\n",
    "\n",
    "class Morph():\n",
    "    dom: list[SortRef] # not so implicit\n",
    "    cod: list[SortRef] # implicit in subst (?).\n",
    "    subst = list[ExprRef]\n",
    "    def __init__(self, dom, cod, subst):\n",
    "        assert [t.sort() for t in in subst] == dom\n",
    "        # assert all set(get_vars(t) for t in subst) in \n",
    "        self.dom = dom\n",
    "        self.cod = cod\n",
    "        self.subst = subst\n",
    "    def __matmul__(self, other):\n",
    "        assert self.dom == other.cod\n",
    "        return Morph(other.dom, self.cod, [substitute_vars(t, *other.subst) for t in self.subst])\n",
    "\n",
    "\n",
    "def id(n): # or a sort list.\n",
    "    return [Var(i) for i in range(n)]\n",
    "def comp(fs,gg):\n",
    "    return [substitute_vars(f, *gs) for f in fs]\n",
    "def par(fs,gs):\n",
    "    # TODO: shift gs.\n",
    "    return [f for f in fs] + [substutute_vars(g, Var(n + len(fs)) for g in gs]\n",
    "mullawv = [mul(Var(0), Var(1))]\n",
    "elawv = [e]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predicates():\n",
    "    vs: Ctx #list[SortRef]\n",
    "    expr: BoolRef\n",
    "    #exprs: set[BoolRef] equivalence exprs?\n",
    "\n",
    "    def proj(self) -> Ctx:\n",
    "        # returns an object in substitution category\n",
    "        return vs #(?)\n",
    "\n",
    "# category is preorder\n",
    "class Morph():\n",
    "    dom : Pred\n",
    "    cod : Pred\n",
    "    subst : Subst\n",
    "    def __init__(self, dom, cod, subst):\n",
    "        # The variables aren't shared? Hmmmmm.\n",
    "        assert dom.vs == subst.dom\n",
    "        assert cod.vs == subst.cod\n",
    "\n",
    "        assert prove(ForAll(cod.vs, Implies(substitute_vars(dom.expr, *subst.subst), cod.expr)))\n",
    "\n",
    "        #assert prove(ForAll(dom.vs, Implies(dom.expr, cod.expr)))\n",
    "        self.dom = dom\n",
    "        self.cod = cod\n",
    "    # quantifiers\n",
    "    def add(self, vsort): \n",
    "        # add an unused var along for the ride? Antiprojecting.\n",
    "        # \"weaken\". \"lift\" \"raise\"\n",
    "    def leftadjoint(self):\n",
    "        # x.add(v).leftadjoint() ~ x\n",
    "\n",
    "    def rightadjoint(self):\n",
    "        # x.rightadjoint().add(v) ~ x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typing as fibers.\n",
    "gamma |- A  is like a (entangled) product of gamma and A\n",
    "\n",
    "proj(gamma |- A) = gamma\n",
    "\n",
    "The functoriality of substutuition to the predicate category is saying that if you prove and implication with variables in it, you can substute in anything you want and still have a proof.\n",
    "No. predicates have to be over the same context to be compared...\n",
    "gamma |- A -> B\n",
    "No wait. If we include a subst we have a way to compare the two variable sets...\n",
    "\n",
    "\n",
    "There is a category over a single ctx.\n",
    "The is also a category of ctx maps\n",
    "\n",
    "Apropos partial functions: the thing that Nate and I talked about a bit was modeling these as spans, So a partial function f:A-> B would be a pair of regular functions g:X->A, h:X->B, where h is monic, and f(a) = b would translate to Ex.g(x) = a and h(x) = b. If you make h epic, that corresponds to the function being total, and if you relax the constraint that h is monic, you get what feel like multiset valued functions. For encoding in a theorem prover, I wonder if it would be smoother to use cospans, so g:A->X, h:B->X, with h monic. Then f(a) = b could translate to g(a) = f(b), and you don't need the quantifier. X could be basically Maybe B.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "From lunch: sorry, coequalizer, not equalizer\n",
    "About the substitution thing: the inclusion function, from the set of definable sets of individuals (represented by one-variable formulas/predicates) to the set of definable sets of pairs of individuals (represented by two-variable formulas) is actually the result of a substitution, if you look at it a certain way. Suppose I have a two-argument function, f(x,y) and a one variable formula F(x). I can make a two variable formula by substitution: F(f(x,y)). If my function is projection of the left argument, so that f(x,y) = x, then what my substitution is doing is, in a more explicit way, turning F from a one variable formula into a slightly degenerate case of a two variable formula.\n",
    "\n",
    "There's a contravariant functor thing going on here: f : A -> B induces a functor from the fiber (in this case, a Boolean algebra of definable sets or something) over B to the fiber over A.\n",
    "\n",
    "\n",
    "Yea, coequalizer does seem right now\n",
    "What is the fiber? There is a special Bool object maybe and  strangely the morphisms coming out of bool represent predicates and the target object is the vars in the predicate expression?\n",
    "Or it the boolean algebra a category connected to our substitution category by a functor, ie a model of our signature\n",
    "\n",
    "So, the boolean algebra is the fiber. The objects in there are equivalence classes of formulas, and the arrows are the boolean algebra ordering, which corresponds to implication.\n",
    "\n",
    "The idea is that there's a total category whose objects are formulas in a typing context. So, like a \"two variable formula\" is a formula whose variables are a subset of x,y, in a context \"x: individual, y: individual\". The contexts are the base category, and the functor that erases formulas and just leaves the context is the fibration. The fibers are the preimage categories of a given context plus its identity map - in the FOL case, these turn out to be Boolean algebras. (edited) \n",
    "\n",
    "The contexts are the objects in the base category of substitutions or each context is an entire base category? (edited) \n",
    "\n",
    "\n",
    "They're objects in a base category. Base category is not quite a category of substitutions, it's more like a category where the maps are function symbols. So like, a two variable function f induces a map from the context \"x: individual, y: individual\" to \"x:individual\". But a map in the base category like this creates a map (going in the other direction) between the fibers, which is essentially the result of substituting f(x,y) for x in each of the formulas-in-context in the fiber, thereby changing the context that it lives in.\n",
    "\n",
    "\n",
    "What about if you compose two maps? Isn’t it then not a function symbol and something more structured, more like a general substitution? Its generated by the function symbols ?\n",
    "\n",
    "Yeah, that's right.\n",
    "I'd think of it as a term, so like f(g(x,z),y) might be a map from the context x,y,z to the context x.\n",
    "\n",
    "\n",
    "\n",
    "Something I was realizing last night is substitution goes the other way. x,y,z is the codomain, despite how weird that feels\n",
    "{x’ -> f(g(x,z),y)}\n",
    "makes that feel better. Those codomain vars are on the right now\n",
    "\n",
    "All is well with the world.\n",
    "\n",
    "Are the upper objects full equivalence classes? Seems like a burden. Why can’t the upper objects be individual predicate expressions, what is the set getting us?\n",
    "\n",
    "I think they can. It just wouldn't be a boolean algebra anymore.\n",
    "\n",
    "a = b = c, why can’t an object be {a,b}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lawvere\n",
    "\n",
    "The equalizer in a lawvere theory is E-unification.\n",
    "\n",
    "combinator form of substitutions\n",
    "\n",
    "\n",
    "coalgebra.\n",
    "a -> f a\n",
    "\n",
    "operads\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gat EAT\n",
    "https://ncatlab.org/nlab/show/essentially+algebraic+theory\n",
    "\n",
    "t1 = t2 /\\ t3 = t4 => t5 = t6\n",
    "\n",
    "t5 . solve(par(t1,t3),par(t2, t4)) = t6 . solve(...)\n",
    "\n",
    "This is saying the under the substitution/assumption t1 = t2 ... \n",
    "And I think it's a sefl consitent E assumtionb.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Having equalizers + products is the same as having all finite limits somehow?\n",
    "\n",
    "\n",
    "\n",
    "In egglog, t1 = t2 ,,.... => t3 = t4\n",
    "You can solve e-unify in the body via egraph ematching.\n",
    "\n",
    "But then this asserts a new equality.\n",
    "\n",
    "t1 =E t2 ==> t3 = t4\n",
    "Conditional KB.\n",
    "\n",
    "https://www.youtube.com/watch?v=RmiTOa4b0bA&ab_channel=ToposInstitute CB Aberle: All Concepts are Essentially Algebraic\n",
    "\n",
    "The next one up in evan's hierarchy was\n",
    "locally carteian closed\n",
    "https://ncatlab.org/nlab/show/locally+cartesian+closed+category\n",
    "https://link.springer.com/chapter/10.1007/BFb0022273 On the interpretation of type theory in locally cartesian closed categories . Hofmann\n",
    "\n",
    "burtsall rydeheard style slicing.\n",
    "cod(f) = x =>\n",
    "slice(f)?\n",
    "\n",
    "\n",
    "GAT to EAT relationship. Should probably try to model that first. Or maybe multisorted logic?\n",
    "\n",
    "\n",
    "The monad form of lawvere theory is kind of like the herband model in set? The monad action is applying the constructors of the theories and quitented by axioms?\n",
    "https://anuyts.github.io/files/keml-diagrams.pdf\n",
    "\n",
    "Type -> Ctx style vs  EAT\n",
    "x,y,z -> Type  style  GAT\n",
    "\n",
    "Evocative of the observational vs record approach to tuples\n",
    "prod(x,y)\n",
    "vs q opaque, fst(q) = x, snd(q) = y\n",
    "\n",
    "Type -> ctx\n",
    "Type is total space, ctx is base space\n",
    "\n",
    "dom(subst) = ctx1\n",
    "cod(subst) = ctx2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# refeinment sorts\n",
    "I had notes somewhere about prolog using CLP.\n",
    "\n",
    "https://arxiv.org/pdf/2010.07763 tutorial\n",
    "\n",
    "https://noamz.org/oplss16/refinements-notes.pdf \n",
    "\n",
    "https://proofassistants.stackexchange.com/questions/755/whats-the-relationship-between-refinement-types-and-dependent-types hmm. Pierre-Marie suggest that a insifficiently restricted P in {x | P} can effectively enocde full dependent types. \"realizability interpetation\" in PRL.\n",
    "\n",
    "Does this subsyetms make me closer to cody's Boole?\n",
    "\n",
    "\n",
    "smtlib is basically a simply type programming language. Why not\n",
    "\n",
    "For using new logics in knuckeldragger we can:\n",
    "deep embed in z3\n",
    "shallow embed into z3\n",
    "make new judgement forms at the python metalevel that contain kd.Proof.\n",
    "\n",
    "\n",
    "annotate will be an immediate call to check (?). So annotate will take in Gamma.\n",
    "\n",
    "reflection could be an axiom schema to convert HasType to a kd.Proof. Interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x : Int | x > 0, y : Int | x > y, z : Int | z < y"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from kdrag.all import *\n",
    "@dataclass\n",
    "class Telescope():\n",
    "    vs : list[smt.ExprRef]\n",
    "    preds : list[smt.BoolRef | smt.QuantifierRef] # crucially can contain previous vars\n",
    "    def __init__(self, *vspreds): # could just make the empty context?\n",
    "        self.vs, self.preds = zip(*vspreds)\n",
    "    def __repr__(self):\n",
    "        return \", \".join([f\"{v} : {v.sort()} | {pred}\" for v,pred in zip(self.vs,self.preds)])\n",
    "    def entail(self):\n",
    "        acc = smt.BoolVal(True)\n",
    "    def extend(self, v, pred):\n",
    "        # add a new variable to the context\n",
    "        # should check that previous preds do not contain new v.\n",
    "        return Telescope(self.vs + [v], self.preds + [pred])\n",
    "\n",
    "# more linked list like. Easier to make immutable? Hmm. But lists are so much easier to work with.\n",
    "class Telescope2():\n",
    "    tail : Telescope2\n",
    "    v : smt.ExprRef\n",
    "    pred : smt.BoolRef\n",
    "\n",
    "\n",
    "\n",
    "# as bottom up judgement, base case should take a kd.Proof\n",
    "# This is actually kind of cool.\n",
    "@dataclass\n",
    "class EntailJudge():\n",
    "    ctx: Telescope\n",
    "    c : smt.BoolRef\n",
    "\n",
    "@dataclass\n",
    "class SubClass():\n",
    "    ctx : Telescope\n",
    "    v1 : smt.ExprRef\n",
    "    typ1 : smt.BoolRef\n",
    "    v2 : smt.ExprRef\n",
    "    typ2 : smt.BoolRef\n",
    "    # do we automatically do it in the smart consutrctor or not?\n",
    "    def __init__(self): ...\n",
    "    def __repr__(self):\n",
    "        return f\"{self.ctx} |- {self.t} <: {{ {self.t.sort()} | {self.typ} }}\"\n",
    "\n",
    "@dataclass\n",
    "class HasType():\n",
    "    ctx : Telescope\n",
    "    t : smt.ExprRef\n",
    "    typ : smt.BoolRef\n",
    "    def __repr__(self):\n",
    "        return f\"{self.ctx} |- {self.t} : {{ {self.t.sort()} | {self.typ} }}\"\n",
    "\n",
    "\n",
    "x,y,z = smt.Ints(\"x y z\")\n",
    "\n",
    "Telescope((x, x > 0), (y, x > y), (z, z < y))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RefinedSort():\n",
    "    sort : z3.SortRef\n",
    "    pred : z3.ExprRef # not a boolref. a lambda {x : Sort | pred(x) } -> {y : : sort2 | pred(x,y) }\n",
    "    v : z3.ExprRef\n",
    "    pred : z3.BoolRef # maybe invloing pred\n",
    "    ctx : list[z3.ExprRef] # y : ?  |- {x : sort | pred(x)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 18 (1256577910.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 19\u001b[0;36m\u001b[0m\n\u001b[0;31m    if\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 18\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from z3 import *\n",
    "import z3\n",
    "@dataclass\n",
    "class RSort():\n",
    "    sort : z3.SortRef\n",
    "    pred : z3.BoolRef # self is referred to as var(0)\n",
    "@dataclass\n",
    "class Arr():\n",
    "    dom: RSort\n",
    "    cod: RSort # var(1) refers to var bound in dom.\n",
    "    @property\n",
    "    def sort(self):\n",
    "        return ArraySort(self.dom.sort, self.cod.sort)\n",
    "\n",
    "\n",
    "def entail(gamma, c):\n",
    "    xs = [FreshConst(sort) for sort in gamma]\n",
    "    s = Solver()\n",
    "    s.add(Not(ForAll(xs, substitute_vars(c, *xs))))\n",
    "    assert s.check() == unsat\n",
    "\n",
    "\n",
    "def subtyp(gamma, sort1, sort2):\n",
    "    if isinstance(sort1, Arr) and isinstance(sort2, Arr):\n",
    "        assert subtyp(gamma, sort2.dom, sort1.dom) and subtyp([sort2.dom] + gamma, sort1.cod, sort2.cod)    \n",
    "    elif isinstance(sort1, RSort) and isinstance(sort2, RSort):\n",
    "        assert sort1.sort == sort2.sort\n",
    "        x = FreshConst(sort1.sort)\n",
    "        f = ForAll([x], substitute_vars(Implies(sort1.pred, sort2.pred), x))\n",
    "        assert entail(gamma, f)\n",
    "    else:\n",
    "        raise Exception(\"Unknown type\", sort1, sort2)\n",
    "\n",
    "\n",
    "def synth(gamma, term):\n",
    "    \n",
    "\n",
    "def check(gamma, term, typ):\n",
    "    assert term.sort() == typ.sort\n",
    "    if is_select(term): # app\n",
    "    elif is_quantifier(term) and term.is_lambda():\n",
    "        assert isinstance(typ, Arr)\n",
    "        x, body = open_binder(term)\n",
    "        gamma[x] = typ.dom\n",
    "        return check(gamma, body, typ.cod)\n",
    "    elif term in gamma: # gotta find it\n",
    "        s = gamma[term]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a type\n",
    "a word. paper words. a speronality.\n",
    "\n",
    "bertrand russell, a method to remove paradoxes\n",
    "\n",
    "datatypes\n",
    "\n",
    "a syntactical discipline to maintain abstractions - reynolds\n",
    "\n",
    "compositional analyses - Neel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realizability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Z = namedtuple(\"Z\", \"n\") # zero\n",
    "S = namedtuple(\"S\", \"n\") # succ\n",
    "T = namedtuple(\"T\", \"n m\") # transfer\n",
    "J = namedtuple(\"J\", \"n m q\") # jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primes = [2,3,5,7,11,13,17,19,23,29,31,37,41,43,47]\n",
    "def code(e):\n",
    "    if tuple(e):\n",
    "        acc = 1\n",
    "        for p,c in zip(primes, e):\n",
    "            acc *= p ** code(c)\n",
    "        return primes[0]**acc\n",
    "\n",
    "\n",
    "def decode(e):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = DeclareSort(\"A\")\n",
    "K = Const(\"K\", A)\n",
    "S = Const(\"S\", A)\n",
    "app = Function(\"app\", A, A, A, BoolSort())\n",
    "kd.define\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBE\n",
    "See nbe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import z3\n",
    "TYPE = z3.DeclareSort(\"TYPE\")\n",
    "TERM = z3.DeclareSort(\"TERM\")\n",
    "\n",
    "def check(ctx, term,typ):\n",
    "    is_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from typing import Callable\n",
    "\"\"\"\n",
    "def C(tag, *args):\n",
    "    return tuple[Literal(tag), *args]\n",
    "\n",
    "type L[A] = Literal[A] # not allowed\n",
    "type app = Literal[\"app\"]\n",
    "type Arr[A,B] = Callable[[A],B]\n",
    "type typ = C[\"arr\", typ, typ] | C(\"unit\")\n",
    "type term = C[App, term, term] | C[\"lam\", term] | C[\"var\", int]\n",
    "\"\"\"\n",
    "# This is about as short as I can go. The system doesn't enable abstraction over types. it's pretty rigid\n",
    "\n",
    "type term = tuple[Literal[\"app\"], term, term] | \\\n",
    "            tuple[Literal[\"lam\"], term] | \\\n",
    "            tuple[Literal[\"var\"], int]\n",
    "\n",
    "type typ = tuple[Literal[\"arr\"], typ, typ] | \\\n",
    "           tuple[Literal[\"unit\"]]\n",
    "\n",
    "def pprint(t : term) -> str:\n",
    "    match t:\n",
    "        case (\"barf\",):\n",
    "            return \"barf\"\n",
    "        case (\"app\", f, x):\n",
    "            return f\"{pprint(f)} {pprint(x)}\"\n",
    "        case (\"lam\", x):\n",
    "            return f\"λ{pprint(x)}\"\n",
    "        #case (\"var\", x):\n",
    "        #    return f\"x{x}\"\n",
    "\n",
    "def poo(x : int) -> term:\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "type aexpr = tuple[Literal[\"var\"], str] | \\\n",
    "             tuple[Literal[\"lit\"], int] | \\\n",
    "             tuple[Literal[\"add\"], aexpr, aexpr]\n",
    "\n",
    "def eval(e : aexpr, env : dict[str,int]) -> int:\n",
    "    match e:\n",
    "        case (\"var\", x):\n",
    "            return env[x]\n",
    "        case (\"lit\", x):\n",
    "            return x\n",
    "        case (\"add\", x, y):\n",
    "            return eval(x, env) + eval(y, env)\n",
    "\n",
    "assert eval((\"add\", (\"lit\", 1), (\"var\", \"x\")), {\"x\" : 2}) == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[](old/2024-07/typecheck_pcode_DATALLLLLLLLLLOG.IPYNB)\n",
    "\n",
    "\n",
    "System F\n",
    "\n",
    "types\n",
    "\n",
    "Programming in Martin Lof type theory\n",
    "\n",
    "HOTT - john sterling stuff\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "type Foo[A] = tuple[A,A]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
