{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://people.cs.nott.ac.uk/psztxa/publ/fomus19.pdf altelnkirch note\n",
    "\n",
    "https://eprints.nottingham.ac.uk/41385/1/th.pdf  Type theory in a type theory with\n",
    "quotient inductive types kaposi thesis\n",
    "\n",
    "Winterhalter thesis\n",
    "\n",
    "https://drops.dagstuhl.de/storage/00lipics/lipics-vol131-fscd2019/LIPIcs.FSCD.2019.25/LIPIcs.FSCD.2019.25.pdf  Gluing for Type Theory\n",
    "\n",
    "abstract and concrerte type theories - uemeura https://eprints.illc.uva.nl/id/document/12150\n",
    "\n",
    "artin gluing is a way to put two cetagories together\n",
    "Logical relations\n",
    "\n",
    "\n",
    "LF\n",
    "\n",
    "https://www.danielgratzer.com/papers/type-theory-book.pdf\n",
    "programming in martin lof type theory\n",
    "hott book\n",
    "egbert hott book\n",
    "\n",
    "Cody's notes https://www.kleene.church/tt-notes\n",
    "\n",
    "https://logic.berkeley.edu/logic@UCB/Rathjen_logic@UCB.pdf On relating type theories to (intuitionistic) set theories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Telescopes as tries.\n",
    "Compressed tries. If we have True in every branch, it'll compress to true.\n",
    "In this sense, a term in context has more values than just True and False\n",
    "\n",
    "How does one compress branches where the assumptions fail?\n",
    "\n",
    "[x : Bool, y : if x then Unit else Void] |- red : RGB\n",
    "\n",
    "I guess compression gets to elide one thing? The full set going the the same value. {True:a , False:a}  . The map {True: a} does not get elided.\n",
    "Maybe this is like ZDD vs BDD?\n",
    "\n",
    "This does seem right. It's the analog of whether you can trim context. You get blocked on the first scrutinee you actually gotta scrute.\n",
    "\n",
    "https://ncatlab.org/nlab/show/canonical+form canonicity. closed terms compute to normal forms\n",
    "Maybe somehow Trie compression is a model of computation?\n",
    "\n",
    "\n",
    "Adding axioms makes \"blocked terms\" stuck terms\n",
    "\n",
    "Intentional equality can go in assumptions.\n",
    "\n",
    "\n",
    "\n",
    "Setoid model. Def is on the nose equal. Prop is equivalence in equiv relation\n",
    "\n",
    "{a,b}, {(a,b), (a,a), (b,b)}\n",
    "\n",
    "id1(a) = b\n",
    "id1(b) = b\n",
    "\n",
    "extensionality.\n",
    "\n",
    "https://inria.hal.science/hal-01445835/document  The next 700 syntactical models of type theory. https://proofassistants.stackexchange.com/questions/1922/independence-of-function-extensionality\n",
    "\n",
    "Just interpret functions with an extra bool? application forgets the bool. An extra anything? Color? id? Binary code?\n",
    "What about dictionaries that are the same extensionally but different like red black trees.\n",
    " = is defined as actual structural equality.\n",
    " forall x, f x = g x is structural equality on lookup.\n",
    "\n",
    "Assoc lists is the easiest one.\n",
    "\n",
    "They are permutation equal\n",
    "\n",
    "forall x, f[x] == g[x]  <--->  f = g\n",
    "if f = g is proof relevant with a permutation. Interesting.\n",
    "\n",
    "Proof producing sort function actually returns the permutation. Hmm.\n",
    "Sorting is a great way to canonize.\n",
    "\n",
    "```C\n",
    "bool check_ext(f, g){\n",
    "    f(true) == g(true) // extensional equality\n",
    "    f(false) == g(false)\n",
    "    implies\n",
    "    f == g // pointer equality\n",
    "}\n",
    "// nope\n",
    "```\n",
    "\n",
    "\n",
    "And interpreting Sets as (deduped?) lists.\n",
    "\n",
    "[True, False] != [False, True]\n",
    "{True, False}\n",
    "\n",
    "A 1-Set of bool and and 2-set of bool?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x\n",
    "def g(x):\n",
    "    return x\n",
    "assert (f == g) is False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ordered set model. From a set theory persepctive, every set copmes with a total / well ordering (not sure which since in finite case distinction doesn't matter).\n",
    "This is _extra_ structure from Set perspective.\n",
    "\n",
    "From a programming eprsective, sets do not come for free. They require active dedupping, sorting, treeing. Sets requires extra structure on tree like things. This is the purer model\n",
    "\n",
    "Is it every useful to append two assoc lists?\n",
    "Disjoint union I guess, but that adds tags.\n",
    "\n",
    "\n",
    "Even though we can give meaningful data to the identity type, this is still the setoid model. with the setoid being generatred by a canonization function.\n",
    "\n",
    "\n",
    "`type Type = tuple[frozenset, Callable[[object], object]]`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((False, False), (True, False)),\n",
       " ((False, False), (True, True)),\n",
       " ((False, True), (True, False)),\n",
       " ((False, True), (True, True)),\n",
       " ((True, False), (False, False)),\n",
       " ((True, False), (False, True)),\n",
       " ((True, True), (False, False)),\n",
       " ((True, True), (False, True)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type Type = tuple\n",
    "import itertools\n",
    "def Pi(A,B):\n",
    "    # Only returning canonically ordered. But should it?\n",
    "    return tuple(tuple(zip(A,vs)) for vs in itertools.product(*[B(a) for a in A]))\n",
    "def Pi2(A,B):\n",
    "    return tuple(tuple(zip(A1,vs)) for A1 in itertools.permutations(A) for vs in itertools.product(*[B(a) for a in A1]))\n",
    "Bool = (False, True)\n",
    "Unit = ((),)\n",
    "Pi2(Bool, lambda x : Bool)\n",
    "def Sigma(A,B):\n",
    "    return tuple((a,b) for a in A for b in B(a))\n",
    "def Sigma2(A,B): ...\n",
    "    # No, we're double counting here a lot?\n",
    "    # But we were before too in a sense./\n",
    "    return tuple((a,b) for A1 in itertools.permutations(A) for a in A1 for B1 in itertools.permutations(B(a)) for b in B1))\n",
    "def Id(A, x, y):\n",
    "    # x and y are sequences of some kind?\n",
    "    # But we still only have one possible perm?\n",
    "    # unless x and y allow double counting.\n",
    "\n",
    "    px = sorted(range(len(x)), key=lambda i: x[i])\n",
    "    py = sorted(range(len(y)), key=lambda i: y[i])\n",
    "    return tuple()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# identity types\n",
    "\n",
    "Families.\n",
    "parameters vs indices\n",
    "https://golem.ph.utexas.edu/category/2022/07/identity_types_in_context.html\n",
    "https://cs.stackexchange.com/questions/20100/what-are-the-difference-between-and-consequences-of-using-type-parameters-and-ty\n",
    "https://homotopytypetheory.org/2011/04/10/just-kidding-understanding-identity-elimination-in-homotopy-type-theory/\n",
    "\n",
    "P(a,refla)\n",
    "P selects where to rewrite.\n",
    "\n",
    "\n",
    "A refinment version?\n",
    "p : EqInfo | eq(p, a, b)\n",
    "\n",
    "pattern matching and unification problems. How to compiler dependent matcvhes to \n",
    "\n",
    "\n",
    "Constructors internalize meta notions.\n",
    "sigma types tinernalize things that can happen in a context.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Terms sort is not that different from ZF.\n",
    "https://ncatlab.org/nlab/show/subsingleton\n",
    "\n",
    "Consider other congruence relations. Combinators on them?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TERMS = smt.DeclareSort(\"TERMS\") # Constructions\n",
    "TYPE = set_.Set(TERMS) # Is type judgement\n",
    "elem = smt.Function(\"elem\", TERMS, smt.SetSort(TERMS)) # has type judgement\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantics of type theory\n",
    "\n",
    "https://cms.sic.saarland/semantics_ws2122/materials/\n",
    "\n",
    "https://cstheory.stackexchange.com/questions/17668/resources-for-mathematicians-hoping-to-learn-more-computer-science\n",
    "\n",
    "https://people.mpi-sws.org/~dreyer/courses/catlogic/jacobs.pdf catgeorical logic and type theory bart jacobs\n",
    "\n",
    "practical foundatiosn - taylor\n",
    "\n",
    "https://www.lfcs.inf.ed.ac.uk/reports/92/ECS-LFCS-92-208/  An introduction to fibrations, topos theory, the effective topos and modest sets\n",
    "\n",
    "https://ncatlab.org/nlab/show/categorical+semantics+of+dependent+type+theory\n",
    "Ok. \n",
    "sets pointing into their \"type\" sets considered as subsets of them.\n",
    "Then there are squares that \n",
    "type families Ai  project into their indexing space (?). Yeah, I guess so.\n",
    "\n",
    "\n",
    "Categories with families. Cody says related to explicit substituion calculus like lambda sigma.\n",
    "\n",
    "Substitutions as a category\n",
    "\n",
    "GATs involved somehow.\n",
    "\n",
    "Maybe the first step is to deeply understand lawvere theories. https://en.wikipedia.org/wiki/Lawvere_theory\n",
    "https://ncatlab.org/nlab/show/Lawvere+theory\n",
    " How do you combinatorify equational/algebraic or first order logic?\n",
    "term = morphism from unit?\n",
    "https://www.youtube.com/watch?v=IZcrASzCybs&ab_channel=SchmidCollege%2CChapmanUniversity evan patterson. standard hierachy at 41:10\n",
    "free substitutions vs substituions under a theory? Adding equations to the category of substitutions?\n",
    "\n",
    "Functor to set = model\n",
    "\n",
    "To turn n-arity into single arity we can use a prod construction. Just like we can make multiarg computer programs using tuples\n",
    "fst(prod(x,y)) = x\n",
    "snd(prod(x,y)) = y\n",
    "`assoc(prod(x,prod(y,z))) = prod(prod(x,y),z)` vs `prod(x,prod(y,z)) = prod(prod(x,y),z)`. fst and snd get confused if we make equal on the nose.\n",
    "So is this an an example of how to model higher structures that aren't \"equal on the nose\"?\n",
    "\n",
    "Another style\n",
    "prod2(x,y)\n",
    "prod3(x,y,z)\n",
    "\n",
    "negassoc(prod(prod(x,y),z)) = prod(x,prod(y,z))\n",
    "\n",
    "\n",
    "\n",
    "see fibers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# subtyping\n",
    "https://en.wikipedia.org/wiki/Subtyping\n",
    "\n",
    "algebraic subtyping dolan\n",
    "\n",
    "https://softwarefoundations.cis.upenn.edu/plf-current/Sub.html\n",
    "https://dl.acm.org/doi/10.1145/3409006 simple essense lionel parreaux\n",
    "\n",
    "PVS 1998 Rushby\n",
    "Liquid type Rondon 2008\n",
    "vazou 2014\n",
    "\n",
    "\n",
    "\n",
    "Hindley Milner is unification based\n",
    "\n",
    "Biunification is something else. Trasntivie clousre based?\n",
    "\n",
    "Kind of triggers my refinement egraph senses.\n",
    "\n",
    "https://github.com/brendanzab/language-garden\n",
    "elaboration zoo\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# depedent matching\n",
    "Agda may or may not have it's definitions arrange internally as case equations.\n",
    "It seems like this may be a legtiimate way to think about things rather than insisting about compiling to recursors.\n",
    "\n",
    "Dependent pattern matching has unification in the forced bits.\n",
    "\n",
    "How does one chew? It's like \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hott\n",
    "\n",
    "https://ncatlab.org/nlab/show/categorical+semantics+of+dependent+type+theory\n",
    "https://www.cs.uoregon.edu/research/summerschool/summer14/rwh_notes/ssdt.pdf\n",
    "\n",
    "What is the name \n",
    "\n",
    "https://www.cs.cmu.edu/~rwh/courses/hott/ bob harper course\n",
    "\n",
    "https://mathstodon.xyz/@MartinEscardo/110890155815254064 escardo threads on hott\n",
    "\n",
    "https://www.youtube.com/@epitspringschoolonhomotopy6943 EPIT Spring School on Homotopy Type Theory 2021\n",
    "https://www.youtube.com/@jdchristensen123  HoTTEST 2022\n",
    "https://www.youtube.com/playlist?list=PL-47DDuiZOMCRDiXDZ1fI0TFLQgQqOdDa 2019 bauer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Before you assert univalence, there is still a notion of path\n",
    "truncation level.  (A, eqs) ,  (B, eqs, eq_eqs) ? Types carry an extra layer. 2-setoids. 2-subsets (?)  (A, B, C) s.t. C <= B <= A \n",
    "A claim is that Category theory is naturally truncated a level up because object equality is due to isomorphisms.\n",
    "O1 ~ O2  is a pair of morphisms.  The higher equality is _ ? 2-categories? A notion of equality on pairs of morphisms?\n",
    "\n",
    "equivalences\n",
    "\n",
    "A homotopy is f ~ g = pi x:A f(x) =_B(x) g(x)\n",
    "If A is parameter space. The abstract torus\n",
    "f builds a cofrfee cup in R3\n",
    "g builds a donut in R3\n",
    "f(x) = g(x) the euqality is the trail a point in the cofee to donut transformatyion\n",
    "\n",
    "The [0,1] is curried or something.\n",
    "[0,1] -> B(x) is the cubical looking weay of talking about it\n",
    "\n",
    "\n",
    "sec(f)\n",
    "retr(f)\n",
    "is-equiv(f) = sec(f) and retr(f)\n",
    "A ~= B  = exists f, is_equiv(f) . Kind of sutble.\n",
    "\n",
    "B ~= A ought to wokr by fliiping sec retr.\n",
    "\n",
    "\n",
    "Kind of like saying invertible but not quote.\n",
    "\n",
    "\n",
    "Maps are homotopic\n",
    "Homotopy of spaces.\n",
    "\n",
    "Disk to point are homotopic\n",
    "\n",
    "Quadtrees interval trees https://en.wikipedia.org/wiki/Interval_tree\n",
    "https://gap-packages.github.io/hap/tutorial/chap1_mj.html\n",
    "https://global.oup.com/academic/product/an-invitation-to-computational-homotopy-9780198832980?cc=us&lang=en&\n",
    "\n",
    "I x A -> B  vs A -> (I -> B)  vs I -> (A -> B)\n",
    "\n",
    "Ordered multisets (?) for simplicial sets\n",
    "\n",
    "\n",
    "https://www.youtube.com/watch?v=FUOJbN1iswg&ab_channel=AppliedAlgebraicTopologyNetwork  \n",
    "Chris Kapulkin (05/06/25): An invitation to discrete homotopy theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# z3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "TYPE = smt.DeclareSort(\"TYPE\")\n",
    "TERM = smt.DeclareSort(\"TERM\")\n",
    "\n",
    "@dataclass\n",
    "class Judgement():\n",
    "    ctx : list[tuple[smt.ExprRef, smt.ExprRef]]\n",
    "@dataclass\n",
    "class IsType(Judgement):\n",
    "    typ : smt.ExprRef\n",
    "    def __repr__(self):\n",
    "        return f\"{self.ctx} |- {self.typ} TYPE\"\n",
    "@dataclass\n",
    "class HasType(Judgement):\n",
    "    term : smt.ExprRef\n",
    "    typ : smt.ExprRef\n",
    "    def __repr__(self):\n",
    "        return f\"{self.ctx} |- {self.term} : {self.typ}\"\n",
    "@dataclass\n",
    "class EqType(Judgement):\n",
    "    typ1 : smt.ExprRef\n",
    "    typ2 : smt.ExprRef\n",
    "    def __repr__(self):\n",
    "        return f\"{self.ctx} |- {self.typ1} = {self.typ2}\"\n",
    "@dataclass\n",
    "class EqTerm(Judgement):\n",
    "    term1 : smt.ExprRef\n",
    "    term2 : smt.ExprRef\n",
    "    typ : smt.ExprRef\n",
    "    def __repr__(self):\n",
    "        return f\"{self.ctx} |- {self.term1} = {self.term2} : {self.typ}\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Array(T, Bool)"
      ],
      "text/plain": [
       "Array(T, Bool)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "T = smt.DeclareSort(\"T\")\n",
    "TSet = smt.SetSort(T)\n",
    "\n",
    "TSet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ncatlab.org/nlab/show/type+telescope\n",
    "https://www.pls-lab.org/en/telescope\n",
    "https://www.sciencedirect.com/science/article/pii/089054019190066B?ref=pdf_download&fr=RR-2&rr=92eb234868378fa9  Telescopic mappings in typed lambda calculus\n",
    "\n",
    "telescopes as trees?\n",
    "telescopes are ordered variables. grobner elmination tries to find a fopr of the polynomial like that. Gauss elimination.\n",
    "Triangular form. trinagular unfication. We're just playing mind jazz baby\n",
    "J Zucker\n",
    "\n",
    "T3elescope dot product. Terms are in the telescope. Dot product instantiations vairables. hmmm.\n",
    "`[1 , 2] . [x : x = 17, y : y + x = 14] =  1 = 17 /\\ 2 + 1 = 14` \n",
    "`[foo(a), bar(biz)] . [x : baz(x), y : edge(x,y)] = baz(foo(a)) /\\ edge(foo(a), bar(biz))`\n",
    "\n",
    "telescopic mappings are matrices?\n",
    "dot product is maybe like |=? \n",
    "\n",
    "telescopic mappings are instnation of the contex? They are substitutions. BUt then the telescope isn't\n",
    "Some kind of trinagular matrix? a stack of rows or a stack of columns?\n",
    "nested telescopes.\n",
    "x -> [y : B(y)]\n",
    "No whole hog. The substiution rule applied one by one? Subst + weaken.\n",
    "Add in new variable we're going to subst to. Then eliminate using subst old variable in terms of new.\n",
    "[x : A(x)] |- f(x) : Z(x) \n",
    "[y : B(y), x : A(x)] |- f(x) : Z(x) weaken\n",
    "[y : B(y)] |- f(g(y)) |- Z(g(y)) subst\n",
    "\n",
    "Gam, x : A, Del\n",
    "and\n",
    "Gam |- t : A \n",
    "\n",
    "Gam, Del[t/A]\n",
    "\n",
    "\n",
    "I guess telescope is a generalization of my `vs` list, which was a context, sure.\n",
    "If telescopes are a context, what is a ntext? :)\n",
    "\n",
    "\n",
    "\n",
    "def unify(telescope, t1 , t2, typ)\n",
    "def pmatch(telescope, p, t1, typ)\n",
    "\n",
    "\n",
    "You could have GAT rewriting logic. \n",
    "Gam |- t1 -> t2 : A.  asymmettric\n",
    "Gam |- A -> A1\n",
    "\n",
    "Gam |- T type is a fibration.\n",
    "\n",
    "predicates with variables in them are sets at the metalevel. Before we use comprehension / lambda to internalize them.\n",
    "\n",
    "If you have an equational theory of types, you could find an ordering the context that puts the thing you want to substitute last or first?\n",
    "\n",
    "definitional type equality is in a context. Not clear if I have to use kleene equality or no. Well, I need to quantify over the variables in scope...\n",
    "If I don't have function symbols, this is probably all in EPR?\n",
    "\n",
    "To say we have a iterative fibering of a surface is kind of like saying we have a fully projection sequence form.\n",
    "It's weird to say that we have this from the get go.\n",
    "block triangular form is almost as good.\n",
    "mappings between\n",
    "[x : R,  y : R | y = x**2 + 2]\n",
    "Does a telescope have anything to do with triangular form solutions / projection / gauss elimination / elimination / quantifer elim.   I could descibe a sphere as something like [x : R, y : R | x**2 + y**2 <= 1, z : R | z = 1 - x**2 - y**2] \n",
    "Or some robot configuration it's nice to have the kinematics straightened out. Or maybe something something cylindrical algerbaic decomposition\n",
    "I could decribe a triangular linear equation as  [x : R | x = 42, y : R | y = 3* x + 14, ...]\n",
    "Or fourier motzkin form as   [x : R | 1 < x < 7, y : R | x + y < 4 /\\ x + y < 17, ....]\n",
    "\n",
    "[ p : R^3|   p.x**2 + p.y**2 + p.z**2 = 1 ] converting this telescope into that above one is hard in general\n",
    "\n",
    "SympyTelescope. SolveSet.\n",
    "\n",
    "TERM and TYPE\n",
    "\n",
    "But what if they were the same? is TYPE = Set(TERM), this requires some kind of class -> set comprehension like thing. An internalization.\n",
    "TYPE1 = smt.SetSort(TYPE)\n",
    " and so on\n",
    "\n",
    "\n",
    "```\n",
    "# n are universe levels. Obviously they are not in the system. They are python integers\n",
    "def TYPE(n):\n",
    "    if n == 0:\n",
    "        return TERM \n",
    "    return smt.SetSort(TYPE(n-1))\n",
    "```\n",
    "\n",
    "is univalence statable?\n",
    "```\n",
    "def univalence(n):\n",
    "    return Iso(A == B, Iso(A,B)) # no. == is definitional equality. We want propositional equality (?) right?\n",
    "    retrun Iso(PropEq(A,B), Iso(A,B))\n",
    "\n",
    "def Iso(A,B):\n",
    "    #which for ismorphic stuff means same cardinality? But maybe less clear given we're recursing into an equality.\n",
    "    f,g = smt.Array(\"f g\", TYPE(n), TYPE(n))\n",
    "    smt.Exists([f,g], A[x] => B[f(x)], B[y] => A[g(y)], f(g(x)) == x, g(f(y)) == y)\n",
    "```\n",
    "\n",
    "finite models by encding up to universe level n. If it trivialize at some N, we're good to go? It stays trivial?\n",
    "\n",
    "I'm building a model of dependent type theory. I don't know if that proves it in the original system, that unsat means that there must be a judgement in dependent type theory. Can i extract such a judgement tree from an unsat core?\n",
    "\n",
    "\n",
    "\n",
    "lifting property\n",
    "unit ->  spiral\n",
    "|         |\n",
    "\\/        \\/\n",
    "interval -> circl\n",
    "\n",
    "we pick an \"inital condition\" for which layer we want to be on, that's what the upper and left edges do, then the r5est of the path is derivable.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Resolution_of_singularities\n",
    "\n",
    "\n",
    "co de bruijn telescopes.\n",
    "\n",
    "VMap = \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SolveSet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mTelescope\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvs\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msympy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSymbol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# maybe if we want it in block solved form, list[tuple[sympy.Symbol, ...]]\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtyps\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSolveSet\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mTelescope\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mTelescope\u001b[39;00m():\n\u001b[32m      4\u001b[39m     vs : \u001b[38;5;28mlist\u001b[39m[sympy.Symbol]  \u001b[38;5;66;03m# maybe if we want it in block solved form, list[tuple[sympy.Symbol, ...]]\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     typs : \u001b[43mSolveSet\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'SolveSet' is not defined"
     ]
    }
   ],
   "source": [
    "import sympy\n",
    "\n",
    "class Telescope():\n",
    "    vs : list[sympy.Symbol]  # maybe if we want it in block solved form, list[tuple[sympy.Symbol, ...]]\n",
    "    typs : SolveSet\n",
    "\n",
    "class Shape(): #Fibration\n",
    "    ctx : Telescope   # base\n",
    "    typ : SolveSet # a constrjiat on the rewals\n",
    "\n",
    "class Point():\n",
    "    ctx : Telescope\n",
    "    t : sympy.Expr\n",
    "    typ : SolveSet\n",
    "\n",
    "type Tele = list[tuple[sympy.Symbol, SolveSet] | tuple[sympy.Symbol, sympy.Constraint]]  # and maybe an implcit f(x) == 0, which is idiomatic sympy.\n",
    "\n",
    "# list of (variable, type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we go meta. The Universal sort TERM is a pain in the ass\n",
    "\n",
    "This is more like the subset model (?)\n",
    "\n",
    "\n",
    "I have said that `vs` is a form of context.\n",
    "Changing everywhere I give vs to a tele is reasonable\n",
    "\n",
    "Gives us constrained \"loops\". Could this help spacer infer stuff? Hmm\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QForAll(): # change name to Pi? Ehhhh, not a function type though.\n",
    "    if (x,T) in ctx:\n",
    "        if isinstance(T, BoolRef):\n",
    "            P = smt.ForAll(x, smt.Implies(T, P))\n",
    "        elif isinstance(T, smt.ArraySort):\n",
    "            P = smt.ForAll(x, smt.Implies(T(x), P))\n",
    "        elif \n",
    "\n",
    "def QExists(xs, body): # change name to Sigma? Not a Pair type.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(x, Lambda(f!5, ForAll(x!4, Implies(x!4 > 0, f!5[x!4] > x!4))))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "type Tele = list[tuple[smt.ExprRef, smt.ExprRef]] # (name)\n",
    "def wf_tele(tele : Tele):\n",
    "    for n, (v, T) in enumerate(tele):\n",
    "        if any(v.eq(v1) for v1, T1 in tele[:n]): # previous variables are not equal\n",
    "            raise ValueError(f\"Variable {v} at position {n} is not unique.\")\n",
    "        if not smt.is_const(v):\n",
    "            raise ValueError(f\"Variable {v} at position {n} is not a constant.\")\n",
    "        if smt.SetSort(v.sort()) != T.sort():\n",
    "            raise ValueError(f\"{T} has type {T.sort()} which is not a set of the variable type {v.sort()} at position {n}.\")\n",
    "        # I suppose that variables don't have to bve ordered\n",
    "        if not kd.utils.free_in([v1 for v1, T1 in tele[n:]], T): #current and later variables do not appear\n",
    "            raise ValueError(f\"{T} references future or current variables\") \n",
    "        \n",
    "x,y,z = smt.Reals(\"x y z\")\n",
    "R = smt.K(smt.RealSort(), smt.BoolVal(True))\n",
    "Pos = smt.Lambda([x], x > 0)\n",
    "wf_tele([(x, R), (y, R), (z, R)]) # ok\n",
    "#wf_tele([(x, R), (x, R)])\n",
    "#wf_tele([(x, smt.Lambda([y], y == x))])\n",
    "\n",
    "def ctx_thm(tele : Tele, P : smt.BoolRef) -> smt.BoolRef:\n",
    "    for v,T in reversed(tele):\n",
    "        # could default to convenience of True.\n",
    "        # Also we auto insert wf in same spot. Interesting.\n",
    "        P = kd.QForAll([v], T(v), P)\n",
    "    return P\n",
    "def TForAll(tele : Tele, P : smt.BoolRef) -> smt.BoolRef:\n",
    "    return ctx_thm(tele, P)\n",
    "# vs QForAll(vs, *Preds, P). The context is more of a thing. More structured. Hmm.\n",
    "def GT(x): # GT is a family of predicates\n",
    "    return smt.Lambda([z], z > x)\n",
    "\n",
    "#The lambda means you really are referring to cxurrent var. Why not just allow it?\n",
    "# Why not have subset just be a BoolExpr that may or may not have x in it.\n",
    "# Lambda([x], P) <-> (x,P)\n",
    "\n",
    "ctx_thm([(x, Pos), (y, smt.Lambda([z], z > x))], y > 0)\n",
    "ctx_thm([(x, Pos), (y, GT(x))], y > 0)\n",
    "\n",
    "def Pi(APred, BFam):\n",
    "    A = APred.sort().domain()\n",
    "    a = smt.FreshConst(A, prefix=\"x\")\n",
    "    BPred = BFam(a)\n",
    "    B = BPred.sort().domain()\n",
    "    AB = smt.ArraySort(A, B)\n",
    "    f = smt.FreshConst(AB, prefix=\"f\")\n",
    "    return smt.Lambda([f], smt.ForAll([a], smt.Implies(APred(a), BPred(f(a)))))\n",
    "def Arr(APred,BPred):\n",
    "    A = APred.domain()\n",
    "    B = BPred.domain()\n",
    "    AB = smt.ArraySort(A, B)\n",
    "    f = smt.FreshConst(AB)\n",
    "    a = smt.FreshConst(A)\n",
    "    return smt.Lambda([f], smt.ForAll([a], smt.Implies(APred(a), BPred(f(a)))))\n",
    "# Pair. Hmm.\n",
    "# Dep Pair\n",
    "\n",
    "[(x, Pi(Pos, GT))]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pvs.csl.sri.com/doc/tse98.pdf predicate subtyping in pvs\n",
    "https://pvs.csl.sri.com/doc/semantics.pdf \n",
    "Variant of refinment / liquid types?\n",
    "Coq Program directive https://rocq-prover.org/doc/V9.0.0/refman/addendum/program.html Matthieu Sozeau. Subset coercions in Coq. In TYPES'06, volume 4502 of LNCS, 237–252. Springer, 2007.  https://sozeau.gitlabpages.inria.fr/www/research/publications/Subset_Coercions_in_Coq.pdf\n",
    "\n",
    "https://goto.ucsd.edu/~rjhala/liquid/liquid_types.pdf \n",
    "\n",
    "ok so liquid types has increases inference, reduced annotation burden. ok. https://arxiv.org/pdf/2010.07763according to history section\n",
    "\n",
    "\n",
    "predicate subtyping https://www.gilith.com/talks/tphols2001-subtypes.pdf https://belle.sourceforge.net/doc/subtypes.pdf simulating in HOL\n",
    "https://inria.hal.science/hal-01673518/document Extending higher-order logic with predicate subtyping \n",
    "\n",
    "could register the subset theorems into kernel.defns\n",
    "prove( , wf=True)  could find and inject lemmas about wellformedness akin to how unfold traverses and injects unfolding lemmas. \n",
    "\n",
    "I guess dafny could also be kind of using this.\n",
    "\n",
    "If I made a definition with the output type reflecting the body. Is that liquid haskell's thing proof by reflection thing?\n",
    "\n",
    "\n",
    "Horn solver. Hmm. Could I use a horn solver (spacer) to solver for higher order unify? or vice versa?\n",
    "\n",
    "https://shemesh.larc.nasa.gov/fm/pvs/TutorialCADE2021/\n",
    "https://shemesh.larc.nasa.gov/PVSClass2012/pvsclass2012/\n",
    "https://shemesh.larc.nasa.gov/PVSClass2012/pvsclass2012/lectures-printer/real-proving.pdf\n",
    "https://shemesh.larc.nasa.gov/fm/pvs/TutorialCADE2021/material/cade-real-proving.pdf\n",
    "https://fm.csl.sri.com/SSFT16/PVScourse.pdf\n",
    "\n",
    "manip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tdefine(name, tele, restype, body, by=[]):\n",
    "    non_empty(tele)\n",
    "    #undef = smt.FreshFunction(, prefix=\"undef\")\n",
    "    # undef = smt.FreshConst(restype, prefix=\"undef\") non dependent undef\n",
    "    f = kd.define(name,args(tele, smt.If(cond, body, undef))) \n",
    "    wf1 = kd.prove(kd.TForAll(tele, restype(body)), by=by)\n",
    "    f.wf = kd.prove(kd.TForAll(tele, restype(f(*args)))), by=[wf1, f.defn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (1919204856.py, line 28)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mreturn Telescope(self.vs[:posn] self.vs[posn+1:], self.typs[:posn] + tailtyps)\u001b[39m\n                     ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "# Gatexpr is like Gam |- t : A judgement. see cat_topos_free.ipynb\n",
    "TERM = smt.DeclareSort(\"TERM\")\n",
    "TYPE = smt.SetSort(TERM)\n",
    "\n",
    "@dataclass\n",
    "class TeleScope():\n",
    "    vs : list[smt.ExprRef]\n",
    "    typs : list[smt.BoolRef] # vs smt.ExprRef. Pre applied to vs or not?\n",
    "    def interp(self):\n",
    "        return smt.And(self.typs)\n",
    "        #return smt.And(typ(*self.vs[:i]) for i,typ in enumerate(self.typs))\n",
    "    def extend(self, typ): # C-ext\n",
    "        v = smt.FreshConst(TERM)\n",
    "        return v, Telescope(vs + [v], typs + [typ(v)]) # typ is a z3 or python lambda that can also contain previous variables.\n",
    "    # I guess I'm considering all type expressions to be valid.\n",
    "    # Gamma |- T type is not a judgement that is needed.\n",
    "    # if wqe capture \"variables\" not in scope somehow, they are considered to be constants.\n",
    "    # We have an open notion of constant\n",
    "    #def strengthen(self, n): ... # check nothing using variable n and then remove it. Is this weakening, or is this strengthening.\n",
    "    def weaken(self, posn, typ):\n",
    "        v = smt.FreshConst(TERM)\n",
    "        # maybe check typ does not contain any vs[posn:]. THis is just fancy extend\n",
    "        return v, Telescope(vs[:posn] + [v] + vs[posn+1:], typs[:posn] + [typ(v)] + typs[posn+1:])\n",
    "    def subst(self, v_or_posn, t : GatExpr):\n",
    "        assert t.ctx == self[:posn] # or alpha eq? and normalize?\n",
    "        assert t.typ == self.typs[posn]\n",
    "        tailtyps = [smt.substitute(typ  (v, t.t)) for typ in self.typs[posn+1]]\n",
    "        return Telescope(self.vs[:posn] self.vs[posn+1:], self.typs[:posn] + tailtyps)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GATExpr():\n",
    "    ctx : Telescope\n",
    "    t : smt.ExprRef # t.sort() == TERM\n",
    "    typ : smt.ExprRef # this is a typ.sort() == TYPE\n",
    "\n",
    "    def judge(self):\n",
    "        smt.ForAll(self.ctx.vs, self.ctx.interp(), self.typ[self.t])\n",
    "    def __eq__(self, other):\n",
    "        # either require to be in same context or reconcile them. (common prefix?)\n",
    "\n",
    "\n",
    "\n",
    "Ob = smt.Const(\"Ob\", TYPE)\n",
    "Hom = smt.Function(\"Hom\", Ob, Ob, TYPE)\n",
    "a,b,c = smt.Consts(\"a b c\", TERM)\n",
    "kd.axiom(Ob[a])\n",
    "kd.axiom(Ob[b])\n",
    "kd.axiom(Ob[c])\n",
    "f,g,h = smt.Consts(\"f g h\", TERM)\n",
    "id_ = smt.Function(\"id\", TERM, TERM)\n",
    "comp = smt.Function(\"comp\", TERM, TERM, TERM)\n",
    "kd.notation.matmul.register(TERM, comp)\n",
    "\n",
    "kd.axiom(kd.QForAll([a], Ob[a], Hom(a,a)[id_(a)])) # a : Ob |- id(a) : Hom(a,a)\n",
    "kd.axiom(kd.QForAll([a,b,c], Ob[a], Ob[b], Ob[c], Hom(a,b)[f], Hom(b,c)[g], Hom(a,c)[f @ g])) # a : ob, b : Ob, c : Ob, f : Hom(a,b), g : Hom(b,c) |- f . g : Hom(a,c) \n",
    "\n",
    "# hmm. Hom(a,b)[f] is there difference of those like the difference between indexes and parameters? Nooooo. Porb not.\n",
    "\n",
    "\n",
    "# equality rules\n",
    "kd.axiom(kd.QForAll([a,b], Ob[a], Ob[b], Hom(a,b)[f], f @ id_(a)) == f) # a : Ob, b : Ob, f : Hom(a,b) |- f. id(a) = f\n",
    "# other id\n",
    "# assoc comp\n",
    "\n",
    "# Ob[a] is a simple predicate. And i can do it ahead of time in z3 sort system. If I know these things don't intersect? \n",
    "# Injectivity of Type constructors?\n",
    "# This is an optimization though.\n",
    "\n",
    "\n",
    "# a : Ob, b : Ob, f : Hom(a,b) |- dom(f) = a\n",
    "# a : Ob, b : Ob, f : Hom(a,b) |- cod(f) = b\n",
    "\n",
    "# internalizing type. deep embedding GAT/ Martin Lof into GAT\n",
    "type0 = smt.Function(\"type0\", TYPE)\n",
    "type1 = smt.Function(\"type1\", TERM)\n",
    "eq = smt.Function(\"eq\", TERM, TERM, TERM) # \n",
    "eq1 = smt.Function(\"eq\", TERM, TERM, TYPE)\n",
    "eq2 = smt.Function(\"eq\", TYPE, TYPE, TERM) # eq1 is a judgement, eq2 is a term.\n",
    "eq3 = smt.Function(\"eq\", TYPE, TYPE, TYPE) # eq1 is a judgement, eq2 is a term.\n",
    "eq4 = smt.Function(\"eq\", TYPE, TERM, TYPE) # THe two inputs hsould at least match yeah?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, here's the idea with maps between contexts and substitutions. Say I've got a context x:A,y:B(x), and another x:C,y:D(x). Then a map from the first to the second should be a pair of terms x:A, y:B(x) |- c(x,y), d(x,y) - so the components can depend on every variable in the first context - but the types of these terms should be C and D(c(x,y)). So strictly speaking what you want are terms x:A, y:B(x) |- c(x,y) : C and x:A, y:B(x) |- d(x,y) : D(c(x,y)). Mutatis mutandis for more than two types, these give you a mapping between the contexts if you just think of each context as a dependent tuple type.\n",
    "They also give you a substitution mapping going in the other direction. Like if you have terms c, d as above, and some type T(x,y) in context x:C,y:D(x), then you can turn T into a type in context x:A, y:B(x) by substitution: x:A,y:B(x)|-T(c(x,y), d(x,y)).\n",
    "So this is an example of the general picture where a morphism in a base category between two objects X,Y induces a functor between the fiber categories above X,Y in the total category, going in the opposite direction. The contexts are objects of the base category, and the types in a given context are the objects in the fiber over that context.\n",
    "\n",
    "\n",
    "Put ticks on x’:C, y’:D(x’)\n",
    "\n",
    "\n",
    "Fair (edited) \n",
    "\n",
    "Is it c(x’,y’) ?\n",
    "4:32\n",
    "Or c(x,y)?\n",
    "\n",
    "\n",
    "The second. The arguments to c(x,y) have types A and B(x)\n",
    "\n",
    "\n",
    "See that’s the part that is non intuitive to me\n",
    "\n",
    "I’d have thought it should be c(x’,y’)\n",
    "\n",
    "Because I want to change out the x variables for x’ variablez\n",
    "\n",
    "Then I think you want a map from the context x':C,y'D(x') to x:A,y:B(x).\n",
    "\n",
    "Analogy: if I have a function from nats to reals, it turns predicates depending on reals into predicates depending on nats. If I have a map from context C to context C', it turns things that depend on C' (like types in that context) into things that depend on C.\n",
    "\n",
    "\n",
    "So i should actually be thinking of context mappings as functions, not substitutions\n",
    "\n",
    "Yeah. They're mappings, and mappings induce substitutions.\n",
    "\n",
    "And contexts actually have a semantics and arent just syntax\n",
    "\n",
    "Yeah. They're the base category. Concretely, you can even think about them as sets (of indices) if you're thinking about types in context as indexed families of sets.\n",
    "\n",
    "x : A, y : B(x) |- x’ := c(x,y) : C, y’ := d(x,y) : D(x’)\n",
    "\n",
    "I see, so in the semantics “free” single sorted herbrand model case, the “function” form is applying those terms to the input. This is not a very interesting thing to discuss, so it doesn’t show up in automated reasoning texts\n",
    "5:17\n",
    "And its tuples of terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{a: Lambda([x, y], x + y), b: Lambda([x, y], x - y), c: Lambda([x, y], x*y)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "from dataclasses import dataclass\n",
    "V = smt.ExprRef\n",
    "@dataclass\n",
    "class Mapping():\n",
    "    vs : list[V] # ctx. Gamma\n",
    "    ts : dict[V, smt.ExprRef] # labelled output\n",
    "    # x,y,z |- x' := f(x,y), y' := g(x,y), z' := h(x,y)\n",
    "    def __post_init__(self):\n",
    "        assert all(v.sort() == t.sort() for v,t in self.ts.items())\n",
    "    def apply(self, ts : dict[V, smt.ExprRef]):\n",
    "        assert all(v in self.vs for v in ts.keys())\n",
    "        return {v: smt.substitute(t, *[(v,ts[v]) for v in self.vs]) for v,t in self.ts.items()}\n",
    "    def __matmul__(self, other):\n",
    "        assert isinstance(other, Mapping)\n",
    "        return Mapping(other.vs, self.apply(other.ts))\n",
    "    def meaning(self):\n",
    "        return {l : smt.Lambda(self.vs, t) for l,t in self.ts.items()}\n",
    "\n",
    "x,y,z,a,b,c,p,q = smt.Ints(\"x y z a b c p q\")\n",
    "\n",
    "m1 = Mapping([x,y], {a : x + y, b : x - y, c : x * y})\n",
    "m2 = Mapping([a,b,c], {p : a + b, q : a})    \n",
    "\n",
    "x0 = {x : smt.IntVal(1), y : smt.IntVal(2)}\n",
    "m1.apply(x0)\n",
    "\n",
    "class Predicate(Mapping):\n",
    "    # ts should be a single\n",
    "    def __post_init__(self):\n",
    "        assert len(self.ts) == 1\n",
    "        assert all(v.sort() == smt.BoolSort() for v,t in self.ts.items())\n",
    "        super().__post_init__()\n",
    "\n",
    "m2 @ m1\n",
    "assert (m2 @ m1).apply(x0) == m2.apply(m1.apply(x0))\n",
    "\n",
    "m1.meaning()\n",
    "\n",
    "\n",
    "def unify(m1 : Mapping, m2 : Mapping):\n",
    "    assert m1.ts.keys() == m2.ts.keys()\n",
    "    todo = [(t, m2[l]) l,t in for m1.ts.items()]\n",
    "    subst = kd.utils.unify(todo)\n",
    "    vs = m1.vs + m2.vs - subst.keys()\n",
    "    return Mapping(vs, {v : subst[v] if v in subst else v for v in m1.vs} ), Mapping(vs, {v : subst[v] if v in subst else v  for v in m2.vs} )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PMapping():\n",
    "    vs : list[V] # ctx. Gamma\n",
    "    pre : list[smt.BoolRef] # pres over vs. could intertwine with vs\n",
    "    ts : dict[V, tuple[smt.ExprRef, smt.BoolRef]] # labelled output.\n",
    "    #post : list[smt.BoolRef] # post over with vs as vars. same length as ts.\n",
    "    # x,y,z |- x' := f(x,y), y' := g(x,y), z' := h(x,y)\n",
    "    def __post_init__(self):\n",
    "        assert all(v.sort() == t.sort() for v,t in self.ts.items())\n",
    "    def apply(self, ts : dict[V, smt.ExprRef]):\n",
    "        assert all(v in self.vs for v in ts.keys())\n",
    "        return {v: smt.substitute(t, *[(v,ts[v]) for v in self.vs]) for v,t in self.ts.items()}\n",
    "    def __matmul__(self, other):\n",
    "        assert isinstance(other, Mapping)\n",
    "        return Mapping(other.vs, self.apply(other.ts))\n",
    "    def meaning(self):\n",
    "        defined = smt.And(self.preds)\n",
    "        #return {l : smt.Lambda(self.vs, smt.If(defined, t, smt.FreshConst(t.sort()))) for l,t in self.ts.items()}\n",
    "        # relational semantics. Partial functions.\n",
    "        return {l : smt.Lambda(self.vs + [l], smt.Implies(defined, smt.And(l == t, post))) for l,(t,post) in self.ts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PMapping():\n",
    "    vs : list[tuple[V, smt.BoolRef]] # ctx. Gamma\n",
    "    ts : dict[V, tuple[smt.ExprRef, smt.BoolRef]] # labelled output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labelled term tuples. They themselves are kind of substitutions. Hmm. But like ground ones.\n",
    "\n",
    "Obviously, could use de bruijn indices and ordered tuples of terms instead.\n",
    "\n",
    "\n",
    "a telescope mapping is conceptually a function from gamma vars with preconditions given be types into post labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finset models of families\n",
    "Idenitty types / squashed prpositions are kind of a way to do nested for loops and remove the need for if statements.\n",
    "\n",
    "for x in A:\n",
    "    for y in B(x):\n",
    "        if cond(x,y):\n",
    "            do something\n",
    "\n",
    "is like\n",
    "\n",
    "def C(x,y):\n",
    "    return set([()]) if x == y else set()\n",
    "\n",
    "for x in A:\n",
    "    for y in B(x):\n",
    "        for p in C(x,y):\n",
    "            do something\n",
    "\n",
    "FROM A as x From B as y FROM p \n",
    "    WHERE B.arg = x\n",
    "    WHERE P \n",
    "\n",
    "\n",
    "https://www.philipzucker.com/frozenset_dtt/\n",
    "\n",
    "What is the point?\n",
    "maybe if you can lazily eval Type... Then asking if t in T \n",
    "semantic tableau vs truth tables.\n",
    "\n",
    "laziness + object identity shortcuts id(x) == id(x)\n",
    "Moving stuff up through loops ~ weakening. Keep things in factored form\n",
    "\n",
    "compression + laziness\n",
    "https://arxiv.org/pdf/2301.10841\n",
    "\n",
    "pattern matching. lazy trie join.\n",
    "\n",
    "Distinguishing between positive and negative type positions.\n",
    "\n",
    "\n",
    "terms are search procedures through the Type trie. pattern matching\n",
    "\n",
    "can all this business with cells be transformed into a pure style?\n",
    "\n",
    "state + nondet\n",
    "env -> [(v, env)] \n",
    "\n",
    "\n",
    "\n",
    "prolog version\n",
    "\n",
    "```\n",
    "bool(true).\n",
    "bool(false).\n",
    "\n",
    "ite(true, A, B) --> A.\n",
    "ite(false, A, B) --> B.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "[env] = [val, typ, val]\n",
    "\n",
    "\n",
    "def lam(A, f):\n",
    "    def res(env):\n",
    "        env = env + [A]\n",
    "        return f(env)\n",
    "\n",
    "def ite(c, t, e):\n",
    "    for vc in c(env):\n",
    "        if \n",
    "\n",
    "def lam(A, f):\n",
    "    def res(typ):\n",
    "\n",
    "\n",
    "def lam\n",
    "\n",
    "def ann(e, typ):\n",
    "    def res\n",
    "    return typ\n",
    "\n",
    "\n",
    "def ann(t, A):\n",
    "    if t(A):\n",
    "        return A\n",
    "def lam(f):\n",
    "    def check(env, A1, A2):\n",
    "        return f()\n",
    "    return check\n",
    "def var(v):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bool():\n",
    "    return (None, [True, False])\n",
    "def Bool():\n",
    "    yield True\n",
    "    yield False\n",
    "def Pair(A, B):\n",
    "    def forcea_b(a):\n",
    "        yield from [(a, b) for b in B]\n",
    "    def forceb_a(b):\n",
    "        yield from [(a, b) for a in A]\n",
    "    def force_a():\n",
    "        return [((a, None), forcea_b(a)) for a in A]\n",
    "    def force_b():\n",
    "        return [((None, b), forceb_a(b)) for b in B]\n",
    "    forcea = [(x)]\n",
    "    return ((None,None), [force_a, force_b])\n",
    "\n",
    "def Pair(A, B):\n",
    "    def forcea_b(a):\n",
    "        yield from [(a, b) for b in B]\n",
    "    def forceb_a(b):\n",
    "        yield from [(a, b) for a in A]\n",
    "    def force_a():\n",
    "        return [(a, forcea_b(a)) for a in A]\n",
    "    def force_b():\n",
    "        return [(b, forceb_a(b)) for b in B]\n",
    "    return (force_a, force_b)\n",
    "\n",
    "\n",
    "def force(ctx, x):\n",
    "    for v in ctx[x]:\n",
    "        ctx1 = ctx.copy()\n",
    "        ctx1[x] = V\n",
    "        yield ctx1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  true false\n",
    " /  \\ /   /\n",
    "e1  e2   e3\n",
    "\\   /   /\n",
    " None\n",
    "\n",
    "The only way for e1 and e2 to be refined is to values?\n",
    "\n",
    "   \n",
    "   {true}   {false}\n",
    "      \\     /\n",
    "{true, false}\n",
    " /   /   /\n",
    "e1  e2   e3  ... en\n",
    "\\   /   /\n",
    "   None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bool(n): # named nones. n is context size? But there was be other stuck terms than just x |- x.\n",
    "             # but fitnizing the number of names is reasonable to keep things finite.\n",
    "             # Names are known equal but not known apart. You can always approximate to None\n",
    "    return [True, False] + [(None, i) for i in range(n)]\n",
    "\n",
    "\n",
    "#  \n",
    "\n",
    "\n",
    "# tail saturated list. all chains of partial order.\n",
    "Bool = [(None, True), (None, False), True, False]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Pair(A,B):\n",
    "    # all interleavings\n",
    "    taila\n",
    "    for a in A:\n",
    "        a[0]\n",
    "        Pair([a[1:]], B)\n",
    "\n",
    "    return [None, \n",
    "\n",
    "\n",
    "type Type = Poset\n",
    "\n",
    "# a little datalog.\n",
    "def trans_close(order):\n",
    "    pass\n",
    "class Poset():\n",
    "    set_ : frozenset\n",
    "    order : frozenset[tuple[object,object]]\n",
    "    def check(self):\n",
    "        for (a,b) in self.order:\n",
    "            for (b1, c) in self.order:\n",
    "                if b == b1:\n",
    "                    assert (a, c) in self.order, f\"Transitivity failed: {a} < {b} < {c} not in order\"\n",
    "    def __mul__(self, other):\n",
    "        seed = [((a,x), (a,y))  for a in self.set_ for (x,y) in other.order] + [((a,x), (b,x)) for (a,b) in self.order for x in other.set] \n",
    "        return Poset(frozenset(itertools.product(self.set, other.set)), trans_close(seed))\n",
    "    def __add__(self, other): # disjoint sum of posets.\n",
    "        return Poset([(\"inl\", a) for a in self.set] + [(\"inr\", b) for b in other.set], \n",
    "                     frozenset([((\"inl\", a), (\"inl\", b)) for (a, b) in self.order] + \n",
    "                               [((\"inr\", a), (\"inr\", b)) for (a, b) in other.order]))\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "Bool = Poset(frozenset([None, True, False]), frozenset([(None, True), (None, False)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interleave_pair (1, 2) (3, 4)\n",
      "interleave_pair (2,) (3, 4)\n",
      "interleave_pair (2,) (4,)\n",
      "interleave_pair (1, 2) (4,)\n",
      "interleave_pair (2,) (4,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((1, 3), (2, 3), (2, 4)),\n",
       " ((1, 3), (2, 3), (2, 4)),\n",
       " ((1, 3), (2, 3), (2, 4)),\n",
       " ((1, 3), (1, 4), (2, 4)),\n",
       " ((1, 3), (1, 4), (2, 4)),\n",
       " ((1, 3), (1, 4), (2, 4))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bool = [(None, True), (None, False), (True,), (False,)]\n",
    "#def interleave(a, b):\n",
    "#    for x in interleave(a[1:], b):\n",
    "#        yield (a[0],) + x\n",
    "#    for y in interleave(a, b[1:]):\n",
    "#        yield (b[0],) + y\n",
    "\n",
    "# chain product. chains in product of posets\n",
    "def interleave_pair(a, b):\n",
    "    print(f\"interleave_pair {a} {b}\")\n",
    "    if len(a) == 1:\n",
    "        yield tuple((a[0],x) for x in b)\n",
    "    else:\n",
    "        for xs in interleave_pair(a[1:], b):\n",
    "            yield ((a[0],b[0]),) + xs\n",
    "    if len(b) == 1:\n",
    "        yield tuple((x,b[0]) for x in a)\n",
    "    else:\n",
    "        for ys in interleave_pair(a, b[1:]):\n",
    "            yield ((a[0],b[0]),) + ys\n",
    "\n",
    "list(interleave_pair((1,2), (3,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "type Type = (Gen, Check)\n",
    "\n",
    "def lam(A, f):\n",
    "    def res(env):\n",
    "        env += [A]\n",
    "        AB[1](f(len(env)))\n",
    "def app(f, x):\n",
    "    def res(B):\n",
    "        for  in f.items():\n",
    "\n",
    "def ann(t, A):\n",
    "    # recollect up?\n",
    "    def res(env):\n",
    "        return env, A\n",
    "    assert t in A\n",
    "    return A\n",
    "\n",
    "\n",
    "def has_type(t,  typ):\n",
    "\n",
    "\n",
    "\n",
    "def Bool():\n",
    "    yield True\n",
    "    yield False\n",
    "def Pair(A, B):\n",
    "    def res():\n",
    "        for a in A:\n",
    "            yield (a, B)\n",
    "    return res\n",
    "def Sum(A,B):\n",
    "    yield (\"inl\", A)\n",
    "    yield (\"inr\", B)\n",
    "def Arr(A,B):\n",
    "    return {a : B() for a in A}\n",
    "def app(f,x):\n",
    "    yield from f[x]()\n",
    "\n",
    "\n",
    "\n",
    "def ite(c,t,e):\n",
    "\n",
    "def eq_type(typ1, typ2):\n",
    "    if id(typ1) == id(typ2):\n",
    "    \n",
    "\n",
    "\n",
    "def has_type(t, typ):\n",
    "    # This slams producer against consumer\n",
    "\n",
    "\n",
    "lam(A, lambda x: var(x))\n",
    "\n",
    "lam([True, False], lambda x: var(x))\n",
    "def var()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138593187061184, 138593187061824)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "def Bool():\n",
    "    yield True\n",
    "    yield False\n",
    "def Bool1():\n",
    "    yield True\n",
    "    yield False\n",
    "def eq_type(a,b):\n",
    "    if callable(a):\n",
    "        return id(a) == id(b)\n",
    "    elif callable(b):\n",
    "        return False\n",
    "    else:\n",
    "        return a == b\n",
    "@dataclass\n",
    "class Box():\n",
    "    val : object\n",
    "    forced : bool = False\n",
    "    def __eq__(self, other):\n",
    "        return id(self) == id(other) if not self.forced else self.val == other.val\n",
    "    \n",
    "\n",
    "def def_eq(x,y):\n",
    "    if isinstance(x, list) and isinstance(y, list):\n",
    "        return id(x) == id(y)\n",
    "    else:\n",
    "    return id(x) == id(y)\n",
    "assert def_eq(Bool, Bool)\n",
    "assert not def_eq(Bool, Bool1)\n",
    "\n",
    "def lam(A, f):\n",
    "    return f(Box(A)) # f([A])\n",
    "def lam(As, f):\n",
    "    return f(*map(Box, As))\n",
    "\n",
    "assert lam(Bool, lambda x: lam(Bool, lambda y: def_eq(x,x)))\n",
    "lam(Bool, lambda x: lam(Bool, lambda y: (id(x), id(y)))) # this is not a type judgement. This is a term.\n",
    "\n",
    "def ite(x : Box, t, e):\n",
    "    def res(typ):\n",
    "        if x.forced:\n",
    "            return t() if x.val else e()\n",
    "        else:\n",
    "            return t(typ) and e(typ)\n",
    "    return res\n",
    "\n",
    "def Arr(A,B):\n",
    "    return (\"Arr\", A, B)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function __main__.<lambda>()>,\n",
       " <function __main__.<lambda>()>,\n",
       " <function __main__.<lambda>()>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = lambda: True\n",
    "t2 = lambda: True\n",
    "id(t1) == id(t2)\n",
    "[t1,t2,t1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from frozendict import frozendict\n",
    "import itertools\n",
    "type Family = Callable[[object], Type]\n",
    "type Type = frozenset\n",
    "\n",
    "Void = frozenset({})\n",
    "Unit = frozenset({()})\n",
    "Bool = frozenset({True, False})\n",
    "def Fin(n : int) -> Type:\n",
    "    return frozenset(range(n))\n",
    "def Vec(A : Type, n : int) -> Type:\n",
    "    return frozenset(itertools.product(A, repeat=n))\n",
    "\n",
    "def is_type(A: Type) -> bool: # |- A type\n",
    "    return isinstance(A, frozenset)\n",
    "def has_type(t: object, A: Type) -> bool: # |- t : A\n",
    "    return t in A\n",
    "def eq_type(A: Type, B: Type) -> bool: # |- A = B type\n",
    "    return A == B\n",
    "def def_eq(x : object, y: object, A : Type) -> bool: # |- x = y : A\n",
    "    return x == y and has_type(x, A) and has_type(y, A)\n",
    "\n",
    "def Sigma(A: Type, B: Family) -> Type:\n",
    "    return frozenset({(a, b) for a in A for b in B(a)})\n",
    "def Pair(A : Type, B: Type) -> Type:\n",
    "    return Sigma(A, lambda x: B)\n",
    "\n",
    "def Pi(A : Type, B : Family) -> Type:\n",
    "    Alist = list(A)\n",
    "    return frozenset(frozendict({k:v for k,v in zip(Alist, bvs)}) for bvs in itertools.product(*[B(a) for a in Alist]))\n",
    "def Arr(A : Type, B: Type) -> Type:\n",
    "    return Pi(A, lambda x: B)\n",
    "\n",
    "def Sum(A : Type, B: Type) -> Type:\n",
    "    return frozenset({(\"inl\", a) for a in A} | {(\"inr\", b) for b in B})\n",
    "\n",
    "def Id(A : Type, x : object, y : object) -> Type:\n",
    "    return frozenset({\"refl\"}) if x == y else frozenset()\n",
    "def U(n : int, l : int) -> Type:\n",
    "    if l > 0:\n",
    "        u = U(n, l-1)\n",
    "        return u | frozenset([u]) # Cumulative\n",
    "    elif n > 0:\n",
    "        u = U(n-1, 0)\n",
    "        # TODO also the Pi and Sigma\n",
    "        return u | frozenset([Arr(A,B) for A in u for B in u]) | frozenset([Pair(A,B) for A in u for B in u]) | frozenset([Fin(n)])\n",
    "    else:\n",
    "        return frozenset([Unit, Bool, Void])\n",
    "def Quot(A : Type, R) -> Type:\n",
    "    return frozenset(frozenset({y for y in A if R(x,y)}) for x in A)\n",
    "def SubSet(A :  Type, P : Family) -> Type: # very much like Sigma\n",
    "    return frozenset({(x, ()) for x in A if P(x)}) # Note because of pythion truthiness, this also accepts ordinary bool value predicates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More examples. \n",
    "Pair ~ Dependent product over bool\n",
    "Bounded Fixpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({('SuccF', ('SuccF', ('SuccF', ('ZeroF',)))),\n",
       "           ('SuccF', ('SuccF', ('ZeroF',))),\n",
       "           ('SuccF', ('ZeroF',)),\n",
       "           ('ZeroF',)})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bounded fixpoint types\n",
    "type TypeFamily = Callable[[Type], Type]\n",
    "def Mu(n : int, f : TypeFamily) -> Type:\n",
    "    if n <= 0:\n",
    "        return Void\n",
    "    else:   # Fix and roll?\n",
    "        return f(Mu(n-1, f))\n",
    "\n",
    "def NatF(A : Type) -> Type:\n",
    "    return frozenset({(\"ZeroF\",)}) | {(\"SuccF\", x) for x in A}\n",
    "\n",
    "Mu(4, NatF)\n",
    "\n",
    "# distinction between least and greatest? Not clear.\n",
    "#def Nu(n, f):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SumSigma(A,B):\n",
    "    # a construction of sum types out of sigma + bool\n",
    "    return Sigma(Bool, lambda x: A if x else B)\n",
    "\n",
    "def PiPair(A,B): # construction of pairs out of pi + bool\n",
    "    return Pi(Bool, lambda x: A if x else B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Modk(N, k):\n",
    "    # Modk is x such that exists y such that x = k*y\n",
    "    return Sigma(Fin(N), lambda x: Sigma(Fin(N), lambda y: Id(Fin(N), x, k*y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LE(m, k):\n",
    "    return frozenset({\"le\"}) if m <= k else frozenset()\n",
    "\n",
    "\n",
    "def Fin2(N, max):\n",
    "    return Sigma(Fin(N), )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partial evaluation model\n",
    "\n",
    "Representation \n",
    "structural vs semanti equality. \n",
    "Bigin limbs\n",
    "unnormalized fractions\n",
    "modular arith\n",
    "snoc cons\n",
    "AVL tree with different insertion order\n",
    "big endian little endian\n",
    "free monoid delays\n",
    "For Fin(n), iso forms of Pred(Pred(N)) and Succ(Succ(Zero)). Kind of interesting.\n",
    "\n",
    "\n",
    "if you hash cons, structural equality is `is` equality\n",
    "canonization / terms modulo theories. canonization is 'further computation\"\n",
    "\n",
    "canon(x) == canon(y)\n",
    "find(x) == find(y)\n",
    "\n",
    "code strings and partial evaluation\n",
    "eval(x) == eval(y)\n",
    "\n",
    "NP equality vs P equality. NP certificates in \n",
    "x: B, y : B, x /\\ y <-> True  |-  Id B x y\n",
    "\n",
    "relationalnal mdel\n",
    "[(unnormed1, canon1), (unnormed1, canon1)]\n",
    "type Type = {unnormed : canon} ?\n",
    "[(t1,t2,t3,t4)] a tower of euiqvalences. a uniform nuber of steps across elements or no?\n",
    "\n",
    "t1 from egraph1, t2 from egraph2 which is a refinement and so on.\n",
    "Sets of refining equalities. Egrahs inm time. Or like  OrietendSergment -> Segment -> Line refinement. \n",
    "\n",
    "FreeGroup -> Group -> Abelian Group\n",
    "\n",
    "mod out by an axiom at a time.  A -- aa=b ->  B -- cc == q -> C --> ...\n",
    "list -AC> multiset -I> set\n",
    "tree ->  unordertree ->\n",
    "portedgraph -> multigraph -> \n",
    "tree -> dag \n",
    "\n",
    "Proof -> normalization\n",
    "program -> partial eval\n",
    "automata -> observational equivalence\n",
    "autotmatra --forget> Auto1 ---forget2-> Auto2\n",
    "\n",
    "\n",
    "seflloop                    selflooprefl\n",
    "| |                        | |\n",
    "True  ------quote ------ False \n",
    "\n",
    "Quotent a Bool like thing?\n",
    "Quotient a three object thing into a 2 object thing?\n",
    "[(\"red\", True), (\"green\", True), (\"blue\", False)]\n",
    "[(0,0), (1,0), (2,2)]  \n",
    "\n",
    "\n",
    "Like in \"the trick\" I think. that pattern matching should move information from refined world to upper world?\n",
    "\"Quoting\" moves to lower world?\n",
    "\n",
    "a relational model of static and dynamic time. Akin to relational model of parametrciity. But here we have a notion of refinement so the relation has to be many to one.\n",
    "\n",
    "\n",
    "More of a bottom persepctive. if unevaluated stuff is modelled as bottom, the refinment goers the other way.\n",
    "\n",
    "\n",
    "def Implies(A,B): # add a world?\n",
    "    B1 = [(None, *B) for b in B]\n",
    "    Alist = \n",
    "    [ for itertools.product(B, repeat=len(Alist))]\n",
    "    # but like only consistent stuff.\n",
    "\n",
    "This is more like a domain theory model. Interesting.\n",
    "\n",
    "FIntie domain theory\n",
    "\n",
    "https://en.wikipedia.org/wiki/Domain_theory  Is allowing sequences (arbitrarily large?) mean things aren't finite anymore? Not if we kind of compress.\n",
    "(None, None, True) ===> (None, True)\n",
    "\n",
    "We can generically deduplicate sueqences\n",
    "def dup_cons(x, xs):\n",
    "    if x == xs[0]:\n",
    "        return xs\n",
    "    else:\n",
    "        return (x, *xs)\n",
    "\n",
    "Bool = {(True,), (None, True), (None, False), (False,), (None,), ()}\n",
    "Tail closed sets.\n",
    "Bool = Bool | {x[1:] for x in Bool}\n",
    "\n",
    "def Pair(A,B):\n",
    "    {(None, map(lambda a,b: (a,b), a, b)) |   for a in A for b in B} # outer product.. No but one can stay frozen while the other moves.\n",
    "\n",
    "\n",
    "What's an empty chain?\n",
    "What is Void?\n",
    "\n",
    "I guess all chains in the lattice? all upward closures?\n",
    "No maybe dcpo is more appropriate. But all chains are intentionally finite, so the complete part isn't relevant\n",
    "\n",
    "https://en.wikipedia.org/wiki/Complete_partial_order \n",
    "\n",
    "match statement prunes None away. Hmm.\n",
    "\n",
    "def join(a,b):\n",
    "    \n",
    "So really just a set + partial order relation. Partial order can be explicit set of function, doesn't matter much because we enumerate.\n",
    "type Type = tuple[frozenset, frozenset]\n",
    "\n",
    "Pair is cartesian product I guess + bottom? Partial order combines only if both compoenets do?\n",
    "https://en.wikipedia.org/wiki/Dedekind%E2%80%93MacNeille_completion\n",
    "\n",
    "\n",
    "\n",
    "Implies(A,B): # should prune for only monotonic functions.\n",
    "\n",
    "On continuas functions means monotonic. That is kind opf like simplical sets\n",
    "https://people.cs.nott.ac.uk/pszgmh/domains.html Hutton domain theory\n",
    "It's not that I need bottoms to denote nontermintating programs. Just stuff that isn't done to values yet\n",
    "\n",
    "With \"named nones / nulls\" we could know equality before the thing have evaluated. There is object identity. This is very egraphy chasy.\n",
    "But a finite number of names? Hmm. Names come from context? de bruijn indices? de buijn index sets. Which variables need to be filled in before it can eval further. {0,1} --> {1} --> True\n",
    "lazy AND may of may not need more data  {0,1} -> False, {1} -> True, {1} -> False, {0,1} -> {1}\n",
    "\n",
    "class NNone(NamedTuple):\n",
    "    id : int\n",
    "\n",
    "Traces are kind of different because maybe traces could take jumps or ...\n",
    "\n",
    "hash(x) == hash(y) equality. fast and slow equality.\n",
    "\n",
    "Irreleanve Prop.\n",
    "{\"True\", \"False\"}, lambda x,y: True\n",
    "\n",
    "Isomorphic types (same len) as equal?\n",
    "\n",
    "\n",
    "\n",
    "Setoid is Type = frozenset, eqrel\n",
    "\n",
    "https://inria.hal.science/hal-02281225/document\n",
    "setoid nmodel, gropoid model justifies negation of uip, cubical set model justifies univalence.\n",
    "\"In general, the usage of an axiom is justified by a model [18] in which the\n",
    "axiom holds. For example, the cubical set model [8] justifies the univalence axiom, the reflexive graph model [6] justifies parametricity, the groupoid model\n",
    "[19] justifies the negation of UIP, the setoid model [17,1] justifies function extensionality. \"\n",
    "\n",
    "\n",
    "https://libres.uncg.edu/ir/asu/f/Johann_Patricia_2014_A_Relationally_Parametric_Model_Of_Dependent_Type_Theory..pdf reflexive graph model. Parametricity. Instead of having equivalence relation, just a reflexive relation.\n",
    "\n",
    "Hmm. So a the cyubical set model\n",
    "\n",
    "Interpreting into a normalizedc union find \n",
    "canon[x] = y\n",
    "type Type = frozendict[object, object]\n",
    "\n",
    "Interpreting into a refinement/colored uf.\n",
    "Interpeting into group uf. Groupoid uf. multi edge groupoid uf?\n",
    "Interpeting into a theory uf. Gauss, grobner\n",
    "\n",
    "\n",
    "\n",
    "types as multiset of values. I'm kind of trying to use something like provenance to track distinction between definitional and propositional.\n",
    "Multiset gives more provenance. Or semiring provenance. Carrying history.\n",
    "sorted([])\n",
    "\n",
    "type Type = trace,value \n",
    "\n",
    "type = (A0, =A0) setoid model\n",
    "type = (A0, A1, =A1) groupoid model\n",
    "type = (A0, A1, A2, .., =AN)  higher truncation models?\n",
    "https://www.cse.chalmers.se/~peterd/slides/hits-AIMXXV.pdf \"constructivity is maintained because setoid model can be formulated in constructive metatheory (extensional type theory) itself justified by Martin-L¨of’s (1979) standard meaning explanations.\"\n",
    "\n",
    "Hmm. https://ncatlab.org/nlab/files/HofmannExtensionalIntensionalTypeTheory.pdf Yes the sertoid model is for modelling exetensional inside intentional type theory.\n",
    "\n",
    "\n",
    "The z3 syntax model. `.eq` equality vs  `prove(x == y)` equality. Knuckledragger proofs are the things in Id.\n",
    "Types are python predciates that synatctically recorgnize aspects of z3 expressions without using `check`?\n",
    "\n",
    "\n",
    "Maybe I do need to refomrulate into the categorical style to understand models.\n",
    "It's possible python's notion of comprehension is not rich enough to handle other kinds of models.\n",
    "\n",
    "\n",
    "\n",
    "depedent types, a vcalue in the image of an expression?\n",
    "Sets with extra structure. \n",
    "types as C-sets? Arr is homomorphism?\n",
    "\n",
    "\" These could be terms in a lambda calculus, or elements of a partial combinatory algebra, or even programs in a real-world programming language such as C, Java, or Python\"  https://ncatlab.org/nlab/show/meaning+explanation\n",
    "\n",
    "\n",
    "\n",
    "https://unimath.github.io/SymmetryBook/book.pdf\n",
    "I was hoping that a book\n",
    "Computational Groupoid theory. Dependent types wouldn't be the crazy substrate for that. Could I use a ocmputational group theory library?\n",
    "\n",
    "\n",
    "https://www.stephendiehl.com/posts/calculus_of_constructions_python/ syntactical. But he uses a hoas which is interesting. Hoas for de bruijn indices, level for open terms?\n",
    "https://tiarkrompf.github.io/notes/?/dependent-types/\n",
    "\n",
    "\n",
    "def ann(t, A):\n",
    "    assert t in A\n",
    "    return t\n",
    "\n",
    "In runtime form, ann(t, A) ought to return a t that checks it is in A possibly on inputs (?)\n",
    "A -> bool vs\n",
    "pair of predciates for polarities\n",
    "[] -> bool, [] -> bool\n",
    "relation to bidi checking?\n",
    "\n",
    "\n",
    "\n",
    "I ought to be able to form the categorical model interface over even the simple Set Model\n",
    "\n",
    "Dependent typing judgements as database queries. Hmm.\n",
    "FROM ... |-  Select \n",
    "dependent Type ~ tables\n",
    "nondependent type ~ single column table\n",
    "\n",
    "Egrasphs are models, so \"dependent typed\" egraphs should also be models.\n",
    "\n",
    "DQL - dependent query language\n",
    "Gam |- \n",
    "\n",
    "trie homomorphisms are telescope mappings?\n",
    "\n",
    "ca\n",
    "\n",
    "\n",
    "https://martinescardo.github.io/HoTT-UF-in-Agda-Lecture-Notes/index.html\n",
    "\n",
    "\n",
    "Fin(0) ~ Void\n",
    "Fin(1) ~ Unit\n",
    "Fin(2) ~ Bool\n",
    "\n",
    "canonically iso, but\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ann(m=Lam(f=<function curry5.<locals>.<lambda> at 0x711e19d50860>), a=Pi(a=Pi(a=Star(), f=<function <lambda> at 0x711e19d50540>), f=<function <lambda> at 0x711e19d507c0>))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Callable, List, Tuple\n",
    "# https://www.stephendiehl.com/posts/calculus_of_constructions_python/\n",
    "@dataclass\n",
    "class Term: ...\n",
    "@dataclass\n",
    "class Lam(Term): f: Callable[[Term], Term]\n",
    "@dataclass\n",
    "class Pi(Term): a: Term; f: Callable[[Term], Term]\n",
    "@dataclass\n",
    "class Appl(Term): m: Term; n: Term\n",
    "@dataclass\n",
    "class Ann(Term): m: Term; a: Term\n",
    "@dataclass\n",
    "class FreeVar(Term): x: int\n",
    "@dataclass\n",
    "class Star(Term): ...\n",
    "@dataclass\n",
    "class Box(Term): ...\n",
    "\n",
    "def eval(term: Term) -> Term:\n",
    "    match term:\n",
    "        case Lam(f):\n",
    "            return Lam(lambda n: eval(f(n)))\n",
    "        case Pi(a, f):\n",
    "            return Pi(eval(a), lambda n: eval(f(n)))\n",
    "        case Appl(m, n):\n",
    "            m_eval = eval(m)\n",
    "            n_eval = eval(n)\n",
    "            match m_eval:\n",
    "                case Lam(f):\n",
    "                    return f(n_eval)\n",
    "                case _:\n",
    "                    return Appl(m_eval, n_eval)\n",
    "        case Ann(m, _):\n",
    "            return eval(m)\n",
    "        case FreeVar() | Star() | Box():\n",
    "            return term\n",
    "def infer_ty(lvl: int, ctx: List[Term], term: Term) -> Term:\n",
    "    match term:\n",
    "        case Pi(a, f):\n",
    "            _s1 = infer_sort(lvl, ctx, a)\n",
    "            s2 = infer_sort(lvl + 1, [eval(a)] + ctx, unfurl(lvl, f))\n",
    "            return s2\n",
    "        case Appl(m, n):\n",
    "            m_ty = infer_ty(lvl, ctx, m)\n",
    "            match m_ty:\n",
    "                case Pi(a, f):\n",
    "                    _ = check_ty(lvl, ctx, (n, a))\n",
    "                    return f(n)\n",
    "                case _:\n",
    "                    return panic(lvl, m, f\"Want a Pi type, got {print_term(lvl, m_ty)}\")\n",
    "        case Ann(m, a):\n",
    "            _s = infer_sort(lvl, ctx, a)\n",
    "            return check_ty(lvl, ctx, (m, eval(a)))\n",
    "        case FreeVar(x):\n",
    "            return ctx[lvl - x - 1]\n",
    "        case Star():\n",
    "            return Box()\n",
    "        case Box():\n",
    "            return panic(lvl, Box(), \"Has no type\")\n",
    "def infer_sort(lvl: int, ctx: List[Term], a: Term) -> Term:\n",
    "    ty = infer_ty(lvl, ctx, a)\n",
    "    match ty:\n",
    "        case Star() | Box():\n",
    "            return ty\n",
    "        case _:\n",
    "            return panic(lvl, a, f\"Want a sort, got {print_term(lvl, ty)}\")\n",
    "def check_ty(lvl: int, ctx: List[Term], pair: Tuple[Term, Term]) -> Term:\n",
    "    t, ty = pair\n",
    "    match (t, ty):\n",
    "        case (Lam(f), Pi(a, g)):\n",
    "            _ = check_ty(lvl + 1, [a] + ctx, unfurl2(lvl, (f, g)))\n",
    "            return Pi(a, g)\n",
    "        case (Lam(f), _):\n",
    "            return panic(lvl, Lam(f), f\"Want a Pi type, got {print_term(lvl, ty)}\")\n",
    "        case _:\n",
    "            got_ty = infer_ty(lvl, ctx, t)\n",
    "            if equate(lvl, (ty, got_ty)):\n",
    "                return ty\n",
    "            return panic(lvl, t, f\"Want type {print_term(lvl, ty)}, got {print_term(lvl, got_ty)}\")\n",
    "def equate(lvl: int, terms: Tuple[Term, Term]) -> bool:\n",
    "    def plunge(pair: Tuple[Callable[[Term], Term], Callable[[Term], Term]]) -> bool:\n",
    "        return equate(lvl + 1, unfurl2(lvl, pair))\n",
    "\n",
    "    match terms:\n",
    "        case (Lam(f), Lam(g)):\n",
    "            return plunge((f, g))\n",
    "        case (Pi(a, f), Pi(b, g)):\n",
    "            return equate(lvl, (a, b)) and plunge((f, g))\n",
    "        case (Appl(m, n), Appl(m2, n2)):\n",
    "            return equate(lvl, (m, m2)) and equate(lvl, (n, n2))\n",
    "        case (Ann(m, a), Ann(m2, b)):\n",
    "            return equate(lvl, (m, m2)) and equate(lvl, (a, b))\n",
    "        case (FreeVar(x), FreeVar(y)):\n",
    "            return x == y\n",
    "        case (Star(), Star()) | (Box(), Box()):\n",
    "            return True\n",
    "        case _:\n",
    "            return False\n",
    "def unfurl(lvl: int, f: Callable[[Term], Term]) -> Term:\n",
    "    return f(FreeVar(lvl))\n",
    "\n",
    "def unfurl2(lvl: int, pair: Tuple[Callable[[Term], Term], Callable[[Term], Term]]) -> Tuple[Term, Term]:\n",
    "    f, g = pair\n",
    "    return (unfurl(lvl, f), unfurl(lvl, g))\n",
    "def print_term(lvl: int, term: Term) -> str:\n",
    "    def plunge(f: Callable[[Term], Term]) -> str:\n",
    "        return print_term(lvl + 1, unfurl(lvl, f))\n",
    "\n",
    "    match term:\n",
    "        case Lam(f):\n",
    "            return f\"(λ{plunge(f)})\"\n",
    "        case Pi(a, f):\n",
    "            return f\"(Π{print_term(lvl, a)}.{plunge(f)})\"\n",
    "        case Appl(m, n):\n",
    "            return f\"({print_term(lvl, m)} {print_term(lvl, n)})\"\n",
    "        case Ann(m, a):\n",
    "            return f\"({print_term(lvl, m)} : {print_term(lvl, a)})\"\n",
    "        case FreeVar(x):\n",
    "            return str(x)\n",
    "        case Star():\n",
    "            return \"*\"\n",
    "        case Box():\n",
    "            return \"☐\"\n",
    "def curry2(f):\n",
    "    return Lam(lambda x: Lam(lambda y: f(x, y)))\n",
    "\n",
    "def curry3(f):\n",
    "    return Lam(lambda x: curry2(lambda y, z: f(x, y, z)))\n",
    "\n",
    "def curry4(f):\n",
    "    return Lam(lambda x: curry3(lambda y, z, w: f(x, y, z, w)))\n",
    "\n",
    "def curry5(f):\n",
    "    return Lam(lambda x: curry4(lambda y, z, w, v: f(x, y, z, w, v)))\n",
    "\n",
    "def appl(f: Term, args: List[Term]) -> Term:\n",
    "    return reduce(lambda m, n: Appl(m, n), args, f)\n",
    "# The type of Church numerals\n",
    "n_ty = Pi(Star(), lambda a:\n",
    "          Pi(Pi(a, lambda _x: a), lambda _f:\n",
    "             Pi(a, lambda _x: a)))\n",
    "\n",
    "# Zero is the identity function\n",
    "zero = Ann(curry3(lambda _a, _f, x: x), n_ty)\n",
    "\n",
    "# Successor applies f one more time\n",
    "succ = Ann(\n",
    "    curry4(lambda n, a, f, x: Appl(f, appl(n, [a, f, x]))),\n",
    "    Pi(n_ty, lambda _n: n_ty)\n",
    ")\n",
    "\n",
    "# Addition combines the function applications\n",
    "add = Ann(\n",
    "    curry5(lambda n, m, a, f, x:\n",
    "          appl(n, [a, f, appl(m, [a, f, x])])),\n",
    "    Pi(n_ty, lambda _n: Pi(n_ty, lambda _m: n_ty))\n",
    ")\n",
    "add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicates are sets of their models.\n",
    "type Type = smt.BoolRef\n",
    "#type \n",
    "\n",
    "#type Ctx = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contexts are kind of Tries.\n",
    "I could rediscover the ordering by trying to factor and carteisan producting and see if it works.\n",
    "\n",
    "No. It always works doesn't it?\n",
    "\n",
    "I guess if we have some sense of what families are possible\n",
    "\n",
    "\n",
    "\n",
    "registering iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor[K,V](k : K, ctxs : list[dict[K,V]]):\n",
    "    res = {}\n",
    "    for ctx in ctxs:\n",
    "        res[ctx[k]] = ctx.remove(k)\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def factor(ctx : list[dict]):\n",
    "    keys = ctx[0].keys()\n",
    "    for k in keys: # attempt factoring out k\n",
    "        factroed = \n",
    "        for env in ctx.items():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'a': 0, 'b': 0}, 0),\n",
       " ({'a': 0, 'b': 1}, 1),\n",
       " ({'a': 0, 'b': 2}, 2),\n",
       " ({'a': 1, 'b': 0}, 1),\n",
       " ({'a': 1, 'b': 1}, 2),\n",
       " ({'a': 1, 'b': 2}, 3),\n",
       " ({'a': 2, 'b': 0}, 2),\n",
       " ({'a': 2, 'b': 1}, 3),\n",
       " ({'a': 2, 'b': 2}, 4)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type TypeJudge = tuple[dict, object]\n",
    "def Foo():\n",
    "    return [(locals().copy(), a + b) for a in range(3) for b in range(3)]\n",
    "Foo()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 hello\n"
     ]
    }
   ],
   "source": [
    "d = {'foo': 42, 'bar': 'hello'}\n",
    "type Code = str\n",
    "def unpack(d) -> Code:\n",
    "    return '; '.join(f\"{k} = {repr(v)}\" for k, v in d.items())\n",
    "exec(unpack(d))\n",
    "print(foo, bar)\n",
    "#locals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarski universe\n",
    "\n",
    "Elements of U are codes.\n",
    "string codes via eval?\n",
    "AST codes?\n",
    "\n",
    "https://mathstodon.xyz/@olynch/114557642774172861 https://owenlynch.org/static/universes/slides/1.html\n",
    "Relationship to staged metaprogramming. \"e database queries, SAT formula, differential algebraic equations\"\n",
    "\"Python\" as a higher meta place than finite sets\n",
    "\n",
    "https://github.com/JacquesCarette/Drasil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({False, None, True})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The finiteness of El is akin to finiteness of Mu fixpoint.\n",
    "def El(T): # self codes?\n",
    "    return T\n",
    "def El(T : str):\n",
    "    return eval(T)\n",
    "def El0(T):\n",
    "    match T:\n",
    "        case \"Bool\": return Bool\n",
    "        case \"Unit\": return Unit\n",
    "        case \"Void\": return Void\n",
    "        case (\"Fin\", n): return Fin(0)\n",
    "        case (\"Vec\", A, n): return Vec(El(A), n)\n",
    "        case \"Sigma\": return Sigma(Bool, lambda x: Bool)\n",
    "        case \"Pi\": return Pi(Bool, lambda x: Bool)\n",
    "def El1(T):\n",
    "    match T:\n",
    "        case (\"El0\", T): return El0(T)\n",
    "        case _: return El0(T)\n",
    "def El(n, T):\n",
    "    if n == 0: return {}\n",
    "def joinU(U,V):\n",
    "    return U | V | frozenset({U}) | frozenset({V}) # Cumulative\n",
    "\n",
    "# open set vs closed set (in open closed sense). Open(frozenset(foo, bar)) is a set that copntains at least foo bar, not exactyl foo bar\n",
    "# El as an open function. class?\n",
    "class El0():\n",
    "    def __call__(self, T):\n",
    "\n",
    "class El1(El0):\n",
    "    def __call__(self, T):    \n",
    "        super().__call__(T)\n",
    "\n",
    "# note we don't need frozenset anymore? We can have sets of codes no problem\n",
    "U0 = [\"Bool\", \"Unit\", \"Void\"]\n",
    "El(\"Bool\")\n",
    "\n",
    "\n",
    "# reflection principle.\n",
    "# relativized predciates\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset Model\n",
    "Hofmann thesis chapter 4\n",
    "\n",
    "subset model of type theory. Hmm. Is to subsets what setyoid is to quotients?\n",
    "type Type = tuple[frozenset, frozenset] when B <= A ?\n",
    "functions from set to set, \n",
    "proof irrelevance Sigma() just restrictions second component.\n",
    "Exists(A : Type, P : a -> bool) vs Sigma(A : Type, P : Family) (Subset vs Sigma?)\n",
    "\n",
    "Pi types are equal if they take equal functions on suibsets to equal functions on output subsets. Hmm.\n",
    "def is_type(A):\n",
    "    isinstance(A[0], frozenset) and isintance(A[1], frozenset) and A[1] <= A[0]\n",
    "def is_eq(t1, t2, A):\n",
    "    return t1 == t2 and t1 in A[1] and t2 in A[1] # kleene equality? No.  t1 == t2 or t1 not in A[1] or t2 not in A[1] would be kleene. Undefined stuff is consdered equal.\n",
    "\n",
    "\n",
    "This is more like refinement types.\n",
    "Once you've got the first set, it doesn't hurt to have a python function as second set. If convenient.\n",
    "\n",
    "type Type = tuple[frozenset, Callable[[object], bool]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type Type = tuple[frozenset, frozenset]\n",
    "def is_type(A : Type) -> bool: # |- A type\n",
    "    isinstance(A[0], frozenset) and isinstance(A[1], frozenset) and A[1] <= A[0]\n",
    "def eq_type(A: Type, B: Type) -> bool: # |- A = B type\n",
    "    return is_type(A) and is_type(B) and A == B\n",
    "type Family = Callable[[object], Type] # But has to play nice? Not really.\n",
    "def Pi(A : Type, B):\n",
    "    #Alist = list(A[1]) # A[0] ? Maybe we uniformly make them all do the same thing off of defined? This wouuld then reconcile kleene and regular equality.\n",
    "    Alist = list(A[0])\n",
    "    # itertools.product(*[B(a)[0] for a in Alist]) ? Picking undefine values is bad\n",
    "    fs = frozenset(frozendict({k:v for k,v in zip(Alist, bvs)}) for bvs in itertools.product(*[B(a)[0] for a in Alist]))\n",
    "    # now there are functions that are not definitionally equal, but are kleene equal.\n",
    "    return fs, frozenset(f for f in fs if all(f[a] in B(a)[1] for a in A[1])) # only those that are defined\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setoid model\n",
    "\n",
    "https://people.cs.nott.ac.uk/psztxa/publ/lics99.pdf \n",
    "\"Another way to look at it is as if a setoid was a category (equalities are morphisms, reflexivity is identity, transitivity if composition), families are then functors from setoid-as-category into the category of all setoids.\" https://types.pl/@bentnib/114587130921412422\n",
    "\n",
    "Is a simplicial set a set with structure?\n",
    "Subset model is kind of PartialFinSet (?) Or at least related.\n",
    "Setoid Model\n",
    "Poset model (?)\n",
    "\n",
    "\n",
    "\n",
    "The setoid model with a canonizer is a little more than just an equivalence relation even in the finite case. If we have a global \"term order\" the canonizer should be the least one.\n",
    "\n",
    "https://ncatlab.org/nlab/files/HofmannExtensionalIntensionalTypeTheory.pdf hofmann thesis. Very nice intro. \"In Sect. 5.2 the|in our opinion|most natural solution to the above question\n",
    "of dependent setoids is described: the groupoid interpretation of type theory\"\n",
    "\n",
    "He has a setoid model where the base type of the saet doesn't vary but the trnasporter does?\n",
    "type Family = frozenset, Callable[[object,object],dict[object,object]] Callable[[object,object, callabl[objject,object], bool]]\n",
    "\n",
    "context relative to `Gam |- Del`\n",
    "tuple[Tele, int] int is how deep to place the |-. 2.2.2 is a way cleaer description of context morphisms than I have seen\n",
    "\n",
    "\n",
    "ModN\n",
    "Pairs of Fin(n) as negative numbers x - y (quotient)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "I should look at Luo too\n",
    "\n",
    "\n",
    "\n",
    "So what do I do with it? What thing should the setoid model do that the simple model didn't? Do I need to build the term language combinators to see that?\n",
    "\n",
    "Fin induction\n",
    "P(0), P(n), n < l => P(n+1) \n",
    "\n",
    "\n",
    "partial setoids. Don't require refl. https://people.cs.nott.ac.uk/pszvc/publications/Setoids_JFP_2003.pdf\n",
    "Hmm. Partialness would make sense if we want the subset model to be folded in.\n",
    "\n",
    "\n",
    "Canonical isomorphism if we make sets ordered (in unique mapping to nats) rather than sets.\n",
    "\n",
    "Free monoid lists --> Nat.\n",
    "\n",
    "\n",
    "Hmm. A \"proof\" that (1,4,5) == (5,1,4) would be the permutation that does it. https://www.philipzucker.com/proof_objects/\n",
    "\n",
    "types as sequences. Hmm.\n",
    "\n",
    "https://www.cse.chalmers.se/research/group/logic/TypesSS05/Extra/palmgren.pdf\n",
    "\n",
    "https://martinescardo.github.io/events/MGS12/lectures/CoquandSlides/tt2.pdf coquand intuitionsitc mathemtics\n",
    "\n",
    "\n",
    "operation is dict that may or may nmot comply with setoid\n",
    "\n",
    "Family takes in equality relation too.\n",
    "type Family = Callable[[object, object[a,b]]]\n",
    "Callable[object, Setoid], Callable[proof, dict[]]\n",
    "bundle with the definition of family how to transport stuff.\n",
    "\n",
    "\n",
    "\n",
    "Bishop set theory is maybe what I want? https://ncatlab.org/nlab/show/Bishop+set\n",
    "\n",
    "https://ncatlab.org/nlab/show/set+truncation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Setoid():\n",
    "    carrier: frozenset\n",
    "    eq: frozenset[tuple[object,object]]\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        # Ok, but actually setoids themselves should have a setoid satructure\n",
    "        # a set of all setoids and what equivalences they have\n",
    "        return self.carrier == other.carrier and self.eq == other.eq\n",
    "\n",
    "type Type = Setoid\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type Bool = (False, True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRecursionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m ((\u001b[33m\"\u001b[39m\u001b[33mzero\u001b[39m\u001b[33m\"\u001b[39m,),)\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m((\u001b[33m\"\u001b[39m\u001b[33madd\u001b[39m\u001b[33m\"\u001b[39m, FinTree(n-i), FinTree(i)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n) \u001b[38;5;28;01mfor\u001b[39;00m t1 \u001b[38;5;129;01min\u001b[39;00m FinTree(n-i) \u001b[38;5;28;01mfor\u001b[39;00m t2 \u001b[38;5;129;01min\u001b[39;00m FinTree(i))\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mFinTree\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mFinTree\u001b[39m\u001b[34m(n)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n == \u001b[32m0\u001b[39m:\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ((\u001b[33m\"\u001b[39m\u001b[33mzero\u001b[39m\u001b[33m\"\u001b[39m,),)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43madd\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFinTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m-\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFinTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mFinTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m-\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mFinTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n == \u001b[32m0\u001b[39m:\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ((\u001b[33m\"\u001b[39m\u001b[33mzero\u001b[39m\u001b[33m\"\u001b[39m,),)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m((\u001b[33m\"\u001b[39m\u001b[33madd\u001b[39m\u001b[33m\"\u001b[39m, FinTree(n-i), FinTree(i)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n) \u001b[38;5;28;01mfor\u001b[39;00m t1 \u001b[38;5;129;01min\u001b[39;00m \u001b[43mFinTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m-\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t2 \u001b[38;5;129;01min\u001b[39;00m FinTree(i))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mFinTree\u001b[39m\u001b[34m(n)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n == \u001b[32m0\u001b[39m:\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ((\u001b[33m\"\u001b[39m\u001b[33mzero\u001b[39m\u001b[33m\"\u001b[39m,),)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43madd\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFinTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m-\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFinTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mFinTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m-\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mFinTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n == \u001b[32m0\u001b[39m:\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ((\u001b[33m\"\u001b[39m\u001b[33mzero\u001b[39m\u001b[33m\"\u001b[39m,),)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m((\u001b[33m\"\u001b[39m\u001b[33madd\u001b[39m\u001b[33m\"\u001b[39m, FinTree(n-i), FinTree(i)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n) \u001b[38;5;28;01mfor\u001b[39;00m t1 \u001b[38;5;129;01min\u001b[39;00m \u001b[43mFinTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m-\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t2 \u001b[38;5;129;01min\u001b[39;00m FinTree(i))\n",
      "    \u001b[31m[... skipping similar frames: FinTree at line 17 (1486 times), <genexpr> at line 17 (1485 times)]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n == \u001b[32m0\u001b[39m:\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ((\u001b[33m\"\u001b[39m\u001b[33mzero\u001b[39m\u001b[33m\"\u001b[39m,),)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m((\u001b[33m\"\u001b[39m\u001b[33madd\u001b[39m\u001b[33m\"\u001b[39m, FinTree(n-i), FinTree(i)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n) \u001b[38;5;28;01mfor\u001b[39;00m t1 \u001b[38;5;129;01min\u001b[39;00m \u001b[43mFinTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m-\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t2 \u001b[38;5;129;01min\u001b[39;00m FinTree(i))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mFinTree\u001b[39m\u001b[34m(n)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n == \u001b[32m0\u001b[39m:\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ((\u001b[33m\"\u001b[39m\u001b[33mzero\u001b[39m\u001b[33m\"\u001b[39m,),)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43madd\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFinTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m-\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFinTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mFinTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m-\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mFinTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRecursionError\u001b[39m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "def oset(A):\n",
    "    return tuple(sorted(set(A)))\n",
    "\n",
    "\n",
    "def Fin(n):\n",
    "    return tuple(range(n))\n",
    "def Nif(n):\n",
    "    # The Snoc Nat to Fin's Cons List\n",
    "    return tuple(reversed(range(n)))\n",
    "\n",
    "Fin(3)\n",
    "Nif(3)\n",
    "\n",
    "def FinTree(n):\n",
    "    if n == 0:\n",
    "        return ((\"zero\",),)\n",
    "    return tuple((\"add\", FinTree(n-i), FinTree(i)) for i in range(n) for t1 in FinTree(n-i) for t2 in FinTree(i))\n",
    "FinTree(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigma(A, B):\n",
    "    return frozendict({(t1,t2) : (v1,v2) for t1,v1 in A.items() for t2,v2 in B(v1).items()})\n",
    "    #return frozendict({(t1,t2) : (v1,v2) for t1,v1 in A.items() for t2,v2 in B(_).items()})\n",
    "    #return frozendict{(v1,t2) : (v1,v2) for t1,v1 in A.items() for t2,v2 in B(v1).items()} # sigma as compared to Pair does have eval ordering suggested.\n",
    "    #return frozendict{(t1,t2) : (v1,v2) for t1,v1 in A.items() for t2,v2 in B(t1).items()}\n",
    "\n",
    "    # More and Done ?\n",
    "    # return {()\"stuck\", t1) : (\"stuck\", v1)} for t in A}) | unstuck  \n",
    "    # retrun {(\"stuck\",t1,t2) : (\"stuck\", v1, t2) for t2, v2 in B(t1).items() } | {(\"unstuck\", t1, t2) : (\"unstuck\", v1, t2) for t1,v1 in A.items() for t2,v2 in B(v1).items()}\n",
    "    #return frozendict{(t1,t2) : (v1,v2) for t1,v1 in A.items() for t2,v2 in B(v1, t1).items()}\n",
    "    #return frozendict{(t1,t2) : (v1,v2) for t1,v1 in A.items() for t2,v2 in B(t1).items() for t3,t4 in B(v1).items()}\n",
    "    # return { ((t1,t2), (v1,t2), (v1,v2))   for t1,v1 in A.items() for t2,v2 in B(v1).items() }\n",
    "def Id(A,x,y):\n",
    "    return frozendict({\"refl\" : \"refl\"}) if x[1] == y[1] else frozendict()\n",
    "def def_eq(x,y,A):\n",
    "    # but since x[1] refines x[0], x[0] == y[0] is equivalent to x == y\n",
    "    return x[0] == y[0]                                                                  \n",
    "\n",
    "# setoid map has to play nice with equiv relation\n",
    "# I don't think I have to do much.\n",
    "# Pick value mapping first or term mapping first?\n",
    "# congruence closure... ?\n",
    "# is it a mapping of functions to normalized functions?\n",
    "def Pi(A,B):\n",
    "    Alist1 = list(A.keys())\n",
    "    Alist2 = list(A.values())\n",
    "    return frozendict(frozendict(     for bvs in itertools.product(*[B(a) for a in Alist1]) : frozendict() )\n",
    "\n",
    "    # suggests that                                               \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "brute force smt equality. Only the equalities justified?\n",
    "\n",
    "## Telescope tries\n",
    "Compression is weakening?\n",
    "\n",
    "\n",
    "context mappings are just composed telescopes.\n",
    "Telescope composition is trie join and projection\n",
    "\n",
    "\n",
    "What would be a trie telescope in the setoid model?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Contexts as tries? We were kind of doing something trie-join like in my for loop nesting.\n",
    "\n",
    "{x : (3, {\"y\" : })}\n",
    "{\n",
    "    3 : { \"foo\" : ...}\n",
    "}\n",
    "\n",
    "comprehension telescope\n",
    "{x : { y :  { z : for z in C(x,y) } for y in B(x)} for x in A}\n",
    "type Tele[T] = dict[object, Tele[T] | T]\n",
    "\n",
    "Tele[tuple[]]  is context\n",
    "\n",
    "def proj(Tele[T]) -> Tele[tuple[]]:\n",
    "    #remove mapped to item basically.\n",
    "    \n",
    "Gamma |- t : Bool is kind of a BDD?\n",
    "\n",
    "def Bool(ctx : Trie):\n",
    "    frozenset{   } all ways of assigning bool to leaves\n",
    "\n",
    "x : Bool |- ite(x, Bool, Unit) type\n",
    "is the trie {False : {}, True : {True, False}}\n",
    "def proj(fam):\n",
    "    # traverse down to leaves, replace final set with None\n",
    "Internalization of trie  does require a new capability\n",
    "x : Bool |- Int  --> |- Bool -> Int  but this is a set of tries (dicts) which requires frozendict.\n",
    "So maybe I'll use regular dict for ctx, but an immutable dict for Pi.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "how to think about non empty contexts -> non canonical elements?\n",
    "I guess if we use compression, there is the True value in an context which is True at every leaf\n",
    "But there are other tries dicts with superpositions. As we eliminate pieces of the trie, the Bool heads towards being more consistent across worlds.\n",
    "\n",
    "x : Bool |- ite(x, 1, 0) : Int\n",
    "\n",
    "So refl not being the only element in a ctx means...\n",
    "\n",
    "so we can distinguish between x : Bool |- x : Bool  and x : Bool |- True : Bool \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "R(x,y) /\\ R(z,w) /\\ R()\n",
    "Mark one as the binding var. Depending on ordering we need to project existential.\n",
    "\n",
    "x : exists z, R(z,_), y : R(x, _), z : R(x,y)\n",
    "\n",
    "𝑅(𝑥, 𝑦), 𝑆 (𝑦, 𝑧),𝑇 (𝑧, 𝑥). https://arxiv.org/pdf/2301.10841\n",
    "\n",
    "\n",
    "a : exists w v. R(_, w) /\\ T(v,_),  b : exists w, S(_, w) /\\ R(a,_),  c : S(b,_) /\\ T(_, a)   |-  output(a,b,c)\n",
    "\n",
    "Oh yeah, a long time ago i had this idea wondering if query optimization might be useful for finding small brute force proof terms.\n",
    "Make an inductive datatype database.\n",
    "\n",
    "But really it would end up factored like this:\n",
    "a : X, p : exists w v. R(a, w) /\\ T(v,a), ...\n",
    "\n",
    "picking an order of elements. Well-ordering. Axiom of choice\n",
    "\n",
    "second order set theory\n",
    "\n",
    "cloven fibration https://ncatlab.org/nlab/show/cleavage\n",
    "global choice https://en.wikipedia.org/wiki/Axiom_of_global_choice\n",
    "https://jdh.hamkins.org/the-global-choice-principle-in-godel-bernays-set-theory/\n",
    "\n",
    "lean \"cast\"\n",
    "\n",
    "I guess we're quotienting by a decdiable equality. What would that look like?\n",
    "\n",
    "class Universe(Egraph):\n",
    "    # a global eq notion.\n",
    "    eq = smt.Function(\"eq\", Term, Term, BoolSort())\n",
    "    def fresh_type()\n",
    "        FreshConst()\n",
    "    def univ(types):\n",
    "        fresh_type()\n",
    "        assert u == lambda([T], smt.Or(T == typ for typ in types))\n",
    "\n",
    "\n",
    "https://arxiv.org/pdf/1909.01414  From type theory to setoids and back - Palmgren https://www.youtube.com/watch?v=SQ3WrTNJ2Bs&ab_channel=InstituteforAdvancedStudy\n",
    "https://www.youtube.com/watch?v=se22z_YzD2g&pp=ygUGc2V0b2lk\n",
    "\n",
    "E-categoires  https://ncatlab.org/nlab/show/E-category \n",
    "\n",
    "Squashed types\n",
    "\n",
    "def Squash(A):\n",
    "    return Quot(A, lambda x,y: True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_type(gamma, A):\n",
    "    ctx = []\n",
    "    stack = []\n",
    "    while gamma:\n",
    "        B = gamma.pop()\n",
    "        for b in B(*ctx):\n",
    "            ctx.append(b)\n",
    "\n",
    "def is_type(A, B):\n",
    "    for a in A:\n",
    "        assert isinstance(B(a), frozenset)\n",
    "\n",
    "def iso(Aset, Bset):\n",
    "    A = sorted(Aset)\n",
    "    B = sorted(Bset)\n",
    "    return lambda a: B[A.index(a)], lambda b: A[B.index(b)]\n",
    "\n",
    "\n",
    "def iso(a, a1 , B : Family): # https://ncatlab.org/nlab/show/transport\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sqlite\n",
    "\n",
    "Also relatedly CSP formulated in dependent typed style.\n",
    "Reminds me of relational algebra engine torlak.\n",
    "\n",
    "sql = csp in blog post. \n",
    "Dependent expressions can be seen as qeuries and databases.\n",
    "\n",
    "\n",
    "for x in A:\n",
    "    for y in B(x):\n",
    "        for z in C(x,y):\n",
    "            ...\n",
    "\n",
    "Kind of reminds me of egglog.  \n",
    "functions -> unit   are represent database facts.\n",
    "\n",
    "for x in A:\n",
    "    for y in B(x):\n",
    "        p in C(x,y):  # a way to bind to provenance\n",
    "\n",
    "Extended sql if the table names could take arguments. Expands to implicit where clause. \n",
    "From x in A, from y in B(x)\n",
    "\n",
    "From y in B(x) == (Select y From B where B.arg0 = x)\n",
    "\n",
    "\n",
    "\n",
    "Is there a multiset model of dtt? Why not right?\n",
    "\n",
    "\n",
    "scallop provenance. Uhhhh. Hmm.\n",
    "\n",
    "\n",
    "Use sympy for semrring semantics? Quotient rings\n",
    "\n",
    "table[] = sympy.symbol(\"a\")\n",
    "\n",
    "edge[(1,2)] = sympy.Function(\"edge\")(1,2)\n",
    "\n",
    "defaultdict(lambda: 0)\n",
    "\n",
    "for (x,y),prov in edge.items():\n",
    "    for (y,z) in path.items():\n",
    "        path[(x,z)] += prov1*prov2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Type():\n",
    "    set : frozenset\n",
    "    #eq : Callable[[object, object], bool]\n",
    "    def __eq__(self, other): # definitional equality of type. eq_type\n",
    "        pass\n",
    "    #def __hash__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Families of sets have more structure than in set theory.\n",
    "A family F of sets indexed by a set I is a functor F : I# → Sets.\n",
    "Explication:\n",
    "For each element a of I, F(a) is a set.\n",
    "For any proof object p : a =I b, F(p) is function from F(a) to F(b), a socalled transporter function.\"\n",
    "\n",
    "\"Proof\" of R(a,b) is just tuple (a,b)  : R(a,b) ?\n",
    "Kind of same as \"refl\" since it's useless. (\"refl\", a, b)\n",
    "\n",
    "\n",
    "subfinite sets \"we are only required to enumerate the elements, not tell them apart\". That feels egraphy\n",
    "\n",
    "A growing equality relation is the model. n : N -> eq_n\n",
    "\n",
    "\n",
    "Having the second component of the family return a dict feels right? that's more functorial.\n",
    "But it doesn't generate well into the non dependent case.\n",
    "\n",
    "Maybe I do need the fiber perspective?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type Family = tuple[Callable[[object, frozenset]], Callable[[object,object], frozenset[tuple[object, object]]]]\n",
    "def Sigma(A : Type, B : Family) -> Type:\n",
    "    return frozenset({(a, b) for a in A[0] for b in B[0](a)}), {((x, b0), (y, b1)) for (x,y) in A[1] for (b0,b1) in B[1](x,y)}\n",
    "\n",
    "def Pair1(A,B):\n",
    "    return frozenset((a,b) for a in A[0] for b in B[0]), {((x,b0), (y,b1)) for (x,y) in A[1] for (b0,b1) in B[1]}\n",
    "def Pair2(A,B):\n",
    "    return Sigma(A, (lambda x: B[0], lambda x,y: B[1]))\n",
    "\n",
    "def Pi(A : Type, B : Family) -> Type:\n",
    "    Alist = list(A.set)\n",
    "    fs = frozenset(frozendict({k:v for k,v in zip(Alist, bvs)}) for bvs in itertools.product(*[B[0](a) for a in Alist]))\n",
    "    eqs = {(f0,f1) for f0 in fs for f1 in fs if all((f0[a0], f1[a1]) in B[1](a0,a1) for (a0,a1) in A[1])}\n",
    "    # == is involved? The use of `in` hides it.\n",
    "    return fs, eqs\n",
    "# \"obvious\" definition of Arr assuming tuple form of family.\n",
    "def Arr(A, B):\n",
    "    fs = frozenset(frozendict({k:v for k,v in zip(Alist, bvs)}) for bvs in itertools.product(*[B[0](a) for a in Alist]))\n",
    "    eqs = {(f0,f1) for f0 in fs for f1 in fs if all( (f0[a0], f0[a1]) in B[1] for (a0,a1) in A[1])} # == is involved?\n",
    "    # There is some way to feather this out from f0 along B[1] instead of two loops. But probably not worth it.\n",
    "    return fs, eqs\n",
    "def Arr2(A,B):\n",
    "    return Pi(A, lambda x: B[0], lambda x,y: B[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type Family = tuple[Callable[[object, frozenset]], Callable[[object,object,object], frozenset[tuple[object, object]]]]\n",
    "def Sigma(A : Type, B : Family) -> Type:\n",
    "    return frozenset({(a, b) for a in A[0] for b in B[0](a)}), {(((x, b0), (y, b1)), (p,p1)) for (x,y,p) in A[1] for (b0,b1,p1) in B[1](x,y,p)}\n",
    "# (p,p1) is direct sum of groups? Sigma is a sum... Hm.\n",
    "\n",
    "def Pi(A : Type, B : Family) -> Type:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1304.5729 yet another family of setoids\n",
    "https://www2.math.uu.se/~palmgren/pfsitt-rev.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Id(A,x,y):\n",
    "    {(a,b) for a,b in A[1]  } if (x,y) in A[1] else frozenset()}, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type Family = tuple[Callable[[object], frozenset]], tuple[Callable[[object,object]], tuple[object,object]]\n",
    "type Family = tuple[Callable[[object, Type]], Callable[[object,object], dict[object, object]]]\n",
    "type PreSet = frozenset\n",
    "type Type = tuple[PreSet, frozenset[tuple[object,object]]]\n",
    "type Family = tuple[Callable[[object, frozenset]], Callable[[object,object], dict[object, object]]]\n",
    "\n",
    "# maybe we insist an iso for the map. canonical iso? An iso on preset elementsvor mod t\n",
    "# and maybe the first map really is to a setoid for which the trnasporter must be cohernet.\n",
    "type Family = tuple[Callable[[object, Setoid]], Callable[[object,object], dict[object, object]]]\n",
    "\n",
    "def is_family(A : Type, B : Family) -> bool:\n",
    "    isinstance(B[0](a)[0],frozenset) and is_equivB[1](a) \n",
    "    # coherence\n",
    "    all(for (x,y) in A[1] B)\n",
    "\n",
    "# a family has it's transporter function\n",
    "\n",
    "def Sigma(A : Type, B : Family) -> Type:\n",
    "    return frozenset({(a, b) for a in A.set for b in B[0](a)}), {((x, b), (y, B[1](x,y)[b])) for x in A[0] for y in A[0] if A[1](x,y) for b in B[0](x)}\n",
    "\n",
    "\n",
    "\n",
    "def Sigma(A : Type, B : Family) -> Type:\n",
    "    return frozenset({(a, b) for a in A[0] for b in B[0](a)}), {((x, b), (y, B[1](x,y)[b])) for (x,y) in A[1] for b in B[0](x)}\n",
    "\n",
    "\n",
    "def Pair(A : Type, B : Type) -> Type:\n",
    "    return Sigma(A, (lambda x: B, lambda x,y: {b : b for b in B[0]} )  )\n",
    "\n",
    "\n",
    "def Sigma(A : Type, B : Family) -> Type:\n",
    "    frozenset({(a, b) for a in A[0] for b in B[0](a)}), lambda x, y: B[1](x,y) if A[1](x,y) else None\n",
    "\n",
    "\n",
    "\n",
    "def Pi(A : Type, B : Family) -> Type:\n",
    "    Alist = list(A.set)\n",
    "    fs = frozenset(frozendict({k:v for k,v in zip(Alist, bvs)}) for bvs in itertools.product(*[B[0](a) for a in Alist]))\n",
    "    eqs = {(f0,f1) for f0 in fs for f1 in fs if all( B[1](a0,a1)[f0[a0]] == f1[a1] for (a0,a1) in A[1])} # == is involved?\n",
    "    return fs, eqs\n",
    "def Arr(A, B):\n",
    "    fs = frozenset(frozendict({k:v for k,v in zip(Alist, bvs)}) for bvs in itertools.product(*[B[0](a) for a in Alist]))\n",
    "    eqs = {(f0,f1) for f0 in fs for f1 in fs if all( (f0[a0], f0[a1]) in B[1] for (a0,a1) in A[1])} # == is involved?\n",
    "    return fs, eqs\n",
    "\n",
    "def Arr2(A,B):\n",
    "    Pi(A, lambda x: B[0], lambda x,y: B[1]) #? Not a dictionary... Pick something arbitrary? .... Meeeeeh.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    def allbasemoves(alist):\n",
    "        # return all possible base moves for alist\n",
    "        return itertools.product(*[A[1](a) for a in alist])\n",
    "    A[1](a)\n",
    "    for (alist,bvs) in fs:\n",
    "        for alist1 in allbasemoves(alist): #? allbasemoves? What? No alist is total. permutations?\n",
    "            bv1 = [B[1](x,y)(b) for x,b,y in zip(alist, bvs, alist1)]\n",
    "            (zip(alist,bvs), zip(alist1, bv1))\n",
    "                \n",
    "    eqs = frozenset(((f1, f2), (v1, v2)) for f1, f2 in itertools.product(fs, fs) for v1, v2 in zip(f1.values(), f2.values()) if B[1](f1, f2))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type Type = tuple[frozenset, Callable]\n",
    "type Family = Callable[[object], Type] # Family should obey setoidness (?) On the nose?\n",
    "# families carry the setoid transporter?\n",
    "\n",
    "import operator\n",
    "\n",
    "def is_type(A):\n",
    "    assert isinstance(A[0], frozenset)\n",
    "    assert all(A[1](a,a) for a in A[0]) # refl\n",
    "    assert all(A[1](a,a1) == A[1](a1,a) for a in A[0] for a1 in A[0]) # symm\n",
    "    assert all(A[1](x,z) for x in A[0] for y in A[0] for z in A[0] if A[1](x,y) and A[1](y,z)) # trans\n",
    "\n",
    "\n",
    "\n",
    "def eq_type(A,B):\n",
    "    # cody says == here is too weak or strong. But what else could I do?\n",
    "    # exists an element in B equal to any element A and vice versa?\n",
    "    # all(any(B[1](a,b) for b in B[0]) for a in A[0])) and all(any(A[1](a,b) for a in A[0]) for b in B[0])\n",
    "    # construct an iso? Use an ordering on the elements to do so?\n",
    "    # len(A[0]) == len(B[0]) too flimsy\n",
    "    # A[0] == B[0] too rigid\n",
    "    # to,from = iso(A[0], B[0])\n",
    "    # len(A[0]) == len(B[0]) and all(B[1](to(a), to(a1)) for a in A[0] for a1 in A[0] if A[1](a,a1)) and all(A[1](from(b), from(b1)) for b in B[0] for b1 in B[0])\n",
    "    # arbitrary iso, but \n",
    "    return A[0] == B[0] and all(A[1](a,b) == B[1](a,b) for a in A[0] for b in B[0])\n",
    "def Sigma(A,B):\n",
    "    # all(iso())\n",
    "    assert all(eq_type(B(a), B(a1)) for a in A[0] for a1 in A[0] if A[1](a,a1)) # This is really checking x:A |- B(x) type\n",
    "    # assert is_type(B)\n",
    "    # lambda (a,b), (a1,b1) : A[1](a,a1) and B(a)[1](b, iso(b1))     # B(a1)[1](iso(b), b1) symmettrically.\n",
    "    return frozenset({(a, b) for a in A[0] for b in B[0](a)}), lambda z,w: A[1](z[0], w[0]) and B(z[0])[1](z[1], w[1])\n",
    "def def_eq(x,y,A):\n",
    "    return x == y # not A[1](x,y)\n",
    "Void = (frozenset({}), lambda x,y: True)\n",
    "Unit = (frozenset({()}), lambda x,y: True)\n",
    "Bool = (frozenset({True, False}), operator.eq)\n",
    "\n",
    "def Fin(n : int) -> Type:\n",
    "    return (frozenset(range(n)), lambda x,y: x == y)\n",
    "\n",
    "def Quot(A, R):\n",
    "    # assuming R refines existing or else incorherent\n",
    "    assert all(not A[1](x,y) or R(x,y) for x in A[0] for y in A[0])\n",
    "    return A[0], lambda x,y: R(x,y)\n",
    "\n",
    "Mod3 = Quot(Fin(6), lambda x,y : x % 3 == y % 3)\n",
    "\n",
    "assert not def_eq(0,3, Mod3)\n",
    "assert def_eq(0,0, Mod3)\n",
    "\n",
    "def Pi(A,B):\n",
    "    assert all(eq_type(B(a), B(a1)) for a in A[0] for a1 in A[0] if A[1](a,a1))\n",
    "    Alist = list(A[0])\n",
    "    def fun_eq(f1, f2):\n",
    "        return all(B(a)[1](f[a], f1[a1]) for a in Alist for a1 in Alist if A[1](a,a1))\n",
    "    def playsnice(f):\n",
    "        return fun_eq(f, f)\n",
    "        #assert all(B(a)[1](f[a], f[a1]) for a in Alist for a1 in Alist if A[1](a,a1))\n",
    "    f0 = frozenset(filter(playsnice, [frozendict({k:v for k,v in zip(Alist, bvs)}) for bvs in itertools.product(*[B(a) for a in Alist])]))\n",
    "    return f0, fun_eq\n",
    "\n",
    "\n",
    "def Id(A, x, y):\n",
    "    return (frozenset({\"refl\"}), lambda x,y: True) if A[1](x, y) else (frozenset(), lambda x,y: True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Groups.\n",
    "A set with a group action.\n",
    "Orbit under group action is equivalence class\n",
    "\n",
    "\n",
    "Silly_Unit = {(0,1), (1,0)}, [{0 : 1, 1 : 0}, {0:0, 1:1} ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#type Group = int\n",
    "type Group = # list of generators of permutation group?\n",
    "type Type = tuple[frozenset, Group]\n",
    "\n",
    "Bool = (frozenset({True, False}), ({True: True, False : False},))\n",
    "BoolU = (frozenset({True, False}), ({True: True, False: False} ,{True: True, False : False},)) # a quotient of Bool isomoprhic to Unit\n",
    "\n",
    "def Arr(A, B):\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Unit = (frozenset({()}), {((), ())})\n",
    "UnitG = (frozenset({()}),  G) # group is gorupoid of single element.\n",
    "Bool = (frozenset({True, False}), ({(True, True), (False, False)}))\n",
    "BoolU = (frozenset({True, False}), {(True, False), (True,True), (False, True), (False, False)}) # a quotient of Bool isomoprhic to Unit\n",
    "\n",
    "type Family = #?\n",
    "\n",
    "def inv(p):\n",
    "    return (p[1], p[0])\n",
    "def comp(p,q):\n",
    "    assert p[1] == q[0]\n",
    "    return (p[0], q[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quasiquoting. \n",
    "type Code = tuple[str, type]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type Type = tuple[frozenset, Callable[object,object], object]  # type as set/eq_fun pair\n",
    "type Type = tuple[frozenset, Callable[object], object] # type as set/canon pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Void = frozenset({None}) # ?\n",
    "Unit = frozenset({(), None})\n",
    "Bool = frozenset({True, False, None})\n",
    "\n",
    "def Sigma(A : Type, B : Family) -> Type:\n",
    "    # B has to be a monotonic family.\n",
    "    return frozenset({(a, b) for a in A for b in B(a)}) | [None]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_le(x, y):\n",
    "    # partial order.\n",
    "    if x == y:\n",
    "        return True\n",
    "    if x is None:\n",
    "        return True\n",
    "    elif y is None:\n",
    "        return False\n",
    "    elif isinstance(x, tuple) and isinstance(y, tuple):\n",
    "        return all(def_le(xi, yi) for xi, yi in zip(x, y))\n",
    "    else:\n",
    "        return False\n",
    "#def_lt(None, 1)\n",
    "#def_lt(1, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({frozendict.frozendict({False: False, True: False, None: False}),\n",
       "           frozendict.frozendict({False: False, True: False, None: None}),\n",
       "           frozendict.frozendict({False: False, True: None, None: None}),\n",
       "           frozendict.frozendict({False: False, True: True, None: None}),\n",
       "           frozendict.frozendict({False: None, True: False, None: None}),\n",
       "           frozendict.frozendict({False: None, True: None, None: None}),\n",
       "           frozendict.frozendict({False: None, True: True, None: None}),\n",
       "           frozendict.frozendict({False: True, True: False, None: None}),\n",
       "           frozendict.frozendict({False: True, True: None, None: None}),\n",
       "           frozendict.frozendict({False: True, True: True, None: None}),\n",
       "           frozendict.frozendict({False: True, True: True, None: True})})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Arr(A, B):\n",
    "    Alist = list(A)\n",
    "    return frozenset(frozendict({k:v for k,v in zip(Alist, bvs)}) for bvs in itertools.product(*[B for a in Alist]) if all(not def_le(a, a1) or def_le(b,b1) for a,b in zip(Alist, bvs) for a1,b1 in zip(Alist, bvs)))\n",
    "Arr(Bool, Bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bidirectional style\n",
    "\n",
    "Does bidriectional have any meaning?\n",
    "subset types?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lam(A : Type, f):\n",
    "    return frozendict({a : f(a) for a in A})\n",
    "def app(f, x):\n",
    "\n",
    "\n",
    "def synth(t) -> Type:\n",
    "    \n",
    "\n",
    "def check(t, A : Type) -> bool:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Set2D = frozendict[object, object]\n",
    "# directed graph is simplicial set. Glued  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type Code = str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle x \\in \\left\\{1, 2\\right\\}$"
      ],
      "text/plain": [
       "Contains(x, {1, 2})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sympy\n",
    "x,y,z = sympy.symbols(\"x y z\")\n",
    "sympy.ConditionSet(x, x > 0, sympy.S.Reals)\n",
    "sympy.Contains(x, sympy.UniversalSet)\n",
    "x in sympy.UniversalSet\n",
    "sympy.Contains(x, sympy.FiniteSet(1,2)) # in doesn't work. Needs to evlauates to Bool\n",
    "\n",
    "#def Arr(A,B):\n",
    "#def Pi(A,B):\n",
    "\n",
    "Contains(x, sympy.UniversalSet), Contains(y, FiniteSet(1,2)(x), Contains(z, FiniteSet(1,2)(x,y))\n",
    "                                          ImageSet().Contains()\n",
    "                                        \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def Te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Turnstile(*vs, body): # TeleForAll\n",
    "    acc = body\n",
    "    # TODO: maybe compress stretches of unquantified.\n",
    "    for v in reversed(vs):\n",
    "        if isinstance(v, tuple):\n",
    "            #acc = kd.QForAll([v[0]], v[1], acc) # this is more refinement style. Strictly speaking B can still contain x in other ways.\n",
    "            acc = kd.QForAll([v[0]], v[1][v[0]], acc)\n",
    "        else:\n",
    "            acc = kd.QForAll([v], acc)\n",
    "    return acc\n",
    "\n",
    "IntT = smt.K(smt.IntSort(), True)\n",
    "#Pos = smt.Lambda([x], x > 0)\n",
    "def GT(x):\n",
    "    return smt.Lambda([y], y > x)\n",
    "def Fin(n): # meta Fin\n",
    "    return smt.Lambda([x], smt.And(0 <= x, x < n))\n",
    "# Internal-ish Fin\n",
    "Fin = kd.define(\"Fin\", [n], smt.Lambda([x], smt.And(0 <= x, x < n)))\n",
    "#Fin2 = smt.Lambda([x], smt.Lambda([y], smt.And(0 <= x, x < 2))\n",
    "Turnstile([(x, Fin(3)), (y, Fin(x))], )\n",
    "\n",
    "type Type = smt.ArraySortRef\n",
    "def Pi(A : smt.ArraySortRef, B : smt.ArraySortRef) -> Type:\n",
    "    return smt.Lambda([f], kd.QForAll([x], A[x], B(x)(f[x])))\n",
    "def Arr(A : Type, B : Type) -> Type:\n",
    "    return smt.Lambda([f], kd.QForAll([x], A[x], B(f[x])))\n",
    "def Pair(A : Type, B : Type) -> Type:\n",
    "    return smt.Lambda([p], smt.And(p.is_pair, A(p[0]), B(p[1])))\n",
    "def Sigma(A : Type, B : Type) -> Type:\n",
    "    return smt.Lambda([p], smt.And(p.is_pair, A(p[0]), B(p[0])(p[1])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contracts? diualectica? Something something?\n",
    "# You needs both variance to do stuff.\n",
    "\n",
    "type Type = type[Gen, Callable[object, bool]]\n",
    "def Pi(A, B):\n",
    "    return lambda f: all(lambda x: A(x) and B(x)(f(x))) # can't really do this part.\n",
    "def Pi(A, B):\n",
    "    def check(f):\n",
    "        hypothesis.get(A[0])\n",
    "        # quick check property that pull from A, then B(f(x))\n",
    "    def gen():\n",
    "        return lambda x: gen(B(x))\n",
    "    return gen, check\n",
    "\n",
    "def Sigma()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({frozenset(), frozenset({False, True}), frozenset({()})})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Env((\"x\", A), (\"y\", B(\"x\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://hylang.org/hy/doc/v1.1.0\n",
    "Hy. Kind of interesting. Something about python metaprogramming using fstrings wasn't that nice. The well typedness?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hy\n",
    "hy.eval(hy.read_many(\"(+ 1 1)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hy.models.Lazy(<hy.models.Lazy object at 0x7e0cd59bc3e0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hy.read_many(\"(+ 1 1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lambda x35243: x35243(1)'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "type Code = str\n",
    "def lam(f : Callable[[Code], Code]) -> Code:\n",
    "    x = \"x\" + str(random.randint(0, 100000))\n",
    "    return f\"lambda {x}: {f(x)}\"\n",
    "def app(f : Code, x : Code) -> Code:\n",
    "    return f\"{f}({x})\"\n",
    "def lit(x : Code) -> Code:\n",
    "    return f\" {x} \"\n",
    "lam(lambda x: f\"{x} + 1\")\n",
    "\n",
    "lam(lambda f: f\"{f}(1)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3           0 RESUME                   0\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 LOAD_CONST               1 (1)\n",
      "              6 BINARY_OP                0 (+)\n",
      "             10 RETURN_VALUE\n",
      "  4           0 RESUME                   0\n",
      "              2 LOAD_FAST                0 (y)\n",
      "              4 LOAD_CONST               1 (1)\n",
      "              6 BINARY_OP                0 (+)\n",
      "             10 RETURN_VALUE\n"
     ]
    }
   ],
   "source": [
    "import dis\n",
    "\n",
    "f = lambda x: x + 1\n",
    "f1 = lambda y: y + 1\n",
    "dis.dis(f)\n",
    "dis.dis(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction(opname='RESUME', opcode=151, arg=0, argval=0, argrepr='', offset=0, starts_line=3, is_jump_target=False, positions=Positions(lineno=3, end_lineno=3, col_offset=0, end_col_offset=0)) Instruction(opname='RESUME', opcode=151, arg=0, argval=0, argrepr='', offset=0, starts_line=5, is_jump_target=False, positions=Positions(lineno=5, end_lineno=5, col_offset=0, end_col_offset=0))\n",
      "Instruction(opname='LOAD_FAST', opcode=124, arg=0, argval='x', argrepr='x', offset=2, starts_line=None, is_jump_target=False, positions=Positions(lineno=3, end_lineno=3, col_offset=14, end_col_offset=15)) Instruction(opname='LOAD_FAST', opcode=124, arg=0, argval='y', argrepr='y', offset=2, starts_line=None, is_jump_target=False, positions=Positions(lineno=5, end_lineno=5, col_offset=15, end_col_offset=16))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def def_eq(f, f1):\n",
    "    # not alpha equiv\n",
    "    # could have some simlifying rewriting in here?\n",
    "    for i1,i2 in zip(dis.Bytecode(f), dis.Bytecode(f1)):\n",
    "        print(i1,i2)\n",
    "        if i1.opname != i2.opname or i1.arg != i2.arg or i1.argval != i2.argval:\n",
    "            return False\n",
    "    return True\n",
    "def_eq(f,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frozenset([x + y for x in Fin(5) for y in Fin(x)]) <= Fin(8) # x : Fin(5), y : Fin(x) |- x + y : Fin(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([x + y in Fin(8) for x in Fin(5) for y in Fin(x)])  # x : Fin(5), y : Fin(x) |- x + y : Fin(8)\n",
    "all([x + y in Fin(5 + y) for x in Fin(5) for y in Fin(x)]) \n",
    "\n",
    "all([frozendict({y : x + y for y in Fin(x)}) in Pi(Fin(x), lambda z: Fin(5 + z)) for x in Fin(5)])\n",
    "# x : Fin(5) |- fun y => y + x : forall z : Fin(x), Fin(5 + z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all([isinstance(Fin(x), frozenset) for x in Fin(5)]) # x : Fin(5) |- Fin(x) Type\n",
    "all([x + y == y + x for x in Fin(5) for y in Fin(x)]) # x : Fin(5), y : Fin(x) |- x + y = y + x # judge_eq? But I don't want x + y == y + x judgementally?\n",
    "# id(x + y) == id(y + x) or  \"x + y\" == \"y + x\" or \n",
    "all([Fin(x + y) == Fin(y + x) for x in Fin(5) for y in Fin(x)]) # x : Fin(5), y : Fin(x) |- Fin(x + y) = Fin(y + x) judge_eq ? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({frozendict.frozendict({'x': False, 'y': False}),\n",
       "           frozendict.frozendict({'x': False, 'y': True}),\n",
       "           frozendict.frozendict({'x': True, 'y': False}),\n",
       "           frozendict.frozendict({'x': True, 'y': True})})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# python contexts as Gamma? No this is more like env rho? But like all envs\n",
    "def foo():\n",
    "    #A = Bool\n",
    "    #y = iter(A)\n",
    "    ctxs = [] # Gamma? Interpretation of Gamma as a set of contexts.\n",
    "    def inner():\n",
    "        for x in Bool:\n",
    "            for y in Bool:\n",
    "                t = locals()\n",
    "                del t[\"ctxs\"]\n",
    "                ctxs.append(frozendict(t))\n",
    "                del t\n",
    "    inner()\n",
    "    return frozenset(ctxs)\n",
    "foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def app(f, x):\n",
    "    return f[x]\n",
    "def var(x):\n",
    "    return x\n",
    "tt = ()\n",
    "true = True\n",
    "false = False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step indexing.\n",
    "\n",
    "# gas parameter\n",
    "def Pi(A,B,gas):\n",
    "    # all steps < gas\n",
    "    Alist = list(functools.reduce(operator.or_, A(i) for i in range(gas)))\n",
    "    return frozenset(frozendict({k:v for k,v in zip(Alist, bvs)}) for bvs in itertools.product(*[B(a,gas) for a in Alist]))\n",
    "\n",
    "# generator style.\n",
    "# B is generator of families.\n",
    "def Pi(A,B):\n",
    "    Biter = B()\n",
    "    B.next() # B is one ahead of A\n",
    "    for An in A:\n",
    "        Bn = B.next()\n",
    "        yield frozenset(frozendict({k:v for k,v in zip(An, bvs)}) for bvs in itertools.product(*[Bn(a) for a in An]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp(e : smt.ExprRef, env) -> object:\n",
    "    if isinstance(e, smt.QuantifierRef):\n",
    "        assert e.is_lambda()\n",
    "        e.vars + env\n",
    "    if smt.is_select(e):\n",
    "        app(interp(e.arg(0)), interp(e.arg(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python vs z3 meta.\n",
    "ctx can be z3 meta ctx. Not refiied.\n",
    "Forall x y z, is analog of above for loops.\n",
    "\n",
    "forall x, B[x], forall y, A[x,y], ... C[t(x,y,z)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Term0 = smt.DeclareSort(\"Term0\")\n",
    "Term = smt.Datatype(\"Term\")\n",
    "Term.declare(\"TT\")\n",
    "Term.declare(\"BoolVal\", (\"bval\", smt.BoolSort()))\n",
    "Term.declare(\"IntVal\", (\"ival\", smt.IntSort()))\n",
    "Term.declare(\"PairVal\", (\"fst\", Term), (\"snd\", Term))\n",
    "Term.declare(\"OtherVal\", (\"val\", Term0)) # Functions, etc. We only separate out primitives for fun.\n",
    "\n",
    "Type = smt.SortSort(Term)\n",
    "Family = smt.ArraySort(Term, Type)\n",
    "Bool = smt.Lambda([t], t.is_BoolVal)\n",
    "Void = smt.Lambda([t], False)\n",
    "Unit = smt.Lambda([t], t.is_TT)\n",
    "\n",
    "Arr = smt.Function(\"Arr\", Type, Type, Type)\n",
    "apply = smt.Function(\"apply\", Term, Term, Term)\n",
    "lam = smt.Function(\"lam\", smt.ArraySort(Term, Term), Term)\n",
    "kd.axiom(kd.QForAll([a,b], apply(lam(a), b)) == a[b])\n",
    "# extensionality forall x, apply(t1, x) == apply(t2, x) == (t2 == t1)\n",
    "\n",
    "\n",
    "kd.define(\"Arr\", [A,B], smt.Lambda([t], smt.And(t.is_OtherVal, kd.QForAll([x], A[x], B[apply(t, x)]))))\n",
    "kd.define('Pi', [A,B], smt.Lambda([t], smt.And(t.is_OtherVal, kd.QForAll([x], A[x], B[x][apply(t, x)]))))\n",
    "def Pi(A, B):\n",
    "    return smt.Lambda([t], smt.And(t.is_OtherVal, kd.QForAll([x], A(x), B(x, apply(t, x)))))\n",
    "# comp = smt.Function(\"comp\", Type, Term)\n",
    "# This might be ok, but the reverse,   Term, Type or asking if Term in Term requires carefulness.\n",
    "\n",
    "lamB = smt.Function(\"lamB\", smt.ArraySort(smt.BoolSort(), Term), Term)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Univ = smt.Const(\"Univ0\", Type)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependent typed egraph.\n",
    "in SMT egraph, everything was keyed on sort.\n",
    "If we're in a dependent context why not seek dependent sorts\n",
    "\n",
    "\n",
    "egraphs are models. Ifwe watn an \"dependently typed egraph\" seek it in a models of dependent type theory.\n",
    "\n",
    "\n",
    "{\"Ob\" :  }\n",
    "{\"Hom\" : dict{(1,2) : {   }}\n",
    "\n",
    "bottom up ematching indeed. Tries indeed.\n",
    "\n",
    "\"Bool\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.all import *\n",
    "from kdrag.solvers.egraph import EGraph\n",
    "import kdrag.theoires.set as set_\n",
    "T = smt.DeclareSort(\"PreTerm\")\n",
    "Type = smt.SortSort(T)\n",
    "class DTT(EGraph):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.families = defaultdict(lambda: defaultdict(set))\n",
    "        self.infer_type = defaultdict(set) # ?\n",
    "    #def declare_family(self, *tele):\n",
    "    #    # a b c   |-  Hom(a,b) type\n",
    "    #    # register rule to be fired by bidi\n",
    "    # maybe rules are better suggested in external ematching loops. \n",
    "\n",
    "    def assert_is_type(self, typ):\n",
    "        self.families[typ.decl()][typ.children()]\n",
    "    def has_type(self, term, typ):\n",
    "        assert typ.sort() == Type\n",
    "        assert term.sort() == T\n",
    "        # a, b, c |- t : A\n",
    "        # dterm is a pair (name, family)\n",
    "        #name, family = dterm\n",
    "        #return self.infer_type[dterm.get_id()] == typ.get_id() and typ[dterm]\n",
    "        self.infer_type[dterm.get_id()] = typ.get_id()\n",
    "        self.solver.add(typ[dterm])\n",
    "        self.families[typ.decl()][typ.children()].add(dterm)\n",
    "\n",
    "    def reflect_universe(self):\n",
    "        codes = smt.Enum(self.families.keys())\n",
    "        #U = smt.FreshConst(Type, prefix=\"Univ\"\n",
    "        El = FreshFunction(\"El\", Code, Type)\n",
    "        # self.solver.assert(El(code[n]) == smt.Lambda(args, self.families[key](args))) for enumerate(self.families.keys())\n",
    "        self.families[U] = {code : set(self.families.keys()) for code in codes}\n",
    "    def add_dterm(self, dterm, typ):\n",
    "        # a, b, c |- t : A      # ?? a,b,c are implicit?\n",
    "        # dterm is a pair (name, family)\n",
    "        # Do bidi checking here? Recursively.\n",
    "        name, family = dterm\n",
    "        for c in typ.children():\n",
    "            self.add_dterm(c)\n",
    "        self.families[typ.decl()][typ.children()].add(dterm)\n",
    "    def union(self, ctx, t1, t2):\n",
    "        pass\n",
    "\n",
    "Ob = smt.Const(\"Ob\", Type)\n",
    "Hom = smt.Function(\"Hom\", Ob, Ob, Type)\n",
    "\n",
    "a,b,c = smt.Consts(\"a b c\", T)\n",
    "E = DTT()\n",
    "E.add_dterm(a, Ob)\n",
    "E.add_dterm(b, Ob)\n",
    "E.add_dterm(c, Ob)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EGraph():\n",
    "    families : dict[object, dict[, set[int]]] # roots keyed by type family\n",
    "\n",
    "    def declare_type(self, name):\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## categorical persecptive\n",
    "If I combine my finset cat and finset dtt post, can I do categorical semantics of type theory?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametricity\n",
    "Finite parametricity\n",
    "\n",
    "https://people.mpi-sws.org/~dreyer/tor/papers/wadler.pdf\n",
    "\n",
    "\n",
    "Paramatricity is an information hiding theorem about the type universe? We want to allow open universes / be non specific about exactly what's in the universe.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Binary_relation . Hmm Class vs set issues in relation algebra\n",
    "\n",
    "schmidt relational mathematics\n",
    "\n",
    "Sympyifying and that parametricity = noether thing. Hmm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({(frozendict.frozendict({True: False, False: False}),\n",
       "            frozendict.frozendict({True: False, False: False})),\n",
       "           (frozendict.frozendict({True: False, False: True}),\n",
       "            frozendict.frozendict({True: False, False: True})),\n",
       "           (frozendict.frozendict({True: True, False: False}),\n",
       "            frozendict.frozendict({True: True, False: False})),\n",
       "           (frozendict.frozendict({True: True, False: True}),\n",
       "            frozendict.frozendict({True: True, False: True}))})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bools = frozenset({(True, True), (False, False)})\n",
    "Unit = frozenset({((), ())})\n",
    "Void = frozenset()\n",
    "def Fin(n):\n",
    "    return frozenset({(i,i) for i in range(n)})\n",
    "\n",
    "\n",
    "# I am not sure this is right.\n",
    "# Alist is longer than just the naive length of single A. So I'm picking a dependence\n",
    "# maybe I do need to do cartisan product and then \n",
    "def Arr(A,B): # In B the product is already done.\n",
    "    Alist = list(A)\n",
    "    res = []\n",
    "    for bs in itertools.product(B, repeat=len(Alist)):\n",
    "        f,f1 = zip(*[((a,b), (a1,b1)) for ((a,a1), (b,b1)) in zip(Alist, bs)])\n",
    "        res.append((frozendict(f), frozendict(f1)))\n",
    "    #f,f1 = zip(*[(a,b), (a1,b1) for ((a,a1), (b,b1)) in zip(Alist, bs)] for bs in itertools.product(B, repeat=len(Alist)))\n",
    "    return frozenset(res)\n",
    "    #return frozenset(frozendict(data), frozendict()\n",
    "\n",
    "def breakup(B):\n",
    "    xs, ys = zip(*A)\n",
    "    return frozenset(xs), frozenset(ys)\n",
    "\n",
    "\n",
    "\n",
    "type Type = frozenset[tuple[object, object]]\n",
    "type Family = frozenset[tuple[Callable[object, Type0], Callable[object, Type0]]] # this is too many tuples? Type0 doesn't really let us express correlation.\n",
    "def Pi(A, B : Family):\n",
    "    Alist = list(A)\n",
    "    res = []\n",
    "    for bs in itertools.product(*[itertools.product((B0(x), B1(y)) for B0, B1 in B) for (x,y) in Alist]):\n",
    "    #for bs in itertools.product(*[itertools.product(B[0](x), B[1](y)) for (x,y) in Alist]):\n",
    "        f,f1 = zip(*[((a,b), (a1,b1)) for ((a,a1), (b,b1)) in zip(Alist, bs)])\n",
    "        res.append((frozendict(f), frozendict(f1)))\n",
    "    #f,f1 = zip(*[(a,b), (a1,b1) for ((a,a1), (b,b1)) in zip(Alist, bs)] for bs in itertools.product(B, repeat=len(Alist)))\n",
    "    return frozenset(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(frozenset({1, 2}), frozenset({1, 2, 3}))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# factor into smallest overapaproximation if you cartieana producted again\n",
    "def factor(A):\n",
    "    xs, ys = zip(*A)\n",
    "    return frozenset(xs), frozenset(ys)\n",
    "\n",
    "factor({(1,2), (2,3), (2,1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## monotonic\n",
    "type interpeted as monotnically increasing sets\n",
    "\n",
    "maybe is becomes more interesting.\n",
    "\n",
    "vs finite sets of monotinically evaluating objects.\n",
    "vs monotonically evaluating \n",
    "Motonically producing objects?\n",
    "\n",
    "\n",
    "FRP as model of intuionistic logic? Hmm. label realvbalue of when stuiff becomes true\n",
    "\n",
    "sets of pairs of (timestamp, value) # and take the earliest timestamp\n",
    "\n",
    "vs fix how many timesteps in advance.\n",
    "\n",
    "There's no reason to use generators really. Huh.\n",
    "\n",
    "I interpret a type into this? Feels weird.\n",
    "\n",
    "a growing egraph universe\n",
    "sorts are interpreted as subuniverses?\n",
    "Next step of universe could contain it's previous self.\n",
    "This was an angle on the finite set post.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozendict.frozendict({'x': 1, 'y': 2, 'z': 4})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "def tset(vs):\n",
    "    d = {}\n",
    "    for v,t in vs:\n",
    "        d[v] = min(d.get(v, float(\"inf\")), t)\n",
    "    return frozendict(d)\n",
    "\n",
    "tset([(\"x\",1), (\"y\",2), (\"x\", 3), (\"z\",4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, None), (None, None), (42, None), (42, None), (42, 'hello')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "def delay(t, v):\n",
    "    for i in range(t):\n",
    "        yield\n",
    "    yield v\n",
    "    #return v\n",
    "\n",
    "list(delay(4, 2))\n",
    "\n",
    "x = delay(4,3)\n",
    "next(x)\n",
    "next(x)\n",
    "next(x)\n",
    "next(x)\n",
    "next(x)\n",
    "\n",
    "\n",
    "def pair(x,y):\n",
    "    for i in x:\n",
    "        yield (i,None)\n",
    "    for j in y:\n",
    "        yield (i,j)\n",
    "list(pair(delay(2,42), delay(1, \"hello\")))\n",
    "\n",
    "def Pair(A,B):\n",
    "    return [pair(i,j) for i in A for j in B]\n",
    "def Pi(A,B):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Int at 0x736ae2208a00>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Int():\n",
    "    s = set()\n",
    "    i = 0\n",
    "    while True:\n",
    "        s.add(i)\n",
    "        yield frozenset(s)\n",
    "        i += 1\n",
    "\n",
    "Int()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impredicativity\n",
    "https://cstheory.stackexchange.com/questions/36043/impredicative-in-type-theory\n",
    "How do we read this answer? Full comprehension of some formula is allowable (?).\n",
    "indctive(S) = elem(emp,S) & forall x, elem(x,S), elem(succ(x), S)\n",
    "\n",
    "large eliminations\n",
    "\n",
    "exlcuded middle gets you prop resizing https://ncatlab.org/nlab/show/propositional+resizing\n",
    "\n",
    "\n",
    "\"A type signature for church encoded natural numbers is forall (A : Prop), (A -> A) -> A -> A.\n",
    "This signature quantifies over A : Prop hence if this type signature is in Prop then Prop is impredicative which is necessary to even define functions from the church nats to church nats. \n",
    "The alternatives to impredicative Prop would be either:\"  https://discord.com/channels/1128334405795061800/1324761377801502720/1326012154830393424\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proofs as categories\n",
    "single succedent singel conseqeunt\n",
    "\n",
    "```\n",
    " ...\n",
    "------\n",
    "A |- B\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "--------- id\n",
    " id(A) : A |- A\n",
    "```\n",
    "\n",
    "```\n",
    "f : A |- B   g :  B |- C\n",
    "------------------------- cut\n",
    "     comp(f,g) : A |- C\n",
    "```\n",
    "\n",
    "```\n",
    "------------------\n",
    " fst : A /\\ B |- A\n",
    "```\n",
    "\n",
    "```\n",
    "---------------\n",
    "snd :  A /\\ B |- B\n",
    "```\n",
    "\n",
    "```\n",
    "f : A |- B   g : C |- D\n",
    "------------------ par\n",
    "par(f,g) : A /\\ C |- B /\\ D\n",
    "```\n",
    "\n",
    "```\n",
    "----------- dup\n",
    "dup : A |- A /\\ A\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "   f : A /\\ B |- C\n",
    "-------------------------\n",
    "   curry(f) : A |- B -> C\n",
    "```\n",
    "\n",
    "```\n",
    "-----------------\n",
    "apply : A /\\ A -> B |- B\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lawvere\n",
    "\n",
    "The equalizer in a lawvere theory is E-unification.\n",
    "\n",
    "combinator form of substitutions\n",
    "\n",
    "\n",
    "coalgebra.\n",
    "a -> f a\n",
    "\n",
    "operads\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# refinement sorts\n",
    "went into bottom of Telescope blog post. substitution etudes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gat EAT\n",
    "https://ncatlab.org/nlab/show/essentially+algebraic+theory\n",
    "\n",
    "t1 = t2 /\\ t3 = t4 => t5 = t6\n",
    "\n",
    "t5 . solve(par(t1,t3),par(t2, t4)) = t6 . solve(...)\n",
    "\n",
    "This is saying the under the substitution/assumption t1 = t2 ... \n",
    "And I think it's a sefl consitent E assumtionb.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Having equalizers + products is the same as having all finite limits somehow?\n",
    "\n",
    "\n",
    "\n",
    "In egglog, t1 = t2 ,,.... => t3 = t4\n",
    "You can solve e-unify in the body via egraph ematching.\n",
    "\n",
    "But then this asserts a new equality.\n",
    "\n",
    "t1 =E t2 ==> t3 = t4\n",
    "Conditional KB.\n",
    "\n",
    "https://www.youtube.com/watch?v=RmiTOa4b0bA&ab_channel=ToposInstitute CB Aberle: All Concepts are Essentially Algebraic\n",
    "\n",
    "The next one up in evan's hierarchy was\n",
    "locally carteian closed\n",
    "https://ncatlab.org/nlab/show/locally+cartesian+closed+category\n",
    "https://link.springer.com/chapter/10.1007/BFb0022273 On the interpretation of type theory in locally cartesian closed categories . Hofmann\n",
    "\n",
    "burtsall rydeheard style slicing.\n",
    "cod(f) = x =>\n",
    "slice(f)?\n",
    "\n",
    "\n",
    "GAT to EAT relationship. Should probably try to model that first. Or maybe multisorted logic?\n",
    "\n",
    "\n",
    "The monad form of lawvere theory is kind of like the herband model in set? The monad action is applying the constructors of the theories and quitented by axioms?\n",
    "https://anuyts.github.io/files/keml-diagrams.pdf\n",
    "\n",
    "Type -> Ctx style vs  EAT\n",
    "x,y,z -> Type  style  GAT\n",
    "\n",
    "Evocative of the observational vs record approach to tuples\n",
    "prod(x,y)\n",
    "vs q opaque, fst(q) = x, snd(q) = y\n",
    "\n",
    "Type -> ctx\n",
    "Type is total space, ctx is base space\n",
    "\n",
    "dom(subst) = ctx1\n",
    "cod(subst) = ctx2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a type\n",
    "a word. paper words. a speronality.\n",
    "\n",
    "bertrand russell, a method to remove paradoxes\n",
    "\n",
    "datatypes\n",
    "\n",
    "a syntactical discipline to maintain abstractions - reynolds\n",
    "\n",
    "compositional analyses - Neel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realizability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Z = namedtuple(\"Z\", \"n\") # zero\n",
    "S = namedtuple(\"S\", \"n\") # succ\n",
    "T = namedtuple(\"T\", \"n m\") # transfer\n",
    "J = namedtuple(\"J\", \"n m q\") # jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primes = [2,3,5,7,11,13,17,19,23,29,31,37,41,43,47]\n",
    "def code(e):\n",
    "    if tuple(e):\n",
    "        acc = 1\n",
    "        for p,c in zip(primes, e):\n",
    "            acc *= p ** code(c)\n",
    "        return primes[0]**acc\n",
    "\n",
    "\n",
    "def decode(e):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = DeclareSort(\"A\")\n",
    "K = Const(\"K\", A)\n",
    "S = Const(\"S\", A)\n",
    "app = Function(\"app\", A, A, A, BoolSort())\n",
    "kd.define\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBE\n",
    "See nbe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import z3\n",
    "TYPE = z3.DeclareSort(\"TYPE\")\n",
    "TERM = z3.DeclareSort(\"TERM\")\n",
    "\n",
    "def check(ctx, term,typ):\n",
    "    is_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from typing import Callable\n",
    "\"\"\"\n",
    "def C(tag, *args):\n",
    "    return tuple[Literal(tag), *args]\n",
    "\n",
    "type L[A] = Literal[A] # not allowed\n",
    "type app = Literal[\"app\"]\n",
    "type Arr[A,B] = Callable[[A],B]\n",
    "type typ = C[\"arr\", typ, typ] | C(\"unit\")\n",
    "type term = C[App, term, term] | C[\"lam\", term] | C[\"var\", int]\n",
    "\"\"\"\n",
    "# This is about as short as I can go. The system doesn't enable abstraction over types. it's pretty rigid\n",
    "\n",
    "type term = tuple[Literal[\"app\"], term, term] | \\\n",
    "            tuple[Literal[\"lam\"], term] | \\\n",
    "            tuple[Literal[\"var\"], int]\n",
    "\n",
    "type typ = tuple[Literal[\"arr\"], typ, typ] | \\\n",
    "           tuple[Literal[\"unit\"]]\n",
    "\n",
    "def pprint(t : term) -> str:\n",
    "    match t:\n",
    "        case (\"barf\",):\n",
    "            return \"barf\"\n",
    "        case (\"app\", f, x):\n",
    "            return f\"{pprint(f)} {pprint(x)}\"\n",
    "        case (\"lam\", x):\n",
    "            return f\"λ{pprint(x)}\"\n",
    "        #case (\"var\", x):\n",
    "        #    return f\"x{x}\"\n",
    "\n",
    "def poo(x : int) -> term:\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "type aexpr = tuple[Literal[\"var\"], str] | \\\n",
    "             tuple[Literal[\"lit\"], int] | \\\n",
    "             tuple[Literal[\"add\"], aexpr, aexpr]\n",
    "\n",
    "def eval(e : aexpr, env : dict[str,int]) -> int:\n",
    "    match e:\n",
    "        case (\"var\", x):\n",
    "            return env[x]\n",
    "        case (\"lit\", x):\n",
    "            return x\n",
    "        case (\"add\", x, y):\n",
    "            return eval(x, env) + eval(y, env)\n",
    "\n",
    "assert eval((\"add\", (\"lit\", 1), (\"var\", \"x\")), {\"x\" : 2}) == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[](old/2024-07/typecheck_pcode_DATALLLLLLLLLLOG.IPYNB)\n",
    "\n",
    "\n",
    "System F\n",
    "\n",
    "types\n",
    "\n",
    "Programming in Martin Lof type theory\n",
    "\n",
    "HOTT - john sterling stuff\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "type Foo[A] = tuple[A,A]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "philzook58.github.io",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
