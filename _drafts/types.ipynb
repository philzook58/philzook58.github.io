{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LF\n",
    "\n",
    "https://www.danielgratzer.com/papers/type-theory-book.pdf\n",
    "programming in martin lof type theory\n",
    "hott book\n",
    "egbert hott book\n",
    "\n",
    "Cody's notes https://www.kleene.church/tt-notes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantics of type theory\n",
    "\n",
    "https://cms.sic.saarland/semantics_ws2122/materials/\n",
    "\n",
    "https://cstheory.stackexchange.com/questions/17668/resources-for-mathematicians-hoping-to-learn-more-computer-science\n",
    "\n",
    "https://people.mpi-sws.org/~dreyer/courses/catlogic/jacobs.pdf catgeorical logic and type theory bart jacobs\n",
    "\n",
    "practical foundatiosn - taylor\n",
    "\n",
    "https://www.lfcs.inf.ed.ac.uk/reports/92/ECS-LFCS-92-208/  An introduction to fibrations, topos theory, the effective topos and modest sets\n",
    "\n",
    "https://ncatlab.org/nlab/show/categorical+semantics+of+dependent+type+theory\n",
    "Ok. \n",
    "sets pointing into their \"type\" sets considered as subsets of them.\n",
    "Then there are squares that \n",
    "type families Ai  project into their indexing space (?). Yeah, I guess so.\n",
    "\n",
    "\n",
    "Categories with families. Cody says related to explicit substituion calculus like lambda sigma.\n",
    "\n",
    "Substitutions as a category\n",
    "\n",
    "GATs involved somehow.\n",
    "\n",
    "Maybe the first step is to deeply understand lawvere theories. https://en.wikipedia.org/wiki/Lawvere_theory\n",
    "https://ncatlab.org/nlab/show/Lawvere+theory\n",
    " How do you combinatorify equational/algebraic or first order logic?\n",
    "term = morphism from unit?\n",
    "https://www.youtube.com/watch?v=IZcrASzCybs&ab_channel=SchmidCollege%2CChapmanUniversity evan patterson. standard hierachy at 41:10\n",
    "free substitutions vs substituions under a theory? Adding equations to the category of substitutions?\n",
    "\n",
    "Functor to set = model\n",
    "\n",
    "To turn n-arity into single arity we can use a prod construction. Just like we can make multiarg computer programs using tuples\n",
    "fst(prod(x,y)) = x\n",
    "snd(prod(x,y)) = y\n",
    "`assoc(prod(x,prod(y,z))) = prod(prod(x,y),z)` vs `prod(x,prod(y,z)) = prod(prod(x,y),z)`. fst and snd get confused if we make equal on the nose.\n",
    "So is this an an example of how to model higher structures that aren't \"equal on the nose\"?\n",
    "\n",
    "Another style\n",
    "prod2(x,y)\n",
    "prod3(x,y,z)\n",
    "\n",
    "negassoc(prod(prod(x,y),z)) = prod(x,prod(y,z))\n",
    "\n",
    "\n",
    "\n",
    "see fibers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hott\n",
    "\n",
    "https://ncatlab.org/nlab/show/categorical+semantics+of+dependent+type+theory\n",
    "https://www.cs.uoregon.edu/research/summerschool/summer14/rwh_notes/ssdt.pdf\n",
    "\n",
    "What is the name \n",
    "\n",
    "https://mathstodon.xyz/@MartinEscardo/110890155815254064 escardo threads on hott"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "TYPE = smt.DeclareSort(\"TYPE\")\n",
    "TERM = smt.DeclareSort(\"TERM\")\n",
    "\n",
    "@dataclass\n",
    "class Judgement():\n",
    "    ctx : list[tuple[smt.ExprRef, smt.ExprRef]]\n",
    "@dataclass\n",
    "class IsType(Judgement):\n",
    "    typ : smt.ExprRef\n",
    "    def __repr__(self):\n",
    "        return f\"{self.ctx} |- {self.typ} TYPE\"\n",
    "@dataclass\n",
    "class HasType(Judgement):\n",
    "    term : smt.ExprRef\n",
    "    typ : smt.ExprRef\n",
    "    def __repr__(self):\n",
    "        return f\"{self.ctx} |- {self.term} : {self.typ}\"\n",
    "@dataclass\n",
    "class EqType(Judgement):\n",
    "    typ1 : smt.ExprRef\n",
    "    typ2 : smt.ExprRef\n",
    "    def __repr__(self):\n",
    "        return f\"{self.ctx} |- {self.typ1} = {self.typ2}\"\n",
    "@dataclass\n",
    "class EqTerm(Judgement):\n",
    "    term1 : smt.ExprRef\n",
    "    term2 : smt.ExprRef\n",
    "    typ : smt.ExprRef\n",
    "    def __repr__(self):\n",
    "        return f\"{self.ctx} |- {self.term1} = {self.term2} : {self.typ}\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Array(T, Bool)"
      ],
      "text/plain": [
       "Array(T, Bool)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "T = smt.DeclareSort(\"T\")\n",
    "TSet = smt.SetSort(T)\n",
    "\n",
    "TSet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ncatlab.org/nlab/show/type+telescope\n",
    "https://www.pls-lab.org/en/telescope\n",
    "https://www.sciencedirect.com/science/article/pii/089054019190066B?ref=pdf_download&fr=RR-2&rr=92eb234868378fa9  Telescopic mappings in typed lambda calculus\n",
    "\n",
    "telescopes as trees?\n",
    "telescopes are ordered variables. grobner elmination tries to find a fopr of the polynomial like that. Gauss elimination.\n",
    "Triangular form. trinagular unfication. We're just playing mind jazz baby\n",
    "J Zucker\n",
    "\n",
    "T3elescope dot product. Terms are in the telescope. Dot product instantiations vairables. hmmm.\n",
    "`[1 , 2] . [x : x = 17, y : y + x = 14] =  1 = 17 /\\ 2 + 1 = 14` \n",
    "`[foo(a), bar(biz)] . [x : baz(x), y : edge(x,y)] = baz(foo(a)) /\\ edge(foo(a), bar(biz))`\n",
    "\n",
    "telescopic mappings are matrices?\n",
    "dot product is maybe like |=? \n",
    "\n",
    "telescopic mappings are instnation of the contex? They are substitutions. BUt then the telescope isn't\n",
    "Some kind of trinagular matrix? a stack of rows or a stack of columns?\n",
    "nested telescopes.\n",
    "x -> [y : B(y)]\n",
    "No whole hog. The substiution rule applied one by one? Subst + weaken.\n",
    "Add in new variable we're going to subst to. Then eliminate using subst old variable in terms of new.\n",
    "[x : A(x)] |- f(x) : Z(x) \n",
    "[y : B(y), x : A(x)] |- f(x) : Z(x) weaken\n",
    "[y : B(y)] |- f(g(y)) |- Z(g(y)) subst\n",
    "\n",
    "Gam, x : A, Del\n",
    "and\n",
    "Gam |- t : A \n",
    "\n",
    "Gam, Del[t/A]\n",
    "\n",
    "\n",
    "I guess telescope is a generalization of my `vs` list, which was a context, sure.\n",
    "If telescopes are a context, what is a ntext? :)\n",
    "\n",
    "\n",
    "\n",
    "def unify(telescope, t1 , t2, typ)\n",
    "def pmatch(telescope, p, t1, typ)\n",
    "\n",
    "\n",
    "You could have GAT rewriting logic. \n",
    "Gam |- t1 -> t2 : A.  asymmettric\n",
    "Gam |- A -> A1\n",
    "\n",
    "Gam |- T type is a fibration.\n",
    "\n",
    "predicates with variables in them are sets at the metalevel. Before we use comprehension / lambda to internalize them.\n",
    "\n",
    "If you have an equational theory of types, you could find an ordering the context that puts the thing you want to substitute last or first?\n",
    "\n",
    "definitional type equality is in a context. Not clear if I have to use kleene equality or no. Well, I need to quantify over the variables in scope...\n",
    "If I don't have function symbols, this is probably all in EPR?\n",
    "\n",
    "To say we have a iterative fibering of a surface is kind of like saying we have a fully projection sequence form.\n",
    "It's weird to say that we have this from the get go.\n",
    "block triangular form is almost as good.\n",
    "mappings between\n",
    "[x : R,  y : R | y = x**2 + 2]\n",
    "Does a telescope have anything to do with triangular form solutions / projection / gauss elimination / elimination / quantifer elim.   I could descibe a sphere as something like [x : R, y : R | x**2 + y**2 <= 1, z : R | z = 1 - x**2 - y**2] \n",
    "Or some robot configuration it's nice to have the kinematics straightened out. Or maybe something something cylindrical algerbaic decomposition\n",
    "I could decribe a triangular linear equation as  [x : R | x = 42, y : R | y = 3* x + 14, ...]\n",
    "Or fourier motzkin form as   [x : R | 1 < x < 7, y : R | x + y < 4 /\\ x + y < 17, ....]\n",
    "\n",
    "[ p : R^3|   p.x**2 + p.y**2 + p.z**2 = 1 ] converting this telescope into that above one is hard in general\n",
    "\n",
    "SympyTelescope. SolveSet.\n",
    "\n",
    "TERM and TYPE\n",
    "\n",
    "But what if they were the same? is TYPE = Set(TERM), this requires some kind of class -> set comprehension like thing. An internalization.\n",
    "TYPE1 = smt.SetSort(TYPE)\n",
    " and so on\n",
    "\n",
    "\n",
    "```\n",
    "# n are universe levels. Obviously they are not in the system. They are python integers\n",
    "def TYPE(n):\n",
    "    if n == 0:\n",
    "        return TERM \n",
    "    return smt.SetSort(TYPE(n-1))\n",
    "```\n",
    "\n",
    "is univalence statable?\n",
    "```\n",
    "def univalence(n):\n",
    "    return Iso(A == B, Iso(A,B)) # no. == is definitional equality. We want propositional equality (?) right?\n",
    "    retrun Iso(PropEq(A,B), Iso(A,B))\n",
    "\n",
    "def Iso(A,B):\n",
    "    #which for ismorphic stuff means same cardinality? But maybe less clear given we're recursing into an equality.\n",
    "    f,g = smt.Array(\"f g\", TYPE(n), TYPE(n))\n",
    "    smt.Exists([f,g], A[x] => B[f(x)], B[y] => A[g(y)], f(g(x)) == x, g(f(y)) == y)\n",
    "```\n",
    "\n",
    "finite models by encding up to universe level n. If it trivialize at some N, we're good to go? It stays trivial?\n",
    "\n",
    "I'm building a model of dependent type theory. I don't know if that proves it in the original system, that unsat means that there must be a judgement in dependent type theory. Can i extract such a judgement tree from an unsat core?\n",
    "\n",
    "\n",
    "\n",
    "lifting property\n",
    "unit ->  spiral\n",
    "|         |\n",
    "\\/        \\/\n",
    "interval -> circl\n",
    "\n",
    "we pick an \"inital condition\" for which layer we want to be on, that's what the upper and left edges do, then the r5est of the path is derivable.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Resolution_of_singularities\n",
    "\n",
    "\n",
    "co de bruijn telescopes.\n",
    "\n",
    "VMap = \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy\n",
    "\n",
    "class Telescope():\n",
    "    vs : list[sympy.Symbol]  # maybe if we want it in block solved form, list[tuple[sympy.Symbol, ...]]\n",
    "    typs : SolveSet\n",
    "\n",
    "class Shape(): #Fibration\n",
    "    ctx : Telescope   # base\n",
    "    typ : SolveSet # a constrjiat on the rewals\n",
    "\n",
    "class Point():\n",
    "    ctx : Telescope\n",
    "    t : sympy.Expr\n",
    "    typ : SolveSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gatexpr is like Gam |- t : A judgement. see cat_topos_free.ipynb\n",
    "TERM = smt.DeclareSort(\"TERM\")\n",
    "TYPE = smt.SetSort(TERM)\n",
    "\n",
    "@dataclass\n",
    "class TeleScope():\n",
    "    vs : list[smt.ExprRef]\n",
    "    typs : list[smt.BoolRef] # vs smt.ExprRef. Pre applied to vs or not?\n",
    "    def interp(self):\n",
    "        return smt.And(self.typs)\n",
    "        #return smt.And(typ(*self.vs[:i]) for i,typ in enumerate(self.typs))\n",
    "    def extend(self, typ): # C-ext\n",
    "        v = smt.FreshConst(TERM)\n",
    "        return v, Telescope(vs + [v], typs + [typ(v)]) # typ is a z3 or python lambda that can also contain previous variables.\n",
    "    # I guess I'm considering all type expressions to be valid.\n",
    "    # Gamma |- T type is not a judgement that is needed.\n",
    "    # if wqe capture \"variables\" not in scope somehow, they are considered to be constants.\n",
    "    # We have an open notion of constant\n",
    "    #def strengthen(self, n): ... # check nothing using variable n and then remove it. Is this weakening, or is this strengthening.\n",
    "    def weaken(self, posn, typ):\n",
    "        v = smt.FreshConst(TERM)\n",
    "        # maybe check typ does not contain any vs[posn:]. THis is just fancy extend\n",
    "        return v, Telescope(vs[:posn] + [v] + vs[posn+1:], typs[:posn] + [typ(v)] + typs[posn+1:])\n",
    "    def subst(self, v_or_posn, t : GatExpr):\n",
    "        assert t.ctx == self[:posn] # or alpha eq? and normalize?\n",
    "        assert t.typ == self.typs[posn]\n",
    "        tailtyps = [smt.substitute(typ  (v, t.t)) for typ in self.typs[posn+1]]\n",
    "        return Telescope(self.vs[:posn] self.vs[posn+1:], self.typs[:posn] + tailtyps)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GATExpr():\n",
    "    ctx : Telescope\n",
    "    t : smt.ExprRef # t.sort() == TERM\n",
    "    typ : smt.ExprRef # this is a typ.sort() == TYPE\n",
    "\n",
    "    def judge(self):\n",
    "        smt.ForAll(self.ctx.vs, self.ctx.interp(), self.typ[self.t])\n",
    "    def __eq__(self, other):\n",
    "        # either require to be in same context or reconcile them. (common prefix?)\n",
    "\n",
    "\n",
    "\n",
    "Ob = smt.Const(\"Ob\", TYPE)\n",
    "Hom = smt.Function(\"Hom\", Ob, Ob, TYPE)\n",
    "a,b,c = smt.Consts(\"a b c\", TERM)\n",
    "kd.axiom(Ob[a])\n",
    "kd.axiom(Ob[b])\n",
    "kd.axiom(Ob[c])\n",
    "f,g,h = smt.Consts(\"f g h\", TERM)\n",
    "id_ = smt.Function(\"id\", TERM, TERM)\n",
    "comp = smt.Function(\"comp\", TERM, TERM, TERM)\n",
    "kd.notation.matmul.register(TERM, comp)\n",
    "\n",
    "kd.axiom(kd.QForAll([a], Ob[a], Hom(a,a)[id_(a)])) # a : Ob |- id(a) : Hom(a,a)\n",
    "kd.axiom(kd.QForAll([a,b,c], Ob[a], Ob[b], Ob[c], Hom(a,b)[f], Hom(b,c)[g], Hom(a,c)[f @ g])) # a : ob, b : Ob, c : Ob, f : Hom(a,b), g : Hom(b,c) |- f . g : Hom(a,c) \n",
    "\n",
    "# hmm. Hom(a,b)[f] is there difference of those like the difference between indexes and parameters? Nooooo. Porb not.\n",
    "\n",
    "\n",
    "# equality rules\n",
    "kd.axiom(kd.QForAll([a,b], Ob[a], Ob[b], Hom(a,b)[f], f @ id_(a)) == f) # a : Ob, b : Ob, f : Hom(a,b) |- f. id(a) = f\n",
    "# other id\n",
    "# assoc comp\n",
    "\n",
    "# Ob[a] is a simple predicate. And i can do it ahead of time in z3 sort system. If I know these things don't intersect? \n",
    "# Injectivity of Type constructors?\n",
    "# This is an optimization though.\n",
    "\n",
    "\n",
    "# a : Ob, b : Ob, f : Hom(a,b) |- dom(f) = a\n",
    "# a : Ob, b : Ob, f : Hom(a,b) |- cod(f) = b\n",
    "\n",
    "# internalizing type. deep embedding GAT/ Martin Lof into GAT\n",
    "type0 = smt.Function(\"type0\", TYPE)\n",
    "type1 = smt.Function(\"type1\", TERM)\n",
    "eq = smt.Function(\"eq\", TERM, TERM, TERM) # \n",
    "eq1 = smt.Function(\"eq\", TERM, TERM, TYPE)\n",
    "eq2 = smt.Function(\"eq\", TYPE, TYPE, TERM) # eq1 is a judgement, eq2 is a term.\n",
    "eq3 = smt.Function(\"eq\", TYPE, TYPE, TYPE) # eq1 is a judgement, eq2 is a term.\n",
    "eq4 = smt.Function(\"eq\", TYPE, TERM, TYPE) # THe two inputs hsould at least match yeah?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impredicativity\n",
    "https://cstheory.stackexchange.com/questions/36043/impredicative-in-type-theory\n",
    "How do we read this answer? Full comprehension of some formula is allowable (?).\n",
    "indctive(S) = elem(emp,S) & forall x, elem(x,S), elem(succ(x), S)\n",
    "\n",
    "large eliminations\n",
    "\n",
    "exlcuded middle gets you prop resizing https://ncatlab.org/nlab/show/propositional+resizing\n",
    "\n",
    "\n",
    "\"A type signature for church encoded natural numbers is forall (A : Prop), (A -> A) -> A -> A.\n",
    "This signature quantifies over A : Prop hence if this type signature is in Prop then Prop is impredicative which is necessary to even define functions from the church nats to church nats. \n",
    "The alternatives to impredicative Prop would be either:\"  https://discord.com/channels/1128334405795061800/1324761377801502720/1326012154830393424\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proofs as categories\n",
    "single succedent singel conseqeunt\n",
    "\n",
    "```\n",
    " ...\n",
    "------\n",
    "A |- B\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "--------- id\n",
    " id(A) : A |- A\n",
    "```\n",
    "\n",
    "```\n",
    "f : A |- B   g :  B |- C\n",
    "------------------------- cut\n",
    "     comp(f,g) : A |- C\n",
    "```\n",
    "\n",
    "```\n",
    "------------------\n",
    " fst : A /\\ B |- A\n",
    "```\n",
    "\n",
    "```\n",
    "---------------\n",
    "snd :  A /\\ B |- B\n",
    "```\n",
    "\n",
    "```\n",
    "f : A |- B   g : C |- D\n",
    "------------------ par\n",
    "par(f,g) : A /\\ C |- B /\\ D\n",
    "```\n",
    "\n",
    "```\n",
    "----------- dup\n",
    "dup : A |- A /\\ A\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "   f : A /\\ B |- C\n",
    "-------------------------\n",
    "   curry(f) : A |- B -> C\n",
    "```\n",
    "\n",
    "```\n",
    "-----------------\n",
    "apply : A /\\ A -> B |- B\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# z3 subst catgegoyr\n",
    "\n",
    "https://ncatlab.org/nlab/show/substitution#CategoricalSemantics\n",
    "\n",
    "\n",
    "A cateogical presentrration of the nufnication algorithm.\n",
    "We break down the lawvere theory into par and do it piece by piece somehow.\n",
    "\n",
    "\n",
    "I guess pullback is kind of like unifying terms from two different unification var sets\n",
    "\n",
    "https://math.andrej.com/2012/09/28/substitution-is-pullback/\n",
    "predicates.\n",
    "https://en.wikipedia.org/wiki/Pullback\n",
    "\n",
    "substitution equationally\n",
    "We work with the entire system...\n",
    "```\n",
    "-- eq is equalizer morphism\n",
    "eq(f,f) = id(dom(f))  -- id rule\n",
    "eq(f,g) = eq(g,f)  -- kind of orient rule but all at once.\n",
    "eq(par(f,g),par(h,k)) = par(eq(f,h),eq(g,k))\n",
    "eq(comp(f,g), comp(h,k)) =?\n",
    " -- unify  f,h first, then unify \n",
    " eq(comp(f,g), h) = eq(f . ??, h) something?\n",
    "\n",
    "\n",
    "eq(id,f) =? \n",
    "```\n",
    "\n",
    "https://link.springer.com/chapter/10.1007/3-540-17162-2_139  A categorical unification algorithm\n",
    "Ryhdeheard and burstall\n",
    "Hmm. Coequalizer?\n",
    "\n",
    "Hmm. Yes the variables in the terms are associated with the CODOMINA of the subtitution.\n",
    "The domain of the substitution is a mere indexing basically and almost doesn't have a sense of being a variable.\n",
    "\n",
    "To be comparing vars in codomain like unification, it should be aa coequalizer\n",
    "\n",
    "{x -> f(x', y'), y -> g(x', y')}\n",
    "[f(v0,v1), g(v0,v1)]\n",
    "\n",
    "[f(p(q(a)))] is a concrete ground term. The codomain is implicit. It could be 0 vars (?)\n",
    "The domain is 1.\n",
    "\n",
    "A signature can be expressed as noting atomic elements [f(v0,v1)]  [g(v0)]. [mul(v0,v1)] [inv(v0)] []\n",
    "\n",
    "\n",
    "A particular open preciate is [even(succ(succ(v0)))]  a multi predicate is interpreted as conjunction?\n",
    "\n",
    "\n",
    "Raising nad lowering unneccesary variables.\n",
    "Projecting out variables as exists and forall\n",
    "duplicating variables ~ eq\n",
    "\n",
    "[v0, v0]  expsress {x -> x', y -> x'}  a merging substitution\n",
    "There is no duplicating susbtitution. {x -> x', x -> y'}\n",
    "\n",
    "vBool -> F(x)  . vInt -> succ(y) = vBool -> F(succ(y))\n",
    "post composition is substituion into predicate\n",
    "vBool -> F(x)  . vInt -> add(z,y) = vBool -> F(add(x,y)) this makes morew vairblwes.\n",
    "\n",
    "f(x,y) = x   is and equation saying the vInt -> f(x,y) is the same as raise(vInt -> x, vInt)\n",
    "\n",
    "\n",
    " `|-` \n",
    "\n",
    " https://www.cl.cam.ac.uk/~amp12/papers/catl/catl.pdf catehorical logic pitts\n",
    "\n",
    " https://www.youtube.com/watch?v=uQp-Pi5jSNk quantifiers as djoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from z3 import *\n",
    "\n",
    "Ctx = list[SortRef]\n",
    "\n",
    "\n",
    "class Morph():\n",
    "    dom: list[SortRef] # not so implicit\n",
    "    cod: list[SortRef] # implicit in subst (?).\n",
    "    subst = list[ExprRef]\n",
    "    def __init__(self, dom, cod, subst):\n",
    "        assert [t.sort() for t in in subst] == dom\n",
    "        # assert all set(get_vars(t) for t in subst) in \n",
    "        self.dom = dom\n",
    "        self.cod = cod\n",
    "        self.subst = subst\n",
    "    def __matmul__(self, other):\n",
    "        assert self.dom == other.cod\n",
    "        return Morph(other.dom, self.cod, [substitute_vars(t, *other.subst) for t in self.subst])\n",
    "\n",
    "\n",
    "def id(n): # or a sort list.\n",
    "    return [Var(i) for i in range(n)]\n",
    "def comp(fs,gg):\n",
    "    return [substitute_vars(f, *gs) for f in fs]\n",
    "def par(fs,gs):\n",
    "    # TODO: shift gs.\n",
    "    return [f for f in fs] + [substutute_vars(g, Var(n + len(fs)) for g in gs]\n",
    "mullawv = [mul(Var(0), Var(1))]\n",
    "elawv = [e]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predicates():\n",
    "    vs: Ctx #list[SortRef]\n",
    "    expr: BoolRef\n",
    "    #exprs: set[BoolRef] equivalence exprs?\n",
    "\n",
    "    def proj(self) -> Ctx:\n",
    "        # returns an object in substitution category\n",
    "        return vs #(?)\n",
    "\n",
    "# category is preorder\n",
    "class Morph():\n",
    "    dom : Pred\n",
    "    cod : Pred\n",
    "    subst : Subst\n",
    "    def __init__(self, dom, cod, subst):\n",
    "        # The variables aren't shared? Hmmmmm.\n",
    "        assert dom.vs == subst.dom\n",
    "        assert cod.vs == subst.cod\n",
    "\n",
    "        assert prove(ForAll(cod.vs, Implies(substitute_vars(dom.expr, *subst.subst), cod.expr)))\n",
    "\n",
    "        #assert prove(ForAll(dom.vs, Implies(dom.expr, cod.expr)))\n",
    "        self.dom = dom\n",
    "        self.cod = cod\n",
    "    # quantifiers\n",
    "    def add(self, vsort): \n",
    "        # add an unused var along for the ride? Antiprojecting.\n",
    "        # \"weaken\". \"lift\" \"raise\"\n",
    "    def leftadjoint(self):\n",
    "        # x.add(v).leftadjoint() ~ x\n",
    "\n",
    "    def rightadjoint(self):\n",
    "        # x.rightadjoint().add(v) ~ x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typing as fibers.\n",
    "gamma |- A  is like a (entangled) product of gamma and A\n",
    "\n",
    "proj(gamma |- A) = gamma\n",
    "\n",
    "The functoriality of substutuition to the predicate category is saying that if you prove and implication with variables in it, you can substute in anything you want and still have a proof.\n",
    "No. predicates have to be over the same context to be compared...\n",
    "gamma |- A -> B\n",
    "No wait. If we include a subst we have a way to compare the two variable sets...\n",
    "\n",
    "\n",
    "There is a category over a single ctx.\n",
    "The is also a category of ctx maps\n",
    "\n",
    "Apropos partial functions: the thing that Nate and I talked about a bit was modeling these as spans, So a partial function f:A-> B would be a pair of regular functions g:X->A, h:X->B, where h is monic, and f(a) = b would translate to Ex.g(x) = a and h(x) = b. If you make h epic, that corresponds to the function being total, and if you relax the constraint that h is monic, you get what feel like multiset valued functions. For encoding in a theorem prover, I wonder if it would be smoother to use cospans, so g:A->X, h:B->X, with h monic. Then f(a) = b could translate to g(a) = f(b), and you don't need the quantifier. X could be basically Maybe B.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "From lunch: sorry, coequalizer, not equalizer\n",
    "About the substitution thing: the inclusion function, from the set of definable sets of individuals (represented by one-variable formulas/predicates) to the set of definable sets of pairs of individuals (represented by two-variable formulas) is actually the result of a substitution, if you look at it a certain way. Suppose I have a two-argument function, f(x,y) and a one variable formula F(x). I can make a two variable formula by substitution: F(f(x,y)). If my function is projection of the left argument, so that f(x,y) = x, then what my substitution is doing is, in a more explicit way, turning F from a one variable formula into a slightly degenerate case of a two variable formula.\n",
    "\n",
    "There's a contravariant functor thing going on here: f : A -> B induces a functor from the fiber (in this case, a Boolean algebra of definable sets or something) over B to the fiber over A.\n",
    "\n",
    "\n",
    "Yea, coequalizer does seem right now\n",
    "What is the fiber? There is a special Bool object maybe and  strangely the morphisms coming out of bool represent predicates and the target object is the vars in the predicate expression?\n",
    "Or it the boolean algebra a category connected to our substitution category by a functor, ie a model of our signature\n",
    "\n",
    "So, the boolean algebra is the fiber. The objects in there are equivalence classes of formulas, and the arrows are the boolean algebra ordering, which corresponds to implication.\n",
    "\n",
    "The idea is that there's a total category whose objects are formulas in a typing context. So, like a \"two variable formula\" is a formula whose variables are a subset of x,y, in a context \"x: individual, y: individual\". The contexts are the base category, and the functor that erases formulas and just leaves the context is the fibration. The fibers are the preimage categories of a given context plus its identity map - in the FOL case, these turn out to be Boolean algebras. (edited) \n",
    "\n",
    "The contexts are the objects in the base category of substitutions or each context is an entire base category? (edited) \n",
    "\n",
    "\n",
    "They're objects in a base category. Base category is not quite a category of substitutions, it's more like a category where the maps are function symbols. So like, a two variable function f induces a map from the context \"x: individual, y: individual\" to \"x:individual\". But a map in the base category like this creates a map (going in the other direction) between the fibers, which is essentially the result of substituting f(x,y) for x in each of the formulas-in-context in the fiber, thereby changing the context that it lives in.\n",
    "\n",
    "\n",
    "What about if you compose two maps? Isn’t it then not a function symbol and something more structured, more like a general substitution? Its generated by the function symbols ?\n",
    "\n",
    "Yeah, that's right.\n",
    "I'd think of it as a term, so like f(g(x,z),y) might be a map from the context x,y,z to the context x.\n",
    "\n",
    "\n",
    "\n",
    "Something I was realizing last night is substitution goes the other way. x,y,z is the codomain, despite how weird that feels\n",
    "{x’ -> f(g(x,z),y)}\n",
    "makes that feel better. Those codomain vars are on the right now\n",
    "\n",
    "All is well with the world.\n",
    "\n",
    "Are the upper objects full equivalence classes? Seems like a burden. Why can’t the upper objects be individual predicate expressions, what is the set getting us?\n",
    "\n",
    "I think they can. It just wouldn't be a boolean algebra anymore.\n",
    "\n",
    "a = b = c, why can’t an object be {a,b}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lawvere\n",
    "\n",
    "The equalizer in a lawvere theory is E-unification.\n",
    "\n",
    "combinator form of substitutions\n",
    "\n",
    "\n",
    "coalgebra.\n",
    "a -> f a\n",
    "\n",
    "operads\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gat EAT\n",
    "https://ncatlab.org/nlab/show/essentially+algebraic+theory\n",
    "\n",
    "t1 = t2 /\\ t3 = t4 => t5 = t6\n",
    "\n",
    "t5 . solve(par(t1,t3),par(t2, t4)) = t6 . solve(...)\n",
    "\n",
    "This is saying the under the substitution/assumption t1 = t2 ... \n",
    "And I think it's a sefl consitent E assumtionb.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Having equalizers + products is the same as having all finite limits somehow?\n",
    "\n",
    "\n",
    "\n",
    "In egglog, t1 = t2 ,,.... => t3 = t4\n",
    "You can solve e-unify in the body via egraph ematching.\n",
    "\n",
    "But then this asserts a new equality.\n",
    "\n",
    "t1 =E t2 ==> t3 = t4\n",
    "Conditional KB.\n",
    "\n",
    "https://www.youtube.com/watch?v=RmiTOa4b0bA&ab_channel=ToposInstitute CB Aberle: All Concepts are Essentially Algebraic\n",
    "\n",
    "The next one up in evan's hierarchy was\n",
    "locally carteian closed\n",
    "https://ncatlab.org/nlab/show/locally+cartesian+closed+category\n",
    "https://link.springer.com/chapter/10.1007/BFb0022273 On the interpretation of type theory in locally cartesian closed categories . Hofmann\n",
    "\n",
    "burtsall rydeheard style slicing.\n",
    "cod(f) = x =>\n",
    "slice(f)?\n",
    "\n",
    "\n",
    "GAT to EAT relationship. Should probably try to model that first. Or maybe multisorted logic?\n",
    "\n",
    "\n",
    "The monad form of lawvere theory is kind of like the herband model in set? The monad action is applying the constructors of the theories and quitented by axioms?\n",
    "https://anuyts.github.io/files/keml-diagrams.pdf\n",
    "\n",
    "Type -> Ctx style vs  EAT\n",
    "x,y,z -> Type  style  GAT\n",
    "\n",
    "Evocative of the observational vs record approach to tuples\n",
    "prod(x,y)\n",
    "vs q opaque, fst(q) = x, snd(q) = y\n",
    "\n",
    "Type -> ctx\n",
    "Type is total space, ctx is base space\n",
    "\n",
    "dom(subst) = ctx1\n",
    "cod(subst) = ctx2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# refeinment sorts\n",
    "I had notes somewhere about prolog using CLP.\n",
    "\n",
    "https://arxiv.org/pdf/2010.07763 tutorial\n",
    "\n",
    "https://noamz.org/oplss16/refinements-notes.pdf \n",
    "\n",
    "https://proofassistants.stackexchange.com/questions/755/whats-the-relationship-between-refinement-types-and-dependent-types hmm. Pierre-Marie suggest that a insifficiently restricted P in {x | P} can effectively enocde full dependent types. \"realizability interpetation\" in PRL.\n",
    "\n",
    "Does this subsyetms make me closer to cody's Boole?\n",
    "\n",
    "\n",
    "smtlib is basically a simply type programming language. Why not\n",
    "\n",
    "For using new logics in knuckeldragger we can:\n",
    "deep embed in z3\n",
    "shallow embed into z3\n",
    "make new judgement forms at the python metalevel that contain kd.Proof.\n",
    "\n",
    "\n",
    "annotate will be an immediate call to check (?). So annotate will take in Gamma.\n",
    "\n",
    "reflection could be an axiom schema to convert HasType to a kd.Proof. Interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x : Int | x > 0, y : Int | x > y, z : Int | z < y"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from kdrag.all import *\n",
    "@dataclass\n",
    "class Telescope():\n",
    "    vs : list[smt.ExprRef]\n",
    "    preds : list[smt.BoolRef | smt.QuantifierRef] # crucially can contain previous vars\n",
    "    def __init__(self, *vspreds): # could just make the empty context?\n",
    "        self.vs, self.preds = zip(*vspreds)\n",
    "    def __repr__(self):\n",
    "        return \", \".join([f\"{v} : {v.sort()} | {pred}\" for v,pred in zip(self.vs,self.preds)])\n",
    "    def entail(self):\n",
    "        acc = smt.BoolVal(True)\n",
    "    def extend(self, v, pred):\n",
    "        # add a new variable to the context\n",
    "        # should check that previous preds do not contain new v.\n",
    "        return Telescope(self.vs + [v], self.preds + [pred])\n",
    "\n",
    "# more linked list like. Easier to make immutable? Hmm. But lists are so much easier to work with.\n",
    "class Telescope2():\n",
    "    tail : Telescope2\n",
    "    v : smt.ExprRef\n",
    "    pred : smt.BoolRef\n",
    "\n",
    "\n",
    "\n",
    "# as bottom up judgement, base case should take a kd.Proof\n",
    "# This is actually kind of cool.\n",
    "@dataclass\n",
    "class EntailJudge():\n",
    "    ctx: Telescope\n",
    "    c : smt.BoolRef\n",
    "\n",
    "@dataclass\n",
    "class SubClass():\n",
    "    ctx : Telescope\n",
    "    v1 : smt.ExprRef\n",
    "    typ1 : smt.BoolRef\n",
    "    v2 : smt.ExprRef\n",
    "    typ2 : smt.BoolRef\n",
    "    # do we automatically do it in the smart consutrctor or not?\n",
    "    def __init__(self): ...\n",
    "    def __repr__(self):\n",
    "        return f\"{self.ctx} |- {self.t} <: {{ {self.t.sort()} | {self.typ} }}\"\n",
    "\n",
    "@dataclass\n",
    "class HasType():\n",
    "    ctx : Telescope\n",
    "    t : smt.ExprRef\n",
    "    typ : smt.BoolRef\n",
    "    def __repr__(self):\n",
    "        return f\"{self.ctx} |- {self.t} : {{ {self.t.sort()} | {self.typ} }}\"\n",
    "\n",
    "\n",
    "x,y,z = smt.Ints(\"x y z\")\n",
    "\n",
    "Telescope((x, x > 0), (y, x > y), (z, z < y))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RefinedSort():\n",
    "    sort : z3.SortRef\n",
    "    pred : z3.ExprRef # not a boolref. a lambda {x : Sort | pred(x) } -> {y : : sort2 | pred(x,y) }\n",
    "    v : z3.ExprRef\n",
    "    pred : z3.BoolRef # maybe invloing pred\n",
    "    ctx : list[z3.ExprRef] # y : ?  |- {x : sort | pred(x)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 18 (1256577910.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 19\u001b[0;36m\u001b[0m\n\u001b[0;31m    if\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 18\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from z3 import *\n",
    "import z3\n",
    "@dataclass\n",
    "class RSort():\n",
    "    sort : z3.SortRef\n",
    "    pred : z3.BoolRef # self is referred to as var(0)\n",
    "@dataclass\n",
    "class Arr():\n",
    "    dom: RSort\n",
    "    cod: RSort # var(1) refers to var bound in dom.\n",
    "    @property\n",
    "    def sort(self):\n",
    "        return ArraySort(self.dom.sort, self.cod.sort)\n",
    "\n",
    "\n",
    "def entail(gamma, c):\n",
    "    xs = [FreshConst(sort) for sort in gamma]\n",
    "    s = Solver()\n",
    "    s.add(Not(ForAll(xs, substitute_vars(c, *xs))))\n",
    "    assert s.check() == unsat\n",
    "\n",
    "\n",
    "def subtyp(gamma, sort1, sort2):\n",
    "    if isinstance(sort1, Arr) and isinstance(sort2, Arr):\n",
    "        assert subtyp(gamma, sort2.dom, sort1.dom) and subtyp([sort2.dom] + gamma, sort1.cod, sort2.cod)    \n",
    "    elif isinstance(sort1, RSort) and isinstance(sort2, RSort):\n",
    "        assert sort1.sort == sort2.sort\n",
    "        x = FreshConst(sort1.sort)\n",
    "        f = ForAll([x], substitute_vars(Implies(sort1.pred, sort2.pred), x))\n",
    "        assert entail(gamma, f)\n",
    "    else:\n",
    "        raise Exception(\"Unknown type\", sort1, sort2)\n",
    "\n",
    "\n",
    "def synth(gamma, term):\n",
    "    \n",
    "\n",
    "def check(gamma, term, typ):\n",
    "    assert term.sort() == typ.sort\n",
    "    if is_select(term): # app\n",
    "    elif is_quantifier(term) and term.is_lambda():\n",
    "        assert isinstance(typ, Arr)\n",
    "        x, body = open_binder(term)\n",
    "        gamma[x] = typ.dom\n",
    "        return check(gamma, body, typ.cod)\n",
    "    elif term in gamma: # gotta find it\n",
    "        s = gamma[term]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a type\n",
    "a word. paper words. a speronality.\n",
    "\n",
    "bertrand russell, a method to remove paradoxes\n",
    "\n",
    "datatypes\n",
    "\n",
    "a syntactical discipline to maintain abstractions - reynolds\n",
    "\n",
    "compositional analyses - Neel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realizability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Z = namedtuple(\"Z\", \"n\") # zero\n",
    "S = namedtuple(\"S\", \"n\") # succ\n",
    "T = namedtuple(\"T\", \"n m\") # transfer\n",
    "J = namedtuple(\"J\", \"n m q\") # jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primes = [2,3,5,7,11,13,17,19,23,29,31,37,41,43,47]\n",
    "def code(e):\n",
    "    if tuple(e):\n",
    "        acc = 1\n",
    "        for p,c in zip(primes, e):\n",
    "            acc *= p ** code(c)\n",
    "        return primes[0]**acc\n",
    "\n",
    "\n",
    "def decode(e):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = DeclareSort(\"A\")\n",
    "K = Const(\"K\", A)\n",
    "S = Const(\"S\", A)\n",
    "app = Function(\"app\", A, A, A, BoolSort())\n",
    "kd.define\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBE\n",
    "See nbe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import z3\n",
    "TYPE = z3.DeclareSort(\"TYPE\")\n",
    "TERM = z3.DeclareSort(\"TERM\")\n",
    "\n",
    "def check(ctx, term,typ):\n",
    "    is_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from typing import Callable\n",
    "\"\"\"\n",
    "def C(tag, *args):\n",
    "    return tuple[Literal(tag), *args]\n",
    "\n",
    "type L[A] = Literal[A] # not allowed\n",
    "type app = Literal[\"app\"]\n",
    "type Arr[A,B] = Callable[[A],B]\n",
    "type typ = C[\"arr\", typ, typ] | C(\"unit\")\n",
    "type term = C[App, term, term] | C[\"lam\", term] | C[\"var\", int]\n",
    "\"\"\"\n",
    "# This is about as short as I can go. The system doesn't enable abstraction over types. it's pretty rigid\n",
    "\n",
    "type term = tuple[Literal[\"app\"], term, term] | \\\n",
    "            tuple[Literal[\"lam\"], term] | \\\n",
    "            tuple[Literal[\"var\"], int]\n",
    "\n",
    "type typ = tuple[Literal[\"arr\"], typ, typ] | \\\n",
    "           tuple[Literal[\"unit\"]]\n",
    "\n",
    "def pprint(t : term) -> str:\n",
    "    match t:\n",
    "        case (\"barf\",):\n",
    "            return \"barf\"\n",
    "        case (\"app\", f, x):\n",
    "            return f\"{pprint(f)} {pprint(x)}\"\n",
    "        case (\"lam\", x):\n",
    "            return f\"λ{pprint(x)}\"\n",
    "        #case (\"var\", x):\n",
    "        #    return f\"x{x}\"\n",
    "\n",
    "def poo(x : int) -> term:\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "type aexpr = tuple[Literal[\"var\"], str] | \\\n",
    "             tuple[Literal[\"lit\"], int] | \\\n",
    "             tuple[Literal[\"add\"], aexpr, aexpr]\n",
    "\n",
    "def eval(e : aexpr, env : dict[str,int]) -> int:\n",
    "    match e:\n",
    "        case (\"var\", x):\n",
    "            return env[x]\n",
    "        case (\"lit\", x):\n",
    "            return x\n",
    "        case (\"add\", x, y):\n",
    "            return eval(x, env) + eval(y, env)\n",
    "\n",
    "assert eval((\"add\", (\"lit\", 1), (\"var\", \"x\")), {\"x\" : 2}) == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[](old/2024-07/typecheck_pcode_DATALLLLLLLLLLOG.IPYNB)\n",
    "\n",
    "\n",
    "System F\n",
    "\n",
    "types\n",
    "\n",
    "Programming in Martin Lof type theory\n",
    "\n",
    "HOTT - john sterling stuff\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "type Foo[A] = tuple[A,A]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
