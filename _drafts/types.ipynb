{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://people.cs.nott.ac.uk/psztxa/publ/fomus19.pdf altelnkirch note\n",
    "\n",
    "https://eprints.nottingham.ac.uk/41385/1/th.pdf  Type theory in a type theory with\n",
    "quotient inductive types kaposi thesis\n",
    "\n",
    "Winterhalter thesis\n",
    "\n",
    "https://drops.dagstuhl.de/storage/00lipics/lipics-vol131-fscd2019/LIPIcs.FSCD.2019.25/LIPIcs.FSCD.2019.25.pdf  Gluing for Type Theory\n",
    "\n",
    "abstract and concrerte type theories - uemeura https://eprints.illc.uva.nl/id/document/12150\n",
    "\n",
    "artin gluing is a way to put two cetagories together\n",
    "Logical relations\n",
    "\n",
    "\n",
    "LF\n",
    "\n",
    "https://www.danielgratzer.com/papers/type-theory-book.pdf\n",
    "programming in martin lof type theory\n",
    "hott book\n",
    "egbert hott book\n",
    "\n",
    "Cody's notes https://www.kleene.church/tt-notes\n",
    "\n",
    "https://logic.berkeley.edu/logic@UCB/Rathjen_logic@UCB.pdf On relating type theories to (intuitionistic) set theories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# identity types\n",
    "\n",
    "Families.\n",
    "parameters vs indices\n",
    "https://golem.ph.utexas.edu/category/2022/07/identity_types_in_context.html\n",
    "https://cs.stackexchange.com/questions/20100/what-are-the-difference-between-and-consequences-of-using-type-parameters-and-ty\n",
    "https://homotopytypetheory.org/2011/04/10/just-kidding-understanding-identity-elimination-in-homotopy-type-theory/\n",
    "\n",
    "P(a,refla)\n",
    "P selects where to rewrite.\n",
    "\n",
    "\n",
    "A refinment version?\n",
    "p : EqInfo | eq(p, a, b)\n",
    "\n",
    "pattern matching and unification problems. How to compiler dependent matcvhes to \n",
    "\n",
    "\n",
    "Constructors internalize meta notions.\n",
    "sigma types tinernalize things that can happen in a context.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Terms sort is not that different from ZF.\n",
    "https://ncatlab.org/nlab/show/subsingleton\n",
    "\n",
    "Consider other congruence relations. Combinators on them?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TERMS = smt.DeclareSort(\"TERMS\") # Constructions\n",
    "TYPE = set_.Set(TERMS) # Is type judgement\n",
    "elem = smt.Function(\"elem\", TERMS, smt.SetSort(TERMS)) # has type judgement\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantics of type theory\n",
    "\n",
    "https://cms.sic.saarland/semantics_ws2122/materials/\n",
    "\n",
    "https://cstheory.stackexchange.com/questions/17668/resources-for-mathematicians-hoping-to-learn-more-computer-science\n",
    "\n",
    "https://people.mpi-sws.org/~dreyer/courses/catlogic/jacobs.pdf catgeorical logic and type theory bart jacobs\n",
    "\n",
    "practical foundatiosn - taylor\n",
    "\n",
    "https://www.lfcs.inf.ed.ac.uk/reports/92/ECS-LFCS-92-208/  An introduction to fibrations, topos theory, the effective topos and modest sets\n",
    "\n",
    "https://ncatlab.org/nlab/show/categorical+semantics+of+dependent+type+theory\n",
    "Ok. \n",
    "sets pointing into their \"type\" sets considered as subsets of them.\n",
    "Then there are squares that \n",
    "type families Ai  project into their indexing space (?). Yeah, I guess so.\n",
    "\n",
    "\n",
    "Categories with families. Cody says related to explicit substituion calculus like lambda sigma.\n",
    "\n",
    "Substitutions as a category\n",
    "\n",
    "GATs involved somehow.\n",
    "\n",
    "Maybe the first step is to deeply understand lawvere theories. https://en.wikipedia.org/wiki/Lawvere_theory\n",
    "https://ncatlab.org/nlab/show/Lawvere+theory\n",
    " How do you combinatorify equational/algebraic or first order logic?\n",
    "term = morphism from unit?\n",
    "https://www.youtube.com/watch?v=IZcrASzCybs&ab_channel=SchmidCollege%2CChapmanUniversity evan patterson. standard hierachy at 41:10\n",
    "free substitutions vs substituions under a theory? Adding equations to the category of substitutions?\n",
    "\n",
    "Functor to set = model\n",
    "\n",
    "To turn n-arity into single arity we can use a prod construction. Just like we can make multiarg computer programs using tuples\n",
    "fst(prod(x,y)) = x\n",
    "snd(prod(x,y)) = y\n",
    "`assoc(prod(x,prod(y,z))) = prod(prod(x,y),z)` vs `prod(x,prod(y,z)) = prod(prod(x,y),z)`. fst and snd get confused if we make equal on the nose.\n",
    "So is this an an example of how to model higher structures that aren't \"equal on the nose\"?\n",
    "\n",
    "Another style\n",
    "prod2(x,y)\n",
    "prod3(x,y,z)\n",
    "\n",
    "negassoc(prod(prod(x,y),z)) = prod(x,prod(y,z))\n",
    "\n",
    "\n",
    "\n",
    "see fibers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hott\n",
    "\n",
    "https://ncatlab.org/nlab/show/categorical+semantics+of+dependent+type+theory\n",
    "https://www.cs.uoregon.edu/research/summerschool/summer14/rwh_notes/ssdt.pdf\n",
    "\n",
    "What is the name \n",
    "\n",
    "https://www.cs.cmu.edu/~rwh/courses/hott/ bob harper course\n",
    "\n",
    "https://mathstodon.xyz/@MartinEscardo/110890155815254064 escardo threads on hott\n",
    "\n",
    "https://www.youtube.com/@epitspringschoolonhomotopy6943 EPIT Spring School on Homotopy Type Theory 2021\n",
    "https://www.youtube.com/@jdchristensen123  HoTTEST 2022\n",
    "https://www.youtube.com/playlist?list=PL-47DDuiZOMCRDiXDZ1fI0TFLQgQqOdDa 2019 bauer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "TYPE = smt.DeclareSort(\"TYPE\")\n",
    "TERM = smt.DeclareSort(\"TERM\")\n",
    "\n",
    "@dataclass\n",
    "class Judgement():\n",
    "    ctx : list[tuple[smt.ExprRef, smt.ExprRef]]\n",
    "@dataclass\n",
    "class IsType(Judgement):\n",
    "    typ : smt.ExprRef\n",
    "    def __repr__(self):\n",
    "        return f\"{self.ctx} |- {self.typ} TYPE\"\n",
    "@dataclass\n",
    "class HasType(Judgement):\n",
    "    term : smt.ExprRef\n",
    "    typ : smt.ExprRef\n",
    "    def __repr__(self):\n",
    "        return f\"{self.ctx} |- {self.term} : {self.typ}\"\n",
    "@dataclass\n",
    "class EqType(Judgement):\n",
    "    typ1 : smt.ExprRef\n",
    "    typ2 : smt.ExprRef\n",
    "    def __repr__(self):\n",
    "        return f\"{self.ctx} |- {self.typ1} = {self.typ2}\"\n",
    "@dataclass\n",
    "class EqTerm(Judgement):\n",
    "    term1 : smt.ExprRef\n",
    "    term2 : smt.ExprRef\n",
    "    typ : smt.ExprRef\n",
    "    def __repr__(self):\n",
    "        return f\"{self.ctx} |- {self.term1} = {self.term2} : {self.typ}\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Array(T, Bool)"
      ],
      "text/plain": [
       "Array(T, Bool)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "T = smt.DeclareSort(\"T\")\n",
    "TSet = smt.SetSort(T)\n",
    "\n",
    "TSet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ncatlab.org/nlab/show/type+telescope\n",
    "https://www.pls-lab.org/en/telescope\n",
    "https://www.sciencedirect.com/science/article/pii/089054019190066B?ref=pdf_download&fr=RR-2&rr=92eb234868378fa9  Telescopic mappings in typed lambda calculus\n",
    "\n",
    "telescopes as trees?\n",
    "telescopes are ordered variables. grobner elmination tries to find a fopr of the polynomial like that. Gauss elimination.\n",
    "Triangular form. trinagular unfication. We're just playing mind jazz baby\n",
    "J Zucker\n",
    "\n",
    "T3elescope dot product. Terms are in the telescope. Dot product instantiations vairables. hmmm.\n",
    "`[1 , 2] . [x : x = 17, y : y + x = 14] =  1 = 17 /\\ 2 + 1 = 14` \n",
    "`[foo(a), bar(biz)] . [x : baz(x), y : edge(x,y)] = baz(foo(a)) /\\ edge(foo(a), bar(biz))`\n",
    "\n",
    "telescopic mappings are matrices?\n",
    "dot product is maybe like |=? \n",
    "\n",
    "telescopic mappings are instnation of the contex? They are substitutions. BUt then the telescope isn't\n",
    "Some kind of trinagular matrix? a stack of rows or a stack of columns?\n",
    "nested telescopes.\n",
    "x -> [y : B(y)]\n",
    "No whole hog. The substiution rule applied one by one? Subst + weaken.\n",
    "Add in new variable we're going to subst to. Then eliminate using subst old variable in terms of new.\n",
    "[x : A(x)] |- f(x) : Z(x) \n",
    "[y : B(y), x : A(x)] |- f(x) : Z(x) weaken\n",
    "[y : B(y)] |- f(g(y)) |- Z(g(y)) subst\n",
    "\n",
    "Gam, x : A, Del\n",
    "and\n",
    "Gam |- t : A \n",
    "\n",
    "Gam, Del[t/A]\n",
    "\n",
    "\n",
    "I guess telescope is a generalization of my `vs` list, which was a context, sure.\n",
    "If telescopes are a context, what is a ntext? :)\n",
    "\n",
    "\n",
    "\n",
    "def unify(telescope, t1 , t2, typ)\n",
    "def pmatch(telescope, p, t1, typ)\n",
    "\n",
    "\n",
    "You could have GAT rewriting logic. \n",
    "Gam |- t1 -> t2 : A.  asymmettric\n",
    "Gam |- A -> A1\n",
    "\n",
    "Gam |- T type is a fibration.\n",
    "\n",
    "predicates with variables in them are sets at the metalevel. Before we use comprehension / lambda to internalize them.\n",
    "\n",
    "If you have an equational theory of types, you could find an ordering the context that puts the thing you want to substitute last or first?\n",
    "\n",
    "definitional type equality is in a context. Not clear if I have to use kleene equality or no. Well, I need to quantify over the variables in scope...\n",
    "If I don't have function symbols, this is probably all in EPR?\n",
    "\n",
    "To say we have a iterative fibering of a surface is kind of like saying we have a fully projection sequence form.\n",
    "It's weird to say that we have this from the get go.\n",
    "block triangular form is almost as good.\n",
    "mappings between\n",
    "[x : R,  y : R | y = x**2 + 2]\n",
    "Does a telescope have anything to do with triangular form solutions / projection / gauss elimination / elimination / quantifer elim.   I could descibe a sphere as something like [x : R, y : R | x**2 + y**2 <= 1, z : R | z = 1 - x**2 - y**2] \n",
    "Or some robot configuration it's nice to have the kinematics straightened out. Or maybe something something cylindrical algerbaic decomposition\n",
    "I could decribe a triangular linear equation as  [x : R | x = 42, y : R | y = 3* x + 14, ...]\n",
    "Or fourier motzkin form as   [x : R | 1 < x < 7, y : R | x + y < 4 /\\ x + y < 17, ....]\n",
    "\n",
    "[ p : R^3|   p.x**2 + p.y**2 + p.z**2 = 1 ] converting this telescope into that above one is hard in general\n",
    "\n",
    "SympyTelescope. SolveSet.\n",
    "\n",
    "TERM and TYPE\n",
    "\n",
    "But what if they were the same? is TYPE = Set(TERM), this requires some kind of class -> set comprehension like thing. An internalization.\n",
    "TYPE1 = smt.SetSort(TYPE)\n",
    " and so on\n",
    "\n",
    "\n",
    "```\n",
    "# n are universe levels. Obviously they are not in the system. They are python integers\n",
    "def TYPE(n):\n",
    "    if n == 0:\n",
    "        return TERM \n",
    "    return smt.SetSort(TYPE(n-1))\n",
    "```\n",
    "\n",
    "is univalence statable?\n",
    "```\n",
    "def univalence(n):\n",
    "    return Iso(A == B, Iso(A,B)) # no. == is definitional equality. We want propositional equality (?) right?\n",
    "    retrun Iso(PropEq(A,B), Iso(A,B))\n",
    "\n",
    "def Iso(A,B):\n",
    "    #which for ismorphic stuff means same cardinality? But maybe less clear given we're recursing into an equality.\n",
    "    f,g = smt.Array(\"f g\", TYPE(n), TYPE(n))\n",
    "    smt.Exists([f,g], A[x] => B[f(x)], B[y] => A[g(y)], f(g(x)) == x, g(f(y)) == y)\n",
    "```\n",
    "\n",
    "finite models by encding up to universe level n. If it trivialize at some N, we're good to go? It stays trivial?\n",
    "\n",
    "I'm building a model of dependent type theory. I don't know if that proves it in the original system, that unsat means that there must be a judgement in dependent type theory. Can i extract such a judgement tree from an unsat core?\n",
    "\n",
    "\n",
    "\n",
    "lifting property\n",
    "unit ->  spiral\n",
    "|         |\n",
    "\\/        \\/\n",
    "interval -> circl\n",
    "\n",
    "we pick an \"inital condition\" for which layer we want to be on, that's what the upper and left edges do, then the r5est of the path is derivable.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Resolution_of_singularities\n",
    "\n",
    "\n",
    "co de bruijn telescopes.\n",
    "\n",
    "VMap = \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy\n",
    "\n",
    "class Telescope():\n",
    "    vs : list[sympy.Symbol]  # maybe if we want it in block solved form, list[tuple[sympy.Symbol, ...]]\n",
    "    typs : SolveSet\n",
    "\n",
    "class Shape(): #Fibration\n",
    "    ctx : Telescope   # base\n",
    "    typ : SolveSet # a constrjiat on the rewals\n",
    "\n",
    "class Point():\n",
    "    ctx : Telescope\n",
    "    t : sympy.Expr\n",
    "    typ : SolveSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gatexpr is like Gam |- t : A judgement. see cat_topos_free.ipynb\n",
    "TERM = smt.DeclareSort(\"TERM\")\n",
    "TYPE = smt.SetSort(TERM)\n",
    "\n",
    "@dataclass\n",
    "class TeleScope():\n",
    "    vs : list[smt.ExprRef]\n",
    "    typs : list[smt.BoolRef] # vs smt.ExprRef. Pre applied to vs or not?\n",
    "    def interp(self):\n",
    "        return smt.And(self.typs)\n",
    "        #return smt.And(typ(*self.vs[:i]) for i,typ in enumerate(self.typs))\n",
    "    def extend(self, typ): # C-ext\n",
    "        v = smt.FreshConst(TERM)\n",
    "        return v, Telescope(vs + [v], typs + [typ(v)]) # typ is a z3 or python lambda that can also contain previous variables.\n",
    "    # I guess I'm considering all type expressions to be valid.\n",
    "    # Gamma |- T type is not a judgement that is needed.\n",
    "    # if wqe capture \"variables\" not in scope somehow, they are considered to be constants.\n",
    "    # We have an open notion of constant\n",
    "    #def strengthen(self, n): ... # check nothing using variable n and then remove it. Is this weakening, or is this strengthening.\n",
    "    def weaken(self, posn, typ):\n",
    "        v = smt.FreshConst(TERM)\n",
    "        # maybe check typ does not contain any vs[posn:]. THis is just fancy extend\n",
    "        return v, Telescope(vs[:posn] + [v] + vs[posn+1:], typs[:posn] + [typ(v)] + typs[posn+1:])\n",
    "    def subst(self, v_or_posn, t : GatExpr):\n",
    "        assert t.ctx == self[:posn] # or alpha eq? and normalize?\n",
    "        assert t.typ == self.typs[posn]\n",
    "        tailtyps = [smt.substitute(typ  (v, t.t)) for typ in self.typs[posn+1]]\n",
    "        return Telescope(self.vs[:posn] self.vs[posn+1:], self.typs[:posn] + tailtyps)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GATExpr():\n",
    "    ctx : Telescope\n",
    "    t : smt.ExprRef # t.sort() == TERM\n",
    "    typ : smt.ExprRef # this is a typ.sort() == TYPE\n",
    "\n",
    "    def judge(self):\n",
    "        smt.ForAll(self.ctx.vs, self.ctx.interp(), self.typ[self.t])\n",
    "    def __eq__(self, other):\n",
    "        # either require to be in same context or reconcile them. (common prefix?)\n",
    "\n",
    "\n",
    "\n",
    "Ob = smt.Const(\"Ob\", TYPE)\n",
    "Hom = smt.Function(\"Hom\", Ob, Ob, TYPE)\n",
    "a,b,c = smt.Consts(\"a b c\", TERM)\n",
    "kd.axiom(Ob[a])\n",
    "kd.axiom(Ob[b])\n",
    "kd.axiom(Ob[c])\n",
    "f,g,h = smt.Consts(\"f g h\", TERM)\n",
    "id_ = smt.Function(\"id\", TERM, TERM)\n",
    "comp = smt.Function(\"comp\", TERM, TERM, TERM)\n",
    "kd.notation.matmul.register(TERM, comp)\n",
    "\n",
    "kd.axiom(kd.QForAll([a], Ob[a], Hom(a,a)[id_(a)])) # a : Ob |- id(a) : Hom(a,a)\n",
    "kd.axiom(kd.QForAll([a,b,c], Ob[a], Ob[b], Ob[c], Hom(a,b)[f], Hom(b,c)[g], Hom(a,c)[f @ g])) # a : ob, b : Ob, c : Ob, f : Hom(a,b), g : Hom(b,c) |- f . g : Hom(a,c) \n",
    "\n",
    "# hmm. Hom(a,b)[f] is there difference of those like the difference between indexes and parameters? Nooooo. Porb not.\n",
    "\n",
    "\n",
    "# equality rules\n",
    "kd.axiom(kd.QForAll([a,b], Ob[a], Ob[b], Hom(a,b)[f], f @ id_(a)) == f) # a : Ob, b : Ob, f : Hom(a,b) |- f. id(a) = f\n",
    "# other id\n",
    "# assoc comp\n",
    "\n",
    "# Ob[a] is a simple predicate. And i can do it ahead of time in z3 sort system. If I know these things don't intersect? \n",
    "# Injectivity of Type constructors?\n",
    "# This is an optimization though.\n",
    "\n",
    "\n",
    "# a : Ob, b : Ob, f : Hom(a,b) |- dom(f) = a\n",
    "# a : Ob, b : Ob, f : Hom(a,b) |- cod(f) = b\n",
    "\n",
    "# internalizing type. deep embedding GAT/ Martin Lof into GAT\n",
    "type0 = smt.Function(\"type0\", TYPE)\n",
    "type1 = smt.Function(\"type1\", TERM)\n",
    "eq = smt.Function(\"eq\", TERM, TERM, TERM) # \n",
    "eq1 = smt.Function(\"eq\", TERM, TERM, TYPE)\n",
    "eq2 = smt.Function(\"eq\", TYPE, TYPE, TERM) # eq1 is a judgement, eq2 is a term.\n",
    "eq3 = smt.Function(\"eq\", TYPE, TYPE, TYPE) # eq1 is a judgement, eq2 is a term.\n",
    "eq4 = smt.Function(\"eq\", TYPE, TERM, TYPE) # THe two inputs hsould at least match yeah?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, here's the idea with maps between contexts and substitutions. Say I've got a context x:A,y:B(x), and another x:C,y:D(x). Then a map from the first to the second should be a pair of terms x:A, y:B(x) |- c(x,y), d(x,y) - so the components can depend on every variable in the first context - but the types of these terms should be C and D(c(x,y)). So strictly speaking what you want are terms x:A, y:B(x) |- c(x,y) : C and x:A, y:B(x) |- d(x,y) : D(c(x,y)). Mutatis mutandis for more than two types, these give you a mapping between the contexts if you just think of each context as a dependent tuple type.\n",
    "They also give you a substitution mapping going in the other direction. Like if you have terms c, d as above, and some type T(x,y) in context x:C,y:D(x), then you can turn T into a type in context x:A, y:B(x) by substitution: x:A,y:B(x)|-T(c(x,y), d(x,y)).\n",
    "So this is an example of the general picture where a morphism in a base category between two objects X,Y induces a functor between the fiber categories above X,Y in the total category, going in the opposite direction. The contexts are objects of the base category, and the types in a given context are the objects in the fiber over that context.\n",
    "\n",
    "\n",
    "Put ticks on x’:C, y’:D(x’)\n",
    "\n",
    "\n",
    "Fair (edited) \n",
    "\n",
    "Is it c(x’,y’) ?\n",
    "4:32\n",
    "Or c(x,y)?\n",
    "\n",
    "\n",
    "The second. The arguments to c(x,y) have types A and B(x)\n",
    "\n",
    "\n",
    "See that’s the part that is non intuitive to me\n",
    "\n",
    "I’d have thought it should be c(x’,y’)\n",
    "\n",
    "Because I want to change out the x variables for x’ variablez\n",
    "\n",
    "Then I think you want a map from the context x':C,y'D(x') to x:A,y:B(x).\n",
    "\n",
    "Analogy: if I have a function from nats to reals, it turns predicates depending on reals into predicates depending on nats. If I have a map from context C to context C', it turns things that depend on C' (like types in that context) into things that depend on C.\n",
    "\n",
    "\n",
    "So i should actually be thinking of context mappings as functions, not substitutions\n",
    "\n",
    "Yeah. They're mappings, and mappings induce substitutions.\n",
    "\n",
    "And contexts actually have a semantics and arent just syntax\n",
    "\n",
    "Yeah. They're the base category. Concretely, you can even think about them as sets (of indices) if you're thinking about types in context as indexed families of sets.\n",
    "\n",
    "x : A, y : B(x) |- x’ := c(x,y) : C, y’ := d(x,y) : D(x’)\n",
    "\n",
    "I see, so in the semantics “free” single sorted herbrand model case, the “function” form is applying those terms to the input. This is not a very interesting thing to discuss, so it doesn’t show up in automated reasoning texts\n",
    "5:17\n",
    "And its tuples of terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{a: Lambda([x, y], x + y), b: Lambda([x, y], x - y), c: Lambda([x, y], x*y)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "from dataclasses import dataclass\n",
    "V = smt.ExprRef\n",
    "@dataclass\n",
    "class Mapping():\n",
    "    vs : list[V] # ctx. Gamma\n",
    "    ts : dict[V, smt.ExprRef] # labelled output\n",
    "    # x,y,z |- x' := f(x,y), y' := g(x,y), z' := h(x,y)\n",
    "    def __post_init__(self):\n",
    "        assert all(v.sort() == t.sort() for v,t in self.ts.items())\n",
    "    def apply(self, ts : dict[V, smt.ExprRef]):\n",
    "        assert all(v in self.vs for v in ts.keys())\n",
    "        return {v: smt.substitute(t, *[(v,ts[v]) for v in self.vs]) for v,t in self.ts.items()}\n",
    "    def __matmul__(self, other):\n",
    "        assert isinstance(other, Mapping)\n",
    "        return Mapping(other.vs, self.apply(other.ts))\n",
    "    def meaning(self):\n",
    "        return {l : smt.Lambda(self.vs, t) for l,t in self.ts.items()}\n",
    "\n",
    "x,y,z,a,b,c,p,q = smt.Ints(\"x y z a b c p q\")\n",
    "\n",
    "m1 = Mapping([x,y], {a : x + y, b : x - y, c : x * y})\n",
    "m2 = Mapping([a,b,c], {p : a + b, q : a})    \n",
    "\n",
    "x0 = {x : smt.IntVal(1), y : smt.IntVal(2)}\n",
    "m1.apply(x0)\n",
    "\n",
    "class Predicate(Mapping):\n",
    "    # ts should be a single\n",
    "    def __post_init__(self):\n",
    "        assert len(self.ts) == 1\n",
    "        assert all(v.sort() == smt.BoolSort() for v,t in self.ts.items())\n",
    "        super().__post_init__()\n",
    "\n",
    "m2 @ m1\n",
    "assert (m2 @ m1).apply(x0) == m2.apply(m1.apply(x0))\n",
    "\n",
    "m1.meaning()\n",
    "\n",
    "\n",
    "def unify(m1 : Mapping, m2 : Mapping):\n",
    "    assert m1.ts.keys() == m2.ts.keys()\n",
    "    todo = [(t, m2[l]) l,t in for m1.ts.items()]\n",
    "    subst = kd.utils.unify(todo)\n",
    "    vs = m1.vs + m2.vs - subst.keys()\n",
    "    return Mapping(vs, {v : subst[v] if v in subst else v for v in m1.vs} ), Mapping(vs, {v : subst[v] if v in subst else v  for v in m2.vs} )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PMapping():\n",
    "    vs : list[V] # ctx. Gamma\n",
    "    pre : list[smt.BoolRef] # pres over vs. could intertwine with vs\n",
    "    ts : dict[V, tuple[smt.ExprRef, smt.BoolRef]] # labelled output.\n",
    "    #post : list[smt.BoolRef] # post over with vs as vars. same length as ts.\n",
    "    # x,y,z |- x' := f(x,y), y' := g(x,y), z' := h(x,y)\n",
    "    def __post_init__(self):\n",
    "        assert all(v.sort() == t.sort() for v,t in self.ts.items())\n",
    "    def apply(self, ts : dict[V, smt.ExprRef]):\n",
    "        assert all(v in self.vs for v in ts.keys())\n",
    "        return {v: smt.substitute(t, *[(v,ts[v]) for v in self.vs]) for v,t in self.ts.items()}\n",
    "    def __matmul__(self, other):\n",
    "        assert isinstance(other, Mapping)\n",
    "        return Mapping(other.vs, self.apply(other.ts))\n",
    "    def meaning(self):\n",
    "        defined = smt.And(self.preds)\n",
    "        #return {l : smt.Lambda(self.vs, smt.If(defined, t, smt.FreshConst(t.sort()))) for l,t in self.ts.items()}\n",
    "        # relational semantics. Partial functions.\n",
    "        return {l : smt.Lambda(self.vs + [l], smt.Implies(defined, smt.And(l == t, post))) for l,(t,post) in self.ts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PMapping():\n",
    "    vs : list[tuple[V, smt.BoolRef]] # ctx. Gamma\n",
    "    ts : dict[V, tuple[smt.ExprRef, smt.BoolRef]] # labelled output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labelled term tuples. They themselves are kind of substitutions. Hmm. But like ground ones.\n",
    "\n",
    "Obviously, could use de bruijn indices and ordered tuples of terms instead.\n",
    "\n",
    "\n",
    "a telescope mapping is conceptually a function from gamma vars with preconditions given be types into post labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finset models of families\n",
    "\n",
    "https://www.philipzucker.com/frozenset_dtt/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from frozendict import frozendict\n",
    "import itertools\n",
    "type Family = Callable[[object], Type]\n",
    "type Type = frozenset\n",
    "\n",
    "Void = frozenset({})\n",
    "Unit = frozenset({()})\n",
    "Bool = frozenset({True, False})\n",
    "def Fin(n : int) -> Type:\n",
    "    return frozenset(range(n))\n",
    "def Vec(A : Type, n : int) -> Type:\n",
    "    return frozenset(itertools.product(A, repeat=n))\n",
    "\n",
    "def is_type(A: Type) -> bool: # |- A type\n",
    "    return isinstance(A, frozenset)\n",
    "def has_type(t: object, A: Type) -> bool: # |- t : A\n",
    "    return t in A\n",
    "def eq_type(A: Type, B: Type) -> bool: # |- A = B type\n",
    "    return A == B\n",
    "def def_eq(x : object, y: object, A : Type) -> bool: # |- x = y : A\n",
    "    return x == y and has_type(x, A) and has_type(y, A)\n",
    "\n",
    "def Sigma(A: Type, B: Family) -> Type:\n",
    "    return frozenset({(a, b) for a in A for b in B(a)})\n",
    "def Pair(A : Type, B: Type) -> Type:\n",
    "    return Sigma(A, lambda x: B)\n",
    "\n",
    "def Pi(A : Type, B : Family) -> Type:\n",
    "    Alist = list(A)\n",
    "    return frozenset(frozendict({k:v for k,v in zip(Alist, bvs)}) for bvs in itertools.product(*[B(a) for a in Alist]))\n",
    "def Arr(A : Type, B: Type) -> Type:\n",
    "    return Pi(A, lambda x: B)\n",
    "\n",
    "def Sum(A : Type, B: Type) -> Type:\n",
    "    return frozenset({(\"inl\", a) for a in A} | {(\"inr\", b) for b in B})\n",
    "\n",
    "def Id(A : Type, x : object, y : object) -> Type:\n",
    "    return frozenset({\"refl\"}) if x == y else frozenset()\n",
    "def U(n : int, l : int) -> Type:\n",
    "    if l > 0:\n",
    "        u = U(n, l-1)\n",
    "        return u | frozenset([u]) # Cumulative\n",
    "    elif n > 0:\n",
    "        u = U(n-1, 0)\n",
    "        # TODO also the Pi and Sigma\n",
    "        return u | frozenset([Arr(A,B) for A in u for B in u]) | frozenset([Pair(A,B) for A in u for B in u]) | frozenset([Fin(n)])\n",
    "    else:\n",
    "        return frozenset([Unit, Bool, Void])\n",
    "def Quot(A : Type, R) -> Type:\n",
    "    return frozenset(frozenset({y for y in A if R(x,y)}) for x in A)\n",
    "def SubSet(A :  Type, P : Family) -> Type: # very much like Sigma\n",
    "    return frozenset({(x, ()) for x in A if P(x)}) # Note because of pythion truthiness, this also accepts ordinary bool value predicates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More examples. \n",
    "Pair ~ Dependent product over bool\n",
    "Bounded Fixpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({('SuccF', ('SuccF', ('SuccF', ('ZeroF',)))),\n",
       "           ('SuccF', ('SuccF', ('ZeroF',))),\n",
       "           ('SuccF', ('ZeroF',)),\n",
       "           ('ZeroF',)})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bounded fixpoint types\n",
    "type TypeFamily = Callable[[Type], Type]\n",
    "def Mu(n : int, f : TypeFamily) -> Type:\n",
    "    if n <= 0:\n",
    "        return Void\n",
    "    else:   # Fix and roll?\n",
    "        return f(Mu(n-1, f))\n",
    "\n",
    "def NatF(A : Type) -> Type:\n",
    "    return frozenset({(\"ZeroF\",)}) | {(\"SuccF\", x) for x in A}\n",
    "\n",
    "Mu(4, NatF)\n",
    "\n",
    "# distinction between least and greatest? Not clear.\n",
    "#def Nu(n, f):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SumSigma(A,B):\n",
    "    # a construction of sum types out of sigma + bool\n",
    "    return Sigma(Bool, lambda x: A if x else B)\n",
    "\n",
    "def PiPair(A,B): # construction of pairs out of pi + bool\n",
    "    return Pi(Bool, lambda x: A if x else B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Modk(N, k):\n",
    "    # Modk is x such that exists y such that x = k*y\n",
    "    return Sigma(Fin(N), lambda x: Sigma(Fin(N), lambda y: Id(Fin(N), x, k*y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LE(m, k):\n",
    "    return frozenset({\"le\"}) if m <= k else frozenset()\n",
    "\n",
    "\n",
    "def Fin2(N, max):\n",
    "    return Sigma(Fin(N), )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partial evaluation model\n",
    "\n",
    "Representation \n",
    "structural vs semanti equality. \n",
    "Bigin limbs\n",
    "unnormalized fractions\n",
    "modular arith\n",
    "snoc cons\n",
    "AVL tree with different insertion order\n",
    "big endian little endian\n",
    "free monoid delays\n",
    "For Fin(n), iso forms of Pred(Pred(N)) and Succ(Succ(Zero)). Kind of interesting.\n",
    "\n",
    "\n",
    "if you hash cons, structural equality is `is` equality\n",
    "canonization / terms modulo theories. canonization is 'further computation\"\n",
    "\n",
    "canon(x) == canon(y)\n",
    "find(x) == find(y)\n",
    "\n",
    "code strings and partial evaluation\n",
    "eval(x) == eval(y)\n",
    "\n",
    "NP equality vs P equality. NP certificates in \n",
    "x: B, y : B, x /\\ y <-> True  |-  Id B x y\n",
    "\n",
    "relationalnal mdel\n",
    "[(unnormed1, canon1), (unnormed1, canon1)]\n",
    "type Type = {unnormed : canon} ?\n",
    "[(t1,t2,t3,t4)] a tower of euiqvalences. a uniform nuber of steps across elements or no?\n",
    "\n",
    "t1 from egraph1, t2 from egraph2 which is a refinement and so on.\n",
    "Sets of refining equalities. Egrahs inm time. Or like  OrietendSergment -> Segment -> Line refinement. \n",
    "\n",
    "FreeGroup -> Group -> Abelian Group\n",
    "\n",
    "mod out by an axiom at a time.  A -- aa=b ->  B -- cc == q -> C --> ...\n",
    "list -AC> multiset -I> set\n",
    "tree ->  unordertree ->\n",
    "portedgraph -> multigraph -> \n",
    "tree -> dag \n",
    "\n",
    "Proof -> normalization\n",
    "program -> partial eval\n",
    "automata -> observational equivalence\n",
    "autotmatra --forget> Auto1 ---forget2-> Auto2\n",
    "\n",
    "\n",
    "seflloop                    selflooprefl\n",
    "| |                        | |\n",
    "True  ------quote ------ False \n",
    "\n",
    "Quotent a Bool like thing?\n",
    "Quotient a three object thing into a 2 object thing?\n",
    "[(\"red\", True), (\"green\", True), (\"blue\", False)]\n",
    "[(0,0), (1,0), (2,2)]  \n",
    "\n",
    "\n",
    "Like in \"the trick\" I think. that pattern matching should move information from refined world to upper world?\n",
    "\"Quoting\" moves to lower world?\n",
    "\n",
    "a relational model of static and dynamic time. Akin to relational model of parametrciity. But here we have a notion of refinement so the relation has to be many to one.\n",
    "\n",
    "\n",
    "More of a bottom persepctive. if unevaluated stuff is modelled as bottom, the refinment goers the other way.\n",
    "\n",
    "\n",
    "def Implies(A,B): # add a world?\n",
    "    B1 = [(None, *B) for b in B]\n",
    "    Alist = \n",
    "    [ for itertools.product(B, repeat=len(Alist))]\n",
    "    # but like only consistent stuff.\n",
    "\n",
    "This is more like a domain theory model. Interesting.\n",
    "\n",
    "FIntie domain theory\n",
    "\n",
    "https://en.wikipedia.org/wiki/Domain_theory  Is allowing sequences (arbitrarily large?) mean things aren't finite anymore? Not if we kind of compress.\n",
    "(None, None, True) ===> (None, True)\n",
    "\n",
    "We can generically deduplicate sueqences\n",
    "def dup_cons(x, xs):\n",
    "    if x == xs[0]:\n",
    "        return xs\n",
    "    else:\n",
    "        return (x, *xs)\n",
    "\n",
    "Bool = {(True,), (None, True), (None, False), (False,), (None,), ()}\n",
    "Tail closed sets.\n",
    "Bool = Bool | {x[1:] for x in Bool}\n",
    "\n",
    "def Pair(A,B):\n",
    "    {(None, map(lambda a,b: (a,b), a, b)) |   for a in A for b in B} # outer product.. No but one can stay frozen while the other moves.\n",
    "\n",
    "\n",
    "What's an empty chain?\n",
    "What is Void?\n",
    "\n",
    "I guess all chains in the lattice? all upward closures?\n",
    "No maybe dcpo is more appropriate. But all chains are intentionally finite, so the complete part isn't relevant\n",
    "\n",
    "https://en.wikipedia.org/wiki/Complete_partial_order \n",
    "\n",
    "match statement prunes None away. Hmm.\n",
    "\n",
    "def join(a,b):\n",
    "    \n",
    "So really just a set + partial order relation. Partial order can be explicit set of function, doesn't matter much because we enumerate.\n",
    "type Type = tuple[frozenset, frozenset]\n",
    "\n",
    "Pair is cartesian product I guess + bottom? Partial order combines only if both compoenets do?\n",
    "https://en.wikipedia.org/wiki/Dedekind%E2%80%93MacNeille_completion\n",
    "\n",
    "\n",
    "\n",
    "Implies(A,B): # should prune for only monotonic functions.\n",
    "\n",
    "On continuas functions means monotonic. That is kind opf like simplical sets\n",
    "https://people.cs.nott.ac.uk/pszgmh/domains.html Hutton domain theory\n",
    "It's not that I need bottoms to denote nontermintating programs. Just stuff that isn't done to values yet\n",
    "\n",
    "With \"named nones / nulls\" we could know equality before the thing have evaluated. There is object identity. This is very egraphy chasy.\n",
    "But a finite number of names? Hmm. Names come from context? de bruijn indices? de buijn index sets. Which variables need to be filled in before it can eval further. {0,1} --> {1} --> True\n",
    "lazy AND may of may not need more data  {0,1} -> False, {1} -> True, {1} -> False, {0,1} -> {1}\n",
    "\n",
    "class NNone(NamedTuple):\n",
    "    id : int\n",
    "\n",
    "Traces are kind of different because maybe traces could take jumps or ...\n",
    "\n",
    "hash(x) == hash(y) equality. fast and slow equality.\n",
    "\n",
    "Irreleanve Prop.\n",
    "{\"True\", \"False\"}, lambda x,y: True\n",
    "\n",
    "Isomorphic types (same len) as equal?\n",
    "\n",
    "\n",
    "\n",
    "Setoid is Type = frozenset, eqrel\n",
    "\n",
    "https://inria.hal.science/hal-02281225/document\n",
    "setoid nmodel, gropoid model justifies negation of uip, cubical set model justifies univalence.\n",
    "\"In general, the usage of an axiom is justified by a model [18] in which the\n",
    "axiom holds. For example, the cubical set model [8] justifies the univalence axiom, the reflexive graph model [6] justifies parametricity, the groupoid model\n",
    "[19] justifies the negation of UIP, the setoid model [17,1] justifies function extensionality. \"\n",
    "\n",
    "\n",
    "Hmm. So a the cyubical set model\n",
    "\n",
    "Interpreting into a normalizedc union find \n",
    "canon[x] = y\n",
    "type Type = frozendict[object, object]\n",
    "\n",
    "Interpreting into a refinement/colored uf.\n",
    "Interpeting into group uf. Groupoid uf. multi edge groupoid uf?\n",
    "Interpeting into a theory uf. Gauss, grobner\n",
    "\n",
    "\n",
    "\n",
    "types as multiset of values. I'm kind of trying to use something like provenance to track distinction between definitional and propositional.\n",
    "Multiset gives more provenance. Or semiring provenance. Carrying history.\n",
    "sorted([])\n",
    "\n",
    "type Type = trace,value \n",
    "\n",
    "type = (A0, =A0) setoid model\n",
    "type = (A0, A1, =A1) groupoid model\n",
    "type = (A0, A1, A2, .., =AN)  higher truncation models?\n",
    "https://www.cse.chalmers.se/~peterd/slides/hits-AIMXXV.pdf \"constructivity is maintained because setoid model can be formulated in constructive metatheory (extensional type theory) itself justified by Martin-L¨of’s (1979) standard meaning explanations.\"\n",
    "\n",
    "Hmm. https://ncatlab.org/nlab/files/HofmannExtensionalIntensionalTypeTheory.pdf Yes the sertoid model is for modelling exetensional inside intentional type theory.\n",
    "\n",
    "\n",
    "The z3 syntax model. `.eq` equality vs  `prove(x == y)` equality. Knuckledragger proofs are the things in Id.\n",
    "Types are python predciates that synatctically recorgnize aspects of z3 expressions without using `check`?\n",
    "\n",
    "\n",
    "Maybe I do need to refomrulate into the categorical style to understand models.\n",
    "It's possible python's notion of comprehension is not rich enough to handle other kinds of models.\n",
    "\n",
    "\n",
    "\n",
    "depedent types, a vcalue in the image of an expression?\n",
    "Sets with extra structure. \n",
    "types as C-sets? Arr is homomorphism?\n",
    "\n",
    "\" These could be terms in a lambda calculus, or elements of a partial combinatory algebra, or even programs in a real-world programming language such as C, Java, or Python\"  https://ncatlab.org/nlab/show/meaning+explanation\n",
    "\n",
    "\n",
    "\n",
    "https://unimath.github.io/SymmetryBook/book.pdf\n",
    "I was hoping that a book\n",
    "Computational Groupoid theory. Dependent types wouldn't be the crazy substrate for that. Could I use a ocmputational group theory library?\n",
    "\n",
    "\n",
    "https://www.stephendiehl.com/posts/calculus_of_constructions_python/ syntactical. But he uses a hoas which is interesting. Hoas for de bruijn indices, level for open terms?\n",
    "https://tiarkrompf.github.io/notes/?/dependent-types/\n",
    "\n",
    "\n",
    "def ann(t, A):\n",
    "    assert t in A\n",
    "    return t\n",
    "\n",
    "In runtime form, ann(t, A) ought to return a t that checks it is in A possibly on inputs (?)\n",
    "A -> bool vs\n",
    "pair of predciates for polarities\n",
    "[] -> bool, [] -> bool\n",
    "relation to bidi checking?\n",
    "\n",
    "\n",
    "\n",
    "I ought to be able to form the categorical model interface over even the simple Set Model\n",
    "\n",
    "Dependent typing judgements as database queries. Hmm.\n",
    "FROM ... |-  Select \n",
    "dependent Type ~ tables\n",
    "nondependent type ~ single column table\n",
    "\n",
    "Egrasphs are models, so \"dependent typed\" egraphs should also be models.\n",
    "\n",
    "DQL - dependent query language\n",
    "Gam |- \n",
    "\n",
    "trie homomorphisms are telescope mappings?\n",
    "\n",
    "ca\n",
    "\n",
    "\n",
    "https://martinescardo.github.io/HoTT-UF-in-Agda-Lecture-Notes/index.html\n",
    "\n",
    "\n",
    "Fin(0) ~ Void\n",
    "Fin(1) ~ Unit\n",
    "Fin(2) ~ Bool\n",
    "\n",
    "canonically iso, but\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ann(m=Lam(f=<function curry5.<locals>.<lambda> at 0x711e19d50860>), a=Pi(a=Pi(a=Star(), f=<function <lambda> at 0x711e19d50540>), f=<function <lambda> at 0x711e19d507c0>))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Callable, List, Tuple\n",
    "# https://www.stephendiehl.com/posts/calculus_of_constructions_python/\n",
    "@dataclass\n",
    "class Term: ...\n",
    "@dataclass\n",
    "class Lam(Term): f: Callable[[Term], Term]\n",
    "@dataclass\n",
    "class Pi(Term): a: Term; f: Callable[[Term], Term]\n",
    "@dataclass\n",
    "class Appl(Term): m: Term; n: Term\n",
    "@dataclass\n",
    "class Ann(Term): m: Term; a: Term\n",
    "@dataclass\n",
    "class FreeVar(Term): x: int\n",
    "@dataclass\n",
    "class Star(Term): ...\n",
    "@dataclass\n",
    "class Box(Term): ...\n",
    "\n",
    "def eval(term: Term) -> Term:\n",
    "    match term:\n",
    "        case Lam(f):\n",
    "            return Lam(lambda n: eval(f(n)))\n",
    "        case Pi(a, f):\n",
    "            return Pi(eval(a), lambda n: eval(f(n)))\n",
    "        case Appl(m, n):\n",
    "            m_eval = eval(m)\n",
    "            n_eval = eval(n)\n",
    "            match m_eval:\n",
    "                case Lam(f):\n",
    "                    return f(n_eval)\n",
    "                case _:\n",
    "                    return Appl(m_eval, n_eval)\n",
    "        case Ann(m, _):\n",
    "            return eval(m)\n",
    "        case FreeVar() | Star() | Box():\n",
    "            return term\n",
    "def infer_ty(lvl: int, ctx: List[Term], term: Term) -> Term:\n",
    "    match term:\n",
    "        case Pi(a, f):\n",
    "            _s1 = infer_sort(lvl, ctx, a)\n",
    "            s2 = infer_sort(lvl + 1, [eval(a)] + ctx, unfurl(lvl, f))\n",
    "            return s2\n",
    "        case Appl(m, n):\n",
    "            m_ty = infer_ty(lvl, ctx, m)\n",
    "            match m_ty:\n",
    "                case Pi(a, f):\n",
    "                    _ = check_ty(lvl, ctx, (n, a))\n",
    "                    return f(n)\n",
    "                case _:\n",
    "                    return panic(lvl, m, f\"Want a Pi type, got {print_term(lvl, m_ty)}\")\n",
    "        case Ann(m, a):\n",
    "            _s = infer_sort(lvl, ctx, a)\n",
    "            return check_ty(lvl, ctx, (m, eval(a)))\n",
    "        case FreeVar(x):\n",
    "            return ctx[lvl - x - 1]\n",
    "        case Star():\n",
    "            return Box()\n",
    "        case Box():\n",
    "            return panic(lvl, Box(), \"Has no type\")\n",
    "def infer_sort(lvl: int, ctx: List[Term], a: Term) -> Term:\n",
    "    ty = infer_ty(lvl, ctx, a)\n",
    "    match ty:\n",
    "        case Star() | Box():\n",
    "            return ty\n",
    "        case _:\n",
    "            return panic(lvl, a, f\"Want a sort, got {print_term(lvl, ty)}\")\n",
    "def check_ty(lvl: int, ctx: List[Term], pair: Tuple[Term, Term]) -> Term:\n",
    "    t, ty = pair\n",
    "    match (t, ty):\n",
    "        case (Lam(f), Pi(a, g)):\n",
    "            _ = check_ty(lvl + 1, [a] + ctx, unfurl2(lvl, (f, g)))\n",
    "            return Pi(a, g)\n",
    "        case (Lam(f), _):\n",
    "            return panic(lvl, Lam(f), f\"Want a Pi type, got {print_term(lvl, ty)}\")\n",
    "        case _:\n",
    "            got_ty = infer_ty(lvl, ctx, t)\n",
    "            if equate(lvl, (ty, got_ty)):\n",
    "                return ty\n",
    "            return panic(lvl, t, f\"Want type {print_term(lvl, ty)}, got {print_term(lvl, got_ty)}\")\n",
    "def equate(lvl: int, terms: Tuple[Term, Term]) -> bool:\n",
    "    def plunge(pair: Tuple[Callable[[Term], Term], Callable[[Term], Term]]) -> bool:\n",
    "        return equate(lvl + 1, unfurl2(lvl, pair))\n",
    "\n",
    "    match terms:\n",
    "        case (Lam(f), Lam(g)):\n",
    "            return plunge((f, g))\n",
    "        case (Pi(a, f), Pi(b, g)):\n",
    "            return equate(lvl, (a, b)) and plunge((f, g))\n",
    "        case (Appl(m, n), Appl(m2, n2)):\n",
    "            return equate(lvl, (m, m2)) and equate(lvl, (n, n2))\n",
    "        case (Ann(m, a), Ann(m2, b)):\n",
    "            return equate(lvl, (m, m2)) and equate(lvl, (a, b))\n",
    "        case (FreeVar(x), FreeVar(y)):\n",
    "            return x == y\n",
    "        case (Star(), Star()) | (Box(), Box()):\n",
    "            return True\n",
    "        case _:\n",
    "            return False\n",
    "def unfurl(lvl: int, f: Callable[[Term], Term]) -> Term:\n",
    "    return f(FreeVar(lvl))\n",
    "\n",
    "def unfurl2(lvl: int, pair: Tuple[Callable[[Term], Term], Callable[[Term], Term]]) -> Tuple[Term, Term]:\n",
    "    f, g = pair\n",
    "    return (unfurl(lvl, f), unfurl(lvl, g))\n",
    "def print_term(lvl: int, term: Term) -> str:\n",
    "    def plunge(f: Callable[[Term], Term]) -> str:\n",
    "        return print_term(lvl + 1, unfurl(lvl, f))\n",
    "\n",
    "    match term:\n",
    "        case Lam(f):\n",
    "            return f\"(λ{plunge(f)})\"\n",
    "        case Pi(a, f):\n",
    "            return f\"(Π{print_term(lvl, a)}.{plunge(f)})\"\n",
    "        case Appl(m, n):\n",
    "            return f\"({print_term(lvl, m)} {print_term(lvl, n)})\"\n",
    "        case Ann(m, a):\n",
    "            return f\"({print_term(lvl, m)} : {print_term(lvl, a)})\"\n",
    "        case FreeVar(x):\n",
    "            return str(x)\n",
    "        case Star():\n",
    "            return \"*\"\n",
    "        case Box():\n",
    "            return \"☐\"\n",
    "def curry2(f):\n",
    "    return Lam(lambda x: Lam(lambda y: f(x, y)))\n",
    "\n",
    "def curry3(f):\n",
    "    return Lam(lambda x: curry2(lambda y, z: f(x, y, z)))\n",
    "\n",
    "def curry4(f):\n",
    "    return Lam(lambda x: curry3(lambda y, z, w: f(x, y, z, w)))\n",
    "\n",
    "def curry5(f):\n",
    "    return Lam(lambda x: curry4(lambda y, z, w, v: f(x, y, z, w, v)))\n",
    "\n",
    "def appl(f: Term, args: List[Term]) -> Term:\n",
    "    return reduce(lambda m, n: Appl(m, n), args, f)\n",
    "# The type of Church numerals\n",
    "n_ty = Pi(Star(), lambda a:\n",
    "          Pi(Pi(a, lambda _x: a), lambda _f:\n",
    "             Pi(a, lambda _x: a)))\n",
    "\n",
    "# Zero is the identity function\n",
    "zero = Ann(curry3(lambda _a, _f, x: x), n_ty)\n",
    "\n",
    "# Successor applies f one more time\n",
    "succ = Ann(\n",
    "    curry4(lambda n, a, f, x: Appl(f, appl(n, [a, f, x]))),\n",
    "    Pi(n_ty, lambda _n: n_ty)\n",
    ")\n",
    "\n",
    "# Addition combines the function applications\n",
    "add = Ann(\n",
    "    curry5(lambda n, m, a, f, x:\n",
    "          appl(n, [a, f, appl(m, [a, f, x])])),\n",
    "    Pi(n_ty, lambda _n: Pi(n_ty, lambda _m: n_ty))\n",
    ")\n",
    "add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicates are sets of their models.\n",
    "type Type = smt.BoolRef\n",
    "#type \n",
    "\n",
    "#type Ctx = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contexts are kind of Tries.\n",
    "I could rediscover the ordering by trying to factor and carteisan producting and see if it works.\n",
    "\n",
    "No. It always works doesn't it?\n",
    "\n",
    "I guess if we have some sense of what families are possible\n",
    "\n",
    "\n",
    "\n",
    "registering iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor[K,V](k : K, ctxs : list[dict[K,V]]):\n",
    "    res = {}\n",
    "    for ctx in ctxs:\n",
    "        res[ctx[k]] = ctx.remove(k)\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def factor(ctx : list[dict]):\n",
    "    keys = ctx[0].keys()\n",
    "    for k in keys: # attempt factoring out k\n",
    "        factroed = \n",
    "        for env in ctx.items():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'a': 0, 'b': 0}, 0),\n",
       " ({'a': 0, 'b': 1}, 1),\n",
       " ({'a': 0, 'b': 2}, 2),\n",
       " ({'a': 1, 'b': 0}, 1),\n",
       " ({'a': 1, 'b': 1}, 2),\n",
       " ({'a': 1, 'b': 2}, 3),\n",
       " ({'a': 2, 'b': 0}, 2),\n",
       " ({'a': 2, 'b': 1}, 3),\n",
       " ({'a': 2, 'b': 2}, 4)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type TypeJudge = tuple[dict, object]\n",
    "def Foo():\n",
    "    return [(locals().copy(), a + b) for a in range(3) for b in range(3)]\n",
    "Foo()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 hello\n"
     ]
    }
   ],
   "source": [
    "d = {'foo': 42, 'bar': 'hello'}\n",
    "type Code = str\n",
    "def unpack(d) -> Code:\n",
    "    return '; '.join(f\"{k} = {repr(v)}\" for k, v in d.items())\n",
    "exec(unpack(d))\n",
    "print(foo, bar)\n",
    "#locals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarski universe\n",
    "\n",
    "Elements of U are codes.\n",
    "string codes via eval?\n",
    "AST codes?\n",
    "\n",
    "https://mathstodon.xyz/@olynch/114557642774172861 https://owenlynch.org/static/universes/slides/1.html\n",
    "Relationship to staged metaprogramming. \"e database queries, SAT formula, differential algebraic equations\"\n",
    "\"Python\" as a higher meta place than finite sets\n",
    "\n",
    "https://github.com/JacquesCarette/Drasil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({False, None, True})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The finiteness of El is akin to finiteness of Mu fixpoint.\n",
    "def El(T): # self codes?\n",
    "    return T\n",
    "def El(T : str):\n",
    "    return eval(T)\n",
    "def El0(T):\n",
    "    match T:\n",
    "        case \"Bool\": return Bool\n",
    "        case \"Unit\": return Unit\n",
    "        case \"Void\": return Void\n",
    "        case (\"Fin\", n): return Fin(0)\n",
    "        case (\"Vec\", A, n): return Vec(El(A), n)\n",
    "        case \"Sigma\": return Sigma(Bool, lambda x: Bool)\n",
    "        case \"Pi\": return Pi(Bool, lambda x: Bool)\n",
    "def El1(T):\n",
    "    match T:\n",
    "        case (\"El0\", T): return El0(T)\n",
    "        case _: return El0(T)\n",
    "def El(n, T):\n",
    "    if n == 0: return {}\n",
    "def joinU(U,V):\n",
    "    return U | V | frozenset({U}) | frozenset({V}) # Cumulative\n",
    "\n",
    "# open set vs closed set (in open closed sense). Open(frozenset(foo, bar)) is a set that copntains at least foo bar, not exactyl foo bar\n",
    "# El as an open function. class?\n",
    "class El0():\n",
    "    def __call__(self, T):\n",
    "\n",
    "class El1(El0):\n",
    "    def __call__(self, T):    \n",
    "        super().__call__(T)\n",
    "\n",
    "# note we don't need frozenset anymore? We can have sets of codes no problem\n",
    "U0 = [\"Bool\", \"Unit\", \"Void\"]\n",
    "El(\"Bool\")\n",
    "\n",
    "\n",
    "# reflection principle.\n",
    "# relativized predciates\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setoid model\n",
    "\n",
    "Canonical isomorphism if we make sets ordered (in unique mapping to nats) rather than sets.\n",
    "\n",
    "Free monoid lists --> Nat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def oset(A):\n",
    "    return tuple(sorted(set(A)))\n",
    "\n",
    "\n",
    "def Fin(n):\n",
    "    return tuple(range(n))\n",
    "def Nif(n):\n",
    "    # The Snoc Nat to Fin's Cons List\n",
    "    return tuple(reversed(range(n)))\n",
    "\n",
    "Fin(3)\n",
    "Nif(3)\n",
    "\n",
    "def FinTree(n):\n",
    "    (FinTree(n-i), FinTree(i)) for i in range(n):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigma(A, B):\n",
    "    return frozendict({(t1,t2) : (v1,v2) for t1,v1 in A.items() for t2,v2 in B(v1).items()})\n",
    "    #return frozendict({(t1,t2) : (v1,v2) for t1,v1 in A.items() for t2,v2 in B(_).items()})\n",
    "    #return frozendict{(v1,t2) : (v1,v2) for t1,v1 in A.items() for t2,v2 in B(v1).items()} # sigma as compared to Pair does have eval ordering suggested.\n",
    "    #return frozendict{(t1,t2) : (v1,v2) for t1,v1 in A.items() for t2,v2 in B(t1).items()}\n",
    "\n",
    "    # More and Done ?\n",
    "    # return {()\"stuck\", t1) : (\"stuck\", v1)} for t in A}) | unstuck  \n",
    "    # retrun {(\"stuck\",t1,t2) : (\"stuck\", v1, t2) for t2, v2 in B(t1).items() } | {(\"unstuck\", t1, t2) : (\"unstuck\", v1, t2) for t1,v1 in A.items() for t2,v2 in B(v1).items()}\n",
    "    #return frozendict{(t1,t2) : (v1,v2) for t1,v1 in A.items() for t2,v2 in B(v1, t1).items()}\n",
    "    #return frozendict{(t1,t2) : (v1,v2) for t1,v1 in A.items() for t2,v2 in B(t1).items() for t3,t4 in B(v1).items()}\n",
    "    # return { ((t1,t2), (v1,t2), (v1,v2))   for t1,v1 in A.items() for t2,v2 in B(v1).items() }\n",
    "def Id(A,x,y):\n",
    "    return frozendict({\"refl\" : \"refl\"}) if x[1] == y[1] else frozendict()\n",
    "def def_eq(x,y,A):\n",
    "    # but since x[1] refines x[0], x[0] == y[0] is equivalent to x == y\n",
    "    return x[0] == y[0]                                                                  \n",
    "\n",
    "# setoid map has to play nice with equiv relation\n",
    "# I don't think I have to do much.\n",
    "# Pick value mapping first or term mapping first?\n",
    "# congruence closure... ?\n",
    "# is it a mapping of functions to normalized functions?\n",
    "def Pi(A,B):\n",
    "    Alist1 = list(A.keys())\n",
    "    Alist2 = list(A.values())\n",
    "    return frozendict(frozendict(     for bvs in itertools.product(*[B(a) for a in Alist1]) : frozendict() )\n",
    "\n",
    "    # suggests that                                               \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "brute force smt equality. Only the equalities justified?\n",
    "\n",
    "Contexts as tries? We were kind of doing something trie-join like in my for loop nesting.\n",
    "\n",
    "{x : (3, {\"y\" : })}\n",
    "{\n",
    "    3 : { \"foo\" : ...}\n",
    "}\n",
    "\n",
    "\n",
    "picking an order of elements. Well-ordering. Axiom of choice\n",
    "\n",
    "second order set theory\n",
    "\n",
    "cloven fibration https://ncatlab.org/nlab/show/cleavage\n",
    "global choice https://en.wikipedia.org/wiki/Axiom_of_global_choice\n",
    "https://jdh.hamkins.org/the-global-choice-principle-in-godel-bernays-set-theory/\n",
    "\n",
    "lean \"cast\"\n",
    "\n",
    "I guess we're quotienting by a decdiable equality. What would that look like?\n",
    "\n",
    "class Universe(Egraph):\n",
    "    # a global eq notion.\n",
    "    eq = smt.Function(\"eq\", Term, Term, BoolSort())\n",
    "    def fresh_type()\n",
    "        FreshConst()\n",
    "    def univ(types):\n",
    "        fresh_type()\n",
    "        assert u == lambda([T], smt.Or(T == typ for typ in types))\n",
    "\n",
    "\n",
    "https://arxiv.org/pdf/1909.01414  From type theory to setoids and back - Palmgren https://www.youtube.com/watch?v=SQ3WrTNJ2Bs&ab_channel=InstituteforAdvancedStudy\n",
    "https://www.youtube.com/watch?v=se22z_YzD2g&pp=ygUGc2V0b2lk\n",
    "\n",
    "E-categoires  https://ncatlab.org/nlab/show/E-category \n",
    "\n",
    "Squashed types\n",
    "\n",
    "def Squash(A):\n",
    "    return Quot(A, lambda x,y: True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_type(gamma, A):\n",
    "    ctx = []\n",
    "    stack = []\n",
    "    while gamma:\n",
    "        B = gamma.pop()\n",
    "        for b in B(*ctx):\n",
    "            ctx.append(b)\n",
    "\n",
    "def is_type(A, B):\n",
    "    for a in A:\n",
    "        assert isinstance(B(a), frozenset)\n",
    "\n",
    "def iso(Aset, Bset):\n",
    "    A = sorted(Aset)\n",
    "    B = sorted(Bset)\n",
    "    return lambda a: B[A.index(a)], lambda b: A[B.index(b)]\n",
    "\n",
    "\n",
    "def iso(a, a1 , B : Family): # https://ncatlab.org/nlab/show/transport\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Type():\n",
    "    set : frozenset\n",
    "    #eq : Callable[[object, object], bool]\n",
    "    def __eq__(self, other): # definitional equality of type. eq_type\n",
    "        pass\n",
    "    #def __hash__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type Type = tuple[frozenset, Callable]\n",
    "type Family = Callable[[object], Type] # Family should obey setoidness (?) On the nose?\n",
    "import operator\n",
    "\n",
    "def is_type(A):\n",
    "    assert isinstance(A[0], frozenset)\n",
    "    assert all(A[1](a,a) for a in A[0]) # refl\n",
    "    assert all(A[1](a,a1) == A[1](a1,a) for a in A[0] for a1 in A[0]) # symm\n",
    "    assert all(A[1](x,z) for x in A[0] for y in A[0] for z in A[0] if A[1](x,y) and A[1](y,z)) # trans\n",
    "\n",
    "\n",
    "\n",
    "def eq_type(A,B):\n",
    "    # cody says == here is too weak or strong. But what else could I do?\n",
    "    # exists an element in B equal to any element A and vice versa?\n",
    "    # all(any(B[1](a,b) for b in B[0]) for a in A[0])) and all(any(A[1](a,b) for a in A[0]) for b in B[0])\n",
    "    # construct an iso? Use an ordering on the elements to do so?\n",
    "    # len(A[0]) == len(B[0]) too flimsy\n",
    "    # A[0] == B[0] too rigid\n",
    "    # to,from = iso(A[0], B[0])\n",
    "    # len(A[0]) == len(B[0]) and all(B[1](to(a), to(a1)) for a in A[0] for a1 in A[0] if A[1](a,a1)) and all(A[1](from(b), from(b1)) for b in B[0] for b1 in B[0])\n",
    "    # arbitrary iso, but \n",
    "    return A[0] == B[0] and all(A[1](a,b) == B[1](a,b) for a in A[0] for b in B[0])\n",
    "def Sigma(A,B):\n",
    "    # all(iso())\n",
    "    assert all(eq_type(B(a), B(a1)) for a in A[0] for a1 in A[0] if A[1](a,a1)) # This is really checking x:A |- B(x) type\n",
    "    # assert is_type(B)\n",
    "    # lambda (a,b), (a1,b1) : A[1](a,a1) and B(a)[1](b, iso(b1))     # B(a1)[1](iso(b), b1) symmettrically.\n",
    "    return frozenset({(a, b) for a in A[0] for b in B[0](a)}), lambda z,w: A[1](z[0], w[0]) and B(z[0])[1](z[1], w[1])\n",
    "def def_eq(x,y,A):\n",
    "    return x == y # not A[1](x,y)\n",
    "Void = (frozenset({}), lambda x,y: True)\n",
    "Unit = (frozenset({()}), lambda x,y: True)\n",
    "Bool = (frozenset({True, False}), operator.eq)\n",
    "\n",
    "def Fin(n : int) -> Type:\n",
    "    return (frozenset(range(n)), lambda x,y: x == y)\n",
    "\n",
    "def Quot(A, R):\n",
    "    # assuming R refines existing or else incorherent\n",
    "    assert all(not A[1](x,y) or R(x,y) for x in A[0] for y in A[0])\n",
    "    return A[0], lambda x,y: R(x,y)\n",
    "\n",
    "Mod3 = Quot(Fin(6), lambda x,y : x % 3 == y % 3)\n",
    "\n",
    "assert not def_eq(0,3, Mod3)\n",
    "assert def_eq(0,0, Mod3)\n",
    "\n",
    "def Pi(A,B):\n",
    "    assert all(eq_type(B(a), B(a1)) for a in A[0] for a1 in A[0] if A[1](a,a1))\n",
    "    Alist = list(A[0])\n",
    "    def fun_eq(f1, f2):\n",
    "        return all(B(a)[1](f[a], f1[a1]) for a in Alist for a1 in Alist if A[1](a,a1))\n",
    "    def playsnice(f):\n",
    "        return fun_eq(f, f)\n",
    "        #assert all(B(a)[1](f[a], f[a1]) for a in Alist for a1 in Alist if A[1](a,a1))\n",
    "    f0 = frozenset(filter(playsnice, [frozendict({k:v for k,v in zip(Alist, bvs)}) for bvs in itertools.product(*[B(a) for a in Alist])]))\n",
    "    return f0, fun_eq\n",
    "\n",
    "\n",
    "def Id(A, x, y):\n",
    "    return (frozenset({\"refl\"}), lambda x,y: True) if A[1](x, y) else (frozenset(), lambda x,y: True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Groups.\n",
    "A set with a group action.\n",
    "Orbit under group action is equivalence class\n",
    "\n",
    "\n",
    "Silly_Unit = {(0,1), (1,0)}, [{0 : 1, 1 : 0}, {0:0, 1:1} ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#type Group = int\n",
    "type Group = # list of generators of permutation group?\n",
    "type Type = tuple[frozenset, Group]\n",
    "\n",
    "Bool = (frozenset({True, False}), ({True: True, False : False},))\n",
    "BoolU = (frozenset({True, False}), ({True: True, False: False} ,{True: True, False : False},)) # a quotient of Bool isomoprhic to Unit\n",
    "\n",
    "def Arr(A, B):\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Unit = (frozenset({()}), {((), ())})\n",
    "UnitG = (frozenset({()}),  G) # group is gorupoid of single element.\n",
    "Bool = (frozenset({True, False}), ({(True, True), (False, False)}))\n",
    "BoolU = (frozenset({True, False}), {(True, False), (True,True), (False, True), (False, False)}) # a quotient of Bool isomoprhic to Unit\n",
    "\n",
    "type Family = #?\n",
    "\n",
    "def inv(p):\n",
    "    return (p[1], p[0])\n",
    "def comp(p,q):\n",
    "    assert p[1] == q[0]\n",
    "    return (p[0], q[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quasiquoting. \n",
    "type Code = tuple[str, type]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type Type = tuple[frozenset, Callable[object,object], object]  # type as set/eq_fun pair\n",
    "type Type = tuple[frozenset, Callable[object], object] # type as set/canon pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Void = frozenset({None}) # ?\n",
    "Unit = frozenset({(), None})\n",
    "Bool = frozenset({True, False, None})\n",
    "\n",
    "def Sigma(A : Type, B : Family) -> Type:\n",
    "    # B has to be a monotonic family.\n",
    "    return frozenset({(a, b) for a in A for b in B(a)}) | [None]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_le(x, y):\n",
    "    # partial order.\n",
    "    if x == y:\n",
    "        return True\n",
    "    if x is None:\n",
    "        return True\n",
    "    elif y is None:\n",
    "        return False\n",
    "    elif isinstance(x, tuple) and isinstance(y, tuple):\n",
    "        return all(def_le(xi, yi) for xi, yi in zip(x, y))\n",
    "    else:\n",
    "        return False\n",
    "#def_lt(None, 1)\n",
    "#def_lt(1, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({frozendict.frozendict({False: False, True: False, None: False}),\n",
       "           frozendict.frozendict({False: False, True: False, None: None}),\n",
       "           frozendict.frozendict({False: False, True: None, None: None}),\n",
       "           frozendict.frozendict({False: False, True: True, None: None}),\n",
       "           frozendict.frozendict({False: None, True: False, None: None}),\n",
       "           frozendict.frozendict({False: None, True: None, None: None}),\n",
       "           frozendict.frozendict({False: None, True: True, None: None}),\n",
       "           frozendict.frozendict({False: True, True: False, None: None}),\n",
       "           frozendict.frozendict({False: True, True: None, None: None}),\n",
       "           frozendict.frozendict({False: True, True: True, None: None}),\n",
       "           frozendict.frozendict({False: True, True: True, None: True})})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Arr(A, B):\n",
    "    Alist = list(A)\n",
    "    return frozenset(frozendict({k:v for k,v in zip(Alist, bvs)}) for bvs in itertools.product(*[B for a in Alist]) if all(not def_le(a, a1) or def_le(b,b1) for a,b in zip(Alist, bvs) for a1,b1 in zip(Alist, bvs)))\n",
    "Arr(Bool, Bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bidirectional style\n",
    "\n",
    "Does bidriectional have any meaning?\n",
    "subset types?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lam(A : Type, f):\n",
    "    return frozendict({a : f(a) for a in A})\n",
    "def app(f, x):\n",
    "\n",
    "\n",
    "def synth(t) -> Type:\n",
    "    \n",
    "\n",
    "def check(t, A : Type) -> bool:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Set2D = frozendict[object, object]\n",
    "# directed graph is simplicial set. Glued  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type Code = str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle x \\in \\left\\{1, 2\\right\\}$"
      ],
      "text/plain": [
       "Contains(x, {1, 2})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sympy\n",
    "x,y,z = sympy.symbols(\"x y z\")\n",
    "sympy.ConditionSet(x, x > 0, sympy.S.Reals)\n",
    "sympy.Contains(x, sympy.UniversalSet)\n",
    "x in sympy.UniversalSet\n",
    "sympy.Contains(x, sympy.FiniteSet(1,2)) # in doesn't work. Needs to evlauates to Bool\n",
    "\n",
    "#def Arr(A,B):\n",
    "#def Pi(A,B):\n",
    "\n",
    "Contains(x, sympy.UniversalSet), Contains(y, FiniteSet(1,2)(x), Contains(z, FiniteSet(1,2)(x,y))\n",
    "                                          ImageSet().Contains()\n",
    "                                        \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def Te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Turnstile(*vs, body): # TeleForAll\n",
    "    acc = body\n",
    "    # TODO: maybe compress stretches of unquantified.\n",
    "    for v in reversed(vs):\n",
    "        if isinstance(v, tuple):\n",
    "            #acc = kd.QForAll([v[0]], v[1], acc) # this is more refinement style. Strictly speaking B can still contain x in other ways.\n",
    "            acc = kd.QForAll([v[0]], v[1][v[0]], acc)\n",
    "        else:\n",
    "            acc = kd.QForAll([v], acc)\n",
    "    return acc\n",
    "\n",
    "IntT = smt.K(smt.IntSort(), True)\n",
    "#Pos = smt.Lambda([x], x > 0)\n",
    "def GT(x):\n",
    "    return smt.Lambda([y], y > x)\n",
    "def Fin(n): # meta Fin\n",
    "    return smt.Lambda([x], smt.And(0 <= x, x < n))\n",
    "# Internal-ish Fin\n",
    "Fin = kd.define(\"Fin\", [n], smt.Lambda([x], smt.And(0 <= x, x < n)))\n",
    "#Fin2 = smt.Lambda([x], smt.Lambda([y], smt.And(0 <= x, x < 2))\n",
    "Turnstile([(x, Fin(3)), (y, Fin(x))], )\n",
    "\n",
    "type Type = smt.ArraySortRef\n",
    "def Pi(A : smt.ArraySortRef, B : smt.ArraySortRef) -> Type:\n",
    "    return smt.Lambda([f], kd.QForAll([x], A[x], B(x)(f[x])))\n",
    "def Arr(A : Type, B : Type) -> Type:\n",
    "    return smt.Lambda([f], kd.QForAll([x], A[x], B(f[x])))\n",
    "def Pair(A : Type, B : Type) -> Type:\n",
    "    return smt.Lambda([p], smt.And(p.is_pair, A(p[0]), B(p[1])))\n",
    "def Sigma(A : Type, B : Type) -> Type:\n",
    "    return smt.Lambda([p], smt.And(p.is_pair, A(p[0]), B(p[0])(p[1])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contracts? diualectica? Something something?\n",
    "# You needs both variance to do stuff.\n",
    "\n",
    "type Type = type[Gen, Callable[object, bool]]\n",
    "def Pi(A, B):\n",
    "    return lambda f: all(lambda x: A(x) and B(x)(f(x))) # can't really do this part.\n",
    "def Pi(A, B):\n",
    "    def check(f):\n",
    "        hypothesis.get(A[0])\n",
    "        # quick check property that pull from A, then B(f(x))\n",
    "    def gen():\n",
    "        return lambda x: gen(B(x))\n",
    "    return gen, check\n",
    "\n",
    "def Sigma()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({frozenset(), frozenset({False, True}), frozenset({()})})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Env((\"x\", A), (\"y\", B(\"x\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lambda x35243: x35243(1)'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "type Code = str\n",
    "def lam(f : Callable[[Code], Code]) -> Code:\n",
    "    x = \"x\" + str(random.randint(0, 100000))\n",
    "    return f\"lambda {x}: {f(x)}\"\n",
    "def app(f : Code, x : Code) -> Code:\n",
    "    return f\"{f}({x})\"\n",
    "def lit(x : Code) -> Code:\n",
    "    return f\" {x} \"\n",
    "lam(lambda x: f\"{x} + 1\")\n",
    "\n",
    "lam(lambda f: f\"{f}(1)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3           0 RESUME                   0\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 LOAD_CONST               1 (1)\n",
      "              6 BINARY_OP                0 (+)\n",
      "             10 RETURN_VALUE\n",
      "  4           0 RESUME                   0\n",
      "              2 LOAD_FAST                0 (y)\n",
      "              4 LOAD_CONST               1 (1)\n",
      "              6 BINARY_OP                0 (+)\n",
      "             10 RETURN_VALUE\n"
     ]
    }
   ],
   "source": [
    "import dis\n",
    "\n",
    "f = lambda x: x + 1\n",
    "f1 = lambda y: y + 1\n",
    "dis.dis(f)\n",
    "dis.dis(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction(opname='RESUME', opcode=151, arg=0, argval=0, argrepr='', offset=0, starts_line=3, is_jump_target=False, positions=Positions(lineno=3, end_lineno=3, col_offset=0, end_col_offset=0)) Instruction(opname='RESUME', opcode=151, arg=0, argval=0, argrepr='', offset=0, starts_line=5, is_jump_target=False, positions=Positions(lineno=5, end_lineno=5, col_offset=0, end_col_offset=0))\n",
      "Instruction(opname='LOAD_FAST', opcode=124, arg=0, argval='x', argrepr='x', offset=2, starts_line=None, is_jump_target=False, positions=Positions(lineno=3, end_lineno=3, col_offset=14, end_col_offset=15)) Instruction(opname='LOAD_FAST', opcode=124, arg=0, argval='y', argrepr='y', offset=2, starts_line=None, is_jump_target=False, positions=Positions(lineno=5, end_lineno=5, col_offset=15, end_col_offset=16))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def def_eq(f, f1):\n",
    "    # not alpha equiv\n",
    "    # could have some simlifying rewriting in here?\n",
    "    for i1,i2 in zip(dis.Bytecode(f), dis.Bytecode(f1)):\n",
    "        print(i1,i2)\n",
    "        if i1.opname != i2.opname or i1.arg != i2.arg or i1.argval != i2.argval:\n",
    "            return False\n",
    "    return True\n",
    "def_eq(f,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frozenset([x + y for x in Fin(5) for y in Fin(x)]) <= Fin(8) # x : Fin(5), y : Fin(x) |- x + y : Fin(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([x + y in Fin(8) for x in Fin(5) for y in Fin(x)])  # x : Fin(5), y : Fin(x) |- x + y : Fin(8)\n",
    "all([x + y in Fin(5 + y) for x in Fin(5) for y in Fin(x)]) \n",
    "\n",
    "all([frozendict({y : x + y for y in Fin(x)}) in Pi(Fin(x), lambda z: Fin(5 + z)) for x in Fin(5)])\n",
    "# x : Fin(5) |- fun y => y + x : forall z : Fin(x), Fin(5 + z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all([isinstance(Fin(x), frozenset) for x in Fin(5)]) # x : Fin(5) |- Fin(x) Type\n",
    "all([x + y == y + x for x in Fin(5) for y in Fin(x)]) # x : Fin(5), y : Fin(x) |- x + y = y + x # judge_eq? But I don't want x + y == y + x judgementally?\n",
    "# id(x + y) == id(y + x) or  \"x + y\" == \"y + x\" or \n",
    "all([Fin(x + y) == Fin(y + x) for x in Fin(5) for y in Fin(x)]) # x : Fin(5), y : Fin(x) |- Fin(x + y) = Fin(y + x) judge_eq ? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({frozendict.frozendict({'x': False, 'y': False}),\n",
       "           frozendict.frozendict({'x': False, 'y': True}),\n",
       "           frozendict.frozendict({'x': True, 'y': False}),\n",
       "           frozendict.frozendict({'x': True, 'y': True})})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# python contexts as Gamma? No this is more like env rho? But like all envs\n",
    "def foo():\n",
    "    #A = Bool\n",
    "    #y = iter(A)\n",
    "    ctxs = [] # Gamma? Interpretation of Gamma as a set of contexts.\n",
    "    def inner():\n",
    "        for x in Bool:\n",
    "            for y in Bool:\n",
    "                t = locals()\n",
    "                del t[\"ctxs\"]\n",
    "                ctxs.append(frozendict(t))\n",
    "                del t\n",
    "    inner()\n",
    "    return frozenset(ctxs)\n",
    "foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def app(f, x):\n",
    "    return f[x]\n",
    "def var(x):\n",
    "    return x\n",
    "tt = ()\n",
    "true = True\n",
    "false = False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step indexing.\n",
    "\n",
    "# gas parameter\n",
    "def Pi(A,B,gas):\n",
    "    # all steps < gas\n",
    "    Alist = list(functools.reduce(operator.or_, A(i) for i in range(gas)))\n",
    "    return frozenset(frozendict({k:v for k,v in zip(Alist, bvs)}) for bvs in itertools.product(*[B(a,gas) for a in Alist]))\n",
    "\n",
    "# generator style.\n",
    "# B is generator of families.\n",
    "def Pi(A,B):\n",
    "    Biter = B()\n",
    "    B.next() # B is one ahead of A\n",
    "    for An in A:\n",
    "        Bn = B.next()\n",
    "        yield frozenset(frozendict({k:v for k,v in zip(An, bvs)}) for bvs in itertools.product(*[Bn(a) for a in An]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp(e : smt.ExprRef, env) -> object:\n",
    "    if isinstance(e, smt.QuantifierRef):\n",
    "        assert e.is_lambda()\n",
    "        e.vars + env\n",
    "    if smt.is_select(e):\n",
    "        app(interp(e.arg(0)), interp(e.arg(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python vs z3 meta.\n",
    "ctx can be z3 meta ctx. Not refiied.\n",
    "Forall x y z, is analog of above for loops.\n",
    "\n",
    "forall x, B[x], forall y, A[x,y], ... C[t(x,y,z)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Term0 = smt.DeclareSort(\"Term0\")\n",
    "Term = smt.Datatype(\"Term\")\n",
    "Term.declare(\"TT\")\n",
    "Term.declare(\"BoolVal\", (\"bval\", smt.BoolSort()))\n",
    "Term.declare(\"IntVal\", (\"ival\", smt.IntSort()))\n",
    "Term.declare(\"PairVal\", (\"fst\", Term), (\"snd\", Term))\n",
    "Term.declare(\"OtherVal\", (\"val\", Term0)) # Functions, etc. We only separate out primitives for fun.\n",
    "\n",
    "Type = smt.SortSort(Term)\n",
    "Family = smt.ArraySort(Term, Type)\n",
    "Bool = smt.Lambda([t], t.is_BoolVal)\n",
    "Void = smt.Lambda([t], False)\n",
    "Unit = smt.Lambda([t], t.is_TT)\n",
    "\n",
    "Arr = smt.Function(\"Arr\", Type, Type, Type)\n",
    "apply = smt.Function(\"apply\", Term, Term, Term)\n",
    "lam = smt.Function(\"lam\", smt.ArraySort(Term, Term), Term)\n",
    "kd.axiom(kd.QForAll([a,b], apply(lam(a), b)) == a[b])\n",
    "# extensionality forall x, apply(t1, x) == apply(t2, x) == (t2 == t1)\n",
    "\n",
    "\n",
    "kd.define(\"Arr\", [A,B], smt.Lambda([t], smt.And(t.is_OtherVal, kd.QForAll([x], A[x], B[apply(t, x)]))))\n",
    "kd.define('Pi', [A,B], smt.Lambda([t], smt.And(t.is_OtherVal, kd.QForAll([x], A[x], B[x][apply(t, x)]))))\n",
    "def Pi(A, B):\n",
    "    return smt.Lambda([t], smt.And(t.is_OtherVal, kd.QForAll([x], A(x), B(x, apply(t, x)))))\n",
    "# comp = smt.Function(\"comp\", Type, Term)\n",
    "# This might be ok, but the reverse,   Term, Type or asking if Term in Term requires carefulness.\n",
    "\n",
    "lamB = smt.Function(\"lamB\", smt.ArraySort(smt.BoolSort(), Term), Term)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Univ = smt.Const(\"Univ0\", Type)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependent typed egraph.\n",
    "in SMT egraph, everything was keyed on sort.\n",
    "If we're in a dependent context why not seek dependent sorts\n",
    "\n",
    "\n",
    "\n",
    "{\"Ob\" :  }\n",
    "{\"Hom\" : dict{(1,2) : {   }}\n",
    "\n",
    "bottom up ematching indeed. Tries indeed.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## categorical persecptive\n",
    "If I combine my finset cat and finset dtt post, can I do categorical semantics of type theory?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametricity\n",
    "Finite parametricity\n",
    "\n",
    "https://people.mpi-sws.org/~dreyer/tor/papers/wadler.pdf\n",
    "\n",
    "\n",
    "Paramatricity is an information hiding theorem about the type universe? We want to allow open universes / be non specific about exactly what's in the universe.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Binary_relation . Hmm Class vs set issues in relation algebra\n",
    "\n",
    "schmidt relational mathematics\n",
    "\n",
    "Sympyifying and that parametricity = noether thing. Hmm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({(frozendict.frozendict({True: False, False: False}),\n",
       "            frozendict.frozendict({True: False, False: False})),\n",
       "           (frozendict.frozendict({True: False, False: True}),\n",
       "            frozendict.frozendict({True: False, False: True})),\n",
       "           (frozendict.frozendict({True: True, False: False}),\n",
       "            frozendict.frozendict({True: True, False: False})),\n",
       "           (frozendict.frozendict({True: True, False: True}),\n",
       "            frozendict.frozendict({True: True, False: True}))})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bools = frozenset({(True, True), (False, False)})\n",
    "Unit = frozenset({((), ())})\n",
    "Void = frozenset()\n",
    "def Fin(n):\n",
    "    return frozenset({(i,i) for i in range(n)})\n",
    "\n",
    "\n",
    "# I am not sure this is right.\n",
    "# Alist is longer than just the naive length of single A. So I'm picking a dependence\n",
    "# maybe I do need to do cartisan product and then \n",
    "def Arr(A,B): # In B the product is already done.\n",
    "    Alist = list(A)\n",
    "    res = []\n",
    "    for bs in itertools.product(B, repeat=len(Alist)):\n",
    "        f,f1 = zip(*[((a,b), (a1,b1)) for ((a,a1), (b,b1)) in zip(Alist, bs)])\n",
    "        res.append((frozendict(f), frozendict(f1)))\n",
    "    #f,f1 = zip(*[(a,b), (a1,b1) for ((a,a1), (b,b1)) in zip(Alist, bs)] for bs in itertools.product(B, repeat=len(Alist)))\n",
    "    return frozenset(res)\n",
    "    #return frozenset(frozendict(data), frozendict()\n",
    "\n",
    "def breakup(B):\n",
    "    xs, ys = zip(*A)\n",
    "    return frozenset(xs), frozenset(ys)\n",
    "\n",
    "\n",
    "\n",
    "type Type = frozenset[tuple[object, object]]\n",
    "type Family = frozenset[tuple[Callable[object, Type0], Callable[object, Type0]]] # this is too many tuples? Type0 doesn't really let us express correlation.\n",
    "def Pi(A, B : Family):\n",
    "    Alist = list(A)\n",
    "    res = []\n",
    "    for bs in itertools.product(*[itertools.product((B0(x), B1(y)) for B0, B1 in B) for (x,y) in Alist]):\n",
    "    #for bs in itertools.product(*[itertools.product(B[0](x), B[1](y)) for (x,y) in Alist]):\n",
    "        f,f1 = zip(*[((a,b), (a1,b1)) for ((a,a1), (b,b1)) in zip(Alist, bs)])\n",
    "        res.append((frozendict(f), frozendict(f1)))\n",
    "    #f,f1 = zip(*[(a,b), (a1,b1) for ((a,a1), (b,b1)) in zip(Alist, bs)] for bs in itertools.product(B, repeat=len(Alist)))\n",
    "    return frozenset(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(frozenset({1, 2}), frozenset({1, 2, 3}))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# factor into smallest overapaproximation if you cartieana producted again\n",
    "def factor(A):\n",
    "    xs, ys = zip(*A)\n",
    "    return frozenset(xs), frozenset(ys)\n",
    "\n",
    "factor({(1,2), (2,3), (2,1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## monotonic\n",
    "type interpeted as monotnically increasing sets\n",
    "\n",
    "maybe is becomes more interesting.\n",
    "\n",
    "vs finite sets of monotinically evaluating objects.\n",
    "vs monotonically evaluating \n",
    "Motonically producing objects?\n",
    "\n",
    "\n",
    "FRP as model of intuionistic logic? Hmm. label realvbalue of when stuiff becomes true\n",
    "\n",
    "sets of pairs of (timestamp, value) # and take the earliest timestamp\n",
    "\n",
    "vs fix how many timesteps in advance.\n",
    "\n",
    "There's no reason to use generators really. Huh.\n",
    "\n",
    "I interpret a type into this? Feels weird.\n",
    "\n",
    "a growing egraph universe\n",
    "sorts are interpreted as subuniverses?\n",
    "Next step of universe could contain it's previous self.\n",
    "This was an angle on the finite set post.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozendict.frozendict({'x': 1, 'y': 2, 'z': 4})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "def tset(vs):\n",
    "    d = {}\n",
    "    for v,t in vs:\n",
    "        d[v] = min(d.get(v, float(\"inf\")), t)\n",
    "    return frozendict(d)\n",
    "\n",
    "tset([(\"x\",1), (\"y\",2), (\"x\", 3), (\"z\",4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, None), (None, None), (42, None), (42, None), (42, 'hello')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "def delay(t, v):\n",
    "    for i in range(t):\n",
    "        yield\n",
    "    yield v\n",
    "    #return v\n",
    "\n",
    "list(delay(4, 2))\n",
    "\n",
    "x = delay(4,3)\n",
    "next(x)\n",
    "next(x)\n",
    "next(x)\n",
    "next(x)\n",
    "next(x)\n",
    "\n",
    "\n",
    "def pair(x,y):\n",
    "    for i in x:\n",
    "        yield (i,None)\n",
    "    for j in y:\n",
    "        yield (i,j)\n",
    "list(pair(delay(2,42), delay(1, \"hello\")))\n",
    "\n",
    "def Pair(A,B):\n",
    "    return [pair(i,j) for i in A for j in B]\n",
    "def Pi(A,B):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Int at 0x736ae2208a00>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Int():\n",
    "    s = set()\n",
    "    i = 0\n",
    "    while True:\n",
    "        s.add(i)\n",
    "        yield frozenset(s)\n",
    "        i += 1\n",
    "\n",
    "Int()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impredicativity\n",
    "https://cstheory.stackexchange.com/questions/36043/impredicative-in-type-theory\n",
    "How do we read this answer? Full comprehension of some formula is allowable (?).\n",
    "indctive(S) = elem(emp,S) & forall x, elem(x,S), elem(succ(x), S)\n",
    "\n",
    "large eliminations\n",
    "\n",
    "exlcuded middle gets you prop resizing https://ncatlab.org/nlab/show/propositional+resizing\n",
    "\n",
    "\n",
    "\"A type signature for church encoded natural numbers is forall (A : Prop), (A -> A) -> A -> A.\n",
    "This signature quantifies over A : Prop hence if this type signature is in Prop then Prop is impredicative which is necessary to even define functions from the church nats to church nats. \n",
    "The alternatives to impredicative Prop would be either:\"  https://discord.com/channels/1128334405795061800/1324761377801502720/1326012154830393424\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proofs as categories\n",
    "single succedent singel conseqeunt\n",
    "\n",
    "```\n",
    " ...\n",
    "------\n",
    "A |- B\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "--------- id\n",
    " id(A) : A |- A\n",
    "```\n",
    "\n",
    "```\n",
    "f : A |- B   g :  B |- C\n",
    "------------------------- cut\n",
    "     comp(f,g) : A |- C\n",
    "```\n",
    "\n",
    "```\n",
    "------------------\n",
    " fst : A /\\ B |- A\n",
    "```\n",
    "\n",
    "```\n",
    "---------------\n",
    "snd :  A /\\ B |- B\n",
    "```\n",
    "\n",
    "```\n",
    "f : A |- B   g : C |- D\n",
    "------------------ par\n",
    "par(f,g) : A /\\ C |- B /\\ D\n",
    "```\n",
    "\n",
    "```\n",
    "----------- dup\n",
    "dup : A |- A /\\ A\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "   f : A /\\ B |- C\n",
    "-------------------------\n",
    "   curry(f) : A |- B -> C\n",
    "```\n",
    "\n",
    "```\n",
    "-----------------\n",
    "apply : A /\\ A -> B |- B\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# z3 subst catgegoyr\n",
    "\n",
    "https://ncatlab.org/nlab/show/substitution#CategoricalSemantics\n",
    "\n",
    "\n",
    "A cateogical presentrration of the nufnication algorithm.\n",
    "We break down the lawvere theory into par and do it piece by piece somehow.\n",
    "\n",
    "\n",
    "I guess pullback is kind of like unifying terms from two different unification var sets\n",
    "\n",
    "https://math.andrej.com/2012/09/28/substitution-is-pullback/\n",
    "predicates.\n",
    "https://en.wikipedia.org/wiki/Pullback\n",
    "\n",
    "substitution equationally\n",
    "We work with the entire system...\n",
    "```\n",
    "-- eq is equalizer morphism\n",
    "eq(f,f) = id(dom(f))  -- id rule\n",
    "eq(f,g) = eq(g,f)  -- kind of orient rule but all at once.\n",
    "eq(par(f,g),par(h,k)) = par(eq(f,h),eq(g,k))\n",
    "eq(comp(f,g), comp(h,k)) =?\n",
    " -- unify  f,h first, then unify \n",
    " eq(comp(f,g), h) = eq(f . ??, h) something?\n",
    "\n",
    "\n",
    "eq(id,f) =? \n",
    "```\n",
    "\n",
    "https://link.springer.com/chapter/10.1007/3-540-17162-2_139  A categorical unification algorithm\n",
    "Ryhdeheard and burstall\n",
    "Hmm. Coequalizer?\n",
    "\n",
    "Hmm. Yes the variables in the terms are associated with the CODOMINA of the subtitution.\n",
    "The domain of the substitution is a mere indexing basically and almost doesn't have a sense of being a variable.\n",
    "\n",
    "To be comparing vars in codomain like unification, it should be aa coequalizer\n",
    "\n",
    "{x -> f(x', y'), y -> g(x', y')}\n",
    "[f(v0,v1), g(v0,v1)]\n",
    "\n",
    "[f(p(q(a)))] is a concrete ground term. The codomain is implicit. It could be 0 vars (?)\n",
    "The domain is 1.\n",
    "\n",
    "A signature can be expressed as noting atomic elements [f(v0,v1)]  [g(v0)]. [mul(v0,v1)] [inv(v0)] []\n",
    "\n",
    "\n",
    "A particular open preciate is [even(succ(succ(v0)))]  a multi predicate is interpreted as conjunction?\n",
    "\n",
    "\n",
    "Raising nad lowering unneccesary variables.\n",
    "Projecting out variables as exists and forall\n",
    "duplicating variables ~ eq\n",
    "\n",
    "[v0, v0]  expsress {x -> x', y -> x'}  a merging substitution\n",
    "There is no duplicating susbtitution. {x -> x', x -> y'}\n",
    "\n",
    "vBool -> F(x)  . vInt -> succ(y) = vBool -> F(succ(y))\n",
    "post composition is substituion into predicate\n",
    "vBool -> F(x)  . vInt -> add(z,y) = vBool -> F(add(x,y)) this makes morew vairblwes.\n",
    "\n",
    "f(x,y) = x   is and equation saying the vInt -> f(x,y) is the same as raise(vInt -> x, vInt)\n",
    "\n",
    "\n",
    " `|-` \n",
    "\n",
    " https://www.cl.cam.ac.uk/~amp12/papers/catl/catl.pdf catehorical logic pitts\n",
    "\n",
    " https://www.youtube.com/watch?v=uQp-Pi5jSNk quantifiers as djoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from z3 import *\n",
    "\n",
    "Ctx = list[SortRef]\n",
    "\n",
    "\n",
    "class Morph():\n",
    "    dom: list[SortRef] # not so implicit\n",
    "    cod: list[SortRef] # implicit in subst (?).\n",
    "    subst = list[ExprRef]\n",
    "    def __init__(self, dom, cod, subst):\n",
    "        assert [t.sort() for t in in subst] == dom\n",
    "        # assert all set(get_vars(t) for t in subst) in \n",
    "        self.dom = dom\n",
    "        self.cod = cod\n",
    "        self.subst = subst\n",
    "    def __matmul__(self, other):\n",
    "        assert self.dom == other.cod\n",
    "        return Morph(other.dom, self.cod, [substitute_vars(t, *other.subst) for t in self.subst])\n",
    "\n",
    "\n",
    "def id(n): # or a sort list.\n",
    "    return [Var(i) for i in range(n)]\n",
    "def comp(fs,gg):\n",
    "    return [substitute_vars(f, *gs) for f in fs]\n",
    "def par(fs,gs):\n",
    "    # TODO: shift gs.\n",
    "    return [f for f in fs] + [substutute_vars(g, Var(n + len(fs)) for g in gs]\n",
    "mullawv = [mul(Var(0), Var(1))]\n",
    "elawv = [e]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predicates():\n",
    "    vs: Ctx #list[SortRef]\n",
    "    expr: BoolRef\n",
    "    #exprs: set[BoolRef] equivalence exprs?\n",
    "\n",
    "    def proj(self) -> Ctx:\n",
    "        # returns an object in substitution category\n",
    "        return vs #(?)\n",
    "\n",
    "# category is preorder\n",
    "class Morph():\n",
    "    dom : Pred\n",
    "    cod : Pred\n",
    "    subst : Subst\n",
    "    def __init__(self, dom, cod, subst):\n",
    "        # The variables aren't shared? Hmmmmm.\n",
    "        assert dom.vs == subst.dom\n",
    "        assert cod.vs == subst.cod\n",
    "\n",
    "        assert prove(ForAll(cod.vs, Implies(substitute_vars(dom.expr, *subst.subst), cod.expr)))\n",
    "\n",
    "        #assert prove(ForAll(dom.vs, Implies(dom.expr, cod.expr)))\n",
    "        self.dom = dom\n",
    "        self.cod = cod\n",
    "    # quantifiers\n",
    "    def add(self, vsort): \n",
    "        # add an unused var along for the ride? Antiprojecting.\n",
    "        # \"weaken\". \"lift\" \"raise\"\n",
    "    def leftadjoint(self):\n",
    "        # x.add(v).leftadjoint() ~ x\n",
    "\n",
    "    def rightadjoint(self):\n",
    "        # x.rightadjoint().add(v) ~ x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typing as fibers.\n",
    "gamma |- A  is like a (entangled) product of gamma and A\n",
    "\n",
    "proj(gamma |- A) = gamma\n",
    "\n",
    "The functoriality of substutuition to the predicate category is saying that if you prove and implication with variables in it, you can substute in anything you want and still have a proof.\n",
    "No. predicates have to be over the same context to be compared...\n",
    "gamma |- A -> B\n",
    "No wait. If we include a subst we have a way to compare the two variable sets...\n",
    "\n",
    "\n",
    "There is a category over a single ctx.\n",
    "The is also a category of ctx maps\n",
    "\n",
    "Apropos partial functions: the thing that Nate and I talked about a bit was modeling these as spans, So a partial function f:A-> B would be a pair of regular functions g:X->A, h:X->B, where h is monic, and f(a) = b would translate to Ex.g(x) = a and h(x) = b. If you make h epic, that corresponds to the function being total, and if you relax the constraint that h is monic, you get what feel like multiset valued functions. For encoding in a theorem prover, I wonder if it would be smoother to use cospans, so g:A->X, h:B->X, with h monic. Then f(a) = b could translate to g(a) = f(b), and you don't need the quantifier. X could be basically Maybe B.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "From lunch: sorry, coequalizer, not equalizer\n",
    "About the substitution thing: the inclusion function, from the set of definable sets of individuals (represented by one-variable formulas/predicates) to the set of definable sets of pairs of individuals (represented by two-variable formulas) is actually the result of a substitution, if you look at it a certain way. Suppose I have a two-argument function, f(x,y) and a one variable formula F(x). I can make a two variable formula by substitution: F(f(x,y)). If my function is projection of the left argument, so that f(x,y) = x, then what my substitution is doing is, in a more explicit way, turning F from a one variable formula into a slightly degenerate case of a two variable formula.\n",
    "\n",
    "There's a contravariant functor thing going on here: f : A -> B induces a functor from the fiber (in this case, a Boolean algebra of definable sets or something) over B to the fiber over A.\n",
    "\n",
    "\n",
    "Yea, coequalizer does seem right now\n",
    "What is the fiber? There is a special Bool object maybe and  strangely the morphisms coming out of bool represent predicates and the target object is the vars in the predicate expression?\n",
    "Or it the boolean algebra a category connected to our substitution category by a functor, ie a model of our signature\n",
    "\n",
    "So, the boolean algebra is the fiber. The objects in there are equivalence classes of formulas, and the arrows are the boolean algebra ordering, which corresponds to implication.\n",
    "\n",
    "The idea is that there's a total category whose objects are formulas in a typing context. So, like a \"two variable formula\" is a formula whose variables are a subset of x,y, in a context \"x: individual, y: individual\". The contexts are the base category, and the functor that erases formulas and just leaves the context is the fibration. The fibers are the preimage categories of a given context plus its identity map - in the FOL case, these turn out to be Boolean algebras. (edited) \n",
    "\n",
    "The contexts are the objects in the base category of substitutions or each context is an entire base category? (edited) \n",
    "\n",
    "\n",
    "They're objects in a base category. Base category is not quite a category of substitutions, it's more like a category where the maps are function symbols. So like, a two variable function f induces a map from the context \"x: individual, y: individual\" to \"x:individual\". But a map in the base category like this creates a map (going in the other direction) between the fibers, which is essentially the result of substituting f(x,y) for x in each of the formulas-in-context in the fiber, thereby changing the context that it lives in.\n",
    "\n",
    "\n",
    "What about if you compose two maps? Isn’t it then not a function symbol and something more structured, more like a general substitution? Its generated by the function symbols ?\n",
    "\n",
    "Yeah, that's right.\n",
    "I'd think of it as a term, so like f(g(x,z),y) might be a map from the context x,y,z to the context x.\n",
    "\n",
    "\n",
    "\n",
    "Something I was realizing last night is substitution goes the other way. x,y,z is the codomain, despite how weird that feels\n",
    "{x’ -> f(g(x,z),y)}\n",
    "makes that feel better. Those codomain vars are on the right now\n",
    "\n",
    "All is well with the world.\n",
    "\n",
    "Are the upper objects full equivalence classes? Seems like a burden. Why can’t the upper objects be individual predicate expressions, what is the set getting us?\n",
    "\n",
    "I think they can. It just wouldn't be a boolean algebra anymore.\n",
    "\n",
    "a = b = c, why can’t an object be {a,b}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lawvere\n",
    "\n",
    "The equalizer in a lawvere theory is E-unification.\n",
    "\n",
    "combinator form of substitutions\n",
    "\n",
    "\n",
    "coalgebra.\n",
    "a -> f a\n",
    "\n",
    "operads\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gat EAT\n",
    "https://ncatlab.org/nlab/show/essentially+algebraic+theory\n",
    "\n",
    "t1 = t2 /\\ t3 = t4 => t5 = t6\n",
    "\n",
    "t5 . solve(par(t1,t3),par(t2, t4)) = t6 . solve(...)\n",
    "\n",
    "This is saying the under the substitution/assumption t1 = t2 ... \n",
    "And I think it's a sefl consitent E assumtionb.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Having equalizers + products is the same as having all finite limits somehow?\n",
    "\n",
    "\n",
    "\n",
    "In egglog, t1 = t2 ,,.... => t3 = t4\n",
    "You can solve e-unify in the body via egraph ematching.\n",
    "\n",
    "But then this asserts a new equality.\n",
    "\n",
    "t1 =E t2 ==> t3 = t4\n",
    "Conditional KB.\n",
    "\n",
    "https://www.youtube.com/watch?v=RmiTOa4b0bA&ab_channel=ToposInstitute CB Aberle: All Concepts are Essentially Algebraic\n",
    "\n",
    "The next one up in evan's hierarchy was\n",
    "locally carteian closed\n",
    "https://ncatlab.org/nlab/show/locally+cartesian+closed+category\n",
    "https://link.springer.com/chapter/10.1007/BFb0022273 On the interpretation of type theory in locally cartesian closed categories . Hofmann\n",
    "\n",
    "burtsall rydeheard style slicing.\n",
    "cod(f) = x =>\n",
    "slice(f)?\n",
    "\n",
    "\n",
    "GAT to EAT relationship. Should probably try to model that first. Or maybe multisorted logic?\n",
    "\n",
    "\n",
    "The monad form of lawvere theory is kind of like the herband model in set? The monad action is applying the constructors of the theories and quitented by axioms?\n",
    "https://anuyts.github.io/files/keml-diagrams.pdf\n",
    "\n",
    "Type -> Ctx style vs  EAT\n",
    "x,y,z -> Type  style  GAT\n",
    "\n",
    "Evocative of the observational vs record approach to tuples\n",
    "prod(x,y)\n",
    "vs q opaque, fst(q) = x, snd(q) = y\n",
    "\n",
    "Type -> ctx\n",
    "Type is total space, ctx is base space\n",
    "\n",
    "dom(subst) = ctx1\n",
    "cod(subst) = ctx2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# refeinment sorts\n",
    "I had notes somewhere about prolog using CLP.\n",
    "\n",
    "https://arxiv.org/pdf/2010.07763 tutorial\n",
    "\n",
    "https://noamz.org/oplss16/refinements-notes.pdf \n",
    "\n",
    "https://proofassistants.stackexchange.com/questions/755/whats-the-relationship-between-refinement-types-and-dependent-types hmm. Pierre-Marie suggest that a insifficiently restricted P in {x | P} can effectively enocde full dependent types. \"realizability interpetation\" in PRL.\n",
    "\n",
    "Does this subsyetms make me closer to cody's Boole?\n",
    "\n",
    "\n",
    "smtlib is basically a simply type programming language. Why not\n",
    "\n",
    "For using new logics in knuckeldragger we can:\n",
    "deep embed in z3\n",
    "shallow embed into z3\n",
    "make new judgement forms at the python metalevel that contain kd.Proof.\n",
    "\n",
    "\n",
    "annotate will be an immediate call to check (?). So annotate will take in Gamma.\n",
    "\n",
    "reflection could be an axiom schema to convert HasType to a kd.Proof. Interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x : Int | x > 0, y : Int | x > y, z : Int | z < y"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from kdrag.all import *\n",
    "@dataclass\n",
    "class Telescope():\n",
    "    vs : list[smt.ExprRef]\n",
    "    preds : list[smt.BoolRef | smt.QuantifierRef] # crucially can contain previous vars\n",
    "    def __init__(self, *vspreds): # could just make the empty context?\n",
    "        self.vs, self.preds = zip(*vspreds)\n",
    "    def __repr__(self):\n",
    "        return \", \".join([f\"{v} : {v.sort()} | {pred}\" for v,pred in zip(self.vs,self.preds)])\n",
    "    def entail(self):\n",
    "        acc = smt.BoolVal(True)\n",
    "    def extend(self, v, pred):\n",
    "        # add a new variable to the context\n",
    "        # should check that previous preds do not contain new v.\n",
    "        return Telescope(self.vs + [v], self.preds + [pred])\n",
    "\n",
    "# more linked list like. Easier to make immutable? Hmm. But lists are so much easier to work with.\n",
    "class Telescope2():\n",
    "    tail : Telescope2\n",
    "    v : smt.ExprRef\n",
    "    pred : smt.BoolRef\n",
    "\n",
    "\n",
    "\n",
    "# as bottom up judgement, base case should take a kd.Proof\n",
    "# This is actually kind of cool.\n",
    "@dataclass\n",
    "class EntailJudge():\n",
    "    ctx: Telescope\n",
    "    c : smt.BoolRef\n",
    "\n",
    "@dataclass\n",
    "class SubClass():\n",
    "    ctx : Telescope\n",
    "    v1 : smt.ExprRef\n",
    "    typ1 : smt.BoolRef\n",
    "    v2 : smt.ExprRef\n",
    "    typ2 : smt.BoolRef\n",
    "    # do we automatically do it in the smart consutrctor or not?\n",
    "    def __init__(self): ...\n",
    "    def __repr__(self):\n",
    "        return f\"{self.ctx} |- {self.t} <: {{ {self.t.sort()} | {self.typ} }}\"\n",
    "\n",
    "@dataclass\n",
    "class HasType():\n",
    "    ctx : Telescope\n",
    "    t : smt.ExprRef\n",
    "    typ : smt.BoolRef\n",
    "    def __repr__(self):\n",
    "        return f\"{self.ctx} |- {self.t} : {{ {self.t.sort()} | {self.typ} }}\"\n",
    "\n",
    "\n",
    "x,y,z = smt.Ints(\"x y z\")\n",
    "\n",
    "Telescope((x, x > 0), (y, x > y), (z, z < y))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RefinedSort():\n",
    "    sort : z3.SortRef\n",
    "    pred : z3.ExprRef # not a boolref. a lambda {x : Sort | pred(x) } -> {y : : sort2 | pred(x,y) }\n",
    "    v : z3.ExprRef\n",
    "    pred : z3.BoolRef # maybe invloing pred\n",
    "    ctx : list[z3.ExprRef] # y : ?  |- {x : sort | pred(x)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 18 (1256577910.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 19\u001b[0;36m\u001b[0m\n\u001b[0;31m    if\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 18\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from z3 import *\n",
    "import z3\n",
    "@dataclass\n",
    "class RSort():\n",
    "    sort : z3.SortRef\n",
    "    pred : z3.BoolRef # self is referred to as var(0)\n",
    "@dataclass\n",
    "class Arr():\n",
    "    dom: RSort\n",
    "    cod: RSort # var(1) refers to var bound in dom.\n",
    "    @property\n",
    "    def sort(self):\n",
    "        return ArraySort(self.dom.sort, self.cod.sort)\n",
    "\n",
    "\n",
    "def entail(gamma, c):\n",
    "    xs = [FreshConst(sort) for sort in gamma]\n",
    "    s = Solver()\n",
    "    s.add(Not(ForAll(xs, substitute_vars(c, *xs))))\n",
    "    assert s.check() == unsat\n",
    "\n",
    "\n",
    "def subtyp(gamma, sort1, sort2):\n",
    "    if isinstance(sort1, Arr) and isinstance(sort2, Arr):\n",
    "        assert subtyp(gamma, sort2.dom, sort1.dom) and subtyp([sort2.dom] + gamma, sort1.cod, sort2.cod)    \n",
    "    elif isinstance(sort1, RSort) and isinstance(sort2, RSort):\n",
    "        assert sort1.sort == sort2.sort\n",
    "        x = FreshConst(sort1.sort)\n",
    "        f = ForAll([x], substitute_vars(Implies(sort1.pred, sort2.pred), x))\n",
    "        assert entail(gamma, f)\n",
    "    else:\n",
    "        raise Exception(\"Unknown type\", sort1, sort2)\n",
    "\n",
    "\n",
    "def synth(gamma, term):\n",
    "    \n",
    "\n",
    "def check(gamma, term, typ):\n",
    "    assert term.sort() == typ.sort\n",
    "    if is_select(term): # app\n",
    "    elif is_quantifier(term) and term.is_lambda():\n",
    "        assert isinstance(typ, Arr)\n",
    "        x, body = open_binder(term)\n",
    "        gamma[x] = typ.dom\n",
    "        return check(gamma, body, typ.cod)\n",
    "    elif term in gamma: # gotta find it\n",
    "        s = gamma[term]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a type\n",
    "a word. paper words. a speronality.\n",
    "\n",
    "bertrand russell, a method to remove paradoxes\n",
    "\n",
    "datatypes\n",
    "\n",
    "a syntactical discipline to maintain abstractions - reynolds\n",
    "\n",
    "compositional analyses - Neel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realizability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Z = namedtuple(\"Z\", \"n\") # zero\n",
    "S = namedtuple(\"S\", \"n\") # succ\n",
    "T = namedtuple(\"T\", \"n m\") # transfer\n",
    "J = namedtuple(\"J\", \"n m q\") # jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primes = [2,3,5,7,11,13,17,19,23,29,31,37,41,43,47]\n",
    "def code(e):\n",
    "    if tuple(e):\n",
    "        acc = 1\n",
    "        for p,c in zip(primes, e):\n",
    "            acc *= p ** code(c)\n",
    "        return primes[0]**acc\n",
    "\n",
    "\n",
    "def decode(e):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = DeclareSort(\"A\")\n",
    "K = Const(\"K\", A)\n",
    "S = Const(\"S\", A)\n",
    "app = Function(\"app\", A, A, A, BoolSort())\n",
    "kd.define\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBE\n",
    "See nbe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import z3\n",
    "TYPE = z3.DeclareSort(\"TYPE\")\n",
    "TERM = z3.DeclareSort(\"TERM\")\n",
    "\n",
    "def check(ctx, term,typ):\n",
    "    is_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from typing import Callable\n",
    "\"\"\"\n",
    "def C(tag, *args):\n",
    "    return tuple[Literal(tag), *args]\n",
    "\n",
    "type L[A] = Literal[A] # not allowed\n",
    "type app = Literal[\"app\"]\n",
    "type Arr[A,B] = Callable[[A],B]\n",
    "type typ = C[\"arr\", typ, typ] | C(\"unit\")\n",
    "type term = C[App, term, term] | C[\"lam\", term] | C[\"var\", int]\n",
    "\"\"\"\n",
    "# This is about as short as I can go. The system doesn't enable abstraction over types. it's pretty rigid\n",
    "\n",
    "type term = tuple[Literal[\"app\"], term, term] | \\\n",
    "            tuple[Literal[\"lam\"], term] | \\\n",
    "            tuple[Literal[\"var\"], int]\n",
    "\n",
    "type typ = tuple[Literal[\"arr\"], typ, typ] | \\\n",
    "           tuple[Literal[\"unit\"]]\n",
    "\n",
    "def pprint(t : term) -> str:\n",
    "    match t:\n",
    "        case (\"barf\",):\n",
    "            return \"barf\"\n",
    "        case (\"app\", f, x):\n",
    "            return f\"{pprint(f)} {pprint(x)}\"\n",
    "        case (\"lam\", x):\n",
    "            return f\"λ{pprint(x)}\"\n",
    "        #case (\"var\", x):\n",
    "        #    return f\"x{x}\"\n",
    "\n",
    "def poo(x : int) -> term:\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "type aexpr = tuple[Literal[\"var\"], str] | \\\n",
    "             tuple[Literal[\"lit\"], int] | \\\n",
    "             tuple[Literal[\"add\"], aexpr, aexpr]\n",
    "\n",
    "def eval(e : aexpr, env : dict[str,int]) -> int:\n",
    "    match e:\n",
    "        case (\"var\", x):\n",
    "            return env[x]\n",
    "        case (\"lit\", x):\n",
    "            return x\n",
    "        case (\"add\", x, y):\n",
    "            return eval(x, env) + eval(y, env)\n",
    "\n",
    "assert eval((\"add\", (\"lit\", 1), (\"var\", \"x\")), {\"x\" : 2}) == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[](old/2024-07/typecheck_pcode_DATALLLLLLLLLLOG.IPYNB)\n",
    "\n",
    "\n",
    "System F\n",
    "\n",
    "types\n",
    "\n",
    "Programming in Martin Lof type theory\n",
    "\n",
    "HOTT - john sterling stuff\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "type Foo[A] = tuple[A,A]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
