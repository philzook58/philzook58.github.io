{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49b1eff0",
   "metadata": {},
   "source": [
    "https://github.com/ftsrg/chc2c\n",
    "extraction\n",
    "\n",
    "https://www.reddit.com/r/ProgrammingLanguages/comments/1aigns2/discussing_isabellehol_a_proof_assistant_for/kova7l5/\n",
    "\n",
    "\"This is a good question.\n",
    "\n",
    "The advantage of higher-order logic over first-order logic is that propositions (and predicates) become first-class objects that you can abstract over in the theory.\n",
    "\n",
    "Similarly, the advantage of type theory over higher-order logic is that types (and type constructors) become first-class objects that you can abstract over in the theory.\n",
    "\n",
    "In that sense, if you understand what higher order logic gives you over first order logic, then you can understand what type theory gives you over higher order logic by analogy.\n",
    "\n",
    "In both cases you can work around these limitations to some extent by using the meta-language as a macro system. For instance, if you only had first-order logic but you wanted to write a lemma that says something about a predicate (say, the strong induction lemma for natural numbers that is generic over some predicate P : nat -> prop), you could write the lemma as a macro that takes as input a predicate represented as a meta-level function that produces a formula, and write the proof of the lemma as a macro that generates a new proof for each new predicate P that the lemma is used on.\n",
    "\n",
    "Similarly, in HOL you cannot write down code that is generic over a type constructor, e.g. code generic over a monad. Nor can you write down lemmas about such generic code. You can write a meta-level macro that does it, similar to how you can work around the limitations of first-order logic regarding propositions and predicates.\n",
    "\n",
    "The big problem with this workaround is that now all your code and lemmas are checked at the use site instead of the definition site, similar to how C++ templates work. This also means that you can never write down and prove such a generic theorem; you can only generate and check instances of it.\n",
    "\n",
    "The other main way to work around these problems is to not work in first order logic, but instead work in some theory built on top of first order logic. That's what ZFC set theory does. You can do something analogous in HOL, by not really working with types at all, but rather work in some sufficiently general un(i)typed universe and always work with predicates/subsets of that.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2cf0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944b1e7b",
   "metadata": {},
   "source": [
    "# solver for\n",
    "\n",
    "Hmmm. Wait. This is a guassian eliminator?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "53b80b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import z3\n",
    "def solve(eqs, x):\n",
    "   s = z3.SimpleSolver()\n",
    "   s.add(eqs)\n",
    "   return s.solve_for([x])\n",
    "x,y,z = z3.Reals('x y z')\n",
    "solve([x + y == z], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6b9109c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.15.0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import z3\n",
    "x,y,z = z3.Reals('x y z')\n",
    "s = z3.Solver()\n",
    "s.add(x + y == z)\n",
    "print(z3.get_version_string())\n",
    "print(s.solve_for([x]))\n",
    "#s.solve_for1(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec3f021b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z3.IntVal(3).py_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6410485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.15.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z3.get_version_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de7d9cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(z, p + y + 5, And(y + -1*z + p <= -5, y + -1*z + p >= -5)), (x, z + -1*y, And(x + y + -1*z >= 0, x + y + -1*z <= 0))]\n"
     ]
    }
   ],
   "source": [
    "import z3\n",
    "x,y,z,p = z3.Reals('x y z p')\n",
    "s = z3.SimpleSolver()\n",
    "s.add(x + y == z)\n",
    "s.add(p + y + 5 == z)\n",
    "s.check()\n",
    "print(s.solve_for([x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb49297",
   "metadata": {},
   "source": [
    "https://github.com/Z3Prover/doc/tree/master/synthesiz3\n",
    "https://github.com/Z3Prover/doc/commit/690d88ba43a7d706d174da2c48279a5d16810a92"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81c7516",
   "metadata": {},
   "source": [
    "# Proof\n",
    "z3 proof objects were an ast.\n",
    "They even had modus ponens?\n",
    "Hmm.\n",
    "Look at z3 and cvc5 proof objects\n",
    "\n",
    "https://ceur-ws.org/Vol-3185/paper9527.pdf simple proof format for SMT\n",
    "https://ceur-ws.org/Vol-3455/invited1.pdf Challenges in SMT Proof Production and Checking for\n",
    "Arithmetic Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "27b05c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'(let ((a!1 (forall ((x Int)) (! (f x) :pattern ((f x))))))\\n(let ((a!2 (assumption (inst a!1 (not (f 1)) (bind 1) (gen 0))\\n                       (or (not a!1) (f 1)))))\\n  (proof-trail (assumption assumption a!1)\\n               (assumption assumption (not (f 1)))\\n               a!2\\n               false)))'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "s = smt.Solver()\n",
    "s.set(\"clause_proof\", True)\n",
    "f = smt.Function(\"f\", smt.IntSort(), smt.BoolSort())\n",
    "s.add(smt.ForAll([x], f(x)))\n",
    "s.add(smt.Not(f(1)))\n",
    "print(s.check())\n",
    "p = s.proof()\n",
    "p.decl()\n",
    "assert not p.sort() == smt.DeclareSort(\"Proof\")\n",
    "p.sexpr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f095d7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Proof = smt.DeclareSort(\"Proof\")\n",
    "andI = smt.Function(\"andI\", Proof, Proof, Proof) # to build multicontext\n",
    "prove = smt.Function(\"prove\", smt.BoolSort(), Proof, Proof)\n",
    "axiom = smt.Function(\"axiom\", smt.BoolSort(), Proof)\n",
    "\n",
    "#instan = smt.Function(\"instan\", Proof, Proof)\n",
    "\n",
    "# both need to be multiarity / parametric\n",
    "#T = smt.TypeVar(\"T\")\n",
    "#herb = smt.Function(\"herb\", smt.ArraySort(), Proof)\n",
    "#instan = smt.Function(\"instan\", Proof, Proof)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ead3730",
   "metadata": {},
   "source": [
    "# spacer\n",
    "\n",
    "Can we use spacer for something? Inductive theorem proving?\n",
    "https://microsoft.github.io/z3guide/programming/Z3%20Python%20-%20Readonly/Fixedpoints\n",
    "https://github.com/Z3Prover/z3/discussions/5013\n",
    "https://github.com/agurfinkel/spacer-on-jupyter/blob/master/Dagstuhl2019.ipynb\n",
    "https://github.com/agurfinkel/spacer-on-jupyter/blob/master/FSU_2023.ipynb\n",
    "https://github.com/agurfinkel/spacer-on-jupyter/blob/master/src/spacer_tutorial/solve.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f07281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solver_horn(chc):\n",
    "    # https://github.com/agurfinkel/spacer-on-jupyter/blob/master/src/spacer_tutorial/solve.py\n",
    "    s = z3.SolverFor('HORN')\n",
    "    s.set('engine', 'spacer')\n",
    "    s.set('spacer.order_children', 2)\n",
    "    s.add(chc)\n",
    "    res = s.check()\n",
    "    if res == z3.sat:\n",
    "        return res, s.model()\n",
    "    elif res == z3.unsat:\n",
    "        return res, s.proof()\n",
    "    else:\n",
    "        return res, None\n",
    "    \n",
    "def interpolate(As, A, Bs, B, shared):\n",
    "    # Uninterpreted predicate Itp over shared symbols\n",
    "    Itp = z3.Function('Itp', [s.sort() for s in shared] + [z3.BoolSort()])\n",
    "\n",
    "    # first CHC: A ==> Itp\n",
    "    left = z3.ForAll([a for a in As], z3.Implies(A, Itp(shared)))\n",
    "    # second CHC: Itp ==> !B\n",
    "    right = z3.ForAll([b for b in Bs], z3.Implies(Itp(shared), z3.Not(B)))\n",
    "\n",
    "    # run CHC solver\n",
    "    res, answer = solve_horn([left, right])\n",
    "\n",
    "    if res == z3.sat:\n",
    "        return answer.eval(Itp(shared))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d19ffa",
   "metadata": {},
   "source": [
    "# tableau / meson\n",
    "\n",
    "For modal logics might be nice\n",
    "Also smt boosted meson is interesting in and of itself.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dbd31f",
   "metadata": {},
   "source": [
    "# brute check\n",
    "For anything 32bit or less we ought to just brute check it.\n",
    "\n",
    "float16 for example. Would give me more confidence.\n",
    "single variable float32 ops\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adbc6f4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac37c2ab",
   "metadata": {},
   "source": [
    "# Solvers\n",
    "##  isabelle\n",
    "Graham was saying why not just download isabelle... Hmm.\n",
    "\n",
    "\n",
    "\n",
    "```bash\n",
    "emconfigure ./configure --enable-ho\n",
    "emmake make AR=\"/home/philip/Downloads/emsdk/upstream/emscripten/emar rcs\"\n",
    "```\n",
    "\n",
    " And had to comment out in Makefile.vars the forced CC and AR values\n",
    "\n",
    "\n",
    "https://github.com/philzook58/eprover/releases/download/E.3.2.5-ho/eprover-ho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77514bd3",
   "metadata": {},
   "source": [
    "bitwuzla\n",
    "cvc5 \n",
    "ytices\n",
    "pysmt\n",
    "\n",
    "bto2\n",
    "moxi\n",
    "\n",
    "implement model checking algorithms?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a427ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyboolector as btor\n",
    "\n",
    "btor.Parse(\"example.btor\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d232c3da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd55d4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import stat\n",
    "filename = \"eprover-ho\"\n",
    "#urllib.request.urlretrieve(\"https://github.com/philzook58/eprover/releases/download/E.3.2.5-ho/eprover-ho\", filename)\n",
    "st = os.stat(filename)\n",
    "    # Add execute permissions for user, group, and others\n",
    "os.chmod(filename, st.st_mode | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9add68db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'# Preprocessing class: HSSSSMSSSSSNFFN.\\n# Scheduled 4 strats onto 8 cores with 300 seconds (2400 total)\\n# Starting new_ho_10 with 1500s (5) cores\\n# Starting ho_unfolding_6 with 300s (1) cores\\n# Starting sh4l with 300s (1) cores\\n# Starting ehoh_best_nonlift_rwall with 300s (1) cores\\n# new_ho_10 with pid 996928 completed with status 9\\n# ho_unfolding_6 with pid 996929 completed with status 9\\n# sh4l with pid 996930 completed with status 9\\n# ehoh_best_nonlift_rwall with pid 996931 completed with status 9\\n# Schedule exhausted\\n# SZS status GaveUp\\n'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.solvers import EProverTHFSolver\n",
    "s = EProverTHFSolver()\n",
    "s.add(x == y)\n",
    "s.check()\n",
    "s.res.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eaebb343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "E 3.2.5-ho \"Puttabong Moondrop\"\n",
      "\n",
      "Usage: eprover [options] [files]\n",
      "\n",
      "Read a set of first-order (or, in the -ho-version, higher-order)\n",
      "clauses and formulae and try to prove the conjecture (if given)\n",
      "or show the set unsatisfiable.\n",
      "\n",
      "Options:\n",
      "\n",
      "   -h\n",
      "  --help\n",
      "    Print a short description of program usage and options.\n",
      "\n",
      "   -V\n",
      "  --version\n",
      "    Print the version number of the prover. Please include this with all bug\n",
      "    reports (if any).\n",
      "\n",
      "   -v\n",
      "  --verbose[=<arg>]\n",
      "    Verbose comments on the progress of the program. This differs from the\n",
      "    output level (below) in that technical information is printed to stderr,\n",
      "    while the output level determines which logical manipulations of the\n",
      "    clauses are printed to stdout. The short form or the long form without\n",
      "    the optional argument is equivalent to --verbose=1.\n",
      "\n",
      "   -o <arg>\n",
      "  --output-file=<arg>\n",
      "    Redirect output into the named file.\n",
      "\n",
      "   -s\n",
      "  --silent\n",
      "    Equivalent to --output-level=0.\n",
      "\n",
      "   -l <arg>\n",
      "  --output-level=<arg>\n",
      "    Select an output level, greater values imply more verbose output. Level 0\n",
      "    produces nearly no output, level 1 will output each clause as it is\n",
      "    processed, level 2 will output generating inferences, level 3 will give a\n",
      "    full protocol including rewrite steps and level 4 will include some\n",
      "    internal clause renamings. Levels >= 2 also imply PCL2 or TSTP formats\n",
      "    (which can be post-processed with suitable tools).\n",
      "\n",
      "   -p\n",
      "  --proof-object[=<arg>]\n",
      "    Generate (and print, in case of success) an internal proof object. Level\n",
      "    0 will not print a proof object, level 1 will build asimple, compact\n",
      "    proof object that only contains inference rules and dependencies, level 2\n",
      "    will build a proof object where inferences are unambiguously described by\n",
      "    giving inference positions, and level 3 will expand this to a proof\n",
      "    object where all intermediate results are explicit. This feature is under\n",
      "    development, so far only level 0 and 1 are operational. The proof object\n",
      "    will be provided in TPTP-3 or PCL syntax, depending on input format and\n",
      "    explicit settings. The --proof-graph option will suppress normal output\n",
      "    of the proof object in favour of a graphial representation. The short\n",
      "    form or the long form without the optional argument is equivalent to\n",
      "    --proof-object=1.\n",
      "\n",
      "  --proof-graph[=<arg>]\n",
      "    Generate (and print, in case of success) an internal proof object in the\n",
      "    form of a GraphViz dot graph. The optional argument can be 1 (nodes are\n",
      "    labelled with just the name of the clause/formula), 2 (nodes are labelled\n",
      "    with the TPTP clause/formula) or 3  (nodes also labelled with\n",
      "    source/inference record. The option without the optional argument is\n",
      "    equivalent to --proof-graph=3.\n",
      "\n",
      "  --proof-statistics\n",
      "    Print various statistics of the proof object.\n",
      "\n",
      "   -d\n",
      "  --full-deriv\n",
      "    Include all derived formuas/clauses in the proof graph/proof object, not\n",
      "    just the ones contributing to the actual proof.\n",
      "\n",
      "  --force-deriv[=<arg>]\n",
      "    Force output of the derivation even in cases where the prover terminates\n",
      "    in an indeterminate state. By default, the deriviation of all processed\n",
      "    clauses is included in the derivation object. With argument 2, the\n",
      "    derivation of all clauses will be printed. The option without the\n",
      "    optional argument is equivalent to --force-deriv=1.\n",
      "\n",
      "  --record-gcs\n",
      "    Record given-clause selection as separate (pseudo-)inferences and\n",
      "    preserve the form of given clauses evaluated and selected via archiving\n",
      "    for analysis and possibly machine learning.\n",
      "\n",
      "  --training-examples[=<arg>]\n",
      "    Generate and process training examples from the proof search object.\n",
      "    Implies --record-gcs. The argument is a binary or of the desired\n",
      "    processing. Bit zero prints positive exampels. Bit 1 prints negative\n",
      "    examples. Additional selectors will be added later. The option without\n",
      "    the optional argument is equivalent to --training-examples=1.\n",
      "\n",
      "  --pcl-terms-compressed\n",
      "    Print terms in the PCL output in shared representation.\n",
      "\n",
      "  --pcl-compact\n",
      "    Print PCL steps without additional spaces for formatting (safes disk\n",
      "    space for large protocols).\n",
      "\n",
      "  --pcl-shell-level[=<arg>]\n",
      "    Determines level to which clauses and formulas are suppressed in the\n",
      "    output. Level 0 will print all, level 1 will only print initial\n",
      "    clauses/formulas, level 2 will print no clauses or axioms. All levels\n",
      "    will still print the dependency graph. The option without the optional\n",
      "    argument is equivalent to --pcl-shell-level=1.\n",
      "\n",
      "  --print-statistics\n",
      "    Print the inference statistics (only relevant for output level <=1,\n",
      "    otherwise they are printed automatically.\n",
      "\n",
      "   -0\n",
      "  --print-detailed-statistics\n",
      "    Print data about the proof state that is potentially expensive to\n",
      "    collect. Includes number of term cells and number of rewrite steps. This\n",
      "    implies the previous option.\n",
      "\n",
      "   -S\n",
      "  --print-saturated[=<arg>]\n",
      "    Print the (semi-) saturated clause sets after terminating the saturation\n",
      "    process. The argument given describes which parts should be printed in\n",
      "    which order. Legal characters are 'teigEIGaA', standing for type\n",
      "    declarations, processed positive units, processed negative units,\n",
      "    processed non-units, unprocessed positive units, unprocessed negative\n",
      "    units, unprocessed non-units, and two types of additional equality\n",
      "    axioms, respectively. Equality axioms will only be printed if the\n",
      "    original specification contained real equality. In this case, 'a'\n",
      "    requests axioms in which a separate substitutivity axiom is given for\n",
      "    each argument position of a function or predicate symbol, while 'A'\n",
      "    requests a single substitutivity axiom (covering all positions) for each\n",
      "    symbol. The short form or the long form without the optional argument is\n",
      "    equivalent to --print-saturated=eigEIG.\n",
      "\n",
      "  --print-sat-info\n",
      "    Print additional information (clause number, weight, etc) as a comment\n",
      "    for clauses from the semi-saturated end system.\n",
      "\n",
      "  --filter-saturated[=<arg>]\n",
      "    Filter the  (semi-) saturated clause sets after terminating the\n",
      "    saturation process. The argument is a string describing which operations\n",
      "    to take (and in which order). Options are 'u' (remove all clauses with\n",
      "    more than one literal), 'c' (delete all but one copy of identical\n",
      "    clauses, 'n', 'r', 'f' (forward contraction, unit-subsumption only, no\n",
      "    rewriting, rewriting with rules only, full rewriting, respectively), and\n",
      "    'N', 'R' and 'F' (as their lower case counterparts, but with\n",
      "    non-unit-subsumption enabled as well). The option without the optional\n",
      "    argument is equivalent to --filter-saturated=Fc.\n",
      "\n",
      "  --syntax-only\n",
      "    Stop after parsing, i.e. only check if the input can be parsed correcly.\n",
      "\n",
      "  --prune\n",
      "    Stop after relevancy pruning, SInE pruning, and output of the initial\n",
      "    clause- and formula set. This will automatically set output level to 4 so\n",
      "    that the pruned problem specification is printed. Note that the desired\n",
      "    pruning methods must still be specified (e.g. '--sine=Auto').\n",
      "\n",
      "  --cnf\n",
      "    Convert the input problem into clause normal form and print it. This is\n",
      "    (nearly) equivalent to '--print-saturated=eigEIG\n",
      "    --processed-clauses-limit=0' and will by default perform some usually\n",
      "    useful simplifications. You can additionally specify e.g.\n",
      "    '--no-preprocessing' if you want just the result of CNF translation.\n",
      "\n",
      "  --print-pid\n",
      "    Print the process id of the prover as a comment after option processing.\n",
      "\n",
      "  --print-version\n",
      "    Print the version number of the prover as a comment after option\n",
      "    processing. Note that unlike -version, the prover will not terminate, but\n",
      "    proceed normally.\n",
      "\n",
      "  --error-on-empty\n",
      "    Return with an error code if the input file contains no clauses.\n",
      "    Formally, the empty clause set (as an empty conjunction of clauses) is\n",
      "    trivially satisfiable, and E will treat any empty input set as\n",
      "    satisfiable. However, in composite systems this is more often a sign that\n",
      "    something went wrong. Use this option to catch such bugs.\n",
      "\n",
      "   -m <arg>\n",
      "  --memory-limit=<arg>\n",
      "    Limit the memory the prover may use. The argument is the allowed amount\n",
      "    of memory in MB. If you use the argument 'Auto', the system will try to\n",
      "    figure out the amount of physical memory of your machine and claim most\n",
      "    of it. This option may not work everywhere, due to broken and/or strange\n",
      "    behaviour of setrlimit() in some UNIX implementations, and due to the\n",
      "    fact that I know of no portable way to figure out the physical memory in\n",
      "    a machine. Both the option and the 'Auto' version do work under all\n",
      "    tested versions of Solaris and GNU/Linux. Due to problems with limit data\n",
      "    types, it is currently impossible to set a limit of more than 2 GB (2048\n",
      "    MB).\n",
      "\n",
      "  --cpu-limit[=<arg>]\n",
      "    Limit the (per core) cpu time the prover should run. The optional\n",
      "    argument is the CPU time in seconds. The prover will terminate\n",
      "    immediately after reaching the time limit, regardless of internal state.\n",
      "    As a side effect, this option will inhibit core file writing. Please note\n",
      "    that if you use both --cpu-limit and --soft-cpu-limit, the soft limit has\n",
      "    to be smaller than the hard limit to have any effect.  The option without\n",
      "    the optional argument is equivalent to --cpu-limit=300.\n",
      "\n",
      "  --soft-cpu-limit[=<arg>]\n",
      "    Limit the cpu time the prover should spend in the main saturation phase.\n",
      "    The prover will then terminate gracefully, i.e. it will perform\n",
      "    post-processing, filtering and printing of unprocessed clauses, if these\n",
      "    options are selected. Note that for some filtering options (in particular\n",
      "    those which perform full subsumption), the post-processing time may well\n",
      "    be larger than the saturation time. This option is particularly useful if\n",
      "    you want to use E as a preprocessor or lemma generator in a larger\n",
      "    system. The option without the optional argument is equivalent to\n",
      "    --soft-cpu-limit=290.\n",
      "\n",
      "   -R\n",
      "  --resources-info\n",
      "    Give some information about the resources used by the prover. You will\n",
      "    usually get CPU time information. On systems returning more information\n",
      "    with the rusage() system call, you will also get information about memory\n",
      "    consumption.\n",
      "\n",
      "  --select-strategy=<arg>\n",
      "    Select one of the built-in strategies and set all proof search parameters\n",
      "    accordingly.\n",
      "\n",
      "  --print-strategy[=<arg>]\n",
      "    Print a representation of all search parameters and their setting of a\n",
      "    given strategy, then terminate. If no argument is given, the current\n",
      "    strategy is printed. Use the reserved name '>all-strats<'to get a\n",
      "    description of all built-in strategies,  '>all-names<' to get a list of\n",
      "    all names of strategies. The option without the optional argument is\n",
      "    equivalent to --print-strategy=>current-strategy<.\n",
      "\n",
      "  --parse-strategy=<arg>\n",
      "    Parse the previously printed representation of strategy and set all proof\n",
      "    search parameters accordingly.\n",
      "\n",
      "   -C <arg>\n",
      "  --processed-clauses-limit=<arg>\n",
      "    Set the maximal number of clauses to process (i.e. the number of\n",
      "    traversals of the main-loop).\n",
      "\n",
      "   -P <arg>\n",
      "  --processed-set-limit=<arg>\n",
      "    Set the maximal size of the set of processed clauses. This differs from\n",
      "    the previous option in that redundant and back-simplified processed\n",
      "    clauses are not counted.\n",
      "\n",
      "   -U <arg>\n",
      "  --unprocessed-limit=<arg>\n",
      "    Set the maximal size of the set of unprocessed clauses. This is a\n",
      "    termination condition, not something to use to control the deletion of\n",
      "    bad clauses. Compare --delete-bad-limit.\n",
      "\n",
      "   -T <arg>\n",
      "  --total-clause-set-limit=<arg>\n",
      "    Set the maximal size of the set of all clauses. See previous option.\n",
      "\n",
      "  --generated-limit=<arg>\n",
      "    Set the maximal number of generated clauses before the proof search\n",
      "    stops. This is a reasonable (though not great) estimate of the work done.\n",
      "\n",
      "  --tb-insert-limit=<arg>\n",
      "    Set the maximal number of of term bank term top insertions. This is a\n",
      "    reasonable (though not great) estimate of the work done.\n",
      "\n",
      "  --answers[=<arg>]\n",
      "    Set the maximal number of answers to print for existentially quantified\n",
      "    questions. Without this option, the prover terminates after the first\n",
      "    answer found. If the value is different from 1, the prover is no longer\n",
      "    guaranteed to terminate, even if there is a finite number of answers. The\n",
      "    option without the optional argument is equivalent to\n",
      "    --answers=2147483647.\n",
      "\n",
      "  --conjectures-are-questions\n",
      "    Treat all conjectures as questions to be answered. This is a wart\n",
      "    necessary because CASC-J6 has categories requiring answers, but does not\n",
      "    yet support the 'question' type for formulas.\n",
      "\n",
      "   -n\n",
      "  --eqn-no-infix\n",
      "    In LOP, print equations in prefix notation equal(x,y).\n",
      "\n",
      "   -e\n",
      "  --full-equational-rep\n",
      "    In LOP. print all literals as equations, even non-equational ones.\n",
      "\n",
      "  --lop-in\n",
      "    Set E-LOP as the input format. If no input format is selected by this or\n",
      "    one of the following options, E will guess the input format based on the\n",
      "    first token. It will almost always correctly recognize TPTP-3, but it may\n",
      "    misidentify E-LOP files that use TPTP meta-identifiers as logical\n",
      "    symbols.\n",
      "\n",
      "  --pcl-out\n",
      "    Set PCL as the proof object output format.\n",
      "\n",
      "  --tptp-in\n",
      "    Set TPTP-2 as the input format (but note that includes are still handled\n",
      "    according to TPTP-3 semantics).\n",
      "\n",
      "  --tptp-out\n",
      "    Print TPTP format instead of E-LOP. Implies --eqn-no-infix and will\n",
      "    ignore --full-equational-rep.\n",
      "\n",
      "  --tptp-format\n",
      "    Equivalent to --tptp-in and --tptp-out.\n",
      "\n",
      "  --tptp2-in\n",
      "    Synonymous with --tptp-in.\n",
      "\n",
      "  --tptp2-out\n",
      "    Synonymous with --tptp-out.\n",
      "\n",
      "  --tptp2-format\n",
      "    Synonymous with --tptp-format.\n",
      "\n",
      "  --tstp-in\n",
      "    Set TPTP-3 as the input format TPTP-3 syntax is still under development,\n",
      "    and any given version in E may not be fully conforming at all times. E\n",
      "    works on all TPTP 8.2.0 FOF and CNF files (including includes).\n",
      "\n",
      "  --tstp-out\n",
      "    Print output clauses in TPTP-3 syntax. In particular, for output levels\n",
      "    >=2, write derivations as TPTP-3 derivations.\n",
      "\n",
      "  --tstp-format\n",
      "    Equivalent to --tstp-in and --tstp-out.\n",
      "\n",
      "  --tptp3-in\n",
      "    Synonymous with --tstp-in.\n",
      "\n",
      "  --tptp3-out\n",
      "    Synonymous with --tstp-out.\n",
      "\n",
      "  --tptp3-format\n",
      "    Synonymous with --tstp-format.\n",
      "\n",
      "  --auto\n",
      "    Automatically determine settings for proof search.\n",
      "\n",
      "  --auto-schedule[=<arg>]\n",
      "    Use the (experimental) strategy scheduling. This will try several\n",
      "    different fully specified search strategies (aka \"Auto-Modes\"), one after\n",
      "    the other, until a proof or saturation is found, or the time limit is\n",
      "    exceeded. The optional argument is the number of CPUs on which the\n",
      "    schedule is going to be executed on. By default, the schedule is executed\n",
      "    on a single core. To execute on all cores of a system, set the argument\n",
      "    to 'Auto', but note that this will use all reported cores (even\n",
      "    low-performance efficiency cores, if available on the hardware platform\n",
      "    and reported by the OS). The option without the optional argument is\n",
      "    equivalent to --auto-schedule=1.\n",
      "\n",
      "  --force-preproc-sched=<arg>\n",
      "    When autoscheduling is used, make sure that preprocessing schedule is\n",
      "    inserted in the search categories\n",
      "\n",
      "  --serialize-schedule=<arg>\n",
      "    Convert parallel auto-schedule into serialized one.\n",
      "\n",
      "  --satauto-schedule[=<arg>]\n",
      "    Use strategy scheduling without SInE, thus maintaining completeness. The\n",
      "    option without the optional argument is equivalent to\n",
      "    --satauto-schedule=1.\n",
      "\n",
      "  --no-preprocessing\n",
      "    Do not perform preprocessing on the initial clause set. Preprocessing\n",
      "    currently removes tautologies and orders terms, literals and clauses in a\n",
      "    certain (\"canonical\") way before anything else happens. Unless limited by\n",
      "    one of the following options, it will also unfold equational definitions.\n",
      "\n",
      "  --eq-unfold-limit=<arg>\n",
      "    During preprocessing, limit unfolding (and removing) of equational\n",
      "    definitions to those where the expanded definition is at most the given\n",
      "    limit bigger (in terms of standard weight) than the defined term.\n",
      "\n",
      "  --eq-unfold-maxclauses=<arg>\n",
      "    During preprocessing, don't try unfolding of equational definitions if\n",
      "    the problem has more than this limit of clauses.\n",
      "\n",
      "  --no-eq-unfolding\n",
      "    During preprocessing, abstain from unfolding (and removing) equational\n",
      "    definitions.\n",
      "\n",
      "  --goal-defs[=<arg>]\n",
      "    Introduce Twee-style equational definitions for ground terms in\n",
      "    conjecture clauses. The argument can be None, All or Neg, which will only\n",
      "    consider ground terms from negative literals in the CNF (to be\n",
      "    implemented). The option without the optional argument is equivalent to\n",
      "    --goal-defs=All.\n",
      "\n",
      "  --goal-subterm-defs\n",
      "    Introduce goal definitions for all conjecture ground subterms. The\n",
      "    default is to only introduce them for the maximal (with respect to the\n",
      "    subterm relation) ground terms in conjecture clauses (to be implemented).\n",
      "\n",
      "  --sine[=<arg>]\n",
      "    Apply SInE to prune the unprocessed axioms with the specified filter.\n",
      "    'Auto' will automatically pick a filter. The option without the optional\n",
      "    argument is equivalent to --sine=Auto.\n",
      "\n",
      "  --rel-pruning-level[=<arg>]\n",
      "    Perform relevancy pruning up to the given level on the unprocessed\n",
      "    axioms. The option without the optional argument is equivalent to\n",
      "    --rel-pruning-level=3.\n",
      "\n",
      "  --presat-simplify[=<arg>]\n",
      "    Before proper saturation do a complete interreduction of the proof state.\n",
      "    The option without the optional argument is equivalent to\n",
      "    --presat-simplify=true.\n",
      "\n",
      "  --ac-handling[=<arg>]\n",
      "    Select AC handling mode, i.e. determine what to do with redundant AC\n",
      "    tautologies. The default is equivalent to 'DiscardAll', the other\n",
      "    possible values are 'None' (to disable AC handling), 'KeepUnits', and\n",
      "    'KeepOrientable'. The option without the optional argument is equivalent\n",
      "    to --ac-handling=KeepUnits.\n",
      "\n",
      "  --ac-non-aggressive\n",
      "    Do AC resolution on negative literals only on processing (by default, AC\n",
      "    resolution is done after clause creation). Only effective if AC handling\n",
      "    is not disabled.\n",
      "\n",
      "   -W <arg>\n",
      "  --literal-selection-strategy=<arg>\n",
      "    Choose a strategy for selection of negative literals. There are two\n",
      "    special values for this option: NoSelection will select no literal (i.e.\n",
      "    perform normal superposition) and NoGeneration will inhibit all\n",
      "    generating inferences. For a list of the other (hopefully\n",
      "    self-documenting) values run 'eprover -W none'. There are two variants of\n",
      "    each strategy. The one prefixed with 'P' will allow paramodulation into\n",
      "    maximal positive literals in addition to paramodulation into maximal\n",
      "    selected negative literals.\n",
      "\n",
      "  --no-generation\n",
      "    Don't perform any generating inferences (equivalent to\n",
      "    --literal-selection-strategy=NoGeneration).\n",
      "\n",
      "  --select-on-processing-only\n",
      "    Perform literal selection at processing time only (i.e. select only in\n",
      "    the _given clause_), not before clause evaluation. This is relevant\n",
      "    because many clause selection heuristics give special consideration to\n",
      "    maximal or selected literals.\n",
      "\n",
      "   -i\n",
      "  --inherit-paramod-literals\n",
      "    Always select the negative literals a previous inference paramodulated\n",
      "    into (if possible). If no such literal exists, select as dictated by the\n",
      "    selection strategy.\n",
      "\n",
      "   -j\n",
      "  --inherit-goal-pm-literals\n",
      "    In a goal (all negative clause), always select the negative literals a\n",
      "    previous inference paramodulated into (if possible). If no such literal\n",
      "    exists, select as dictated by the selection strategy.\n",
      "\n",
      "  --inherit-conjecture-pm-literals\n",
      "    In a conjecture-derived clause, always select the negative literals a\n",
      "    previous inference paramodulated into (if possible). If no such literal\n",
      "    exists, select as dictated by the selection strategy.\n",
      "\n",
      "  --selection-pos-min=<arg>\n",
      "    Set a lower limit for the number of positive literals a clause must have\n",
      "    to be eligible for literal selection.\n",
      "\n",
      "  --selection-pos-max=<arg>\n",
      "    Set a upper limit for the number of positive literals a clause can have\n",
      "    to be eligible for literal selection.\n",
      "\n",
      "  --selection-neg-min=<arg>\n",
      "    Set a lower limit for the number of negative literals a clause must have\n",
      "    to be eligible for literal selection.\n",
      "\n",
      "  --selection-neg-max=<arg>\n",
      "    Set a upper limit for the number of negative literals a clause can have\n",
      "    to be eligible for literal selection.\n",
      "\n",
      "  --selection-all-min=<arg>\n",
      "    Set a lower limit for the number of literals a clause must have to be\n",
      "    eligible for literal selection.\n",
      "\n",
      "  --selection-all-max=<arg>\n",
      "    Set an upper limit for the number of literals a clause must have to be\n",
      "    eligible for literal selection.\n",
      "\n",
      "  --selection-weight-min=<arg>\n",
      "    Set the minimum weight a clause must have to be eligible for literal\n",
      "    selection.\n",
      "\n",
      "  --prefer-initial-clauses\n",
      "    Always process all initial clauses first.\n",
      "\n",
      "   -x <arg>\n",
      "  --expert-heuristic=<arg>\n",
      "    Select one of the clause selection heuristics. Currently at least\n",
      "    available: Auto, Weight, StandardWeight, RWeight, FIFO, LIFO, Uniq,\n",
      "    UseWatchlist. For a full list check HEURISTICS/che_proofcontrol.c. Auto\n",
      "    is recommended if you only want to find a proof. It is special in that it\n",
      "    will also set some additional options. To have optimal performance, you\n",
      "    also should specify -tAuto to select a good term ordering. LIFO is unfair\n",
      "    and will make the prover incomplete. Uniq is used internally and is not\n",
      "    very useful in most cases. You can define more heuristics using the\n",
      "    option -H (see below).\n",
      "\n",
      "  --filter-orphans-limit[=<arg>]\n",
      "    Orphans are unprocessed clauses where one of the parents has been removed\n",
      "    by back-simolification. They are redundant and usually removed lazily\n",
      "    (i.e. only when they are selected for processing). With this option you\n",
      "    can select a limit on back-simplified clauses  after which orphans will\n",
      "    be eagerly deleted. The option without the optional argument is\n",
      "    equivalent to --filter-orphans-limit=100.\n",
      "\n",
      "  --forward-contract-limit[=<arg>]\n",
      "    Set a limit on the number of processed clauses after which the\n",
      "    unprocessed clause set will be re-simplified and reweighted.  The option\n",
      "    without the optional argument is equivalent to\n",
      "    --forward-contract-limit=80000.\n",
      "\n",
      "  --delete-bad-limit[=<arg>]\n",
      "    Set the number of storage units after which bad clauses are deleted\n",
      "    without further consideration. This causes the prover to be potentially\n",
      "    incomplete, but will allow you to limit the maximum amount of memory used\n",
      "    fairly well. The prover will tell you if a proof attempt failed due to\n",
      "    the incompleteness introduced by this option. It is recommended to set\n",
      "    this limit significantly higher than --filter-limit or\n",
      "    --filter-copies-limit. If you select -xAuto and set a memory limit, the\n",
      "    prover will determine a good value automatically. The option without the\n",
      "    optional argument is equivalent to --delete-bad-limit=1500000.\n",
      "\n",
      "  --assume-completeness\n",
      "    There are various way (e.g. the next few options) to configure the prover\n",
      "    to be strongly incomplete in the general case. E will detect when such an\n",
      "    option is selected and return corresponding exit states (i.e. it will not\n",
      "    claim satisfiability just because it ran out of unprocessed clauses). If\n",
      "    you _know_ that for your class of problems the selected strategy is still\n",
      "    complete, use this option to tell the system that this is the case.\n",
      "\n",
      "  --assume-incompleteness\n",
      "    This option instructs the prover to assume incompleteness (typically\n",
      "    because the axiomatization already is incomplete because axioms have been\n",
      "    filtered before they are handed to the system.\n",
      "\n",
      "  --disable-eq-factoring\n",
      "    Disable equality factoring. This makes the prover incomplete for general\n",
      "    non-Horn problems, but helps for some specialized classes. It is not\n",
      "    necessary to disable equality factoring for Horn problems, as Horn\n",
      "    clauses are not factored anyways.\n",
      "\n",
      "  --disable-paramod-into-neg-units\n",
      "    Disable paramodulation into negative unit clause. This makes the prover\n",
      "    incomplete in the general case, but helps for some specialized classes.\n",
      "\n",
      "  --condense\n",
      "    Enable condensing for the given clause. Condensing replaces a clause by a\n",
      "    more general factor (if such a factor exists).\n",
      "\n",
      "  --condense-aggressive\n",
      "    Enable condensing for the given and newly generated clauses.\n",
      "\n",
      "  --disable-given-clause-fw-contraction\n",
      "    Disable simplification and subsumption of the newly selected given clause\n",
      "    (clauses are still simplified when they are generated). In general, this\n",
      "    breaks some basic assumptions of the DISCOUNT loop proof search\n",
      "    procedure. However, there are some problem classes in which  this\n",
      "    simplifications empirically never occurs. In such cases, we can save\n",
      "    significant overhead. The option _should_ work in all cases, but is not\n",
      "    expected to improve things in most cases.\n",
      "\n",
      "  --simul-paramod\n",
      "    Use simultaneous paramodulation to implement superposition. Default is to\n",
      "    use plain paramodulation.\n",
      "\n",
      "  --oriented-simul-paramod\n",
      "    Use simultaneous paramodulation for oriented from-literals. This is an\n",
      "    experimental feature.\n",
      "\n",
      "  --supersimul-paramod\n",
      "    Use supersimultaneous paramodulation to implement superposition. Default\n",
      "    is to use plain paramodulation.\n",
      "\n",
      "  --oriented-supersimul-paramod\n",
      "    Use supersimultaneous paramodulation for oriented from-literals. This is\n",
      "    an experimental feature.\n",
      "\n",
      "  --split-clauses[=<arg>]\n",
      "    Determine which clauses should be subject to splitting. The argument is\n",
      "    the binary 'OR' of values for the desired classes:\n",
      "         1:  Horn clauses\n",
      "         2:  Non-Horn clauses\n",
      "         4:  Negative clauses\n",
      "         8:  Positive clauses\n",
      "        16:  Clauses with both positive and negative literals\n",
      "    Each set bit adds that class to the set of clauses which will be split.\n",
      "    The option without the optional argument is equivalent to\n",
      "    --split-clauses=7.\n",
      "\n",
      "  --split-method=<arg>\n",
      "    Determine how to treat ground literals in splitting. The argument is\n",
      "    either '0' to denote no splitting of ground literals (they are all\n",
      "    assigned to the first split clause produced), '1' to denote that all\n",
      "    ground literals should form a single new clause, or '2', in which case\n",
      "    ground literals are treated as usual and are all split off into\n",
      "    individual clauses.\n",
      "\n",
      "  --split-aggressive\n",
      "    Apply splitting to new clauses (after simplification) and before\n",
      "    evaluation. By default, splitting (if activated) is only performed on\n",
      "    selected clauses. \n",
      "\n",
      "  --split-reuse-defs\n",
      "    If possible, reuse previous definitions for splitting.\n",
      "\n",
      "  --disequality-decomposition[=<arg>]\n",
      "    Enable the disequality decomposition inference. The optional argument is\n",
      "    the maximal literal number of clauses considered for the inference. The\n",
      "    option without the optional argument is equivalent to\n",
      "    --disequality-decomposition=1024.\n",
      "\n",
      "  --disequality-decomp-maxarity[=<arg>]\n",
      "    Limit disequality decomposition to function symbols of at most the given\n",
      "    arity. The option without the optional argument is equivalent to\n",
      "    --disequality-decomp-maxarity=1.\n",
      "\n",
      "   -t <arg>\n",
      "  --term-ordering=<arg>\n",
      "    Select an ordering type (currently Auto, LPO, LPO4, KBO or KBO6). -tAuto\n",
      "    is suggested, in particular with -xAuto. KBO and KBO6 are different\n",
      "    implementations of the same ordering, KBO6 is usually faster and has had\n",
      "    more testing. Similarly, LPO4 is a new, equivalent but superior\n",
      "    implementation of LPO.\n",
      "\n",
      "   -w <arg>\n",
      "  --order-weight-generation=<arg>\n",
      "    Select a method for the generation of weights for use with the term\n",
      "    ordering. Run 'eprover -w none' for a list of options.\n",
      "\n",
      "  --order-weights=<arg>\n",
      "    Describe a (partial) assignments of weights to function symbols for term\n",
      "    orderings (in particular, KBO). You can specify a list of weights of the\n",
      "    form 'f1:w1,f2:w2, ...'. Since a total weight assignment is needed, E\n",
      "    will _first_ apply any weight generation scheme specified (or the default\n",
      "    one), and then modify the weights as specified. Note that E performs only\n",
      "    very basic sanity checks, so you probably can specify weights that break\n",
      "    KBO constraints.\n",
      "\n",
      "   -G <arg>\n",
      "  --order-precedence-generation=<arg>\n",
      "    Select a method for the generation of a precedence for use with the term\n",
      "    ordering. Run 'eprover -G none' for a list of options.\n",
      "\n",
      "  --prec-pure-conj[=<arg>]\n",
      "    Set a weight for symbols that occur in conjectures only to determinewhere\n",
      "    to place it in the precedence. This value is used for a roughpre-order,\n",
      "    the normal schemes only sort within symbols with the sameoccurrence\n",
      "    modifier. The option without the optional argument is equivalent to\n",
      "    --prec-pure-conj=10.\n",
      "\n",
      "  --prec-conj-axiom[=<arg>]\n",
      "    Set a weight for symbols that occur in both conjectures and axiomsto\n",
      "    determine where to place it in the precedence. This value is used for a\n",
      "    rough pre-order, the normal schemes only sort within symbols with the\n",
      "    same occurrence modifier. The option without the optional argument is\n",
      "    equivalent to --prec-conj-axiom=5.\n",
      "\n",
      "  --prec-pure-axiom[=<arg>]\n",
      "    Set a weight for symbols that occur in axioms only to determine where to\n",
      "    place it in the precedence. This value is used for a rough pre-order, the\n",
      "    normal schemes only sort within symbols with the same occurrence\n",
      "    modifier. The option without the optional argument is equivalent to\n",
      "    --prec-pure-axiom=2.\n",
      "\n",
      "  --prec-skolem[=<arg>]\n",
      "    Set a weight for Skolem symbols to determine where to place it in the\n",
      "    precedence. This value is used for a rough pre-order, the normal schemes\n",
      "    only sort within symbols with the same occurrence modifier. The option\n",
      "    without the optional argument is equivalent to --prec-skolem=2.\n",
      "\n",
      "  --prec-defpred[=<arg>]\n",
      "    Set a weight for introduced predicate symbols (usually via definitional\n",
      "    CNF or clause splitting) to determine where to place it in the\n",
      "    precedence. This value is used for a rough pre-order, the normal schemes\n",
      "    only sort within symbols with the same occurrence modifier. The option\n",
      "    without the optional argument is equivalent to --prec-defpred=2.\n",
      "\n",
      "   -c <arg>\n",
      "  --order-constant-weight=<arg>\n",
      "    Set a special weight > 0 for constants in the term ordering. By default,\n",
      "    constants are treated like other function symbols.\n",
      "\n",
      "  --precedence[=<arg>]\n",
      "    Describe a (partial) precedence for the term ordering used for the proof\n",
      "    attempt. You can specify a comma-separated list of precedence chains,\n",
      "    where a precedence chain is a list of function symbols (which all have to\n",
      "    appear in the proof problem), connected by >, <, or =. If this option is\n",
      "    used in connection with --order-precedence-generation, the partial\n",
      "    ordering will be completed using the selected method, otherwise the\n",
      "    prover runs with a non-ground-total ordering. The option without the\n",
      "    optional argument is equivalent to --precedence=.\n",
      "\n",
      "  --lpo-recursion-limit[=<arg>]\n",
      "    Set a depth limit for LPO comparisons. Most comparisons do not need more\n",
      "    than 10 or 20 levels of recursion. By default, recursion depth is limited\n",
      "    to 1000 to avoid stack overflow problems. If the limit is reached, the\n",
      "    prover assumes that the terms are uncomparable. Smaller values make the\n",
      "    comparison attempts faster, but less exact. Larger values have the\n",
      "    opposite effect. Values up to 20000 should be save on most operating\n",
      "    systems. If you run into segmentation faults while using LPO or LPO4,\n",
      "    first try to set this limit to a reasonable value. If the problem\n",
      "    persists, send a bug report ;-) The option without the optional argument\n",
      "    is equivalent to --lpo-recursion-limit=100.\n",
      "\n",
      "  --restrict-literal-comparisons\n",
      "    Make all literals uncomparable in the term ordering (i.e. do not use the\n",
      "    term ordering to restrict paramodulation, equality resolution and\n",
      "    factoring to certain literals. This is necessary to make\n",
      "    Set-of-Support-strategies complete for the non-equational case (It still\n",
      "    is incomplete for the equational case, but pretty useless anyways).\n",
      "\n",
      "  --literal-comparison=<arg>\n",
      "    Modify how literal comparisons are done. 'None' is equivalent to the\n",
      "    previous option, 'Normal' uses the normal lifting of the term ordering,\n",
      "    'TFOEqMax' uses the equivalent of a transfinite ordering deciding on the\n",
      "    predicate symbol and making equational literals maximal (note that this\n",
      "    setting makes the prover incomplere), and 'TFOEqMin' modifies this by\n",
      "    making equational symbols minimal.\n",
      "\n",
      "  --sos-uses-input-types\n",
      "    If input is TPTP format, use TPTP conjectures for initializing the Set of\n",
      "    Support. If not in TPTP format, use E-LOP queries (clauses of the form\n",
      "    ?-l(X),...,m(Y)). Normally, all negative clauses are used. Please note\n",
      "    that most E heuristics do not use this information at all, it is\n",
      "    currently only useful for certain parameter settings (including the\n",
      "    SimulateSOS priority function).\n",
      "\n",
      "  --destructive-er\n",
      "    Allow destructive equality resolution inferences on pure-variable\n",
      "    literals of the form X!=Y, i.e. replace the original clause with the\n",
      "    result of an equality resolution inference on this literal.\n",
      "\n",
      "  --strong-destructive-er\n",
      "    Allow destructive equality resolution inferences on literals of the form\n",
      "    X!=t (where X does not occur in t), i.e. replace the original clause with\n",
      "    the result of an equality resolution inference on this literal. Unless I\n",
      "    am brain-dead, this maintains completeness, although the proof is rather\n",
      "    tricky.\n",
      "\n",
      "  --destructive-er-aggressive\n",
      "    Apply destructive equality resolution to all newly generated clauses, not\n",
      "    just to selected clauses. Implies --destructive-er.\n",
      "\n",
      "  --forward-context-sr\n",
      "    Apply contextual simplify-reflect with processed clauses to the given\n",
      "    clause.\n",
      "\n",
      "  --forward-context-sr-aggressive\n",
      "    Apply contextual simplify-reflect with processed clauses to new clauses.\n",
      "    Implies --forward-context-sr.\n",
      "\n",
      "  --backward-context-sr\n",
      "    Apply contextual simplify-reflect with the given clause to processed\n",
      "    clauses.\n",
      "\n",
      "   -g\n",
      "  --prefer-general-demodulators\n",
      "    Prefer general demodulators. By default, E prefers specialized\n",
      "    demodulators. This affects in which order the rewrite  index is\n",
      "    traversed.\n",
      "\n",
      "   -F <arg>\n",
      "  --forward-demod-level=<arg>\n",
      "    Set the desired level for rewriting of unprocessed clauses. A value of 0\n",
      "    means no rewriting, 1 indicates to use rules (orientable equations) only,\n",
      "    2 indicates full rewriting with rules and instances of unorientable\n",
      "    equations. Default behavior is 2.\n",
      "\n",
      "  --demod-under-lambda=<arg>\n",
      "    Demodulate *closed* subterms under lambdas.\n",
      "\n",
      "  --strong-rw-inst\n",
      "    Instantiate unbound variables in matching potential demodulators with a\n",
      "    small constant terms.\n",
      "\n",
      "   -u\n",
      "  --strong-forward-subsumption\n",
      "    Try multiple positions and unit-equations to try to equationally subsume\n",
      "    a single new clause. Default is to search for a single position.\n",
      "\n",
      "  --satcheck-proc-interval[=<arg>]\n",
      "    Enable periodic SAT checking at the given interval of main loop\n",
      "    non-trivial processed clauses. The option without the optional argument\n",
      "    is equivalent to --satcheck-proc-interval=5000.\n",
      "\n",
      "  --satcheck-gen-interval[=<arg>]\n",
      "    Enable periodic SAT checking whenever the total proof state size\n",
      "    increases by the given limit. The option without the optional argument is\n",
      "    equivalent to --satcheck-gen-interval=10000.\n",
      "\n",
      "  --satcheck-ttinsert-interval[=<arg>]\n",
      "    Enable periodic SAT checking whenever the number of term tops insertions\n",
      "    matches the given limit (which grows exponentially). The option without\n",
      "    the optional argument is equivalent to\n",
      "    --satcheck-ttinsert-interval=5000000.\n",
      "\n",
      "  --satcheck[=<arg>]\n",
      "    Set the grounding strategy for periodic SAT checking. Note that to enable\n",
      "    SAT checking, it is also necessary to set the interval with one of the\n",
      "    previous two options. The option without the optional argument is\n",
      "    equivalent to --satcheck=FirstConst.\n",
      "\n",
      "  --satcheck-decision-limit[=<arg>]\n",
      "    Set the number of decisions allowed for each run of the SAT solver. If\n",
      "    the option is not given, the built-in value is 10000. Use -1 to allow\n",
      "    unlimited decision. The option without the optional argument is\n",
      "    equivalent to --satcheck-decision-limit=100.\n",
      "\n",
      "  --satcheck-normalize-const\n",
      "    Use the current normal form (as recorded in the termbank rewrite cache)\n",
      "    of the selected constant as the term for the grounding substitution.\n",
      "\n",
      "  --satcheck-normalize-unproc\n",
      "    Enable re-simplification (heuristic re-revaluation) of unprocessed\n",
      "    clauses before grounding for SAT checking.\n",
      "\n",
      "  --watchlist[=<arg>]\n",
      "    Give the name for a file containing clauses to be watched for during the\n",
      "    saturation process. If a clause is generated that subsumes a watchlist\n",
      "    clause, the subsumed clause is removed from the watchlist. The prover\n",
      "    will terminate when the watchlist is empty. If you want to use the\n",
      "    watchlist for guiding the proof, put the empty clause onto the list and\n",
      "    use the built-in clause selection heuristic 'UseWatchlist' (or build a\n",
      "    heuristic yourself using the priority functions 'PreferWatchlist' and\n",
      "    'DeferWatchlist'). Use the argument 'Use inline watchlist type' (or no\n",
      "    argument) and the special clause type 'watchlist' if you want to put\n",
      "    watchlist clauses into the normal input stream. This is only supported\n",
      "    for TPTP input formats. The option without the optional argument is\n",
      "    equivalent to --watchlist='Use inline watchlist type'.\n",
      "\n",
      "  --static-watchlist[=<arg>]\n",
      "    This is identical to the previous option, but subsumed clauses willnot be\n",
      "    removed from the watchlist (and hence the prover will not terminate if\n",
      "    all watchlist clauses have been subsumed. This may be more useful for\n",
      "    heuristic guidance. The option without the optional argument is\n",
      "    equivalent to --static-watchlist='Use inline watchlist type'.\n",
      "\n",
      "  --no-watchlist-simplification\n",
      "    By default, the watchlist is brought into normal form with respect to the\n",
      "    current processed clause set and certain simplifications. This option\n",
      "    disables simplification for the watchlist.\n",
      "\n",
      "  --fw-subsumption-aggressive\n",
      "    Perform forward subsumption on newly generated clauses before they are\n",
      "    evaluated. This is particularly useful if heuristic evaluation is very\n",
      "    expensive, e.g. via externally connected neural networks.\n",
      "\n",
      "  --conventional-subsumption\n",
      "    Equivalent to --subsumption-indexing=None.\n",
      "\n",
      "  --subsumption-indexing=<arg>\n",
      "    Determine choice of indexing for (most) subsumption operations. Choices\n",
      "    are 'None' for naive subsumption, 'Direct' for direct mapped FV-Indexing,\n",
      "    'Perm' for permuted FV-Indexing and 'PermOpt' for permuted FV-Indexing\n",
      "    with deletion of (suspected) non-informative features. Default behaviour\n",
      "    is 'Perm'.\n",
      "\n",
      "  --fvindex-featuretypes=<arg>\n",
      "    Select the feature types used for indexing. Choices are \"None\" to disable\n",
      "    FV-indexing, \"AC\" for AC compatible features (the default) (literal\n",
      "    number and symbol counts), \"SS\" for set subsumption compatible features\n",
      "    (symbol depth), and \"All\" for all features.Unless you want to measure the\n",
      "    effects of the different features, I suggest you stick with the default.\n",
      "\n",
      "  --fvindex-maxfeatures[=<arg>]\n",
      "    Set the maximum initial number of symbols for feature computation.\n",
      "    Depending on the feature selection, a value of X here will convert into\n",
      "    2X+2 features (for set subsumption features), 2X+4 features (for\n",
      "    AC-compatible features) or 4X+6 features (if all features are used, the\n",
      "    default). Note that the actually used set of features may be smaller than\n",
      "    this if the signature does not contain enough symbols.For the Perm and\n",
      "    PermOpt version, this is _also_ used to set the maximum depth of the\n",
      "    feature vector index. Yes, I should probably make this into two separate\n",
      "    options. If you select a small value here, you should probably not use\n",
      "    \"Direct\" for the --subsumption-indexing option. The option without the\n",
      "    optional argument is equivalent to --fvindex-maxfeatures=200.\n",
      "\n",
      "  --fvindex-slack[=<arg>]\n",
      "    Set the number of slots reserved in the index for function symbols that\n",
      "    may be introduced into the signature later, e.g. by splitting. If no new\n",
      "    symbols are introduced, this just wastes time and memory. If PermOpt is\n",
      "    chosen, the slackness slots will be deleted from the index anyways, but\n",
      "    will still waste (a little) time in computing feature vectors. The option\n",
      "    without the optional argument is equivalent to --fvindex-slack=0.\n",
      "\n",
      "  --rw-bw-index[=<arg>]\n",
      "    Select fingerprint function for backwards rewrite index. \"NoIndex\" will\n",
      "    disable paramodulation indexing. For a list of the other values run\n",
      "    'eprover --pm-index=none'. FPX functions will use a fingerprint of X\n",
      "    positions, the letters disambiguate between different fingerprints with\n",
      "    the same sample size. The option without the optional argument is\n",
      "    equivalent to --rw-bw-index=FP7.\n",
      "\n",
      "  --pm-from-index[=<arg>]\n",
      "    Select fingerprint function for the index for paramodulation from indexed\n",
      "    clauses. \"NoIndex\" will disable paramodulation indexing. For a list of\n",
      "    the other values run 'eprover --pm-index=none'. FPX functionswill use a\n",
      "    fingerprint of X positions, the letters disambiguate between different\n",
      "    fingerprints with the same sample size. The option without the optional\n",
      "    argument is equivalent to --pm-from-index=FP7.\n",
      "\n",
      "  --pm-into-index[=<arg>]\n",
      "    Select fingerprint function for the index for paramodulation into the\n",
      "    indexed clauses. \"NoIndex\" will disable paramodulation indexing. For a\n",
      "    list of the other values run 'eprover --pm-index=none'. FPX functionswill\n",
      "    use a fingerprint of X positions, the letters disambiguate between\n",
      "    different fingerprints with the same sample size. The option without the\n",
      "    optional argument is equivalent to --pm-into-index=FP7.\n",
      "\n",
      "  --fp-index[=<arg>]\n",
      "    Select fingerprint function for all fingerprint indices. See above. The\n",
      "    option without the optional argument is equivalent to --fp-index=FP7.\n",
      "\n",
      "  --fp-no-size-constr\n",
      "    Disable usage of size constraints for matching with fingerprint indexing.\n",
      "\n",
      "  --pdt-no-size-constr\n",
      "    Disable usage of size constraints for matching with perfect\n",
      "    discrimination trees indexing.\n",
      "\n",
      "  --pdt-no-age-constr\n",
      "    Disable usage of age constraints for matching with perfect discrimination\n",
      "    trees indexing.\n",
      "\n",
      "  --detsort-rw\n",
      "    Sort set of clauses eliminated by backward rewriting using a total\n",
      "    syntactic ordering.\n",
      "\n",
      "  --detsort-new\n",
      "    Sort set of newly generated and backward simplified clauses using a total\n",
      "    syntactic ordering.\n",
      "\n",
      "   -D <arg>\n",
      "  --define-weight-function=<arg>\n",
      "    Define  a weight function (see manual for details). Later definitions\n",
      "    override previous definitions.\n",
      "\n",
      "   -H <arg>\n",
      "  --define-heuristic=<arg>\n",
      "    Define a clause selection heuristic (see manual for details). Later\n",
      "    definitions override previous definitions.\n",
      "\n",
      "  --free-numbers\n",
      "    Treat numbers (strings of decimal digits) as normal free function symbols\n",
      "    in the input. By default, number now are supposed to denote domain\n",
      "    constants and to be implicitly different from each other.\n",
      "\n",
      "  --free-objects\n",
      "    Treat object identifiers (strings in double quotes) as normal free\n",
      "    function symbols in the input. By default, object identifiers now\n",
      "    represent domain objects and are implicitly different from each other\n",
      "    (and from numbers, unless those are declared to be free).\n",
      "\n",
      "  --definitional-cnf[=<arg>]\n",
      "    Tune the clausification algorithm to introduces definitions for\n",
      "    subformulae to avoid exponential blow-up. The optional argument is a\n",
      "    fudge factor that determines when definitions are introduced. 0 disables\n",
      "    definitions completely. The default works well. The option without the\n",
      "    optional argument is equivalent to --definitional-cnf=24.\n",
      "\n",
      "  --fool-unroll=<arg>\n",
      "    Enable or disable FOOL unrolling. Useful for some SH problems.\n",
      "\n",
      "  --miniscope-limit[=<arg>]\n",
      "    Set the limit of sub-formula-size to miniscope. The build-indefault is\n",
      "    256. Only applies to the new (default) clausification algorithm The\n",
      "    option without the optional argument is equivalent to\n",
      "    --miniscope-limit=2147483648.\n",
      "\n",
      "  --print-types\n",
      "    Print the type of every term. Useful for debugging purposes.\n",
      "\n",
      "  --app-encode\n",
      "    Encodes terms in the proof state using applicative encoding, prints\n",
      "    encoded input problem and exits.\n",
      "\n",
      "  --arg-cong=<arg>\n",
      "    Turns on ArgCong inference rule. Excepts an argument \"all\" or \"max\" that\n",
      "    applies the rule to all or only literals that are eligible for\n",
      "    resolution.\n",
      "\n",
      "  --neg-ext=<arg>\n",
      "    Turns on NegExt inference rule. Excepts an argument \"all\" or \"max\" that\n",
      "    applies the rule to all or only literals that are eligible for\n",
      "    resolution.\n",
      "\n",
      "  --pos-ext=<arg>\n",
      "    Turns on PosExt inference rule. Excepts an argument \"all\" or \"max\" that\n",
      "    applies the rule to all or only literals that are eligible for\n",
      "    resolution.\n",
      "\n",
      "  --ext-sup-max-depth=<arg>\n",
      "    Sets the maximal proof depth of the clause which will be considered for \n",
      "    Ext-family of inferences. Negative value disables the rule.\n",
      "\n",
      "  --inverse-recognition\n",
      "    Enables the recognition of injective function symbols. If such a symbol\n",
      "    is recognized, existence of the inverse function is asserted by adding a\n",
      "    corresponding axiom.\n",
      "\n",
      "  --replace-inj-defs\n",
      "    After CNF and before saturation, replaces all clauses that are\n",
      "    definitions  of injectivity by axiomatization of inverse function.\n",
      "\n",
      "  --lift-lambdas=<arg>\n",
      "    Should the lambdas be replaced by named fuctions?\n",
      "\n",
      "  --eta-normalize=<arg>\n",
      "    Which form of eta normalization to perform?\n",
      "\n",
      "  --ho-order-kind=<arg>\n",
      "    Do we use simple LFHO order or a more advanced Boolean free lambda-KBO?\n",
      "\n",
      "  --cnf-lambda-to-forall=<arg>\n",
      "    Do we turn equations of the form ^X.s (!)= ^X.t into (?)!X. s (!)= t ?\n",
      "\n",
      "  --kbo-lam-weight=<arg>\n",
      "    Weight of lambda symbol in KBO.\n",
      "\n",
      "  --kbo-db-weight=<arg>\n",
      "    Weight of DB var in KBO.\n",
      "\n",
      "  --eliminate-leibniz-eq=<arg>\n",
      "    Maximal proof depth of the clause on which Leibniz equality elimination\n",
      "    should be applied; -1 disaables Leibniz equality elimination altogether\n",
      "\n",
      "  --unroll-formulas-only=<arg>\n",
      "    Set to true if you want only formulas to be recognized as definitions\n",
      "    during CNF. Default is true.\n",
      "\n",
      "  --prim-enum-mode=<arg>\n",
      "    Choose the mode of primitive enumeration \n",
      "\n",
      "  --prim-enum-max-depth=<arg>\n",
      "    Maximal proof depth of a clause on which primitive enumeration is\n",
      "    applied. -1 disables primitive enumeration\n",
      "\n",
      "  --inst-choice-max-depth=<arg>\n",
      "    Maximal proof depth of a clause which is going to be scanned for\n",
      "    occurrences of defined choice symbol -1 disables scanning for choice\n",
      "    symbols\n",
      "\n",
      "  --local-rw=<arg>\n",
      "    Enable/disable local rewriting: if the clause is of the form s != t |  C,\n",
      "    where s > t, rewrite all occurrences of s with t in C.\n",
      "\n",
      "  --prune-args=<arg>\n",
      "    Enable/disable pruning arguments of applied variables.\n",
      "\n",
      "  --func-proj-limit=<arg>\n",
      "    Maximal number of functional projections\n",
      "\n",
      "  --imit-limit=<arg>\n",
      "    Maximal number of imitations\n",
      "\n",
      "  --ident-limit=<arg>\n",
      "    Maximal number of identifications\n",
      "\n",
      "  --elim-limit=<arg>\n",
      "    Maximal number of eliminations\n",
      "\n",
      "  --unif-mode=<arg>\n",
      "    Set the mode of unification: either single or multi.\n",
      "\n",
      "  --pattern-oracle=<arg>\n",
      "    Turn the pattern oracle on or off.\n",
      "\n",
      "  --fixpoint-oracle=<arg>\n",
      "    Turn the pattern oracle on or off.\n",
      "\n",
      "  --max-unifiers=<arg>\n",
      "    Maximal number of imitations\n",
      "\n",
      "  --max-unif-steps=<arg>\n",
      "    Maximal number of variable bindings that can be done in one single call\n",
      "    to copmuting the next unifier.\n",
      "\n",
      "  --classification-timeout-portion=<arg>\n",
      "    Which percentage (from 1 to 99) of the total CPU time will be devoted to\n",
      "    problem classification?\n",
      "\n",
      "  --preinstantiate-induction=<arg>\n",
      "    Abstract unit clauses coming from conjecture and use the abstractions to\n",
      "    instantiate clauses that look like the ones coming from induction axioms.\n",
      "\n",
      "  --bce=<arg>\n",
      "    Turn blocked clause elimination on or off\n",
      "\n",
      "  --bce-max-occs=<arg>\n",
      "    Stop tracking symbol after it occurs in <arg> clauses Set <arg> to -1\n",
      "    disable this limit\n",
      "\n",
      "  --pred-elim=<arg>\n",
      "    Turn predicate elimination on or off\n",
      "\n",
      "  --pred-elim-max-occs=<arg>\n",
      "    Stop tracking symbol after it occurs in <arg> clauses Set <arg> to -1\n",
      "    disable this limit\n",
      "\n",
      "  --pred-elim-tolerance=<arg>\n",
      "    Tolerance for predicate elimination measures.\n",
      "\n",
      "  --pred-elim-recognize-gates=<arg>\n",
      "    Turn gate recognition for predicate elimination on or off\n",
      "\n",
      "  --pred-elim-force-mu-decrease=<arg>\n",
      "    Require that the square number of distinct free variables decreases when\n",
      "    doing predicate elimination. Helps avoid creating huge clauses.\n",
      "\n",
      "  --pred-elim-ignore-conj-syms=<arg>\n",
      "    Disable eliminating symbols that occur in the conjecture.\n",
      "\n",
      "\n",
      "\n",
      "Copyright 1998-2024 by Stephan Schulz, schulz@eprover.org,\n",
      "and the E contributors (see DOC/CONTRIBUTORS).\n",
      "\n",
      "This program is a part of the distribution of the equational theorem\n",
      "prover E. You can find the latest version of the E distribution\n",
      "as well as additional information at\n",
      "http://www.eprover.org\n",
      "\n",
      "This program is free software; you can redistribute it and/or modify\n",
      "it under the terms of the GNU General Public License as published by\n",
      "the Free Software Foundation; either version 2 of the License, or\n",
      "(at your option) any later version.\n",
      "\n",
      "This program is distributed in the hope that it will be useful,\n",
      "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
      "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
      "GNU General Public License for more details.\n",
      "\n",
      "You should have received a copy of the GNU General Public License\n",
      "along with this program (it should be contained in the top level\n",
      "directory of the distribution in the file COPYING); if not, write to\n",
      "the Free Software Foundation, Inc., 59 Temple Place, Suite 330,\n",
      "Boston, MA  02111-1307 USA\n",
      "\n",
      "We welcome bug reports and even reasonable questions. If the prover\n",
      "behaves in an unexpected way, please include the following\n",
      "information:\n",
      "\n",
      "- What did you observe?\n",
      "- What did you expect?\n",
      "- The output of `eprover --version`\n",
      "- The full commandline that lead to the unexpected behaviour\n",
      "- The input file(s) that lead to the unexpected behaviour\n",
      "\n",
      "Most bug reports should be send to <schulz@eprover.org>. Bug reports with \n",
      "respect to the HO-version should be send to or at least copied to \n",
      "<jasmin.blanchette@gmail.com>. Please remember that this is an unpaid\n",
      "volunteer service.\n",
      "\n",
      "The original copyright holder can be contacted via email or as\n",
      "\n",
      "Stephan Schulz\n",
      "DHBW Stuttgart\n",
      "Fakultaet Technik\n",
      "Informatik\n",
      "Lerchenstrasse 1\n",
      "70174 Stuttgart\n",
      "Germany\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['./eprover-ho', '--help'], returncode=0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.run([\"./eprover-ho\", \"--help\"], check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f41943a",
   "metadata": {},
   "source": [
    "# egraph\n",
    "\n",
    "## Mixins vs subclassing\n",
    "\n",
    "GaussMixin()\n",
    "t = GaussTheory()\n",
    "EGraph(GaussTheory(), SympyTheory(), )\n",
    "\n",
    "self.theories = []\n",
    "\n",
    "def find(self, x):\n",
    "    for t in theories:\n",
    "        t.find(x)\n",
    "\n",
    "def union():\n",
    "    todo = []\n",
    "    for t in theories:\n",
    "        todo.extend(t.union())\n",
    "\n",
    "\n",
    "## Lambda\n",
    "alpha_norm before using add term.\n",
    "\n",
    "Recursively carry params down through?\n",
    "Eta long form.\n",
    "\n",
    "A normal form?\n",
    "\n",
    "Do slotted. Add some knd of permutation egraph?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0373cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eta_long(ctx, t : smt.ExprRef):\n",
    "    if isinstance(t, smt.QuantifierRef):\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316d1d19",
   "metadata": {},
   "source": [
    "## Gauss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16b9a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussEGraph():\n",
    "    def __init__(self):\n",
    "        self.eqs = smt.SimpleSolver() # Or sympy grobner basis.\n",
    "    def union(self, x, y):\n",
    "        if isinstance(smt.ArithRef):\n",
    "            self.eqs\n",
    "\n",
    "class GrobnerEGraph(EGraph):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63af2d2c",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76265cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(self, t : smt.ExprRef, cost_fun = lambda _: 1):\n",
    "    best_cost = defaultdict(float(\"inf\"))\n",
    "    best = {}\n",
    "    while True:\n",
    "        done = True\n",
    "        # Terms are taking the place of enodes.\n",
    "        for t in self.terms:\n",
    "            eid = self.find(t.get_id())\n",
    "            cost = cost_fun(t) + sum([best_cost[self._find(c.get_id())] for c in t.children()]) # cost_fun(t.decl()) ?\n",
    "            if cost < best_cost[eid]:\n",
    "                best_cost[eid] = cost\n",
    "                best = {eid : t}\n",
    "                done = False\n",
    "        if done:\n",
    "            break\n",
    "    #@functools.cache\n",
    "    def build_best(t):\n",
    "        t1 = best[self.find(t.get_id())]\n",
    "        t1.decl()(*[build_best(c) for c in t1.children()])\n",
    "    return build_best(t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63464a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f4a948c",
   "metadata": {},
   "source": [
    "## Proof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "209fb6b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "z3.z3.BoolRef"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = smt.Solver()\n",
    "s.set(unsat_core=True)\n",
    "a,b,c,d, e = smt.Ints('a b c d e')\n",
    "id_map = {}\n",
    "def tassert(a):\n",
    "    tid = a.get_id()\n",
    "    id_map[tid] = a\n",
    "    #s.assert_and_track(a, smt.Bool(str(a)))\n",
    "    s.assert_and_track(a, smt.Bool(str(tid)))\n",
    "def core():\n",
    "    core = s.unsat_core()\n",
    "    return [id_map[int(str(c))] for c in core]\n",
    "\n",
    "\n",
    "tassert(a == b)\n",
    "tassert(b == c)\n",
    "tassert(e == d)\n",
    "#s.add(a == b)\n",
    "#s.add(b == c)\n",
    "#s.assert_and_track(a == b)\n",
    "#s.assert_and_track(b == c, b == c)\n",
    "s.add(a != c)\n",
    "s.check()\n",
    "#s.unsat_core()\n",
    "type(core()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3b7b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EgraphProof(EGraph):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reasons = {}\n",
    "        self.solver.set(\"unsat_core\", True)\n",
    "    def union(self, e1, e2, reason=None):\n",
    "        super().union(e1, e2)\n",
    "        if reason is not None:\n",
    "            self.reasons[e1 == e2] = reason\n",
    "    def add(self, expr): # Use this indriectio nin Egrpha, so we can use assert and track\n",
    "        tid = expr.get_id()\n",
    "        self.terms[tid] = expr\n",
    "        self.solver.assert_and_track(expr, smt.BoolRef(str(tid)))\n",
    "    def core(self):\n",
    "        core = self.solver.unsat_core()\n",
    "        return [self.terms[int(str(c))] for c in core]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1be3b65",
   "metadata": {},
   "source": [
    "Return instantiations of rules that make this possible\n",
    "(vs, rule, lhs = rhs)\n",
    "\n",
    "\n",
    "return ground rewrite system that'll do it? But then each rule needs to be itself dignified. bleh.\n",
    "\n",
    "I could also use the trick from the third post of using z3 ematcher and grab the instans\n",
    "\n",
    "Also it'd be neat to extract those into a reified proof object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f856ca67",
   "metadata": {},
   "source": [
    "\n",
    "## Context\n",
    "Egraph does support hypothetical equalities?\n",
    "But I won't ematch unless I'm in that hypothetical situation\n",
    "\n",
    "ctxs = []\n",
    "ctx rebuilding - which ctx subsume, which \n",
    "Implies(ctx1, ctx2)\n",
    "Implies(ctx2, ctx1)  ---> \n",
    "\n",
    "contextual rewrite rules.\n",
    "\n",
    "Brute force contextual egraph\n",
    "\n",
    "Ok so i can build it.\n",
    "But then what is it for?\n",
    "Well, if then else is a good example.\n",
    "\n",
    "add_term(self, ctx, t):\n",
    "    if smt.is_ite(t):\n",
    "        ctx.append(t.arg(0)), t.arg(1)\n",
    "        ctx.append(smt.Not(t.arg(1))), t.arg(0)\n",
    "\n",
    "\n",
    "\n",
    "There's a lot of pruning possible in these queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db50284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.all import *\n",
    "from kdrag.solvers.egraph import EGraph\n",
    "def ctx_order(ctxs):\n",
    "    s = smt.Solver()\n",
    "    eq = []\n",
    "    le = []\n",
    "    for ctx1 in ctxs:\n",
    "        for ctx2 in ctxs:\n",
    "            s.push()\n",
    "            s.add(smt.Not(ctx1 == ctx2))\n",
    "            res = s.check()\n",
    "            s.pop()\n",
    "            if res == smt.unsat:\n",
    "                eq.append((ctx1,ctx2))\n",
    "            s.push()\n",
    "            s.add(smt.Not(smt.Implies(ctx1, ctx2)))\n",
    "            res = s.check()\n",
    "            s.pop()\n",
    "            if res == smt.unsat:\n",
    "                le.append((ctx2,ctx1))\n",
    "\n",
    "def subsumes(ctx1, ctx2):\n",
    "    s = smt.Solver()\n",
    "    s.add(smt.Not(smt.Implies(ctx1, ctx2)))\n",
    "    return s.check() == smt.unsat\n",
    "def iff(ctx1, ctx2):\n",
    "    s = smt.Solver()\n",
    "    s.add(smt.Not(ctx1 == ctx2))\n",
    "    return s.check() == smt.unsat            \n",
    "\n",
    "\n",
    "x,y,z = smt.Ints('x y z')\n",
    "\n",
    "ctx1 = smt.And(x == y, y == z)\n",
    "ctx2 = x == z\n",
    "assert subsumes(ctx1, ctx2)\n",
    "assert not subsumes(ctx2, ctx1)\n",
    "iff(ctx1, ctx1)\n",
    "\n",
    "class CtxEGraph(EGraph):\n",
    "    ctxs : set[int]\n",
    "    subsume : dict[int, set[int]] # \"path\" transitive closure\n",
    "\n",
    "    # there's two versions. One where you have pattern vars in ctx or not. or if contexrt is pattern.\n",
    "    # suearch over all subsumed contexts.\n",
    "    # def ematch_ctx(self, vs, pctx, lhs):\n",
    "    def ematch_ctx(self, vs, lhs):\n",
    "        res = []\n",
    "        for ctx in self.ctxs:\n",
    "            #self.substitute(ctx, vs)\n",
    "            with self.solver: # takes the push?\n",
    "                self.solver.add(self.terms[ctx])\n",
    "                res.extend((ctx, match_) for match_ in self.ematch(vs, lhs))\n",
    "        return res\n",
    "    #def ctx_sub():\n",
    "    def rebuild(self):\n",
    "        super().rebuild()\n",
    "        oldctxs = self.ctxs\n",
    "        for ctx1 in self.ctxs:\n",
    "            for ctx2 in self.ctxs:\n",
    "                if ctx2 in self.subsume[ctx1]:\n",
    "                    continue\n",
    "                else:\n",
    "                    self.solver.push()\n",
    "                    self.solver.add(smt.Not(smt.Implies(ctx1, ctx2)))\n",
    "                    self.solver.pop()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0d78c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ceea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_term_quant(term):\n",
    "    t = alpha_norm(term)\n",
    "    todo = [([], t)]\n",
    "    while todo:\n",
    "        ctx, t = todo.pop()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d549a6a3",
   "metadata": {},
   "source": [
    "# datalog\n",
    "z3 has a datalog, but whatev. Take snakelog approach https://github.com/philzook58/snakelog\n",
    "\n",
    "Also homommorphism finder. A la CSP / sqlite blog post\n",
    "\n",
    "Pretty print into ASP?\n",
    "\n",
    "spacer?\n",
    "\n",
    "\n",
    "sqlite dump of binary\n",
    "sqlite dump of clang ast or treesitter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09f68cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    INSERT OR IGNORE INTO path SELECT DISTINCT edge0.x0 AS x0, edge0.x1 AS x1\n",
      "    FROM edge AS edge0\n",
      "    \n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    INSERT OR IGNORE INTO edge SELECT DISTINCT 1 AS x0, 2 AS x1\\n    \\n    \\n    '"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "x,y,z = smt.Ints(\"x y z\")\n",
    "edge = smt.Function(\"edge\", smt.IntSort(), smt.IntSort(), smt.BoolSort())\n",
    "path = smt.Function(\"path\", smt.IntSort(), smt.IntSort(), smt.BoolSort())\n",
    "edgepath = rw.rule_of_expr(kd.QForAll([x,y], edge(x,y), path(x,y)))\n",
    "trans = rw.rule_of_expr(kd.QForAll([x,y,z], edge(x,y), path(y,z), path(x,z)))\n",
    "\n",
    "\n",
    "def compile_body(vs : list[smt.ExprRef], body : smt.BoolRef) -> str:\n",
    "    todo = [body]\n",
    "    env = {}\n",
    "    froms = []\n",
    "    wheres = []\n",
    "    counter = 0\n",
    "    while todo:\n",
    "        rel = todo.pop()\n",
    "        if smt.is_eq(rel):\n",
    "            raise ValueError(\"Equality not supported\")\n",
    "        elif smt.is_not(rel):\n",
    "            raise ValueError(\"Negation not supported\")\n",
    "        elif smt.is_or(rel):\n",
    "            raise ValueError(\"Disjunction not supported\")\n",
    "        elif smt.is_and(rel):\n",
    "            todo.extend(rel.children())\n",
    "        elif smt.is_true(rel):\n",
    "            continue\n",
    "        elif smt.is_app(rel):\n",
    "            name = rel.decl().name()\n",
    "            args = rel.children()\n",
    "            row_name = name + str(counter)\n",
    "            counter += 1 \n",
    "            froms.append(f\"{name} AS {row_name}\")\n",
    "            for n, arg in enumerate(args):\n",
    "                if arg in vs:\n",
    "                    if arg in env:\n",
    "                        wheres.append(f\"{env[arg]} = {row_name}.x{n}\")\n",
    "                    else:\n",
    "                        env[arg] = f\"{row_name}.x{n}\"\n",
    "                else:\n",
    "                    wheres.append(f\"{row_name}.x{n} = {str(arg)}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported expression: {rel}\")\n",
    "    return env, froms, wheres\n",
    "\n",
    "def compile_rule(rule : kd.rewrite.Rule) -> str:\n",
    "    env, froms, wheres = compile_body(rule.vs, rule.hyp)\n",
    "    name = rule.conc.decl().name()\n",
    "    selects = []\n",
    "    for n,arg in  enumerate(rule.conc.children()):\n",
    "        if arg in rule.vs:\n",
    "            if arg in env:\n",
    "                selects.append(f\"{env[arg]} AS x{n}\") # maybe select as keyword\n",
    "            else:\n",
    "                raise ValueError(f\"Variable {arg} not found in body\")\n",
    "        else:\n",
    "            selects.append(f\"{arg} AS x{n}\")\n",
    "    froms = \", \".join(froms)\n",
    "    wheres = \" AND \".join(wheres)\n",
    "    selects = \", \".join(selects)\n",
    "    return f\"\"\"\n",
    "    INSERT OR IGNORE INTO {name} SELECT DISTINCT {selects}\n",
    "    {\"FROM \" + froms if froms else \"\"}\n",
    "    {\"WHERE \" + wheres if wheres else \"\"}\n",
    "    \"\"\"\n",
    "\n",
    "print(compile_rule(edgepath))\n",
    "compile_rule(kd.rewrite.rule_of_expr(edge(1,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbe97cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (2, 3), (1, 3)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "class Datalog():\n",
    "    def __init__(self):\n",
    "        self.db = sqlite3.connect(\":memory:\")\n",
    "    \n",
    "    def declare_sig(self, sig : list[smt.FuncDeclRef]):\n",
    "        for f in sig:\n",
    "            primkey = \"(\" + \", \".join([f\"x{i}\" for i in range(f.arity())]) + \")\"\n",
    "            self.db.execute(f\"\"\"CREATE TABLE IF NOT EXISTS {f.name()} \n",
    "                            ({', '.join([f'x{i} {f.range().name()}' for i in range(f.arity())])}, \n",
    "                             PRIMARY KEY {primkey})\"\"\")\n",
    "\n",
    "    def run(self, rule : kd.rewrite.Rule | smt.BoolRef):\n",
    "        if isinstance(rule, smt.BoolRef):\n",
    "            rule = kd.rewrite.rule_of_expr(rule)\n",
    "        sql = compile_rule(rule)\n",
    "        self.db.execute(sql)\n",
    "\n",
    "s = Datalog()\n",
    "s.declare_db([edge, path])\n",
    "s.run(edge(1,2))\n",
    "s.run(edge(2,3))\n",
    "s.run(edgepath)\n",
    "s.run(trans)\n",
    "s.run(trans)\n",
    "s.db.execute(\"SELECT * FROM path\").fetchall()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa779ea",
   "metadata": {},
   "source": [
    "# compile out of smt2\n",
    "\n",
    "Look at basic compiler books.\n",
    "Tiger\n",
    "Essentials\n",
    "nanopass\n",
    "\n",
    "smtcc :)\n",
    "prescheme\n",
    "\n",
    "undefined behavior.\n",
    "\n",
    "\n",
    "We can make a meta layer list\n",
    "https://pypy.org/posts/2024/07/toy-abstract-interpretation.html\n",
    "https://pypy.org/posts/2022/07/toy-optimizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ccef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[x + y, x + y + z, x + y - (x + y + z)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y,z = smt.BitVecs(\"x y z\", 64)\n",
    "getarg = smt.Function(\"getarg\", smt.IntSort(), smt.BitVecSort(64))\n",
    "copy = smt.Function(\"copy\", smt.BitVecSort(64), smt.BitVecSort(64)) # kd.define(\"copy\", [x], x)\n",
    "prog = [\n",
    "    a := x + y,\n",
    "    b := a + z,\n",
    "    c := a - b,\n",
    "]\n",
    "def address_code(prog):\n",
    "    seen = set()\n",
    "    for stmt in prog:\n",
    "        if all(c in seen for c in stmt.children()):\n",
    "            seen.add(stmt)\n",
    "        else:\n",
    "            return False\n",
    "    return True\n",
    "# path assumptions could be interesting.\n",
    "\n",
    "def esimplify(prog):\n",
    "    uf = {}\n",
    "    new_prog = []\n",
    "    for n,stmt in prog:\n",
    "        s = smt.Solver()\n",
    "\n",
    "\n",
    "def register(prog):\n",
    "    live = set()\n",
    "    regalloc = {}\n",
    "    availreg = [\"r8\", \"rsi\",\"rdi\",\"rax\"]\n",
    "    for stmt in reversed(prog):\n",
    "        availreg.append(regalloc[stmt])\n",
    "        live.remove(stmt)\n",
    "        for c in stmt.children():\n",
    "            if c not in live:\n",
    "                live.add(c)\n",
    "                if availreg:\n",
    "                    regalloc[c] = availreg.pop()\n",
    "                else:\n",
    "                    # spill\n",
    "                    raise Exception(\"No registers available\")\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec58a266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1 + 0"
      ],
      "text/plain": [
       "1 + 0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "one = smt.BitVecVal(1, 64)\n",
    "zero = smt.BitVecVal(0, 64)\n",
    "\n",
    "one + zero\n",
    "\n",
    "def to_asm(e : smt.ExprRef):\n",
    "    if isinstance(e, smt.BitVecNumRef):\n",
    "        return \"mov rdi, %d\" % e.as_long()\n",
    "    elif smt.is_add(e):\n",
    "        to_asm(e.args[0])\n",
    "        return [\n",
    "            f\"pop %rdi\",\n",
    "            r\"add rdi, %d\" % e.args[1].as_long()\n",
    "        ]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b646e2ea",
   "metadata": {},
   "source": [
    "# vectorize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2c1032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://jamesbornholt.com/papers/diospyros-asplos21.pdf\n",
    "BV16 = smt.BitVecSort(16)\n",
    "BV8 = smt.BitVecSort(8)\n",
    "\n",
    "x,y,z = smt.BitVecs(\"x y z\", 16)\n",
    "vadd = smt.Function('vadd', BV16, BV16, BV16)\n",
    "vsub = smt.Function('vsub', BV16, BV16, BV16)\n",
    "vmul = smt.Function('vmul', BV16, BV16, BV16)\n",
    "vneg = smt.Function('vneg', BV16, BV16)\n",
    "vmac = smt.Function('vmac', BV16, BV16, BV16, BV16)\n",
    "\n",
    "vadd(x,y) == smt.Concat(smt.Extract(15, 8, x) + smt.Extract(15, 8, y), \n",
    "                        smt.Extract(7, 0, x) + smt.Extract(7, 0, y))\n",
    "\n",
    "vsub(x,y) == smt.Concat(smt.Extract(15, 8, x) - smt.Extract(15, 8, y), \n",
    "                        smt.Extract(7, 0, x) - smt.Extract(7, 0, y))\n",
    "vmul(x,y) == smt.Concat(smt.Extract(15, 8, x) * smt.Extract(15, 8, y),\n",
    "                        smt.Extract(7, 0, x) * smt.Extract(7, 0, y))\n",
    "vneg(x) == smt.Concat(-smt.Extract(15, 8, x), -smt.Extract(7, 0, x))\n",
    "vmac(x,y,z) == smt.Concat(smt.Extract(15, 8, x) * smt.Extract(15, 8, y) + smt.Extract(15, 8, z),\n",
    "                        smt.Extract(7, 0, x) * smt.Extract(7, 0, y) + smt.Extract(7, 0, z))\n",
    "\n",
    "smt.prove(smt.Concat(smt.Extract(15, 8, x), smt.Extract(7, 0, x)) == x)\n",
    "\n",
    "vadd(vmul(x,y),z) == vmac(x,y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5a9556",
   "metadata": {},
   "source": [
    "# asymptotic\n",
    "\n",
    "https://github.com/teorth/estimates\n",
    "https://en.wikipedia.org/wiki/Big_O_notation \n",
    "https://www.andrew.cmu.edu/user/avigad/Papers/bigo.pdf  Formalizing O notation in Isabelle/HOL\n",
    "\n",
    "eqaulity isn't equality (unless it is?)\n",
    "\n",
    "f(x) = O(g(x)) is really\n",
    "O(g)[f]\n",
    "\n",
    "But to do this is to ignore the wisdom of the notation perhaps. because formalists can't fit a notation into their rigid paradgims doesn't mean its bad\n",
    "\n",
    "I could do custom overloading of == to mean asymptotic.\n",
    "Didn't I have some idea about O ~ id\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa1ff0d",
   "metadata": {},
   "source": [
    "# pysmt\n",
    "I never _really_ gave pysmt a fair shake.\n",
    "It doesn't support lambda. That is a pretty tough blow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c807787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pysmt.shortcuts import Symbol, And, Not, is_sat\n",
    "\n",
    "varA = Symbol(\"A\") # Default type is Boolean\n",
    "varB = Symbol(\"B\")\n",
    "f = And(varA, Not(varB))\n",
    "is_sat(f)\n",
    "g = f.substitute({varB: varA})\n",
    "is_sat(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca139021",
   "metadata": {},
   "source": [
    "# lambda unify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc66f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_huet():\n",
    "    todo = []\n",
    "    frozen = [] #flexflex?\n",
    "    subst = {}\n",
    "    while True:\n",
    "        while todo:\n",
    "            current = todo.pop()\n",
    "            # do unification.\n",
    "\n",
    "        for p in frozen:\n",
    "            if flexflex(p):\n",
    "                continue\n",
    "            else:\n",
    "                frozen.remove(p)\n",
    "                todo.append(p)\n",
    "                break\n",
    "        else:\n",
    "            return subst, frozen\n",
    "    \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54be818",
   "metadata": {},
   "source": [
    "# GAT / refinement\n",
    "see types.ipynb also\n",
    "\n",
    "\n",
    "The property of being a proper telescoping mapping requires an smt solve?\n",
    "\n",
    "why bother teelscoping? Isabelle pure has no telescoping effect? CVody says that helps build model but did not elaborate\n",
    "https://argo.matf.bg.ac.rs/events/2009/fatpa2009/slides/Wenzel_PureLogicalReasoning%20in%20Isabelle-Isar.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1911.00399 hott in pure\n",
    "https://arxiv.org/pdf/cs/9301105 pualson foundation of generic theorem prover\n",
    "\n",
    "\n",
    "So a conditional judgement can be seen as a fiber just as much as types can (?)\n",
    "A /\\ B /\\ C ===> D\n",
    "\n",
    "|- goal(p)  as a marker. Always provable goal(p) == True\n",
    " \n",
    "unify(pf1, pf2)\n",
    "\n",
    "Rather than an equalizer, a pullback. t1 as a substituion mapping anyway?\n",
    "G1 -> G2\n",
    "G3 -> G2\n",
    "Two telescope mappings that go to common context G2. Can I build a pullback?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8d0d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[y] [y >= -1] y + 1 >= 0\n",
      "[y] [y >= -1] y + 10 >= y + 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[|- ForAll(y, Implies(And(y >= -1), y + 1 >= 0)),\n",
       " |- ForAll(y, Implies(And(y >= -1), y + 10 >= y + 1))]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Telescope():\n",
    "    \"\"\" x | A(x), y | B(x,y), ... \"\"\"\n",
    "    vs : list[smt.ExprRef]\n",
    "    preds : list[smt.BoolRef]\n",
    "    # preds : list[kd.Proof] ? |- ForAll([x], P1), ForAll([x,y], P1 => P2), ...  \n",
    "    # No but the context should be proof recievining, not proof producing.\n",
    "\n",
    "    def expr(self, P):\n",
    "        print(self.vs, self.preds, P)\n",
    "        return kd.QForAll(self.vs, smt.And(self.preds), P)\n",
    "    \n",
    "\n",
    "\n",
    "x,y,z = smt.Reals(\"x y z\")\n",
    "Telescope([x,y], [x > 0, y > x])\n",
    "\n",
    "@dataclass\n",
    "class TeleSubst():\n",
    "    dom : Telescope\n",
    "    cod : Telescope\n",
    "    subst: dict[smt.ExprRef, smt.ExprRef]\n",
    "    # pf : list[smt.Proof] # same length as dom.preds\n",
    "\n",
    "    def check(self,by=[]):\n",
    "        pfs = []\n",
    "        pfs.extend(by)\n",
    "        for P in self.dom.preds:\n",
    "            pfs.append(kd.prove(self.cod.expr(smt.substitute(P, *self.subst.items())), by=pfs))\n",
    "        return pfs\n",
    "    def __call__(self, P):\n",
    "        # P is in context dom\n",
    "        return smt.substitute(P, *self.subst.items())\n",
    "    def __matmul__(self, other):\n",
    "        # substutition forms a category\n",
    "        assert self.dom == other.cod\n",
    "        TeleSubst(other.dom, self.cod, {smt.substitute(...)})\n",
    "\n",
    "# allows subtype weakening.\n",
    "# if it only allowed syntactic substitutions, then we don't really need the proofs\n",
    "\n",
    "ctx1 = Telescope([x,z], [x >= 0, z >= x])\n",
    "ctx2 = Telescope([y], [y >= -1])\n",
    "TeleSubst(ctx1, ctx2, {x: y + 1, z : y + 10}).check()\n",
    "\n",
    "\n",
    "# is there a unification procedure for making TeleSubst?\n",
    "# G1 |- t1 =? t2 -| G2\n",
    "# result is G1 -> G2 substitution? It's assymmetric?\n",
    "# doesn't seem like the right shape.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9f6a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "&#8870;ForAll([y, z], And(z == z, y + 1 == y + 1))"
      ],
      "text/plain": [
       "|- ForAll([y, z], And(z == z, y + 1 == y + 1))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "\n",
    "def subst(pf : kd.Proof, vs : list[smt.ExprRef], subst : list[smt.ExprRef]) -> kd.Proof:\n",
    "    vs1, ab = kd.kernel.herb(smt.ForAll(vs, smt.substitute_vars(pf.thm.body(), *reversed(subst))))\n",
    "    a = kd.kernel.instan([smt.substitute(t, *zip(vs, vs1)) for t in subst], pf)\n",
    "    return kd.kernel.modus(ab, a)\n",
    "x,y,z = smt.Reals(\"x y z\")\n",
    "p = kd.prove(smt.ForAll([x,z], smt.And(z == z, x == x)))\n",
    "subst(p, [y, z], [y + 1, z])\n",
    "\n",
    "def weaken(pf, x):\n",
    "\n",
    "\n",
    "def unify(pf1, pf2) -> Optional[kd.Proof]:\n",
    "    # unify the two proofs forall x, p1(x) and forall y, p2(y)\n",
    "    # return a new proof\n",
    "    vs1, p1 = kd.utils.open_binder(pf1.thm)\n",
    "    vs2, p2 = kd.utils.open_binder(pf2.thm)\n",
    "    vs = vs1 + vs2\n",
    "    subst = kd.utils.unify(vs1+vs2,p1,p2)\n",
    "    if subst is not None:\n",
    "        vs = set(vs) - set(subst.keys()) # maybe keep 'em ordered\n",
    "        return subst_tac(pf1, vs, )\n",
    "\n",
    "def build_telescope(pf : kd.Proof, vs, hyps, conc):\n",
    "    # find a substitution based on unifying conc\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "def chain(pf1, pf2):\n",
    "    # decompose into rules.\n",
    "    # unify\n",
    "    # rebuild\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41112098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "&#8870;ForAll(x, fact(x) == If(0 >= x, 1, x*fact(x - 1)))"
      ],
      "text/plain": [
       "|- ForAll(x, fact(x) == If(0 >= x, 1, x*fact(x - 1)))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kdrag.reflect as reflect\n",
    "from kdrag.all import *\n",
    "x = smt.Bool(\"x\")\n",
    "@reflect.reflect\n",
    "def fact(x : int) -> int:\n",
    "    if x <= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return x*fact(x-1)\n",
    "fact.defn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f19366",
   "metadata": {},
   "source": [
    "# verilog extract\n",
    "\n",
    "Silviu makes a good point.\n",
    "If you're going to be comparing test case outputs,\n",
    "No need to \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69d6744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// Generated by knuckledragger\n",
      "module test (\n",
      "   input x,\n",
      "   input y,\n",
      "   output z\n",
      ");\n",
      "assign z = (x && y);\n",
      "endmodule\n",
      "\n",
      "// Generated by knuckledragger\n",
      "module test (\n",
      "   input [7:0] a,\n",
      "   input [7:0] b,\n",
      "   output z\n",
      ");\n",
      "assign z = ((a & (b + 8'd7)) != b);\n",
      "endmodule\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x,y,z = smt.Bools(\"x y z\")\n",
    "a,b,c = smt.BitVecs(\"a b c\", 8)\n",
    "print(to_verilog(\"test\", [x,y], {z : x & y}))\n",
    "print(to_verilog(\"test\", [a,b], {z : a & b + 7 != b}))\n",
    "#(a & b != b).decl().name()\n",
    "\n",
    "def test():\n",
    "    with open(\"/tmp/test.v\", \"w\") as f:\n",
    "        f.write(to_verilog(\"test\", [x,y], {z : x & y}))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a48664",
   "metadata": {},
   "source": [
    "To say that a verilog file has a property is an axiom schema?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592dbe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sby_axiom(modfile, name, ins, outs):\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c384cc",
   "metadata": {},
   "source": [
    "# diff\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bad30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.all import *\n",
    "\n",
    "def diff(e, x):\n",
    "    if e.eq(x):\n",
    "        return 1\n",
    "    elif smt.is_value(e):\n",
    "        return 0\n",
    "    elif smt.is_add(e):\n",
    "        return smt.Sum([diff(c,x) for c in e.children()])\n",
    "    elif e.decl() == real.sin:\n",
    "        return real.cos(e) * diff(e, x)\n",
    "    elif e.decl() == real.cos:\n",
    "        return -real.sin(e) * diff(e, x)\n",
    "    elif e.decl() == real.exp:\n",
    "        return real.exp(e) * diff(e, x)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884b9aa2",
   "metadata": {},
   "source": [
    "# knuckelproblems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06bcd4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "&#8870;ForAll([n, m],\n",
       "       add(n, m) ==\n",
       "       If(is(Zero, n),\n",
       "          m,\n",
       "          If(is(Succ, n),\n",
       "             Succ(add(pred(n), m)),\n",
       "             unreachable!6)))"
      ],
      "text/plain": [
       "|- ForAll([n, m],\n",
       "       add(n, m) ==\n",
       "       If(is(Zero, n),\n",
       "          m,\n",
       "          If(is(Succ, n),\n",
       "             Succ(add(pred(n), m)),\n",
       "             unreachable!6)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from kdrag.all import *\n",
    "# Knuckledragger support algebraic datatypes and induction\n",
    "Nat = kd.Inductive(\"MyNat\")\n",
    "Zero = Nat.declare(\"Zero\")\n",
    "Succ = Nat.declare(\"Succ\", (\"pred\", Nat))\n",
    "Nat = Nat.create()\n",
    "# We can define an addition function by cases\n",
    "n,m = smt.Consts(\"n m\", Nat)\n",
    "add = smt.Function(\"add\", Nat, Nat, Nat)\n",
    "add = kd.define(\"add\", [n,m], \n",
    "    kd.cond(\n",
    "        (n.is_Zero, m),\n",
    "        (n.is_Succ, Nat.Succ(add(n.pred, m)))\n",
    "))\n",
    "\n",
    "\"\"\"\n",
    "add = kd.define(\"add\", [n,m], \n",
    "    n.match_(\n",
    "        (Nat.Zero, m),\n",
    "        (Nat.Succ(n), Nat.Succ(add(n, m)))\n",
    "))\n",
    "add.defn\n",
    "\"\"\"\n",
    "add.defn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0831560e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "&#8870;ForAll(x, fact(x) == If(0 >= x, 1, x*fact(x - 1)))"
      ],
      "text/plain": [
       "|- ForAll(x, fact(x) == If(0 >= x, 1, x*fact(x - 1)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kdrag.reflect as reflect\n",
    "\n",
    "@reflect.reflect\n",
    "def fact(x : int) -> int:\n",
    "    if x <= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return x*fact(x-1)\n",
    "fact.defn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2daa3cb",
   "metadata": {},
   "source": [
    "# vectors\n",
    "\n",
    "Bitvector operations\n",
    "\n",
    "V4 style of \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d38e7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "BV32 = smt.BitVecSort(32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c68ba81",
   "metadata": {},
   "source": [
    "# Type resgistry\n",
    "\n",
    "Some \n",
    "\n",
    "add_assoc\n",
    "add_comm\n",
    "mul_assoc\n",
    "mul_comm\n",
    "\n",
    "\n",
    "COuld reaplce sortdispatch using T.add, T.mul and just have ExprRef.__add__ = lambda x,y: x.sort().add(x,y)\n",
    "\n",
    "\n",
    "\n",
    "BoolSort\n",
    "RealSort\n",
    "StringSort\n",
    "etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fabcc16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "T = smt.DeclareSort(\"T\")\n",
    "T1 = smt.DeclareSort(\"T\")\n",
    "id(T1) == id(T)\n",
    "T1.get_id() == T.get_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "191cebbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2147483659: Int,\n",
       " 2147483648: Bool,\n",
       " 2147483658: Real,\n",
       " 2147483815: NatI,\n",
       " 2147483814: Nat,\n",
       " 2147483704: BitVec(1),\n",
       " 2147483711: BitVec(8),\n",
       " 2147483898: Seq(BitVec(1)),\n",
       " 2147483841: BitVecN}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "smt.sort_registry\n",
    "import kdrag.theories.nat as nat\n",
    "smt.sort_registry\n",
    "import kdrag.theories.bitvec as bv\n",
    "smt.sort_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ca8125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hash cons the types so that we can tag useful stuff on them\n",
    "types = {}\n",
    "\n",
    "def DeclareSort(name):\n",
    "    if name not in types:\n",
    "        types[name] = type(name, (object,), {})\n",
    "    return types[name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a5313e",
   "metadata": {},
   "source": [
    "# Schematic Vars\n",
    "Explicitly pulling schematic variables out, may let me refer to them in subproofs (How?)\n",
    "\n",
    "   G |- A\n",
    "------------- weaken\n",
    "     G, v fresh |- A\n",
    "Well that's annoying.\n",
    "\n",
    "app(forall x, A, t)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "forall x, A  \n",
    "\n",
    "Maybe I should consider this as A Proof extension rather than proof replacement, likke refinement types\n",
    "\n",
    "\n",
    "```\n",
    "Gam |- t   x not in t\n",
    "-----------\n",
    "Gam, x |- t \n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "If I merged forall intro and removal\n",
    "\n",
    "\n",
    "This is just |- forall x, P(x) but with some extra junk.\n",
    "\n",
    "capture avoiding\n",
    "\n",
    "https://ncatlab.org/nlab/show/substitution\n",
    "\n",
    "https://en.wikipedia.org/wiki/Admissible_rule\n",
    "https://cstheory.stackexchange.com/questions/54600/admissible-rules-in-dependent-type-theory\n",
    "\n",
    "Gam |- A then sigma Gam |- sigma A\n",
    "\n",
    "\n",
    "The point was that\n",
    "\n",
    "prove(t, )\n",
    "\n",
    "def cprove(vs, p, by=)\n",
    "\n",
    "\n",
    "a curried form of backward proof tracking.\n",
    "modus for leaves\n",
    "comp for moves.\n",
    "but yeah, split\n",
    "A /\\ B\n",
    "(A => B => A /\\ B)\n",
    "(A => A \\/ B)\n",
    "(B => A \\/ B)\n",
    "\n",
    "A => B => C\n",
    "\n",
    "but then aplpying move in context is annoying. Hmm.\n",
    "And I don't give a shit about anything except quantifier moves so it's wasteful effort.\n",
    "\n",
    "Maybe the callback method is easier. But it'll have so many expensive calls\n",
    "\n",
    "\n",
    "def intros():\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c7b4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modus(ab, a):\n",
    "    assert smt.is_implies(ab) and ab.arg(0).eq(a)\n",
    "    assert isinstance(ab, Proof) and isinstance(a, Proof)\n",
    "    return Proof(ab.arg(1), reasons=[ab, a])\n",
    "\n",
    "def impl_refl(a):\n",
    "    return Proof(smt.Implies(a,a))\n",
    "\n",
    "def comp(ab, bc): # cut sort of\n",
    "    assert smt.is_implies(ab) and smt.is_implies(bc) and ab.arg(1).eq(bc.arg(0))\n",
    "    assert isinstance(ab, Proof) and isinstance(bc, Proof)\n",
    "    return Proof(smt.Implies(ab.arg(0), bc.arg(1)), reasons=[ab, bc])\n",
    "\n",
    "\n",
    "class Lemma():\n",
    "    self.backward_proof = impl_refl(goal)\n",
    "    self.topgoal = goal\n",
    "    self.curgoal = goal\n",
    "    \n",
    "\n",
    "def qed():\n",
    "    assert self.backwardproof.thm.eq(self.topgoal)\n",
    "    return self.backwardproof\n",
    "def fixes():\n",
    "    herb(self.topgoal)\n",
    "    self.backwardproof = comp(  , self.backwardproof)(modus(ab,a)))\n",
    "def prove():\n",
    "    p = self.prove(curgoal)\n",
    "    self.backwardproof = modus(self.backwardproof, self.proof)\n",
    "def intros():\n",
    "    self.curgoal = self.curgoal.arg(0)\n",
    "    # goal is unchanged?\n",
    "    # (a -> b) -> topgoal. uhhh. G -> \n",
    "    # \n",
    "    # /\\ (forall vs, hyps => conc) -> topgoal\n",
    "    # (hyp1 => conc1) => (hyp2 => conc2) => hyp3 => topgoal\n",
    "    # goal1 => goal2 => topgoal\n",
    "\n",
    "\n",
    "\n",
    "Goal\n",
    "  def to_expr\n",
    "   \n",
    "\n",
    "                                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32936903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deinstan(pf):\n",
    "    # get substution if last thing was an instan?\n",
    "    # Super weird idea.\n",
    "\n",
    "def cprove(\n",
    "    vs : list[smt.ExprRef],\n",
    "    thm: smt.BoolRef,\n",
    "    by = lambda *args: [] #Callable[smt.ExprRefglist[kd.Proof],\n",
    "    **kwargs\n",
    ") -> kd.kernel.Proof:\n",
    "    \"\"\"Contextual proof. Open up variable binders and give by lemmas access to them in callback\"\"\"\n",
    "    goal = smt.ForAll(vs, thm)\n",
    "    vs1, pf = kd.kernel.herb(goal)\n",
    "    subproof = kd.prove(pf.thm.arg(0), by(*vs1))\n",
    "    return kd.kernel.modus(subproof, pf)\n",
    "\n",
    "\n",
    "\n",
    "def indprove(v, thm):\n",
    "    \"\"\"Inductive proof. Open up variable binders and give by lemmas access to them in callback\"\"\"\n",
    "    goal = smt.ForAll(v, thm)\n",
    "    vs1, pf = kd.kernel.herb(goal)\n",
    "    subproof = kd.prove(pf.thm.arg(0), by(*vs1))\n",
    "    return kd.kernel.modus(subproof, pf)\n",
    "\n",
    "def indprove(v : smt.ExprRef, thm, by=None, using=None):\n",
    "    l = kd.Lemma(smt.ForAll(v, thm))\n",
    "    v1 = l.fix()\n",
    "    l.induct(v1, using=using)\n",
    "    l.auto(by=by)\n",
    "    return l.qed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e2c644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subst(vs, p : kd.Proof, subst):\n",
    "    assert isinstance(p, kd.Proof)\n",
    "    vs1, body = kd.utils.open_binder_unhygienic(p.fm)\n",
    "    assert kd.utils.free_in(vs - vs1, body)\n",
    "\n",
    "# vs\n",
    "\n",
    "# ok so we can achieve of substutiton by combining herb and instan.\n",
    "def subst(vs, p : kd.Proof, subst):\n",
    "    goal = smt.ForAll(vs, smt.substitute(p.fm, *subst.items()))\n",
    "    l = kd.Lemma(goal)\n",
    "    vs = l.fixes()\n",
    "    l.qed(by=p(subst[v] for v in vs))\n",
    "    #vs, pf = kd.kernel.herb(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf5837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Proof():\n",
    "    ctx : dict[smt.SortRef, int] # How many de bruijn indices are allowed?\n",
    "    fm : smt.BoolRef\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6262110",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Proof():\n",
    "    vs : list[smt.ExprRef] # ctx\n",
    "    fm : smt.BoolRef | smt.QuantifierRef\n",
    "    reasons : list[object]\n",
    "    def __call__(self, *args, vs=[]):\n",
    "        smt.substitute(self.fm, *zip(self.vs, args))\n",
    "\n",
    "def free(vs, fm):\n",
    "    #fm2 = smt.substitute(fm, *[(v, smt.FreshConst(v.sort())) for v in vs])\n",
    "    return smt.Lambda(vs, fm).body().eq(fm)\n",
    "    #return fm2.eq(fm)\n",
    "\n",
    "def lift(p : kd.Proof) -> Proof:\n",
    "    assert isinstance(p, kd.Proof)\n",
    "    return Proof(\n",
    "        vs = [],\n",
    "        fm = p.fm,\n",
    "        reasons = [p]\n",
    "    )\n",
    "def lift_forall(p : kd.Proof) -> Proof:\n",
    "    assert isinstance(p, kd.Proof)\n",
    "    vs, fm = kd.utils.open_binder_unhiegenic(p.fm)\n",
    "    return Proof(\n",
    "        vs = vs,\n",
    "        fm = fm,\n",
    "        reasons = [p]\n",
    "    )\n",
    "def lift_free(ctx, p : kd.Proof) -> Proof:\n",
    "    assert isinstance(p, kd.Proof)\n",
    "    assert all(v in ctx for v in p.vs)\n",
    "    assert free(ctx, p.fm)\n",
    "    return Proof(\n",
    "        vs = ctx,\n",
    "        fm = p.fm,\n",
    "        reasons = [p]\n",
    "    )\n",
    "\n",
    "\"\"\"\n",
    "  Gam |- forall x, P\n",
    "---------------\n",
    " Gam, x |- P\n",
    "\n",
    " This is reversed intro rule. Feels odd.\n",
    "\"\"\"\n",
    "def open(p : Proof) -> Proof:\n",
    "    vs, fm = kd.utils.open_binder_unhiegenic(p.fm)\n",
    "    Proof(p.vs + vs, fm, [p])\n",
    "\n",
    "def intro(n, p : Proof):\n",
    "    return Proof(p.vs[n:], smt.ForAll(p.vs[:n], p.fm), [p])\n",
    "\n",
    "def extend(vs, p : Proof) -> Proof:\n",
    "    s = smt.Solver()\n",
    "    s.add(smt.ForAll(p.vs, p.fm))\n",
    "    s.add(smt.Not(smt.ForAll(p.vs + vs, p.fm)))\n",
    "    res = s.check()\n",
    "    if res == smt.unsat:\n",
    "        return Proof(\n",
    "            vs = p.vs + vs,\n",
    "            fm = p.fm,\n",
    "            reasons = [p]\n",
    "        )\n",
    "    else:\n",
    "        raise Exception(\"Unknown result from solver\")\n",
    "\n",
    "\n",
    "def subst(p : Proof, ctx : list[smt.ExprRef], subst : dict[smt.ExprRef, smt.ExprRef]):\n",
    "    assert isinstance(p, Proof)\n",
    "    assert all(v in p.vs for v in  subst.keys())\n",
    "    assert free(ctx - p.ctx, p.fm)\n",
    "    #fm = smt.substitute(p.fm, *[(v, smt.FreshConst(v.sort())) for v in ctx])\n",
    "    fm = smt.substitute(p.fm, *subst.items())\n",
    "    # I need to check that ctx2 does not appear in fm. Otherwise I could |- even(zero) ---> zero |- even(zero)\n",
    "    return Proof(\n",
    "        vs = ctx,\n",
    "        fm = fm,\n",
    "        reasons = [p]\n",
    "    )\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "G |- p1    G |- p2 ... \n",
    "-------\n",
    "    G |- p\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def prove(ctx, expr, by=None):\n",
    "    allctx = set(ctx)\n",
    "    for p in by:\n",
    "        assert isinstance(p, Proof)\n",
    "        assert p.ctx == ctx\n",
    "    s.add(smt.Not(smt.ForAll([ctx], smt.Implies(smt.And(hyp.fm for hyp in by), expr))))\n",
    "    s.check()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e114fb5",
   "metadata": {},
   "source": [
    "Ok so yes, any forall infecting the lemmas is a problem.\n",
    "And some things get foralls because its hard an annoying \n",
    "\n",
    "qed should \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe69def9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.all import *\n",
    "import kdrag.theories.real as real\n",
    "x,y = smt.Reals(\"x y\")\n",
    "cos = real.cos\n",
    "sin = real.sin\n",
    "#os_diff = kd.prove(smt.ForAll([x,y], cos(x - y) == cos(x)*cos(y) + sin(x)*sin(y)), [real.cos_add, real.cos_neg, real.sin_neg])\n",
    "\n",
    "_l = kd.Lemma(smt.ForAll([x,y], cos(x - y) == cos(x)*cos(y) + sin(x)*sin(y)))\n",
    "_x, _y = _l.fixes()\n",
    "_l.symm()\n",
    "_l.eq(cos(_x + (-_y)))\n",
    "#_l.rw(kd.prove(cos(_x - _y) == cos(_x + (-_y))))\n",
    "#_l.rw(kd.prove(smt.ForAll([x,y], x - y == (x + (-y))))(_x, _y))\n",
    "_l.rw(real.cos_add(_x, -_y))\n",
    "#_l.auto(by=[real.cos_add, real.sin_add])\n",
    "_l.auto(by=[real.cos_neg(_y), real.sin_neg(_y)])\n",
    "_l.lemmas\n",
    "_l.qed()\n",
    "cos_diff = _l.lemmas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd2f219",
   "metadata": {},
   "source": [
    "# Homomorphism theorems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8dd031",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Not registered in typeclass', (A,))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m id_, assoc, id_left, inv_left\n\u001b[32m     19\u001b[39m B = smt.DeclareSort(\u001b[33m'\u001b[39m\u001b[33mB\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mgroup\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGroup\u001b[49m\u001b[43m.\u001b[49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m idA, assocA, id_leftA, inv_leftA = Group(A)\n\u001b[32m     22\u001b[39m idB, assocB, id_leftB, inv_leftB = Group(B)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/python/knuckledragger/kdrag/property.py:66\u001b[39m, in \u001b[36mTypeClass.register\u001b[39m\u001b[34m(cls, *L, **kwargs)\u001b[39m\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAlready registered key\u001b[39m\u001b[33m\"\u001b[39m, L)\n\u001b[32m     65\u001b[39m registry[L] = kwargs\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mL\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/python/knuckledragger/kdrag/property.py:42\u001b[39m, in \u001b[36mTypeClass.__init__\u001b[39m\u001b[34m(self, *L)\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, k, v)\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcheck\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mL\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/python/knuckledragger/kdrag/theories/algebra/group.py:74\u001b[39m, in \u001b[36mGroup.check\u001b[39m\u001b[34m(self, T)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck\u001b[39m(\u001b[38;5;28mself\u001b[39m, T):\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     \u001b[38;5;28mself\u001b[39m.Monoid = \u001b[43mMonoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mself\u001b[39m.e = \u001b[38;5;28mself\u001b[39m.Monoid.e\n\u001b[32m     76\u001b[39m     \u001b[38;5;28mself\u001b[39m.assoc = \u001b[38;5;28mself\u001b[39m.Monoid.assoc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/python/knuckledragger/kdrag/property.py:38\u001b[39m, in \u001b[36mTypeClass.__init__\u001b[39m\u001b[34m(self, *L)\u001b[39m\n\u001b[32m     36\u001b[39m registry = \u001b[38;5;28mself\u001b[39m.get_registry()\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m L \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m registry:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNot registered in typeclass\u001b[39m\u001b[33m\"\u001b[39m, L)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m registry[L].items():\n\u001b[32m     40\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, k, v)\n",
      "\u001b[31mValueError\u001b[39m: ('Not registered in typeclass', (A,))"
     ]
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "import kdrag.property as prop\n",
    "import kdrag.theories.algebra.group as group\n",
    "\n",
    "A = smt.DeclareSort('A')\n",
    "def Group(A):\n",
    "    mul = smt.Function('mul', A, A, A)\n",
    "    inv = smt.Function('inv', A, A)\n",
    "    id_ = smt.Const('id', A)\n",
    "    x,y,z = smt.Consts('x y z', A)\n",
    "    kd.notation.mul.register(A, mul)\n",
    "    kd.notation.invert.register(A, inv)\n",
    "    assoc = kd.axiom(smt.ForAll([x,y,z], x * (y * z) == (x * y) * z))\n",
    "    id_left = kd.axiom(smt.ForAll([x], id_ * x == x))\n",
    "    inv_left = kd.axiom(smt.ForAll([x], inv(x) * x == id_))\n",
    "    return id_, assoc, id_left, inv_left\n",
    "\n",
    "\n",
    "B = smt.DeclareSort('B')\n",
    "group.Group.register(A)\n",
    "idA, assocA, id_leftA, inv_leftA = Group(A)\n",
    "idB, assocB, id_leftB, inv_leftB = Group(B)\n",
    "\n",
    "h = smt.Function('h', A, B)\n",
    "def homo(id_, h):\n",
    "    A = h.domain(0)\n",
    "    B = h.range()\n",
    "    x,y,z = smt.Consts(\"x y z\", A)\n",
    "    mul = smt.ForAll([x,y], h(x * y) == h(x) * h(y))\n",
    "    id_ = h(idA) == idB\n",
    "    inv = smt.ForAll([x], h(~x) == ~h(x))\n",
    "    return mul, id_, inv\n",
    "homo(h)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eb2f2b",
   "metadata": {},
   "source": [
    "Universe of groups.\n",
    "\n",
    "I was saying construct it as permuations  Int -> Int\n",
    "\n",
    "Nontrivial\n",
    "But we could also driectly axiomatize\n",
    "\n",
    "* is composition\n",
    "id is  x -> x\n",
    "homomorphisms need to... be careful here. Only push homo through on particular Group?\n",
    "SetGrp \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Grp = smt.DeclareSort(\"Grp\")\n",
    "SetGrp = set_.SetSort(Grp)\n",
    "inv = smt.Function(\"inv\", Grp, Grp)\n",
    "# inv = smt.Function(\"inv\", GrpSet, GrpSet)\n",
    "mul = smt.Function(\"mul\", Grp, Grp) # We just leave mul un\n",
    "\n",
    "Closed = smt.QForAll([x,y, S], S[x], S[y], S[x * y], S[inv(x)])\n",
    "\n",
    "smt.QForAll([S], Closed[S], S[x], S[y], S[z],  x*(y*z) == (x * y) * z) # Is there a model where mul can be associative and always defined? \n",
    "smt.QForAll([S], Closed[S], S[x], inv(x) * x == x)  # maybe unconditionally actually\n",
    "smt.QForAll([S], id_ * x == x) # also unconditiojnality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
