{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49b1eff0",
   "metadata": {},
   "source": [
    "https://github.com/ftsrg/chc2c\n",
    "extraction\n",
    "\n",
    "https://arxiv.org/abs/2505.13454 pyeb: A Python Implementation of Event-B Refinement Calculus https://github.com/ncatanoc/pyeb\n",
    "\n",
    "Compete in smtlib / cade?\n",
    "\n",
    "TPTP parser? \n",
    "\n",
    "Try ingesting all of TPTP problem set. Egraph?\n",
    "\n",
    "\n",
    "float16 in numpy. Brute force check properties of floats.\n",
    "float8 would be a lookup table maybe.\n",
    "\n",
    "\n",
    "\n",
    "# Jules jacobs macros vs internal\n",
    "\n",
    "https://www.reddit.com/r/ProgrammingLanguages/comments/1aigns2/discussing_isabellehol_a_proof_assistant_for/kova7l5/\n",
    "\n",
    "\"This is a good question.\n",
    "\n",
    "The advantage of higher-order logic over first-order logic is that propositions (and predicates) become first-class objects that you can abstract over in the theory.\n",
    "\n",
    "Similarly, the advantage of type theory over higher-order logic is that types (and type constructors) become first-class objects that you can abstract over in the theory.\n",
    "\n",
    "In that sense, if you understand what higher order logic gives you over first order logic, then you can understand what type theory gives you over higher order logic by analogy.\n",
    "\n",
    "In both cases you can work around these limitations to some extent by using the meta-language as a macro system. For instance, if you only had first-order logic but you wanted to write a lemma that says something about a predicate (say, the strong induction lemma for natural numbers that is generic over some predicate P : nat -> prop), you could write the lemma as a macro that takes as input a predicate represented as a meta-level function that produces a formula, and write the proof of the lemma as a macro that generates a new proof for each new predicate P that the lemma is used on.\n",
    "\n",
    "Similarly, in HOL you cannot write down code that is generic over a type constructor, e.g. code generic over a monad. Nor can you write down lemmas about such generic code. You can write a meta-level macro that does it, similar to how you can work around the limitations of first-order logic regarding propositions and predicates.\n",
    "\n",
    "The big problem with this workaround is that now all your code and lemmas are checked at the use site instead of the definition site, similar to how C++ templates work. This also means that you can never write down and prove such a generic theorem; you can only generate and check instances of it.\n",
    "\n",
    "The other main way to work around these problems is to not work in first order logic, but instead work in some theory built on top of first order logic. That's what ZFC set theory does. You can do something analogous in HOL, by not really working with types at all, but rather work in some sufficiently general un(i)typed universe and always work with predicates/subsets of that.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2cf0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11731f67",
   "metadata": {},
   "source": [
    "# Hoare\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddbfc287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Module(body=[Assign(targets=[Tuple(elts=[Name(id='x', ctx=Store()), Name(id='y', ctx=Store())], ctx=Store())], value=Tuple(elts=[Constant(value=3), Constant(value=2)], ctx=Load())), Assign(targets=[Name(id='y', ctx=Store())], value=Constant(value=7))], type_ignores=[])\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast.dump(ast.parse(\"x,y = 3,2; y = 7\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f80befb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Hoare():\n",
    "    pre : smt.BoolRef\n",
    "    cmd : ast.AST | list[ast.AST]\n",
    "    post : smt.BoolRef\n",
    "    reasons : list\n",
    "    def __repr__(self):\n",
    "        if isinstance(self.cmd, list):\n",
    "            cmd = ast.Module(body=self.cmd)\n",
    "        else:\n",
    "            cmd = self.cmd\n",
    "        return f\"{{{self.pre}}} {cmd} {{{self.post}}}\"\n",
    "    @classmethod\n",
    "    def skip(cls, P):\n",
    "        return cls(P, ast.Pass(), P, [\"skip\"])\n",
    "    @classmethod\n",
    "    def assign(cls, cmd, P):\n",
    "        match cmd:\n",
    "            case ast.Assign(targets=[ast.Name(id=x, ctx=ast.Store())], value=e):\n",
    "                e = kdrag.reflect.expr(e)\n",
    "                x = smt.Const(x, e.sort())\n",
    "                return cls(smt.substitute(P, (x, e)), cmd, P, [\"assign\"])\n",
    "            case _:\n",
    "                raise ValueError(f\"Unsupported assignment: {ast.unparse(cmd)}\")\n",
    "    def __matmul__(self, other: 'Hoare') -> 'Hoare':\n",
    "        if not self.post.eq(other.pre):\n",
    "            raise ValueError(f\"Postcondition {self.post} does not match precondition {other.pre}\")\n",
    "        return Hoare(self.pre, [self.cmd, other.cmd], other.post, [self, other])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def wp(stmt : ast.AST, P : smt.BoolRef) -> Hoare:\n",
    "    match stmt:\n",
    "        case ast.Assign():\n",
    "            return Hoare.assign(stmt, P)\n",
    "        case ast.Pass():\n",
    "            return Hoare.skip(P)\n",
    "        case ast.Module(body=stmts):\n",
    "            return wps(stmts, P)\n",
    "\n",
    "def wps(stmts : list[ast.AST], P : smt.BoolRef) -> Hoare:\n",
    "    for stmt in reversed(stmts):\n",
    "        pf = wp(stmt, P)\n",
    "        P = pf.pre\n",
    "    return pf\n",
    "\n",
    "\n",
    "def wp_sr(s : str, P : smt.BoolRef) -> Hoare:\n",
    "    \"\"\"\n",
    "    Compute the weakest precondition for a string of Python code `s` with postcondition `P`.\n",
    "    \"\"\"\n",
    "    tree = ast.parse(s)\n",
    "    return wps(tree.body, P)\n",
    "\n",
    "\n",
    "x,y,z = smt.Ints(\"x y z\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1763ce",
   "metadata": {},
   "source": [
    "# python dsl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f34f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TypeAlias(name=Name(id='Foo', ctx=Store()), type_params=[], value=BinOp(left=BinOp(left=BinOp(left=Name(id='Biz', ctx=Load()), op=BitOr(), right=Name(id='Bar', ctx=Load())), op=BitOr(), right=Call(func=Name(id='Baz', ctx=Load()), args=[Name(id='Int', ctx=Load()), Name(id='Int', ctx=Load())], keywords=[])), op=BitOr(), right=Call(func=Name(id='Boz', ctx=Load()), args=[], keywords=[keyword(arg='x', value=Name(id='Int', ctx=Load())), keyword(arg='y', value=Name(id='Int', ctx=Load()))])))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Int"
      ],
      "text/plain": [
       "Int"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "from kdrag.all import *\n",
    "import inspect\n",
    "def datatype(s : str, locals=None, globals=None) -> smt.DatatypeSortRef:\n",
    "    if locals is None:\n",
    "        locals = inspect.currentframe().f_back.f_locals\n",
    "    if globals is None:\n",
    "        globals = inspect.currentframe().f_back.f_globals\n",
    "    mod = ast.parse(s)\n",
    "    body = mod.body\n",
    "    if len(body) != 1:\n",
    "        raise ValueError(f\"Expected a single type alias, got {ast.unparse(mod)}\")\n",
    "    type_alias = body[0]\n",
    "    if not isinstance(body[0], ast.TypeAlias):\n",
    "        raise ValueError(f\"Expected a single type alias, got {ast.unparse(body[0])}\")\n",
    "    print(ast.dump(type_alias))\n",
    "    dt = kd.Inductive(type_alias.name.id)\n",
    "    todo = [type_alias.value]\n",
    "    while todo:\n",
    "        match todo.pop():\n",
    "            case ast.BinOp(op=ast.BitOr(), left=left, right=right):\n",
    "                todo.append(right)\n",
    "                todo.append(left)\n",
    "            case ast.Name(id=name):\n",
    "                dt.declare(name)\n",
    "            case ast.Call(func=ast.Name(id=name), args=args, keywords=[]):\n",
    "                dt.declare(name, *[( f\"{name}_{n}\" ,locals[arg.id]) for n,arg in enumerate(args)]) # caller_frame = inspect.currentframe().f_back\n",
    "            case ast.Call(func=ast.Name(id=name), args=[], keywords=keywords):\n",
    "                dt.declare(name, *[(kw.arg ,locals[kw.value.id]) for kw in keywords]) # caller_frame = inspect.currentframe().f_back\n",
    "            case _:\n",
    "                raise ValueError(f\"Unexpected subexpresison: {ast.unparse(type_alias.value)}\")\n",
    "    return dt.create()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Int = smt.IntSort()\n",
    "Real = smt.RealSort()\n",
    "Foo = datatype(\"type Foo = Biz | Bar | Baz(Int, Int) | Boz(x = Int, y = Int)\")\n",
    "# Foo = datatype(\"type Foo = Biz | Bar | Baz(Int, Int) | Boz(x = Int, y = {Int})\") explicitly mark the things that should be interpolate in?\n",
    "Foo.Biz\n",
    "Foo.Baz.domain(1)\n",
    "Foo.x.range()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97530ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setcomp(s:str, locals=None, globals=None): ...\n",
    "\n",
    "ast.parse(\"{{x + 1 for x in A if x > 0}}\")\n",
    "#smt.Lambda([y], smt.Exists([x], y == x + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b1794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "case ast.SetComp(elt=elt, generators=generators):\n",
    "    res = rec(elt)\n",
    "    y = smt.FreshConst(res.sort())\n",
    "    genvars = []\n",
    "    smt.Lambda([y], smt.Exists())\n",
    "    xs = [ast.unparse(x) for x in elt.generators[0].iter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6ef115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module(\n",
      "    body=[\n",
      "        Expr(\n",
      "            value=SetComp(\n",
      "                elt=Name(id='x', ctx=Load()),\n",
      "                generators=[\n",
      "                    comprehension(\n",
      "                        target=Name(id='x', ctx=Store()),\n",
      "                        iter=Name(id='Int', ctx=Load()),\n",
      "                        ifs=[],\n",
      "                        is_async=0),\n",
      "                    comprehension(\n",
      "                        target=Name(id='y', ctx=Store()),\n",
      "                        iter=Name(id='Int', ctx=Load()),\n",
      "                        ifs=[\n",
      "                            BoolOp(\n",
      "                                op=And(),\n",
      "                                values=[\n",
      "                                    Compare(\n",
      "                                        left=Name(id='x', ctx=Load()),\n",
      "                                        ops=[\n",
      "                                            Gt()],\n",
      "                                        comparators=[\n",
      "                                            Constant(value=0)]),\n",
      "                                    Compare(\n",
      "                                        left=Name(id='y', ctx=Load()),\n",
      "                                        ops=[\n",
      "                                            Lt()],\n",
      "                                        comparators=[\n",
      "                                            Constant(value=0)])])],\n",
      "                        is_async=0)]))],\n",
      "    type_ignores=[])\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "print(ast.dump(ast.parse(\"{x for x in Int for y in Int if x > 0 and y < 0}\"), indent=4))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b23f869",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Could not interpret expression', '{x for x in int if x > 0}', \"SetComp(elt=Name(id='x', ctx=Load()), generators=[comprehension(target=Name(id='x', ctx=Store()), iter=Name(id='int', ctx=Load()), ifs=[Compare(left=Name(id='x', ctx=Load()), ops=[Gt()], comparators=[Constant(value=0)])], is_async=0)])\")",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m x = smt.Int(\u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m expr(\u001b[33m\"\u001b[39m\u001b[33mx + 1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mexpr\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mx for x in int if x > 0}\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/python/knuckledragger/kdrag/reflect.py:554\u001b[39m, in \u001b[36mexpr\u001b[39m\u001b[34m(expr, globals, locals)\u001b[39m\n\u001b[32m    552\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    553\u001b[39m     \u001b[38;5;28mglobals\u001b[39m, _ = _calling_globals_locals()\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_reflect_expr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m    \u001b[49m\u001b[43mast\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\n\u001b[32m    556\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/python/knuckledragger/kdrag/reflect.py:527\u001b[39m, in \u001b[36m_reflect_expr\u001b[39m\u001b[34m(expr, globals, locals)\u001b[39m\n\u001b[32m    522\u001b[39m         \u001b[38;5;28;01mcase\u001b[39;00m x:\n\u001b[32m    523\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    524\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mCould not interpret expression\u001b[39m\u001b[33m\"\u001b[39m, ast.unparse(x), ast.dump(x)\n\u001b[32m    525\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m527\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/python/knuckledragger/kdrag/reflect.py:523\u001b[39m, in \u001b[36m_reflect_expr.<locals>.rec\u001b[39m\u001b[34m(expr)\u001b[39m\n\u001b[32m    521\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(rec(value), attr)\n\u001b[32m    522\u001b[39m \u001b[38;5;28;01mcase\u001b[39;00m x:\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    524\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not interpret expression\u001b[39m\u001b[33m\"\u001b[39m, ast.unparse(x), ast.dump(x)\n\u001b[32m    525\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: ('Could not interpret expression', '{x for x in int if x > 0}', \"SetComp(elt=Name(id='x', ctx=Load()), generators=[comprehension(target=Name(id='x', ctx=Store()), iter=Name(id='int', ctx=Load()), ifs=[Compare(left=Name(id='x', ctx=Load()), ops=[Gt()], comparators=[Constant(value=0)])], is_async=0)])\")"
     ]
    }
   ],
   "source": [
    "from kdrag.reflect import expr\n",
    "from kdrag.all import *\n",
    "x = smt.Int(\"x\")\n",
    "expr(\"x + 1\")\n",
    "expr(\"{x for x in int if x > 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c74565",
   "metadata": {},
   "source": [
    "# unapply\n",
    "\n",
    "What about a table to register unapply patterns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de889154",
   "metadata": {},
   "outputs": [],
   "source": [
    "unapply = {}\n",
    "\n",
    "def add_unapply(t):\n",
    "    \n",
    "#def add_unapply(pat, t): ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e2907b",
   "metadata": {},
   "source": [
    "# recfunction translate\n",
    "\n",
    "Maybe I should just dump the definitions into the main ctx. Why not?\n",
    "Well, sometimes I want to hide them. I dunno.\n",
    "Be an interesting experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f440a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "smt.RecAddDefinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7934a641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "7"
      ],
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "def define_rec(name, args, body):\n",
    "    \"\"\"\n",
    "    Define a recursive function with the given name, arguments, and body.\n",
    "    \"\"\"\n",
    "    f_not_rec = kd.define(name, args, body)\n",
    "    f = smt.RecFunction(name, *[arg.sort() for arg in args], body.sort())\n",
    "    smt.RecAddDefinition(f, args, smt.substitute_funs(body, (f_not_rec, f(*[smt.Var(n, f.domain(n)) for n in range(f.arity())]))))\n",
    "    return f_not_rec #?\n",
    "n,m = smt.Ints(\"n m\")\n",
    "add = smt.RecFunction(\"add\", smt.IntSort(), smt.IntSort(), smt.IntSort())\n",
    "\n",
    "add1 = define_rec(\"add\", [n, m], smt.If(n <= 0, m, add(n - 1, m) + 1))\n",
    "\n",
    "smt.simplify(add(3,4))\n",
    "\n",
    "#smt.simplify(add1(3,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23bddcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function z3.z3core.Z3_to_func_decl(a0, a1, _elems=<z3.z3core.Elementaries object at 0x7d4458071cd0>)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import z3\n",
    "z3.z3core.Z3_to_func_decl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b244db65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(even, even(Var(0))), (odd, odd(Var(0))), (safe_pred, safe_pred(Var(0))), (from_int, from_int(Var(0))), (to_int, Var(0)), (double, double(Var(0))), (add, add(Var(1), Var(0)))]\n",
      "[Int]\n",
      "Int\n",
      "even\n",
      "[even]\n",
      "even [even] Exists(y, odd(even, 2*y))\n",
      "[Int]\n",
      "Int\n",
      "even\n",
      "[even]\n",
      "odd [even] Exists(y, odd(even, 2*y + 1))\n",
      "[n]\n",
      "n\n",
      "Select\n",
      "[Select]\n",
      "safe_pred [Select] If(is(Z, Select), x!1, pred(Select))\n",
      "[a]\n",
      "a\n",
      "a\n",
      "[a]\n",
      "from_int [a] If(a <= 0, x!1, S(from_int(a - 1)))\n",
      "[n]\n",
      "n\n",
      "n\n",
      "[n]\n",
      "to_int [n] If(is(Z, n), 0, 1 + (pred(n)))\n",
      "[n]\n",
      "n\n",
      "n\n",
      "[n]\n",
      "double [n] If(is(Z, n), x!1, S(S(double(pred(n)))))\n",
      "[x, y]\n",
      "x\n",
      "x\n",
      "y\n",
      "x\n",
      "[x, x]\n",
      "add [x, x] If(is(Z, x), x, S(add(x, pred(x))))\n"
     ]
    },
    {
     "ename": "Z3Exception",
     "evalue": "b'index out of bounds'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mZ3Exception\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28mprint\u001b[39m(t)\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m smt.simplify(smt.substitute_funs(t, *subst))\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m simp(\u001b[43mnat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdouble\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mZ\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/philzook58.github.io/.venv/lib/python3.12/site-packages/z3/z3.py:880\u001b[39m, in \u001b[36mFuncDeclRef.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    876\u001b[39m saved = []\n\u001b[32m    877\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num):\n\u001b[32m    878\u001b[39m     \u001b[38;5;66;03m# self.domain(i).cast(args[i]) may create a new Z3 expression,\u001b[39;00m\n\u001b[32m    879\u001b[39m     \u001b[38;5;66;03m# then we must save in 'saved' to prevent it from being garbage collected.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m880\u001b[39m     tmp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m.cast(args[i])\n\u001b[32m    881\u001b[39m     saved.append(tmp)\n\u001b[32m    882\u001b[39m     _args[i] = tmp.as_ast()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/philzook58.github.io/.venv/lib/python3.12/site-packages/z3/z3.py:802\u001b[39m, in \u001b[36mFuncDeclRef.domain\u001b[39m\u001b[34m(self, i)\u001b[39m\n\u001b[32m    792\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdomain\u001b[39m(\u001b[38;5;28mself\u001b[39m, i):\n\u001b[32m    793\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the sort of the argument `i` of a function declaration.\u001b[39;00m\n\u001b[32m    794\u001b[39m \u001b[33;03m    This method assumes that `0 <= i < self.arity()`.\u001b[39;00m\n\u001b[32m    795\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    800\u001b[39m \u001b[33;03m    Real\u001b[39;00m\n\u001b[32m    801\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m802\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _to_sort_ref(\u001b[43mZ3_get_domain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mctx_ref\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m.ctx)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/philzook58.github.io/.venv/lib/python3.12/site-packages/z3/z3core.py:3035\u001b[39m, in \u001b[36mZ3_get_domain\u001b[39m\u001b[34m(a0, a1, a2, _elems)\u001b[39m\n\u001b[32m   3033\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mZ3_get_domain\u001b[39m(a0, a1, a2, _elems=Elementaries(_lib.Z3_get_domain)):\n\u001b[32m   3034\u001b[39m   r = _elems.f(a0, a1, a2)\n\u001b[32m-> \u001b[39m\u001b[32m3035\u001b[39m   \u001b[43m_elems\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3036\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/philzook58.github.io/.venv/lib/python3.12/site-packages/z3/z3core.py:1579\u001b[39m, in \u001b[36mElementaries.Check\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m   1577\u001b[39m err = \u001b[38;5;28mself\u001b[39m.get_error_code(ctx)\n\u001b[32m   1578\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m err != \u001b[38;5;28mself\u001b[39m.OK:\n\u001b[32m-> \u001b[39m\u001b[32m1579\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m.Exception(\u001b[38;5;28mself\u001b[39m.get_error_message(ctx, err))\n",
      "\u001b[31mZ3Exception\u001b[39m: b'index out of bounds'"
     ]
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "import kdrag.theories.nat as nat\n",
    "\n",
    "ctx = smt.Context()\n",
    "z3.ZE_DEBUG = False\n",
    "\n",
    "subst = []\n",
    "for f, defn in kd.kernel.defns.items():\n",
    "    #print(f)\n",
    "    f = f.translate(ctx)\n",
    "    f.ast = z3.z3core.Z3_to_func_decl(f.ctx.ref(), f.ast) #f.ast.translate(ctx)\n",
    "    args = [arg.translate(ctx) for arg in defn.args]\n",
    "    body = defn.body.translate(ctx)\n",
    "    frec = smt.RecFunction(f.name(), *[f.domain(i) for i in range(f.arity())] ,f.range())\n",
    "    #print(type(f), type(body))\n",
    "    subst.append((f, frec(*[smt.Var(f.arity() - n - 1, f.domain(n)) for n in range(f.arity())])))\n",
    "    subst[0][0].as_func_decl()\n",
    "    smt.substitute_funs(body, *subst)\n",
    "print(subst)\n",
    "for f, defn in kd.kernel.defns.items():\n",
    "    #print(f)\n",
    "    f = f.translate(ctx)\n",
    "    print(defn.args)\n",
    "    for arg in defn.args:\n",
    "        print(arg)\n",
    "        print(arg.translate(ctx))\n",
    "    args = [arg.translate(ctx) for arg in defn.args]\n",
    "    print(args)\n",
    "    body = defn.body.translate(ctx)\n",
    "    frec = smt.RecFunction(f.name(), *[f.domain(i) for i in range(f.arity())] ,f.range())\n",
    "    print(frec, args, smt.substitute_funs(body, *subst))\n",
    "    smt.RecAddDefinition(frec, args, smt.substitute_funs(body, *subst))\n",
    "\n",
    "\n",
    "def simp(t):\n",
    "    t = t.translate(ctx)\n",
    "    print(t)\n",
    "    return smt.simplify(smt.substitute_funs(t, *subst))\n",
    "\n",
    "\n",
    "\n",
    "simp(nat.double(nat.Z, nat.Z))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de0de2f",
   "metadata": {},
   "source": [
    "# Extract Langs\n",
    "C boehm GC\n",
    "Rust via maturin + RC\n",
    "Separate z3 context + recfunction\n",
    "Java py4j https://www.py4j.org/\n",
    "\n",
    "\n",
    "\n",
    "Maybe the rust version could lay some claim to\n",
    "Both fast and correct version of code.\n",
    "Output Kani conditions.\n",
    "\n",
    "\n",
    "https://docs.rs/numpy/latest/numpy/\n",
    "\n",
    "copilot inspired.\n",
    "State loop?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477de7ae",
   "metadata": {},
   "source": [
    "## rust\n",
    "\n",
    "What about kdrag-rs? Just do it all in rust. Learning rust details could be fun\n",
    "\n",
    "\n",
    "Could macro the shit out of it I suppose?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b6e436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/test.rs\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/test.rs\n",
    "---cargo\n",
    "[dependencies]\n",
    "z3 = \"0.12.1\"\n",
    "lazy_static = \"1.5.0\"\n",
    "---\n",
    "\n",
    "use z3::ast::Ast;\n",
    "/*\n",
    "\n",
    "use std::sync::LazyLock;\n",
    "\n",
    "lazy_static::lazy_static! {\n",
    "    static ref Z3_CTX: z3::Context = z3::Context::new(&z3::Config::new());\n",
    "}\n",
    "\n",
    "static Z3_CTX: LazyLock<z3::Context> = LazyLock::new(|| {\n",
    "    z3::Context::new(&z3::Config::new())\n",
    " });\n",
    "\n",
    "\n",
    "fn pmatch<'ctx>(ctx : &'ctx z3::Context, vs : , fm : &'ctx z3::ast::Dynamic<'ctx>, pat : &'ctx z3::ast::Dynamic<'ctx>) -> Vec<> {\n",
    "    let mut todo = vec![(fm, pat)];\n",
    "    while todo{\n",
    "\n",
    "    }\n",
    "}\n",
    "*/\n",
    "\n",
    "#[derive(Debug)]\n",
    "struct Proof<'ctx> {\n",
    "    fm : &'ctx z3::ast::Bool<'ctx>,\n",
    "}\n",
    "fn prove<'ctx>(ctx : &'ctx z3::Context, fm : &'ctx z3::ast::Bool) -> Proof<'ctx> {\n",
    "    let solver = z3::Solver::new(ctx);\n",
    "    solver.assert(&fm.not());\n",
    "    if solver.check() == z3::SatResult::Unsat {\n",
    "        Proof { fm }\n",
    "    } else {\n",
    "        panic!(\"Unsatisfiable\");\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "fn main(){\n",
    "    let ctx = z3::Context::new(&z3::Config::new());\n",
    "    let solver = z3::Solver::new(&ctx);\n",
    "    let x = z3::ast::Int::new_const(&ctx, \"x\");\n",
    "    let y = z3::ast::Int::new_const(&ctx, \"y\");\n",
    "    let z = z3::ast::Int::new_const(&ctx, \"z\");\n",
    "\n",
    "    let _true = z3::ast::Bool::from_bool(&ctx, true);\n",
    "    let p = prove(&ctx, &_true);\n",
    "    println!(\"Proof: {:?}\", p.fm);\n",
    "\n",
    "    let _T = z3::Sort::uninterpreted(&ctx, z3::Symbol::from(\"T\"));\n",
    "\n",
    "\n",
    "    solver.assert(&x._eq(&y));\n",
    "    solver.assert(&x._eq(&(y + z)));\n",
    "\n",
    "    if solver.check() == z3::SatResult::Sat {\n",
    "        println!(\"Satisfiable\");\n",
    "        println!(\"Model: {:?}\", solver.get_model());\n",
    "    } else {\n",
    "        println!(\"Unsatisfiable\");\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "92b98e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m:\u001b[0m `package.edition` is unspecified, defaulting to `2024`\n",
      "\u001b[1m\u001b[32m   Compiling\u001b[0m test- v0.0.0 (/tmp/test.rs)\n",
      "\u001b[K\u001b[0m\u001b[1m\u001b[33mwarning\u001b[0m\u001b[0m\u001b[1m: variable `_T` should have a snake case name\u001b[0m       \n",
      "\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0mtest.rs:47:9\u001b[0m\n",
      "\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[38;5;12m47\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m    let _T = z3::Sort::uninterpreted(&ctx, z3::Symbol::from(\"T\"));\u001b[0m\n",
      "\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m         \u001b[0m\u001b[0m\u001b[1m\u001b[33m^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[33mhelp: convert the identifier to snake case: `_t`\u001b[0m\n",
      "\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n",
      "\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mnote\u001b[0m\u001b[0m: `#[warn(non_snake_case)]` on by default\u001b[0m\n",
      "\n",
      "\u001b[K\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m:\u001b[0m `test-` (bin \"test-\") generated 1 warning                 \n",
      "\u001b[1m\u001b[32m    Finished\u001b[0m `dev` profile [unoptimized + debuginfo] target(s) in 0.10s\n",
      "\u001b[1m\u001b[32m     Running\u001b[0m `/home/philip/.cargo/target/e8/a8b1c02d8deab1/debug/test-`\n",
      "Proof: true\n",
      "Satisfiable\n",
      "Model: Some(z -> 0\n",
      "x -> 0\n",
      "y -> 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "! cargo +nightly -Zscript /tmp/test.rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e615406",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'maturin'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmaturin\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'maturin'"
     ]
    }
   ],
   "source": [
    "import maturin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af8dff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use pyo3::prelude::*;\n",
      "use pyo3::wrap_pyfunction;\n",
      "\n",
      "#[derive(FromPyObject, IntoPyObject)]\n",
      "struct MyType { field1: i32, field2: String }\n",
      "\n",
      "#[pyfunction]\n",
      "fn add(n: i32, m: i32) -> i32 {n + m}\n",
      "}\n",
      "\n",
      "#[pymodule]\n",
      "fn kdrag_smt(m: &Bound<'_, PyModule>) -> PyResult<()> {\n",
      "    m.add_function(wrap_pyfunction!(add, m)?)?;\n",
      "    Ok(())\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class RustModule():\n",
    "    def __init__(self, modname):\n",
    "        self.modname = modname\n",
    "        self.funcs = {}\n",
    "        self.types = []\n",
    "\n",
    "    def add_type(self, type_code):\n",
    "        self.types.append(type_code)\n",
    "    \n",
    "    def add_function(self, fun_name, fun_code):\n",
    "        \"\"\"\n",
    "        Add a function to the module with the given name and code.\n",
    "        \"\"\"\n",
    "        if fun_name in self.funcs:\n",
    "            raise ValueError(f\"Function {fun_name} already exists in module {self.modname}.\")\n",
    "        self.funcs[fun_name] = fun_code\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "            types = \"\\n\".join(\"#[derive(FromPyObject, IntoPyObject)]\\n\" + type_code for type_code in self.types)\n",
    "            fun_code = \"\\n\".join(f\"#[pyfunction]\\n{fun_code}\" for fun_code in self.funcs.values())\n",
    "            add_funs = \"\\n\".join(f\"m.add_function(wrap_pyfunction!({fun_name}, m)?)?;\" for fun_name in self.funcs.keys())\n",
    "            return f\"\"\"\\\n",
    "use pyo3::prelude::*;\n",
    "use pyo3::wrap_pyfunction;\n",
    "use pyo3_ffi::c_str;\n",
    "\n",
    "{types}\n",
    "\n",
    "{fun_code}\n",
    "\n",
    "#[pymodule]\n",
    "fn {self.modname}(m: &Bound<'_, PyModule>) -> PyResult<()> {{\n",
    "    {add_funs}\n",
    "    Ok(())\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "M = RustModule(\"kdrag_smt\")\n",
    "M.add_function(\"add\", \"fn add(n: i32, m: i32) -> i32 {n + m}\\n}\")\n",
    "M.add_type(\"struct MyType { field1: i32, field2: String }\")\n",
    "print(str(M))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213dd113",
   "metadata": {},
   "source": [
    "## wasm\n",
    "\n",
    "Extract to wasm, run it./\n",
    "\n",
    "Hmm. wasmtime has gc... That sweetens the pie a lot.\n",
    "\n",
    "https://developer.mozilla.org/en-US/docs/WebAssembly\n",
    "https://developer.mozilla.org/en-US/docs/WebAssembly/Guides/Understanding_the_text_format\n",
    "\n",
    "https://github.com/WebAssembly/gc/blob/main/proposals/gc/Overview.md\n",
    "https://github.com/bytecodealliance/wasmtime-py\n",
    "\n",
    "https://tanishiking.github.io/posts/wasm-gc/\n",
    "\n",
    "Codegen an ematcher. We used to talk about this. Or codegenning actions.\n",
    "\n",
    "Hmm. But maybe one can hold external references to the host... so maybe structured objects could be dealt with that way. Using python.\n",
    "\n",
    "Or pretty print, process call wasmtime cli. Read output. Could be worse. Gets me ready for the day wasm_gc is avaiable in the bindings.\n",
    "wasmer?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fbcdfffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from Python!\n"
     ]
    }
   ],
   "source": [
    "from wasmtime import Store, Module, Instance, Func, FuncType\n",
    "\n",
    "store = Store()\n",
    "module = Module(store.engine, \"\"\"\n",
    "  (module\n",
    "    (func $hello (import \"\" \"hello\"))\n",
    "    (func (export \"run\") (call $hello))\n",
    "  )\n",
    "\"\"\")\n",
    "\n",
    "def say_hello():\n",
    "    print(\"Hello from Python!\")\n",
    "hello = Func(store, FuncType([], []), say_hello)\n",
    "\n",
    "instance = Instance(store, module, [hello])\n",
    "run = instance.exports(store)[\"run\"]\n",
    "run(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12896b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wasmtime import Store, Module, Instance\n",
    "\n",
    "store = Store()\n",
    "module = Module(store.engine, \"\"\"\n",
    "  (module\n",
    "    (func $myadd (export \"myadd\") (param i32 i32) (result i32)\n",
    "    (local.get 0)\n",
    "    (local.get 1)\n",
    "    (i32.add)\n",
    "  )\n",
    "  )\n",
    "\"\"\")\n",
    "instance = Instance(store, module, [])\n",
    "myadd = instance.exports(store)[\"myadd\"]\n",
    "myadd(store,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ab3ac73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /tmp/test.wat\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/test.wat\n",
    "\n",
    "  (module\n",
    "    (type $point (struct (field $x i64) (field $y i64)))\n",
    "    (func $myadd (export \"myadd\") (param i32 i32) (result i32)\n",
    "    (local.get 0)\n",
    "    (local.get 1)\n",
    "    (i32.add)\n",
    "  )\n",
    "  )\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79111473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: wasmtime: command not found\n"
     ]
    }
   ],
   "source": [
    "! wasmtime compile --wasm gc /tmp/test.wat -o /tmp/test.wasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58b41bd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "WasmtimeError",
     "evalue": "failed deserialization for: /tmp/test.wasm\n\nCaused by:\n    Module was compiled with support for WebAssembly feature `gc` but it is not enabled for the host",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mWasmtimeError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m engine = Engine(config)\n\u001b[32m      5\u001b[39m store = Store(engine)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m module = \u001b[43mModule\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeserialize_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/tmp/test.wasm\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/philzook58.github.io/.venv/lib/python3.12/site-packages/wasmtime/_module.py:104\u001b[39m, in \u001b[36mModule.deserialize_file\u001b[39m\u001b[34m(cls, engine, path)\u001b[39m\n\u001b[32m     99\u001b[39m error = ffi.wasmtime_module_deserialize_file(\n\u001b[32m    100\u001b[39m     engine.ptr(),\n\u001b[32m    101\u001b[39m     path_bytes,\n\u001b[32m    102\u001b[39m     byref(ptr))\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m WasmtimeError._from_ptr(error)\n\u001b[32m    105\u001b[39m ret: \u001b[33m\"\u001b[39m\u001b[33mModule\u001b[39m\u001b[33m\"\u001b[39m = \u001b[38;5;28mcls\u001b[39m.\u001b[34m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[32m    106\u001b[39m ret._set_ptr(ptr)\n",
      "\u001b[31mWasmtimeError\u001b[39m: failed deserialization for: /tmp/test.wasm\n\nCaused by:\n    Module was compiled with support for WebAssembly feature `gc` but it is not enabled for the host"
     ]
    }
   ],
   "source": [
    "from wasmtime import Store, Module, Instance, Config, Engine\n",
    "config = Config()\n",
    "config.wasm_gc = True\n",
    "engine = Engine(config)\n",
    "store = Store(engine)\n",
    "module = Module.deserialize_file(store.engine, \"/tmp/test.wasm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95c83d68",
   "metadata": {},
   "outputs": [
    {
     "ename": "WasmtimeError",
     "evalue": "failed to parse WebAssembly module\n\nCaused by:\n    struct indexed types not supported without the gc feature (at offset 0xb)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mWasmtimeError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m engine = Engine(config)\n\u001b[32m      5\u001b[39m store = Store(engine)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m module = \u001b[43mModule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[33;43m  (module\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[33;43m    (type $point (struct (field $x i64) (field $y i64)))\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[33;43m    (func $myadd (export \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmyadd\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m) (param i32 i32) (result i32)\u001b[39;49m\n\u001b[32m     10\u001b[39m \u001b[33;43m    (local.get 0)\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[33;43m    (local.get 1)\u001b[39;49m\n\u001b[32m     12\u001b[39m \u001b[33;43m    (i32.add)\u001b[39;49m\n\u001b[32m     13\u001b[39m \u001b[33;43m  )\u001b[39;49m\n\u001b[32m     14\u001b[39m \u001b[33;43m  )\u001b[39;49m\n\u001b[32m     15\u001b[39m \u001b[33;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m instance = Instance(store, module, [])\n\u001b[32m     17\u001b[39m myadd = instance.exports(store)[\u001b[33m\"\u001b[39m\u001b[33mmyadd\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/philzook58.github.io/.venv/lib/python3.12/site-packages/wasmtime/_module.py:45\u001b[39m, in \u001b[36mModule.__init__\u001b[39m\u001b[34m(self, engine, wasm)\u001b[39m\n\u001b[32m     43\u001b[39m error = ffi.wasmtime_module_new(engine.ptr(), binary, \u001b[38;5;28mlen\u001b[39m(wasm), byref(ptr))\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error:\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m WasmtimeError._from_ptr(error)\n\u001b[32m     46\u001b[39m \u001b[38;5;28mself\u001b[39m._set_ptr(ptr)\n",
      "\u001b[31mWasmtimeError\u001b[39m: failed to parse WebAssembly module\n\nCaused by:\n    struct indexed types not supported without the gc feature (at offset 0xb)"
     ]
    }
   ],
   "source": [
    "from wasmtime import Store, Module, Instance, Config, Engine\n",
    "config = Config()\n",
    "config.wasm_gc = True\n",
    "engine = Engine(config)\n",
    "store = Store(engine)\n",
    "module = Module(store.engine, \"\"\"\n",
    "  (module\n",
    "    (type $point (struct (field $x i64) (field $y i64)))\n",
    "    (func $myadd (export \"myadd\") (param i32 i32) (result i32)\n",
    "    (local.get 0)\n",
    "    (local.get 1)\n",
    "    (i32.add)\n",
    "  )\n",
    "  )\n",
    "\"\"\")\n",
    "instance = Instance(store, module, [])\n",
    "myadd = instance.exports(store)[\"myadd\"]\n",
    "myadd(store,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f965079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def struct_of_dt(d : DatatypeSortRef):\n",
    "    for c in d:\n",
    "        field = \" \".join(f\"(field ${f.name()} {f.sort()}\" for f in c.fields())\n",
    "        cons = f\"(struct ${d}.{c.name()} \"\n",
    "    return f\"\"\"\n",
    "    (rec\n",
    "        \n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1a5fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_wasm_type(sort : smt.SortRef):\n",
    "    if sort == smt.BitVec(32):\n",
    "        return \"i32\"\n",
    "    elif sort == smt.BitVec(64):\n",
    "        return \"i64\"\n",
    "\n",
    "def wasm_of_expr(e : smt.ExprRef):\n",
    "    # recurse through\n",
    "    if \n",
    "\n",
    "    decl = e.decl()\n",
    "    if e.is_add()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def to_wasm(name, args, body : smt.ExprRef):\n",
    "    \"\"\"\n",
    "    Convert a SMT expression to a WebAssembly function.\n",
    "    \"\"\"\n",
    "    return f\"\"\"\n",
    "(module\n",
    "  (func ${name} (export {name}) {params} (result {to_wasm_type(body.sort())})\n",
    "    \n",
    "  )\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac897f5",
   "metadata": {},
   "source": [
    "# combinators\n",
    "\n",
    "A full set of combinators\n",
    "\n",
    "Proof terms that I translate?\n",
    "\n",
    "lambda([P], P)\n",
    "\n",
    "\n",
    "APL is master of the ocmbiunators. An APL knuckledragger would use a heavy combinator style.\n",
    "Knuckledragger numpy?\n",
    "vectorized proofs\n",
    "\n",
    "https://en.wikipedia.org/wiki/Combinatory_logic\n",
    "https://combinatorylogic.com/index.html\n",
    "\n",
    "\n",
    "forall xs, smt.And() => smt.Or()   normal form\n",
    "forall xs, smt.And() => conc   normal form\n",
    "\n",
    "@ * + ~ << >> combinators for Proofs? Hook and etc.\n",
    "Kind of a fun idea. ssreflect?\n",
    "\n",
    "\n",
    "\n",
    "Harrison book has some\n",
    "\n",
    "pluck And(xs) => P  ====>   x[n] => And(xs - x[n]) => P\n",
    "insert   x => And(xs) => P  ====> And(xs + x + xs) => P\n",
    "sort And(xs) => P ====> And(sorted(xs)) => P\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16af702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cut(a, b):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b766740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "&#8870;Implies(And(And(a, b), c), a)"
      ],
      "text/plain": [
       "|- Implies(And(And(a, b), c), a)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def curry(pf : kd.Proof) -> kd.Proof:\n",
    "    assert isinstance(pf, kd.Proof)\n",
    "    assert smt.is_implies(pf.thm)\n",
    "    hyp, conc = pf.thm.children()\n",
    "    assert smt.is_and(hyp)\n",
    "    args = hyp.children()\n",
    "    return kd.axiom(smt.Implies(smt.And(args[:-1]), smt.Implies(args[-1], conc)), by=[\"curry\", pf])\n",
    "a,b,c = smt.Bools(\"a b c\")\n",
    "curry(kd.prove(smt.Implies(smt.And(a, b, c), a)))\n",
    "\n",
    "# curryn ?\n",
    "\n",
    "def uncurry(pf : kd.Proof) -> kd.Proof:\n",
    "    assert isinstance(pf, kd.Proof)\n",
    "    assert smt.is_implies(pf.thm)\n",
    "    hyp, conc = pf.thm.children()\n",
    "    assert smt.is_implies(conc)\n",
    "    hyp1, conc = conc.children() \n",
    "    return kd.axiom(smt.Implies(smt.And(hyp, hyp1), conc), by=[\"uncurry\", pf])\n",
    "uncurry(curry(kd.prove(smt.Implies(smt.And(a, b, c), a))))\n",
    "\n",
    "# modus is apply\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405b36d4",
   "metadata": {},
   "source": [
    "Design  as decorator?\n",
    "\n",
    "A little weird. Interesting looking patterns.\n",
    "\n",
    "```\n",
    "def Ex(vs, P):\n",
    "   def res(cb):\n",
    "\n",
    "def ExistsE(vs, P):\n",
    "    \n",
    "\n",
    "\n",
    "def ForAllI(vs, P):\n",
    "    vs, ab = kd.kernel.herb(smt.ForAll([vs], P))\n",
    "\n",
    "def Pi(vs, P):\n",
    "    def res(cb):\n",
    "        vs, ab = kd.kernel.herb(smt.ForAll(vs, P))\n",
    "        return modus(ab, cb(*vs))\n",
    "    return res\n",
    "\n",
    "@Pi([n], foo(n))\n",
    "def step1(goal, vs)\n",
    "\n",
    "\n",
    "@fixes(smt.ForAll([n], foo(n)))\n",
    "def foo(goal, n):\n",
    "    @fixes\n",
    "    def res(goal1, m):\n",
    "        return kd.prove(...)\n",
    "    return res\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6f69686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "&#8870;ForAll(n, foo(n))"
      ],
      "text/plain": [
       "|- ForAll(n, foo(n))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Callable\n",
    "from functools import partial\n",
    "#@partial\n",
    "def fixes(goal : smt.QuantifierRef, cb : Callable[[smt.ExprRef,...], kd.Proof]) -> kd.Proof:\n",
    "    vs, ab = kd.kernel.herb(goal)\n",
    "    a = cb(*vs) # ab.thm.arg(0) pass in?\n",
    "    pf = kd.kernel.modus(ab, a)\n",
    "    assert pf.thm.eq(goal)\n",
    "    return pf\n",
    "\n",
    "foo = smt.Function(\"foo\", smt.IntSort(), smt.BoolSort())\n",
    "n = smt.Int(\"n\")\n",
    "pf1 = kd.axiom(smt.ForAll([n], foo(n)))\n",
    "fixes(smt.ForAll([n], foo(n)), lambda n: pf1(n))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ef895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aprove(goal, instans):\n",
    "    intros(goal, lambda goal1, *args: kd.prove(goal1, by=instans(*args)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecf3949",
   "metadata": {},
   "source": [
    "# BHK \n",
    "simp is definitional equality.\n",
    "Model\n",
    "ForAllI(lambda x: f)\n",
    "Pi()\n",
    "ForAllI([x,y,z], lambda x,y,z: kd.prove(    ))\n",
    "\n",
    "def ForAllI(vs, prop):\n",
    "    def res(f):\n",
    "        vs, lemma = herb(ForAll(vs, prop))\n",
    "        p = f(lemma.arg(0), *vs)\n",
    "        return modus(lemma, p)\n",
    "    return res\n",
    "    #def res(goal, *vs):\n",
    "\n",
    "class CtxProof():\n",
    "    ctx : \n",
    "    thm : smt.\n",
    "    pf : kd.Proof\n",
    "class CtxExpr():\n",
    "\n",
    "\n",
    "def prove(fm):\n",
    "    if hasattr(fm, \"kdrag_ctx\"):\n",
    "        return prove(smt.ForAll(smt.Implies(fm.kdrag_ctx, fm)))\n",
    "    else:\n",
    "        return prove(fm)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ImplI(prop):\n",
    "    def res(f):\n",
    "        p = prop.arg(1)\n",
    "        p.kdrag_ctx = prop.arg(0) + prop.kdrag_ctx\n",
    "        f(p)\n",
    "\n",
    "        f(CtxProof())\n",
    "        ? = ?(prop)\n",
    "\n",
    "\n",
    "@ForAllI([x,y,z])\n",
    "def add_comm(x : int, y : int, z : int):\n",
    "    return kd.prove()\n",
    "\n",
    "def forall(f):\n",
    "    inspect()\n",
    "    kd.kernal.herb\n",
    "\n",
    "@forall\n",
    "def add_comm(x : int, y : int, z : int):\n",
    "\n",
    "type Prop = BoolRef\n",
    "def ind_eq(motive : Callable([ExprRef,ExprRef], BoolRef), a, b, p : kd.Proof):\n",
    "    t1 = motive(a,a)\n",
    "    assert p.thm.eq(t1)\n",
    "    t2 = motive(a,b)\n",
    "\n",
    "def ImplI()\n",
    "\n",
    "\n",
    "contextmanager\n",
    "generators for algerbaic effects\n",
    "\n",
    "def prove(p):\n",
    "    ctx = get_ctx()\n",
    "    kd.prove(ctx => )\n",
    "\n",
    "global? ctx\n",
    "\n",
    "l = Lemma(forall )\n",
    "with l.fix() as y:\n",
    "    with z.intros() as ih1:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baebb63f",
   "metadata": {},
   "source": [
    "# protocol\n",
    "\n",
    "Protocls as replacement for some uses of typeclasses\n",
    "\n",
    "As replacement for ExprRef\n",
    "\n",
    "metatheory.jl had some interface.\n",
    "\n",
    "Lazy Expr\n",
    "def to_smt(self) -> smt.ExprRef: ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003edd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ast(Protocol):\n",
    "    def arg(self, i: int) -> 'Ast': ...\n",
    "    def children(self) -> list['Ast']: ...\n",
    "    def eq(self, other: 'Ast') -> bool: ...\n",
    "class Sort(Ast, Protocol):\n",
    "    def name(self) -> str: ...\n",
    "class FuncDecl(Ast, Protocol):\n",
    "    def name(self) -> str: ...\n",
    "    def arity(self) -> int: ...\n",
    "    def domain(self, i: int) -> 'Sort': ...\n",
    "    def range(self) -> 'Sort': ...\n",
    "class Expr(Ast, Protocol):\n",
    "    def __eq__(self, other: 'Expr') -> \"Expr\": ...\n",
    "    # all operations?\n",
    "    # is_add: ... operations. Hmm.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ee87bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Protocol, runtime_checkable\n",
    "from kdrag.all import *\n",
    "\n",
    "@runtime_checkable\n",
    "class Monoid(Protocol):\n",
    "    add: smt.FuncDeclRef\n",
    "    zero: smt.ExprRef\n",
    "    assoc: kd.Proof # |- forall x, y, z: add(add(x, y), z) == add(x, add(y, z))\n",
    "    lunit: kd.Proof # |- forall x: add(zero, x) == x\n",
    "    runit: kd.Proof # |- forall x: add(x, zero) == x\n",
    "\n",
    "@runtime_checkable\n",
    "class Group(Monoid, Protocol):\n",
    "    inv: smt.FuncDeclRef # inverse operation\n",
    "    inv_lunit: kd.Proof # |- forall x: add(inv(x), x) == zero\n",
    "    inv_runit: kd.Proof # |- forall x: add(x, inv(x)) == zero\n",
    "\n",
    "# alternative to SortDispatch\n",
    "ExprRef.__add__ = lambda x,y: x.sort().add(x,y)\n",
    "\n",
    "\n",
    "@runtime_checkable\n",
    "class Assoc(Protocol):\n",
    "    assoc: kd.Proof\n",
    "\n",
    "\n",
    "add = (x + y).decl()\n",
    "add.assoc = kd.prove(smt.ForAll([x, y, z], (x + y) + z == x + (y + z)))\n",
    "isinstance(add, Assoc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbf81af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lattice = smt.DeclareSort(\"Lattice\")\n",
    "meet = smt.Function(\"meet\", Lattice, Lattice, Lattice)\n",
    "kd.notation.and_.register(Lattice, meet)\n",
    "join = smt.Function(\"join\", Lattice, Lattice, Lattice)\n",
    "kd.notation.or_.register(Lattice, join)\n",
    "x,y,z = smt.Consts(\"x y z\", Lattice)\n",
    "meet_assoc = kd.axiom(smt.ForAll([x,y,z], x & (y & z) == (x & y) & z))\n",
    "meet_comm = kd.axiom(smt.ForAll([x,y], x & y == y & x))\n",
    "meet_idem = kd.axiom(smt.ForAll(x, x & x == x))\n",
    "join_assoc = kd.axiom(smt.ForAll([x,y,z], x | (y | z) == (x | y) | z))\n",
    "join_comm = kd.axiom(smt.ForAll([x,y], x | y == y | x))\n",
    "join_idem = kd.axiom(smt.ForAll(x, x | x == x))\n",
    "\n",
    "#kd.notation.le([x,y], x & y == x)\n",
    "\n",
    "\n",
    "# complete\n",
    "sup = smt.Function(\"sup\", set_.SetSort(Lattice), Lattice)\n",
    "inf = smt.Function(\"inf\", set_.SetSort(Lattice), Lattice)\n",
    "\n",
    "\n",
    "monotone = smt.Function(\"monotone\", smt.ArraySort(Lattice, Lattice), smt.BoolSort())\n",
    "\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Knaster%E2%80%93Tarski_theorem\n",
    "gfp = sup(smt.Lambda([x], x <= f(x)))\n",
    "lfp = inf(smt.Lambda([x], f(x) <= x))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a7f68b",
   "metadata": {},
   "source": [
    "# Fixed point\n",
    "\n",
    "Could spacer or BMC be a good \n",
    "\n",
    "Could I use this for a typeclass like system?\n",
    "\n",
    "for subtypes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2c4149",
   "metadata": {},
   "source": [
    "from kdrag.all import *\n",
    "\n",
    "fp = smt.FixedPoint()\n",
    "fp.set(engine=\"bmc\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14219484",
   "metadata": {},
   "source": [
    "# user propagators\n",
    "?\n",
    "I have some ideas about forall x, inj(proj(x)) = x\n",
    "User propagators good for that maybe? A simple application.\n",
    "is_set(smt.ArraySort())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84aace2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ca5408",
   "metadata": {},
   "source": [
    "# subtyping\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58f2033e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "&#8870;ForAll(x, Implies(x > 0, ForAll(y, Implies(y > x, y > -1))))"
      ],
      "text/plain": [
       "|- ForAll(x, Implies(x > 0, ForAll(y, Implies(y > x, y > -1))))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "type Telescope = list[tuple[smt.ExprRef, smt.BoolRef] | tuple[smt.ExprRef, smt.ArrayRef] | smt.ExprRef]\n",
    "def TForAll(xs : Telescope, P : smt.BoolRef) -> smt.BoolRef:\n",
    "    \"\"\"\n",
    "    Dependent forall quantifier for a telescope of variables.\n",
    "    \"\"\"\n",
    "    for v in reversed(xs):\n",
    "        if isinstance(v, tuple):\n",
    "            (v, T) = v\n",
    "            if T.sort() == smt.BoolSort():\n",
    "                P = kd.QForAll([v], T, P)\n",
    "            elif isinstance(T, smt.ArrayRef) or (isinstance(T, smt.QuantifierRef) and T.is_lambda()):\n",
    "                P = kd.QForAll([v], T(v), P)\n",
    "            else:\n",
    "                raise TypeError(f\"Unsupported type for quantifier: {T}\")\n",
    "        else:\n",
    "            P = kd.QForAll([v], P)\n",
    "    return P\n",
    "x, y, z = smt.Reals(\"x y z\")\n",
    "kd.prove(TForAll([(x, x > 0), (y, y > x)], y > -1))\n",
    "Pos = smt.Lambda([x], x > 0)\n",
    "def GT(x):\n",
    "    return smt.Lambda([y], y > x)\n",
    "kd.prove(TForAll([(x, Pos), (y, GT(x))], y > -1))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10273138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f04f5272",
   "metadata": {},
   "source": [
    "https://fstar-lang.org/tutorial/proof-oriented-programming-in-fstar.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda3a240",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prop = kd.Enum(\"Prop\", [\"tt\"])\n",
    "p = smt.Const(\"p\", Prop)\n",
    "\n",
    "[(p, x == y)] #==> forall p: x == y\n",
    "def Eq(x,y):\n",
    "    \"\"\"\n",
    "    Equality as a dependent type.\n",
    "    \"\"\"\n",
    "    return smt.Lambda([p], x == y)\n",
    "def Squash(b):\n",
    "    p = smt.FreshConst(Prop)\n",
    "    return smt.Lambda([p], b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c84b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = smt.IntSort()\n",
    "Nat = smt.Lambda([n], n >= 0)\n",
    "Zero = smt.Lambda([n], n == 0)\n",
    "Pos = smt.Lambda([n], n > 0)\n",
    "Neg = smt.Lambda([n], n < 0)\n",
    "Even = smt.Lambda([n], n % 2 == 0)\n",
    "Odd = smt.Lambda([n], n % 2 == 1)\n",
    "\n",
    "incr = kd.define(\"incr\", [n], n + 1)\n",
    "kd.pdefine(\"incr\", [(n, Nat)], Nat, n + 1)\n",
    "kd.pdefine(\"incr\", [(n, Nat)], smt.Lambda([m], m > n), n + 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8196a4e",
   "metadata": {},
   "source": [
    "https://www.philipzucker.com/notes/Languages/ocaml/#universal-types\n",
    "\n",
    "https://okmij.org/ftp/ML/trep.ml\n",
    "\n",
    "Boxing and unboxing.\n",
    "My notes on \"Any\"  in knuckledragger\n",
    "\n",
    "Hmm. Maybe I could do a single RecFunction for my universe levels. Then I do get to bake it in to z3.\n",
    "Or for open recursion?\n",
    "\n",
    "I do have existentials (?) Oh myyyyyy\n",
    "\n",
    "Box = kd.Record(\"Box\", (typ : 'a Code, val : TypeVar(\"a\")))\n",
    "Hmm. Yeah, I kind of need GADTs to use the tag trick.\n",
    "\n",
    "\n",
    "\n",
    "def Get\n",
    "\n",
    "\n",
    "https://dl.acm.org/doi/10.1145/3649836 Persimmon: Nested Family Polymorphism with Extensible Variant Types. Poster at NEPLS\n",
    "\n",
    "\n",
    "\n",
    "GADTs.\n",
    "\n",
    "PInductive()\n",
    "  pred=\n",
    "  pred=\n",
    "\n",
    "InductiveRel\n",
    "wf\n",
    "Why did I call it rel and not use the wf system?\n",
    "That's weird.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9707f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "&lambda;c!227 : Length(c!227) = 2"
      ],
      "text/plain": [
       "Lambda(c!227, Length(c!227) == 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kdrag.theories.seq as seq\n",
    "\n",
    "def Vec(n, S):\n",
    "    T = seq.Seq(S)\n",
    "    x = smt.FreshConst(T)\n",
    "    return smt.Lambda([x], smt.Length(x) == n)\n",
    "\n",
    "def IVec(n):\n",
    "    return Vec(n, smt.IntSort())\n",
    "n = smt.Int(\"n\")\n",
    "Nat = smt.Lambda([n], n >= 0)\n",
    "x,y = smt.Consts(\"x y\", seq.Seq(smt.IntSort()))\n",
    "tdefine(\"add\", [(n, Nat), (x, IVec(n)), (y, IVec(n))],\n",
    "smt.cond(\n",
    "    (n == 0, Nil),\n",
    "    default=Cons(x.head + y.head, add(n - 1, x.tail, y.tail) , \n",
    "    ), IVec(n)\n",
    ")\n",
    "\n",
    "#( add(n - 1, x.tail, y.tail) ,  Nat ))\n",
    "\n",
    "TForAll([(n, Nat), (x, IVec(n)), (y, IVec(n))],   ? )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd45b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extensible sort of Codes\n",
    "# Universes are an open type. Their codes are open\n",
    "# This is exactly what the extensible tricks in ocaml are for. Keys. 'a tag\n",
    "\n",
    "TypeCode = smt.DeclareSort(\"TypeCode\")\n",
    "# Code = smt.IntSort()\n",
    "# El = OpenFunction()\n",
    "\n",
    "\n",
    "def El(code):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e40f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naaaaaah, doesn't really make sense.\n",
    "def ann(x, T):\n",
    "    undef = FreshConst(x.sort())\n",
    "    smt.If(T(x), x, undef)\n",
    "\n",
    "def Epsilon(T):\n",
    "    FreshConst()\n",
    "    smt.If(smt.Exists([y], T(y)) T(x), x, undef)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8338b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "type Type = smt.ArraySortRef | smt.QuantifierRef | smt.BoolRef\n",
    "\n",
    "# domain cannot be inferred\n",
    "def domain(A : TYPE):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac150d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pi(A,B): ...\n",
    "def Pi(xA, B):\n",
    "    (x,A) = xA\n",
    "    #B(x, f(x)))) vs B(x)(f(x)) vs B(f(x))\n",
    "    # Following prior conventions, B should just be a function expression that already contains x\n",
    "    # B has to be a predicate. it can't contain it's variable.\n",
    "    f = smt.FreshConst(smt.ArraySort(x.sort(), B(x).domain()))\n",
    "    return smt.Lambda([f], TForAll([(x,A)], B(f(x))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c2d87a",
   "metadata": {},
   "source": [
    "Could record known substype and register different coercions\n",
    "\n",
    "\n",
    "SHould All of these optionally take a Tuple?\n",
    "\n",
    "def TForAll(vs, P):\n",
    "    if isiinstance(P, tuple):\n",
    "        P = P[1](P(0))\n",
    "\n",
    "def tdefine(name, args, body):\n",
    "    if isinstance(body, tuple):\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e56a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtype_dom(A):\n",
    "    if isinstance(A, smt.QuantifierRef):\n",
    "        return A.sort()\n",
    "\n",
    "def is_subtype(A,B, by=[]):\n",
    "    #x =\n",
    "    return smt.Prove(A <= B, by=by)  #smt.IsSubSet()\n",
    "    #return kd.prove(kd.TForAll([(x,A)], B(x)), by=by)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cbd2c6",
   "metadata": {},
   "source": [
    "types are a syntactic discipline to enforce levels of abstraction\n",
    "\n",
    "Type systems as tactic.\n",
    "\n",
    "Homotopy type and transport and stuff probably says how to manually translate isomorphic based proofs. Which is what Talia was getting at?\n",
    "\n",
    "\n",
    "Definitional equality checks use simp as subtactic.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103a5540",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (647665221.py, line 43)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[31m    \u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def TExists(xs : Tele, P : smt.BoolRef) -> smt.BoolRef:\n",
    "    for v in reversed(xs):\n",
    "        if isinstance(v, tuple):\n",
    "            (v, T) = v\n",
    "            if T.sort() == smt.BoolSort():\n",
    "                P = kd.QExists([v], T, P)\n",
    "            elif isinstance(T, smt.QuantifierRef) and T.is_lambda():\n",
    "                P = kd.QExists([v], T(v), P)\n",
    "            elif isinstance(T, smt.ArraySortRef):\n",
    "                P = kd.QExists([v], T(v), P)\n",
    "            else:\n",
    "                raise TypeError(f\"Unsupported type for quantifier: {T}\")\n",
    "        else:\n",
    "            P = kd.QExists([v], P)\n",
    "    return P\n",
    "\n",
    "# TLambda\n",
    "# TExists\n",
    "\n",
    "\n",
    "\n",
    "def pdefine(name, args, out, body, by=[]):\n",
    "    f = kd.define(name, args, smt.If(cond, body, undef))\n",
    "    kd.prove(smt.TForAll(args, out(f(*args))))\n",
    "    substypes[f] = SubTypeDefn(f, args, out, )\n",
    "\n",
    "def subtype_tac(tele, P):\n",
    "    # sweep though expression\n",
    "    # prove TForAll(tele, P) via subtype abstractions.\n",
    "    # Don't fail, output needed subproofs instead. Or raise with them?\n",
    "\n",
    "subtypes = {}\n",
    "\n",
    "# Gamma, x : T, Delta |- x : T\n",
    "def refl_tele(tele, n : int) -> kd.Proof:\n",
    "    (x,T) = tele[n]\n",
    "    return kd.prove(smt.TForAll(tele, T(x)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def synth(tele, t) -> tuple[Subsort, kd.Proof]:\n",
    "    \"\"\"\n",
    "    Synthesize the type of an expression in a telescope.\n",
    "    Returns a tuple of the type and a proof that the expression has that type.\n",
    "    \"\"\"\n",
    "    if n := tele_vars(tele).find(t):\n",
    "        return tele[n][1], refl_tele(tele, n)\n",
    "    elif smt.is_app(t):\n",
    "        decl, children = t.decl(), t.children()\n",
    "        if t in subtypes:\n",
    "            subtype_defn = subtypes[t]\n",
    "            subproofs = [check(c, v) for c, v in zip(children, subtype_defn.tele)]\n",
    "            kd.prove(smt.TForAll(subtype_defn.tele, subtype_defn.out(t(*t.children()))), by=subproofs + [subtype_defn.subtype_lemma])\n",
    "            return subtype_defn.out, \n",
    "def check(tele, t, T) -> kd.Proof:\n",
    "\n",
    "\n",
    "def ann(t,T):\n",
    "    # refine\n",
    "    # annotation is semantically an identity function. Or a refining function.\n",
    "    x = FreshConst(t.sort())\n",
    "    return kd.tdefine(\"ann\", [(x,T)], T, x)\n",
    "\n",
    "def ann(t, T):\n",
    "    return has_type(?, t, T)\n",
    "\n",
    "def restrict(f, T):\n",
    "    # Can sensible annotate a term. If \n",
    "    xs = [smt.FreshConst(args) for arg in f.args]\n",
    "    undef = smt.FreshFunction(*[x.sort() for x in xs], f.sort())\n",
    "    return smt.Lambda([x], smt.If(T(f(*xs)), f(*xs), undef(*xs)))  # restrict f to the type T\n",
    "\n",
    "def restrict(f, T, by=[]):\n",
    "    if f in subtypes:\n",
    "    # make new anonymous definition?\n",
    "        return kd.tdefine(freshname, args, smt.And(T, Tf), f(), by=[f.subtype_lemma] + by)\n",
    "    else:\n",
    "        return kd.tdefine(freshname, args, T, f(args), by=by)\n",
    "\n",
    "# i could tag metadata to kd.Proof objects. tele, vs. Or it could go in the reasons field... yikes.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def has_type(tele : Telescope, t : smt.ExprRef, T : smt.BoolRef, by=[], **kwargs):\n",
    "    if n := tele_vars(tele).find(t):\n",
    "        return refl_tele(tele, n)\n",
    "    elif smt.is_app(t):\n",
    "        decl, children = t.decl(), t.children()\n",
    "        if decl in subtypes:\n",
    "            subtype_defn = subtypes[decl]\n",
    "            has_typ()\n",
    "\n",
    "\n",
    "# Another case wherwe maybe my core Proof thing holding a context would be useful.\n",
    "def has_type(tele : Telescope, t : smt.ExprRef, T : SubSort, by=[], **kwargs):\n",
    "    # Tactic to prove TForAll(tele, T[t])\n",
    "    # search through collecting up substypes.\n",
    "\n",
    "    lemmas = [] # lemmas starts with tele somehow?\n",
    "    todo = [t]\n",
    "    # The let z3 handle it version.\n",
    "    # The telescope character makes it annoying\n",
    "\n",
    "    # get topological order of children and go bottom up?\n",
    "    # compose ctx -> P ,  tele -> P1 moves\n",
    "    # cut move   ctx -> P   ctx -> (P -> P1)  --->  ctx -> P1 \n",
    "    # I need hilbert style combinators\n",
    "\n",
    "    # Use BMC or horn solvers?\n",
    "    # use consider axiom?\n",
    "    while todo:\n",
    "        t = todo.pop()\n",
    "        if n := tele_vars(tele).find(t):\n",
    "            lemmas.append(refl_tele(tele, n))\n",
    "\n",
    "            #kd.prove(TForAll(tele, T(t)))\n",
    "\n",
    "        if smt.is_app(t):\n",
    "            decl, children = t.decl(), t.children()\n",
    "            if decl in subtypes:\n",
    "                subtype_defn = subtypes[decl]\n",
    "                l = subtype_defn.subtype_lemma\n",
    "                if len(children) > 0 and isinstance(l, smt.QuantifierRef) and l.is_forall():\n",
    "                    l = l(children[0]) # One layer at least is easy\n",
    "                lemmas.append(l)\n",
    "                todo.extend(children)\n",
    "        \"\"\"\n",
    "        if smt.is_app(t):\n",
    "            decl,children = t.decl(), t.children()\n",
    "            if decl in subtypes:\n",
    "                subtype_defn = subtypes[decl]\n",
    "                l = subtype_defn.subtype_lemma\n",
    "                while smt.is_implies(l) or smt.is_forall(l):\n",
    "                    if isinstance(l, smt.QuantifierRef) and l.is_forall():\n",
    "                        c = children.pop()\n",
    "                        l = l(c) # instantiate quantifier.\n",
    "                    elif smt.is_implies(l):\n",
    "                        goal = l.arg(0)\n",
    "                        lemmas.append(kd.prove(goal, by=lemmas))\n",
    "                        l = l.arg(1)\n",
    "                for c in children:\n",
    "                    kd.prove( )\n",
    "                    l = l[c]\n",
    "        \"\"\"\n",
    "    return kd.prove(smt.TForAll(tele, T(t)), by=by + lemmas, **kwargs) # unfold=1\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d2f287",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcca842",
   "metadata": {},
   "source": [
    "idea: just using qforall would make the quantifer easier to instnatiate. Otherwise we need a \n",
    "A => forall x, B    ---> A => B[t/x] rule\n",
    "\n",
    "iterate uncurry and \n",
    "A => forall x (B[x] => C)  ---> A => (B[t] => C) ---> and(A,B) => C\n",
    "\n",
    "comp(acc, instan2(pf.arg(1), t)\n",
    "\n",
    "\n",
    "\n",
    "Not all things of shape forall xs, A => B\n",
    "can be easily turned into forall x0 A0 => forall x1 A1 => ,, (?)\n",
    "Well. In some null sense forall x0 True, forall x1 True, ... forall xn A\n",
    "\n",
    "\n",
    "Oh but I have that with compose instan2\n",
    "    .  forall x phi(x) => phi(t)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "QForAll([x], Nat(x), P) is fine.\n",
    "But still would want to register.\n",
    "\n",
    "Quantifiers are evil and implications are just whatever for smt. So it's not symmettric in that sense\n",
    "\n",
    "\n",
    "What if cbs just get fired at the end and they delete non useful stuff.\n",
    "\n",
    "What if GoalCtx was kept in sequent `forall xs, And(hyps) => P` normal form \n",
    "\n",
    "Interesting... Use lemmas as a second stack. Does this work? It is lensy right? This is the trail.\n",
    "\n",
    "Is there a way to do an earlier call to cbs?\n",
    "\n",
    "maybe lemmas and cbstack\n",
    "\n",
    "## Lemma callbacks\n",
    "lemma : id -> [callback]\n",
    "def add_lemma(p):\n",
    "    pid = p.thm.get_id()\n",
    "    cbs = lemma.get(p.thm.get_id())\n",
    "    if isinstance(cbs, list):\n",
    "        lemmas[pid] = p\n",
    "        for cb in cbs:\n",
    "            cb()\n",
    "    elif isinstance(cbs, kd.Proof):\n",
    "        pass\n",
    "    else:\n",
    "        raise UnExpcted\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lookup proofs by get_id\n",
    "Could also close branches by lookup up to see if already proven.\n",
    "That's kind of interesting.\n",
    "\n",
    "\n",
    "\n",
    "What if I put the callbacks on the goals stack. So then I call them as soon as the subgoals are done\n",
    "Goals might be an iniaprrporatye name at this point.\n",
    "\n",
    "goals.append(newgoal)\n",
    "goals.append(cb)\n",
    "\n",
    "also might help with eexists\n",
    "subst[v] = whatever\n",
    "And then cb can look for it\n",
    "\n",
    "def eexists():\n",
    "    vs, body = open_binder(goal)\n",
    "    for v in vs:\n",
    "        self.subst[v] = None\n",
    "    def cb():\n",
    "        t = self.subst[v]\n",
    "        kd.kernel.abstract()\n",
    "\n",
    "    goals.append(body)\n",
    "    goals.append(cb)\n",
    "\n",
    "\n",
    "\n",
    "class Lemma2\n",
    "    def intros():\n",
    "    def intro()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "Lemmas()\n",
    "    self.lemmas = {}\n",
    "    cbs: list[Callable[[], None]]\n",
    "\n",
    "    def fixes(self):\n",
    "        vs, ab = kd.kernel.herb(self.goals)\n",
    "        def cb():\n",
    "            a = lemmas[ab.thm.arg(0).get_id()]\n",
    "            #a = lemmas.pop()\n",
    "            #if p.thm.arg(0)\n",
    "            pb = modus(ab, a)\n",
    "            lemmas[pb.thm.get_id()] = pb\n",
    "            lemmas.append(modus(a, ab))\n",
    "        cbs.append(cb)\n",
    "        cbs.append(lambda: self.lemmas.find(pf, t.arg(0)))\n",
    "    def \n",
    "\n",
    "    def qed(self):\n",
    "        for cb in reversed(cb):\n",
    "            cb()\n",
    "        return lemma.find(pf, self.topgoal)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60382e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NormTele(vs=[n, m, k], pred=[Lambda(n, n >= 0), Lambda(m, m > 0), Lambda(k, True)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "from kdrag.all import *\n",
    "from kdrag.notation import Telescope\n",
    "\n",
    "type QCtx = tuple[list[smt.ExprRef], list[smt.BoolRef]]\n",
    "type Telescope1 = list[tuple[smt.ExprRef, smt.QuantifierRef | smt.ArrayRef]]\n",
    "type Telescope2 = \n",
    "\n",
    "\n",
    "@dataclass\n",
    "class NormTele():\n",
    "    vs : list[smt.ExprRef]\n",
    "    pred : list[smt.ArrayRef | smt.QuantifierRef] # normalized into predicate form or normalize into Bool form?\n",
    "    @classmethod\n",
    "    def from_tele(cls, tele : Telescope) -> 'NormTele':\n",
    "        vs = []\n",
    "        pred = []\n",
    "        for v in tele:\n",
    "            if isinstance(v, tuple):\n",
    "                (v, T) = v\n",
    "                vs.append(v)\n",
    "                if T.sort() == smt.BoolSort():\n",
    "                    pred.append(smt.Lambda([v], T))\n",
    "                elif isinstance(T, smt.ArrayRef) or (isinstance(T, smt.QuantifierRef) and T.is_lambda()):\n",
    "                    pred.append(T)\n",
    "                else:\n",
    "                    raise TypeError(f\"Unsupported type for quantifier: {T}\")\n",
    "            else:\n",
    "                vs.append(v)\n",
    "                pred.append(smt.Lambda([v], smt.BoolVal(True)))\n",
    "        return cls(vs, pred)\n",
    "    def precond(self):\n",
    "        return smt.And(T(v) for v,T in zip(self.vs, self.preds))\n",
    "    def eval(self, P):\n",
    "        return smt.QForAll(self.vs, self.precond(), P)\n",
    "\n",
    "#def tele_apply(pf : kd.Proof, *args) -> kd.Proof:\n",
    "n,m,k = smt.Ints(\"n m k\")\n",
    "Nat = smt.Lambda([n], n >= 0)\n",
    "NormTele.from_tele([(n, Nat), (m, m > 0), k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e16a342",
   "metadata": {},
   "source": [
    "## Telescoped axioms\n",
    "\n",
    "telescope normal form for Proofs forall x, p -> forall y, q -> ...\n",
    "\n",
    "\n",
    "Qnormal form forall xs, ctx => A\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402a59b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Redefining function incr from |- ForAll(n, incr(n) == If(n >= 0, n + 1, f!70(n))) to ForAll(n, incr(n) == If(n >= 0, n + 1, f!73(n)))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 118\u001b[39m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    116\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not synthesize type for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtele\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[43msynth\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mincr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 113\u001b[39m, in \u001b[36msynth\u001b[39m\u001b[34m(ctx, t)\u001b[39m\n\u001b[32m    111\u001b[39m         subtype_defn = subtypes[decl]\n\u001b[32m    112\u001b[39m         T = subtype_defn.T\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m         subproofs = [\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c, (v, T1) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(children, subtype_defn.ctx)]\n\u001b[32m    114\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m T, kd.prove(TForAll(subtype_defn.ctx, T(decl(*children))), by=subproofs + [subtype_defn.ax])\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 92\u001b[39m, in \u001b[36mcheck\u001b[39m\u001b[34m(ctx, t, T)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck\u001b[39m(ctx : Telescope, t : smt.ExprRef, T : SubSort) -> kd.Proof:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     S,pf = synth(ctx, t)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m S.eq(T):\n\u001b[32m     94\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m pf\n",
      "\u001b[31mTypeError\u001b[39m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "from kdrag.notation import Telescope, SubSort, TForAll, TExists\n",
    "from typing import Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class SubTypeDefn():\n",
    "    decl : smt.FuncDeclRef\n",
    "    ctx : list[tuple[smt.ExprRef, smt.QuantifierRef | smt.ArrayRef]]\n",
    "    T : Optional[smt.BoolRef]\n",
    "    ax : kd.Proof # forall xs, tele(xs), out(f(xs))\n",
    "\n",
    "def tele_vars(tele : Telescope) -> list[smt.ExprRef]:\n",
    "    \"\"\"\n",
    "    Extract the variable names from a telescope.\n",
    "    \"\"\"\n",
    "    return [v if isinstance(v, smt.ExprRef) else v[0] for v in tele]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def norm_tele(tele : Telescope) -> Telescope:\n",
    "    acc = []\n",
    "    for v in tele:\n",
    "        if isinstance(v, tuple):\n",
    "            (var, T) = v\n",
    "            if isinstance(T, smt.ArrayRef) or (isinstance(T, smt.QuantifierRef) and T.is_lambda()):\n",
    "                acc.append((var, T))\n",
    "            elif T.sort() == smt.BoolSort():\n",
    "                acc.append((var, smt.Lambda([var], T)))\n",
    "            else:\n",
    "                raise TypeError(f\"Unsupported type for quantifier: {T}\")\n",
    "        else:\n",
    "            acc.append((v, smt.Lambda([v], True)))\n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "def tele_cond(tele : Telescope) -> Optional[smt.BoolRef]:\n",
    "    \"\"\"\n",
    "    Extract the condition from a telescope.\n",
    "    \"\"\"\n",
    "    acc = []\n",
    "    for v in tele:\n",
    "        if isinstance(v, tuple):\n",
    "            (v, T) = v\n",
    "            if T.sort() == smt.BoolSort():\n",
    "                acc.append(T)\n",
    "            elif isinstance(T, smt.ArrayRef) or (isinstance(T, smt.QuantifierRef) and T.is_lambda()):\n",
    "                acc.append(T(v))\n",
    "            else:\n",
    "                raise TypeError(f\"Unsupported type for quantifier: {T}\")\n",
    "    if len(acc) == 0:\n",
    "        return None\n",
    "    elif len(acc) == 1:\n",
    "        return acc[0]\n",
    "    else:\n",
    "        return smt.And(acc)\n",
    "\n",
    "subtypes = {}\n",
    "\n",
    "# allow synthesis of output Sort?\n",
    "def tdefine(name, args : Telescope, T : SubSort, body, by=[]):\n",
    "    \"\"\"\n",
    "    Define a subtype with a name.\n",
    "    \"\"\"\n",
    "    tvars = tele_vars(args)\n",
    "    body_lemma = kd.prove(TForAll(args, T(body)), by=by)\n",
    "    undef = smt.FreshFunction(*[v.sort() for v in tvars], body.sort())\n",
    "    cond = tele_cond(args)\n",
    "    f = kd.define(name, tvars, smt.If(cond, body, undef(*tvars)))\n",
    "    f.tele = norm_tele(args)\n",
    "    f.subtype = T\n",
    "    f.subtype_lemma = kd.prove(TForAll(args, T(f(*tvars))), by=[body_lemma, f.defn]) # I could do this more directly. It follows from a single unfold.\n",
    "    subtypes[f] = SubTypeDefn(f, args, T, f.subtype_lemma)\n",
    "    return f\n",
    "\n",
    "n = smt.Int(\"n\")\n",
    "Nat = smt.Lambda([n], n >= 0)\n",
    "incr = tdefine(\"incr\", [(n, Nat)], Nat, n + 1)\n",
    "incr.subtype_lemma\n",
    "incr.subtype\n",
    "incr.tele\n",
    "\n",
    "def lookup(ctx : Telescope, v : smt.ExprRef) -> Optional[tuple[smt.ExprRef, smt.BoolRef]]:\n",
    "    for v in ctx:\n",
    "        if isinstance(v, tuple):\n",
    "            (var, T) = v\n",
    "            if var.eq(v):\n",
    "                return (var, T)\n",
    "        elif v.eq(v):\n",
    "            return \n",
    "\n",
    "def check(ctx : Telescope, t : smt.ExprRef, T : SubSort) -> kd.Proof:\n",
    "    S,pf = synth(ctx, t)\n",
    "    if S.eq(T):\n",
    "        return pf\n",
    "    else:\n",
    "        #kd.prove(smt.SubSet(S, T), by=[pf])\n",
    "        return kd.prove(TForAll(ctx, T(t)), by=[pf])  # unfold=1\n",
    "\n",
    "\n",
    "def synth(ctx : Telescope, t : smt.ExprRef) -> tuple[SubSort, kd.Proof]:\n",
    "    \"\"\"\n",
    "    Check that an expression has a type in a telescope.\n",
    "    \"\"\"\n",
    "    ctx = norm_tele(ctx)\n",
    "    for (var, T) in ctx:\n",
    "        if var.eq(t):\n",
    "            return T, kd.prove(TForAll(ctx, T(var)))\n",
    "    if smt.is_app(t):\n",
    "        decl, children = t.decl(), t.children()\n",
    "        if decl in subtypes:\n",
    "            subtype_defn = subtypes[decl]\n",
    "            T = subtype_defn.T\n",
    "            subproofs = [check(ctx, c, T1) for c, (v, T1) in zip(children, subtype_defn.ctx)]\n",
    "            return T, kd.prove(TForAll(subtype_defn.ctx, T(decl(*children))), by=subproofs + [subtype_defn.ax])\n",
    "    else:\n",
    "        raise TypeError(f\"Could not synthesize type for {t} in {tele}\")\n",
    "\n",
    "synth([(n, Nat)], incr(incr(n) + 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ea0685",
   "metadata": {},
   "source": [
    "## qforall axioms\n",
    "```\n",
    "procedure test(x: Seq, y: Seq) returns (res: Seq)\n",
    "requires NonEmpty(x) /\\ NonEmpty(y);\n",
    "ensures NonEmpty(res) {\n",
    "  res := Append(x,y);\n",
    "}\n",
    "```\n",
    "\n",
    "Boogie has intrinsic requires ensures stuff. Hmm.\n",
    "\n",
    "\n",
    "\n",
    "Actually, should QForAll always / sometimes traverse the P term and get the well formedness conditions too?\n",
    "QForAll([xs], precond, P)\n",
    "\n",
    "TForAll([xs], T, P) #?\n",
    "TForAll([xs], t, T) #?  HasType(xs, t, T)\n",
    "WellFormed(ctx, pre, t)\n",
    "\n",
    "\n",
    "That one partial function approach from nipkow reference suggested doing it at `==`\n",
    "\n",
    "I feel like there is an assertion mode and checkingt mode? In one or the other\n",
    "\n",
    "return tuple, vs return Anded Version inside quantifier.\n",
    "def QForAll():\n",
    "    objligations = wf(P)\n",
    "    if len(obligations) == 0:\n",
    "        return QForAll0\n",
    "    return QForAll0([], cond, P) , QForAll([], cond, obl)\n",
    "    vs return QForAll([], cond, And(P, oblig))\n",
    "    vs return QForAll([], And(cond, oblig), P)\n",
    "\n",
    "Quotients. Subsets ofg powerset stable wrt eq relation.\n",
    "Set(IntSort()) |  lam A, forall x y, A[x], eq(x,y) => A[y]\n",
    "def Quot(eq):\n",
    "    T = eq.domain(0)\n",
    "    S = SetSort(T)\n",
    "    A = FreshConst(S)\n",
    "    return smt.Lambda([A], QForAll([x,y], A[x], eq(x,y), A[y]))\n",
    "Not higher order though.\n",
    "def Quot(T : SubSet, eq):\n",
    "    S = SetSort(T.domain())\n",
    "    return smt.Lambda([A], QForAll([x,y], T[x], T[y], eq(x,y), A[x], A[y])\n",
    "Hmm.\n",
    "\n",
    "\n",
    "\n",
    "It is natural if I have QLambda and QForAll and QExists to also have qdefine.\n",
    "\n",
    "Could match for QLambda . maybe associate the undefined false branch with the lambda.\n",
    "\n",
    "if t == Lambda(, If(cond, , undef)):\n",
    "    \n",
    "```\n",
    "# Just as a saniuty check\n",
    "def QLambda(vs, *args, post=None)\n",
    "    l = \n",
    "    if post \n",
    "    l.pf = kd.prove(QForAll( vs, cond, post())\n",
    "```\n",
    "\n",
    "This starts to feel more like Dafny.\n",
    "\n",
    "If proof fails, explanation method could try to traverse don and see which preconditions fail.\n",
    "\n",
    "From the subset typing persepctive. Dependent types are a methodology for deraling with partiality.\n",
    "\n",
    "But so is precondition postcondition style reasoning.\n",
    "\n",
    "What would be the analog of Q reasoning for other models of DTT?\n",
    "Setoid Specs? Maybe a hoare logic style relational thing.\n",
    "forall x0 y0, eq(x0,y0), => eq(f(x0),f(y0))\n",
    "To always show representation independence\n",
    "\n",
    "n = smt.Int(\"n\")\n",
    "[(n, Mod3)]\n",
    "Obviously I can't have n == n % 3, because n is interpreted.\n",
    "\n",
    "Or to show High Low security noninterference security properties\n",
    "idefine([(n, High), (m, Low)], body,  Low)\n",
    "Hmm.\n",
    "\n",
    "or parametricity\n",
    "DeclareSort(\"T\")\n",
    "TypeVar(\"T\") ??? Uhh.\n",
    "[(n, T), (m, S)]\n",
    "\n",
    "\n",
    "The curried vs multiairty is a good analogy.\n",
    "MultiArity Q form is like taking in a refinement tuple (x,y,z) : R(x,y,z)\n",
    "\n",
    "\n",
    "QInductive is InductiveRel?\n",
    "\n",
    "\n",
    "def QInductive():\n",
    "    def create():\n",
    "        dt = old_create()\n",
    "        for i in d.num_constructors()\n",
    "        fun_specs[d.constructor(i), kd.smt.QForAll(  )]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447d379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunSpec():\n",
    "    decl : smt.FuncDeclRef\n",
    "    #args : list[smt.ExprRef]\n",
    "    #precond : smt.BoolRef\n",
    "    #postcond : smt.BoolRef\n",
    "    #bod\n",
    "    thm : kd.Proof\n",
    "\n",
    "fun_specs = {}\n",
    "\n",
    "def qdefine(name, args, body, pre=None, post=None): # could make pre and post keyword args\n",
    "    undef = smt.FreshFunction(*[v.sort() for v in args], body.sort())\n",
    "    f = kd.define(name,   ,smt.If(precond, body, undef(*args)))\n",
    "    kd.prove(smt.QForAll(args, precond, postcond), by=[body.defn] + \n",
    "\n",
    "def FunctionAxiom(name, *sorts, pre=None, post=None, by=[]): # Method ?\n",
    "    f = smt.Function(name, *sorts)\n",
    "    f.wf = kd.axiom(smt.QForAll(args, precond, postcond), by=[body.defn] + by)\n",
    "    fun_specs[f] = FunSpec(f, f.wf)\n",
    "\n",
    "Ob = smt.DeclareSort(\"Ob\")\n",
    "Arr = smt.DeclareSort(\"Arr\")\n",
    "Hom = smt.Function(\"Hom\", Ob, Ob, smt.SetSort(Arr))\n",
    "id_ = Function(\"id\", Ob, Arr)\n",
    "id_.wf = kd.axiom(kd.QForAll([a],Hom(a,a)(id_(a))))\n",
    "fun_specs[id_] = FunSpec(id_, id_.wf)\n",
    "\n",
    "\n",
    "comp = Function(\"comp\", Arr, Arr, Arr, Arr)\n",
    "comp.wf = kd.axiom(kd.QForAll([a,b,c,f,g], smt.Implies(smt.And(Hom(a,b)(f), Hom(b,c)(g)), Hom(a,c)(comp(f,g)))))\n",
    "fun_specs[comp] = FunSpec(comp, comp.wf)\n",
    "\n",
    "def lemmas(t):\n",
    "    todo = [t]\n",
    "\n",
    "def well_formed(vs, pre, t): # \"synth\"\n",
    "    if t.decl() in fun_specs:\n",
    "        spec = fun_specs[t.decl()]\n",
    "        return kd.prove(smt.QForAll(vs, pre, spec.thm), by=[t] + lemmas(t))\n",
    "    else:\n",
    "        return kd.prove(smt.QForAll(vs, pre, smt.BoolVal(True)))\n",
    "\n",
    "def qprove(vs, pre, P, by=[]): # \"check\" ?\n",
    "    vs1, P1 = kd.kernel.herb(smt.QForAll(vs, pre, P))\n",
    "    typ_lemmas\n",
    "\n",
    "def qeq(vs, pre, t1, t2):\n",
    "    lemmas = well_formed(vs, pre, t1)\n",
    "    lemmas = well_formed(vs, pre, t2)\n",
    "\n",
    "\n",
    "def wf_lemmas(t): #empty context\n",
    "    res = []\n",
    "    todo = [t]\n",
    "    while todo:\n",
    "        t = todo.pop()\n",
    "        decl,children = t.decl(), t.children()\n",
    "        if decl in fun_specs:\n",
    "            spec = fun_specs[decl]\n",
    "            res.append(spec.thm(*children))\n",
    "            for c in children:\n",
    "                res.extend(wf_lemmas(c))\n",
    "    return res\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c257564b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Redefining function incr from |- ForAll(n, incr(n) == If(And(n >= 0), n + 1, f!13(n))) to ForAll(n, incr(n) == If(And(n >= 0), n + 1, f!15(n)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "&#8870;ForAll(n, Implies(n >= 0, incr(n) >= 0))"
      ],
      "text/plain": [
       "|- ForAll(n, Implies(n >= 0, incr(n) >= 0))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "from kdrag.notation import Telescope, SubSort, TForAll, TExists\n",
    "from typing import Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "type QCtx = tuple[list[smt.ExprRef], list[smt.BoolRef]]\n",
    "@dataclass\n",
    "class SubTypeDefn():\n",
    "    decl : smt.FuncDeclRef\n",
    "    ctx : QCtx\n",
    "    T : smt.QuantifierRef | smt.ArrayRef  # | smt.FuncDeclRef ?\n",
    "    ax : kd.Proof # forall xs, precond, prop\n",
    "\n",
    "\n",
    "def tele_to_qctx(tele : Telescope) -> QCtx:\n",
    "    \"\"\"\n",
    "    Extract the condition from a telescope.\n",
    "    \"\"\"\n",
    "    vs = []\n",
    "    pred = []\n",
    "    for v in tele:\n",
    "        if isinstance(v, tuple):\n",
    "            (v, T) = v\n",
    "            vs.append(v)\n",
    "            if T.sort() == smt.BoolSort():\n",
    "                pred.append(T)\n",
    "            elif isinstance(T, smt.ArrayRef) or (isinstance(T, smt.QuantifierRef) and T.is_lambda()):\n",
    "                pred.append(T(v))\n",
    "            else:\n",
    "                raise TypeError(f\"Unsupported type for quantifier: {T}\")\n",
    "        elif smt.is_const(v):\n",
    "            vs.append(v)\n",
    "            pred.append(smt.BoolVal(True))\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type for quantifier: {v}\")\n",
    "    return (vs, pred)\n",
    "\n",
    "subtypes = {}\n",
    "\n",
    "# allow synthesis of output Sort?\n",
    "def tdefine(name, args : Telescope, T : SubSort, body, by=[]):\n",
    "    \"\"\"\n",
    "    Define a subtype with a name.\n",
    "    \"\"\"\n",
    "    vs,pred = tele_to_qctx(args)\n",
    "    body_lemma = kd.prove(kd.QForAll(vs, *pred, T(body)), by=by)\n",
    "    undef = smt.FreshFunction(*[v.sort() for v in vs], body.sort())\n",
    "    f = kd.define(name, vs, smt.If(smt.And(pred), body, undef(*vs)))\n",
    "    f.qctx = (vs, pred)\n",
    "    f.subtype = T\n",
    "    f.subtype_lemma = kd.prove(kd.QForAll(vs, *pred, T(f(*vs))), by=[body_lemma, f.defn]) # I could do this more directly. It follows from a single unfold.\n",
    "    subtypes[f] = SubTypeDefn(f, (vs,pred), T, f.subtype_lemma)\n",
    "    return f\n",
    "\n",
    "n = smt.Int(\"n\")\n",
    "Nat = smt.Lambda([n], n >= 0)\n",
    "incr = tdefine(\"incr\", [(n, Nat)], Nat, n + 1)\n",
    "incr.subtype_lemma\n",
    "#incr.subtype\n",
    "#incr.qctx\n",
    "\n",
    "\n",
    "def has_type(ctx : Telescope, t : smt.ExprRef, T : SubSort, by=[], **kwargs):\n",
    "    vs,pred = tele_to_qctx(ctx)\n",
    "    def doit(vs1):\n",
    "        todo = [smt.substitute(t, zip(vs1))]\n",
    "        lemmas = []\n",
    "        while todo:\n",
    "            if smt.is_app(t):\n",
    "                decl, children = t.decl(), t.children()\n",
    "                if decl in subtypes:\n",
    "                    subtype_defn = subtypes[decl]\n",
    "                    lemmas.append(subtype_defn.ax(*children))\n",
    "                    todo.extend(children)\n",
    "        return lemmas\n",
    "    return kd.prove(kd.QForAll(vs, pred, T(t)), by=by, instans=doit  ,**kwargs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9ef2f2",
   "metadata": {},
   "source": [
    "# quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "845bafed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "x + y&middot;z"
      ],
      "text/plain": [
       "x + y*z"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def quote_sort(s : smt.SortRef):\n",
    "    T = smt.DeclareSort(\"'\" + s.sexpr())\n",
    "    return T\n",
    "def quote(t : smt.ExprRef):\n",
    "    assert not isinstance(t, smt.QuantifierRef) # we could handle this though.\n",
    "    T = quote_sort(t.sort())\n",
    "    decl = t.decl()\n",
    "    children = [quote(c) for c in t.children()]\n",
    "    Targs = [c.sort() for c in children]\n",
    "    absdecl = smt.Function(decl.name(), *Targs, T)\n",
    "    qt = absdecl(*children)\n",
    "    qt.unquote = t\n",
    "\n",
    "    interp = smt.Function(\"unquote\", qt.sort(), t.sort())\n",
    "    qt.ax = kd.axiom(interp(qt) == t)\n",
    "\n",
    "    return qt\n",
    "\n",
    "x + y * z\n",
    "quote(x+y*z).unquote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3461659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reify(t : smt.ExprRef):\n",
    "    # maybe it should be a python value coming in? And use kdrag.reflect.reify?\n",
    "    assert smt.is_value(t)\n",
    "    qt = quote(t)\n",
    "    reify_decl = smt.Function(\"reify\", t.sort(), tq.sort())\n",
    "    return kd.axiom(reify_decl(t) == qt)\n",
    "\n",
    "def unquote_reify(t):\n",
    "    kd.axiom(reify(reflect(t)) == t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003e0acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "x + y&middot;z"
      ],
      "text/plain": [
       "x + y*z"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unquote_sort = {}\n",
    "\n",
    "\"\"\"\n",
    "def unquote_sort(T : smt.SortRef):\n",
    "    name = T.name()\n",
    "    assert name.startswith(\"'\")\n",
    "    name = name[1:]  # remove leading quote\n",
    "    if name.startswith(\"'\"):\n",
    "        return smt.DeclareSort(name)\n",
    "    elif name == \"Real\":\n",
    "        return smt.RealSort()\n",
    "    elif name == \"Int\":\n",
    "        return smt.IntSort()\n",
    "    elif name == \"Bool\":\n",
    "        return smt.BoolSort()\n",
    "    else:\n",
    "        raise ValueError(f\"Unimplemented sort name: {name}\")    \n",
    "\"\"\"\n",
    "def interp_ax(s : smt.SortRef):\n",
    "    T = quote_sort(s)\n",
    "    interp = smt.Function(\"interp\", T, s) \n",
    "    reify = smt.Function(\"reify\", s, T)\n",
    "    x = smt.Const(\"x\", s)\n",
    "    return kd.axiom(smt.ForAll([x], interp(reify(x)) == x))\n",
    "\n",
    "def interp_ax(e):\n",
    "    qe = quote(e)\n",
    "    interp = smt.Function(\"unquote\", e.sort(), unquote[e.sort()].sort())\n",
    "    return kd.axiom(interp(qe) == e)\n",
    "unquote = {}  # interp_table?\n",
    "# could save away mapping from quoted to unquoted. But then can't interpret anything new made?\n",
    "# But if I'm actually metaprogramming, just do it in python. This is for internalization.\n",
    "def quote_sort(s : smt.SortRef):\n",
    "    T = smt.DeclareSort(\"'\" + s.sexpr())\n",
    "    #unquote_sort[T] = s\n",
    "    return T\n",
    "def quote(t : smt.ExprRef):\n",
    "    assert not isinstance(t, smt.QuantifierRef)\n",
    "    T = quote_sort(t.sort())\n",
    "    decl, children = t.decl(), t.children()\n",
    "    Targs = [quote_sort(c.sort()) for c in children]\n",
    "    absdecl = smt.Function(decl.name(), *Targs, T)\n",
    "    t1 = absdecl(*[quote(c) for c in children])\n",
    "    interp = smt.Function(\"unquote\", t1.sort(), t.sort())\n",
    "    t1.ax = kd.axiom(interp(t1) == t)\n",
    "    t1.unquote = t\n",
    "    #unquote[t1] = t\n",
    "    return t1\n",
    "\n",
    "x + y * z\n",
    "quote(x+y*z).sort()\n",
    "\n",
    "#def interp(t : smt.ExprRef):\n",
    "\n",
    "is_true = smt.Function(\"is_sat\", quote_sort(smt.BoolSort()), smt.BoolSort())\n",
    "\n",
    "def is_true(t : smt.ExprRef, by=[]):\n",
    "    # is_true is negation is unsat.\n",
    "    #s = smt.Solver()\n",
    "    #s.add(smt.Not(interp(t)))\n",
    "    #if s.check() == smt.sat:\n",
    "    #    return kd.axiom(is_true(t) == False, reasons=[])\n",
    "    p = kd.prove(interp(t), by=by)\n",
    "    return kd.axiom(is_true(t) == True, reasons=[p])\n",
    "    \n",
    "\n",
    "unquote[quote(x+y*z)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc74b54",
   "metadata": {},
   "source": [
    "# smt parse\n",
    "Take all keywords, mangle them.\n",
    "Use regular parser\n",
    "turn \n",
    "sexp parse\n",
    "\n",
    "hmm. doesn't actually work.\n",
    "\n",
    "cmds = [\n",
    "    smt.Function(\"declare-fun\", name, args, )\n",
    "]\n",
    "\n",
    "\n",
    "define_fun\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb7dd92",
   "metadata": {},
   "source": [
    "# sequent extract\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c6bf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclass import dataclass\n",
    "@dataclass\n",
    "class Sequent():\n",
    "    hyps\n",
    "    concs\n",
    "def ProofTree():\n",
    "    judgement : Sequent\n",
    "    rule : object\n",
    "    children : list['ProofTree']\n",
    "\n",
    "\n",
    "\n",
    "def prove(e : smt.ExprRef):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f178c1",
   "metadata": {},
   "source": [
    "# define_fun\n",
    "\n",
    "Maybe doing this could help me understand those early chapters in intro hott\n",
    "\n",
    "A primitve axiom style?\n",
    "\n",
    "\n",
    "Like does induction over Nat really require dependent type in some sense?\n",
    "Also acl2 like ?\n",
    "\n",
    "\n",
    "def_thm(eqs)\n",
    "    # define_fun (which deomnstrates termination)\n",
    "    # but then show it is always True using apporpriate induction principle\n",
    "\n",
    "\n",
    "https://www.cse.chalmers.se/~ulfn/papers/thesis.pdf\n",
    "inaccessible patterns\n",
    "\n",
    "Coquand 92 https://wonks.github.io/type-theory-reading-group/papers/proc92-coquand.pdf\n",
    "Guguen 2006 https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/99.pdf  Eliminating Dependent Pattern Matching\n",
    "Mcbride 1999 https://ncatlab.org/nlab/files/conor-mcbride-thesis.pdf\n",
    "View from Left paper relevant?\n",
    "\n",
    "Hmm. Dependent pattern matching. indices become unification problems\n",
    "Case splitting tree. And finding the accessor patterns of the original guy. THis is like my implementation of Pattern match. But I suppose you could go into recursors. Hmm.\n",
    "Telescopes as tries makes sense because I was distinguishing by value. Hmm.\n",
    "Individual equations vs all equations\n",
    "\n",
    "Sozeau\n",
    "\n",
    "\n",
    "https://jesper.sikanda.be/files/pattern-matching-without-K.pdf pattern macthing wiuthout K. Jesper Cockx\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ea4d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Redefining function add from |- ForAll([c!319, c!320],\n",
      "       add(c!319, c!320) ==\n",
      "       If(And(is(Z, c!319)),\n",
      "          c!320,\n",
      "          If(And(is(S, c!319)),\n",
      "             S(add(pred(c!319), c!320)),\n",
      "             unreachable!321))) to ForAll([c!342, c!343],\n",
      "       add(c!342, c!343) ==\n",
      "       If(And(is(Z, c!342)),\n",
      "          c!343,\n",
      "          If(And(is(S, c!342)),\n",
      "             S(add(pred(c!342), c!343)),\n",
      "             unreachable!344)))\n",
      "WARNING: Redefining function append from |- ForAll([c!330, c!331],\n",
      "       append(c!330, c!331) ==\n",
      "       If(And(is(Nil, c!330)),\n",
      "          c!331,\n",
      "          If(And(is(Cons, c!330)),\n",
      "             Cons(head(c!330), append(tail(c!330), c!331)),\n",
      "             unreachable!332))) to ForAll([c!353, c!354],\n",
      "       append(c!353, c!354) ==\n",
      "       If(And(is(Nil, c!353)),\n",
      "          c!354,\n",
      "          If(And(is(Cons, c!353)),\n",
      "             Cons(head(c!353), append(tail(c!353), c!354)),\n",
      "             unreachable!355)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "&#8870;ForAll([c, x, b],\n",
       "       append(Cons(x, c), b) == Cons(x, append(c, b)))"
      ],
      "text/plain": [
       "|- ForAll([c, x, b],\n",
       "       append(Cons(x, c), b) == Cons(x, append(c, b)))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import kdrag.theories.list as lst\n",
    "IntList = lst.List(smt.IntSort())\n",
    "a,b,c = smt.Consts(\"a b c\", IntList)\n",
    "#rev = smt.Function(\"rev\", IntList, IntList)\n",
    "#define_fun([rev(IntList.Nil) == IntList.Nil,\n",
    "#            rev(lst.Cons(a, lst.Cons(b, c))) == lst.Cons(rev(lst.Cons(b, c)), a)\n",
    "#            ])\n",
    "x = smt.Int(\"x\")\n",
    "append = smt.Function(\"append\", IntList, IntList, IntList)\n",
    "append = define_fun([append(IntList.Nil, b) == b,\n",
    "            append(lst.Cons(x, c), b) == lst.Cons(x, append(c, b))\n",
    "            ])\n",
    "append.case0\n",
    "append.case1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36739949",
   "metadata": {},
   "source": [
    "# partial / extensible\n",
    "\n",
    "\n",
    "Open predicates gives me internalized prolog.\n",
    "Could this be useful for the things typeclasses are used for? Automated search?\n",
    "Extensible datatypes + open functions does help. The integer id is a witness in the \n",
    "https://ocaml.org/manual/5.3/extensiblevariants.html\n",
    "\n",
    "Open Predicates\n",
    "Open Functions\n",
    "Open datatypes\n",
    "https://www.cs.ox.ac.uk/people/ralf.hinze/talks/Open.pdf\n",
    "https://www.cs.ox.ac.uk/ralf.hinze/publications/PPDP06.pdf\n",
    "best fit matching... hmm.\n",
    "\n",
    "Open patterns.\n",
    "\n",
    "https://srfi.schemers.org/srfi-262/srfi-262.html#examples pattern matyching. Extensible pattern macthing / views. Hmm.\n",
    "https://arxiv.org/abs/1106.2578  Extensible Pattern Matching in an Extensible Language. Tobin\n",
    "Universes are open types.\n",
    "Views was kind of an interesting angle on isomorphism. Snoc Cons views. Different reps of nats, etc. Quotienting.\n",
    "\"The original proposal for extensible pattern matching is Wadlers views [25], presented in the context of Haskell. In this system, a view is a pair of an injection and projection from an abstract type to an algebraic datatype. Views are intended to support data abstraction in conjunction with pattern matching.\"\n",
    "\n",
    "https://learn.microsoft.com/en-us/dotnet/fsharp/language-reference/active-patterns active patterns in F# https://en.wikibooks.org/wiki/F_Sharp_Programming/Active_Patterns  https://stackoverflow.com/questions/56536157/what-is-the-main-point-of-active-patterns https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/p29-syme.pdf Extensible Pattern Matching Via a Lightweight Language Extension https://github.com/fsharp/fslang-suggestions/issues/968#issuecomment-764636595 https://github.com/dsyme/dsyme-presentations/blob/master/design-notes/notes-on-learning-fsharp-2.md\n",
    "Kind of reminds me of TypeIs type guards.\n",
    "\n",
    "To what degree can actual OO features be applied to a \"logical\" (pure?) system. There are coinductives. Subtyping. Inheritance. I think these are so confusing that boltiong them on the kernel is fraught with peril, but they can be compiled metafeatures.\n",
    "\n",
    "https://ghc.gitlab.haskell.org/ghc/doc/users_guide/exts/view_patterns.html \n",
    "\n",
    "Maybe views could work as a mechanism.  T <=> {head : int, tail : T} is kind of a view \n",
    "section vs retract.  f(g(x)) ~ x. Which equality ?  I guess ~ could be a permutation or something?\n",
    "\n",
    "I could maybe bolt views into user propagators.\n",
    "OTT is about making views invisible (?) Deriving the needed casts/coercions.\n",
    "call \n",
    "box(unbox(x))\n",
    "force(thunk(x))\n",
    "Lambda([n], T) won't work.\n",
    "\n",
    "\n",
    "{head = n, tail = box(view(repeat(n))) }  = view(repeat(n))\n",
    "\n",
    "\n",
    "\n",
    "unbox(box(x)) = x\n",
    "box(unbox(x)) =? x.  No probably not. What if you boxed it some other way\n",
    "\n",
    "```python\n",
    "\n",
    "views = {}\n",
    "\n",
    "def define_view(inj, proj, by=[]):\n",
    "views.append(inj,proj, kd.prove(proj(inj(x)) == x)) #? left or right \n",
    "\n",
    "```\n",
    "\n",
    "https://dl.acm.org/doi/abs/10.1145/3674627 Minikanren extensible patterns\n",
    "\n",
    "\n",
    "Somehow extesnibility veers into object oriented.\n",
    "\n",
    "https://dl.acm.org/doi/abs/10.1145/3649836 Persimmon: Nested Family Polymorphism with Extensible Variant Types . NEPLS poster. Interesting object orietned bibliography\n",
    "\n",
    "https://dl.acm.org/doi/10.1145/1159803.1159836  Extensible programming with first-class cases. extensible records and extensible sums are dual\n",
    "\n",
    "Familia: unifying interfaces, type classes, and family polymorphism  https://dl.acm.org/doi/10.1145/3133894\n",
    "\n",
    "virtual types Kresten Krab Thorup. 1997. Genericity in Java with virtual types. https://link.springer.com/chapter/10.1007/BFb0053390\n",
    "\n",
    "nested inheritance\n",
    "\n",
    "Mads Torgerson. Virtual types are statically safe.\n",
    "\n",
    "associated types  Chakravorty 2005\n",
    "\n",
    "Object-Oriented Programming in the Beta Programming Language - Madsen https://en.wikipedia.org/wiki/BETA_(programming_language) https://beta.cs.au.dk/ When why and how of beta https://dl.acm.org/doi/10.1145/1238844.1238854\n",
    "\n",
    "https://link.springer.com/chapter/10.1007/3-540-45337-7_17 ernst 2001  Family Polymorphism\n",
    "\n",
    "Scalable extensibility via nested inheritance https://dl.acm.org/doi/10.1145/1028976.1028986\n",
    "\n",
    "Cardelli badai https://www.amazon.com/Theory-Objects-Monographs-Computer-Science/dp/0387947752 1996 Theory of objects\n",
    "\n",
    "https://mitpress.mit.edu/9780262526326/theoretical-aspects-of-object-oriented-programming/ Theoretical Aspects of Object-Oriented Programming\n",
    "Types, Semantics, and Language Design - mitchell and Gunter\n",
    "\n",
    "could seal to create an actual function definition. Later seals create a different but related definition.\n",
    "Likewise could seal the cases... Hmm. So a global program compilation kind of thing. We can fullly defunctionalize if we do so.\n",
    "The results of the different seals have to be ocnsistent, so we could have an axiom:\n",
    "myfun_ver1(x) == y => myfun(inj(x)) == y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "class ExtensibleInductive():\n",
    "    current : int = 0\n",
    "    def __init__(self, name, *sorts):\n",
    "        self.T = self.Record(name, (\"index\", smt.IntSort()), *sorts)\n",
    "    def declare(self, name):\n",
    "\n",
    "\n",
    "Extsenbile(\"Stream\", (\"head\", IntSort()), (\"tail\", smt.Array( , ?))\n",
    "\n",
    "\n",
    "class ExtensibleFun(): # OpenFunction\n",
    "    decl :\n",
    "    args : \n",
    "    cases = []\n",
    "    def __init__(self, *args):\n",
    "        decl = smt.Function(name, smt.IntSort(), *args) # add tag\n",
    "    def extend(self, cond, body)\n",
    "    def extend(self, body):\n",
    "        kd.define(name + \"case\" + len(cases), args, smt.If(ind == len(cases), body, nextcase(*args))\n",
    "\n",
    "    # I could narrow the arguments, but not change them?\n",
    "\n",
    "\n",
    "# maybe code would want more data? You want to scope where the codes came from\n",
    "class Code():\n",
    "    current : int\n",
    "    decode = pdefine(\"decode\")\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d6c738",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "Override vs underride semantics vs enforce disjointness.\n",
    "It is weird and probably bad \n",
    "\n",
    "I have stale axiom around.\n",
    "\n",
    "Is the undefined version becoming more defined too?\n",
    "\n",
    "Hmm. COnsidered as a systematic way of making new undef function. Interesting.\n",
    "foo = if(c, e1, foo_undef1)\n",
    "\n",
    "It's kind of just a way to invert definition ordering then. Is this even useful?\n",
    "\n",
    "foo_undef1 = yada.\n",
    "\n",
    "Oh yeah and the unfolding mechanism still works. Huh.\n",
    "\n",
    "But for condictuvies or sets it will almost never be able to push through the conditionals. When are sets _not_ equal.\n",
    "\n",
    "\n",
    "open predicates like prolog. We can only prove True because of outer Or\n",
    "Or(\n",
    "    case1, case2, undef_case\n",
    ")\n",
    "\n",
    "How to make minikanren extensible like prolog. Need open functions.\n",
    "Re opening the clark completion form.\n",
    "\n",
    "Yes, how do you ever know something isn't in predicate? Seal off. Observations?\n",
    "undef == False would seal off forever. Hmm.\n",
    "partial seal off?\n",
    "\n",
    "```python\n",
    "class OpenPred():\n",
    "    pred : smt.FuncDeclRef\n",
    "    args : list[smt.ExprRef]\n",
    "    cases : list[smt.BoolRef]\n",
    "    _undef : smt.FuncDeclRef\n",
    "    #ax : kd.Proof\n",
    "\n",
    "    def extend(self, body):\n",
    "        new_undef = smt.FreshFunction()\n",
    "        kd.define(self.undef.name(), args, smt.Or(body, newundef(*args)))\n",
    "        self.undef = new_undef\n",
    "\n",
    "    def __call__(self, *args):\n",
    "        return self.pred(*args)\n",
    "```\n",
    "\n",
    "Hmm. Is this superior to closed function form using If?\n",
    "Or(Implies(cond, f(args)  == body1)\n",
    "   Implies(cond2, f(args) == body2)\n",
    "   Implies(cond3, f(args) == )\n",
    ")\n",
    "Or form can start allowing f to have multiple models if clauses overlap. Will we be able to ever prove anything? No I guess.\n",
    "\n",
    "vs\n",
    "\n",
    "And(Implies(cond, f(args)  == body1)\n",
    "   Implies(cond2, f(args) == body2)\n",
    "   Implies(cond3, f(args) == )\n",
    ")\n",
    "And form can have insistency if cond overlap\n",
    "Makes unfolding hard / impossible.\n",
    "\n",
    "\n",
    "elem(x,A) ==\n",
    "\n",
    "pdefine(\"elem\",[x,A], A == pair(y,z), Or(x == y, x == z))\n",
    "\n",
    "An open set of equations seems reasonable\n",
    "e\n",
    "\n",
    "pdefine(\"head\", [s],  s == repeat(n), n)\n",
    "pdefine(\"tail\", [s],  s == repeat(n), repeat(n))\n",
    "\n",
    "\n",
    "but it's hard to prove that streams are or aren't equal to other streams.\n",
    "\n",
    "head(repeate(n), n) == True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ae8c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdefine(name, args, cond, body):\n",
    "    sorts = [arg.sort() for arg in args] + [body.sort()]\n",
    "    f = smt.Function(name, *sorts)\n",
    "    undef = smt.FreshFunction(name + \"_undef\", *sorts)\n",
    "    newbody = smt.If(cond, body, undef(*args))\n",
    "    if f not in kd.kernel.defns:\n",
    "        return kd.define(name, args, newbody)\n",
    "    else:\n",
    "        defn = kd.kernel.defns[f]\n",
    "        #kd.prove(smt.Not(smt.And(cond, defn.defined))) # disjoint\n",
    "        #newbody = smt.substitute(newbody, *zip(args, defn.args))\n",
    "        old_undef = kd.define(defn.undef.name(), args, newbody)\n",
    "        newbody = smt.substitute(defn.body, (defn.undef, newbody))\n",
    "        defn._replace(body=smt.If(cond, body, defn.body))\n",
    "        # we don't _have_ to replace ax.\n",
    "        ax = kd.prove(smt.ForAll(args, f(*args) == newbody, by=[defn.ax, old_undef.defn]))\n",
    "        f.defn = ax\n",
    "        return f\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18218f3",
   "metadata": {},
   "source": [
    "# termination\n",
    "\n",
    "Make a measure checking thing.\n",
    "structural recursion\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1ff867",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (880595545.py, line 5)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpatterns = [[kd.util.is_subterm(x,y) for x,y zip(arg,subargs)] for args,subargs in cases]\u001b[39m\n                                               ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "#def lex_less(subargs, args):\n",
    "#    all( subargs[i] <= args[i] for i in range(len(subargs) - 1) ) and subargs[-1] < args[-1]\n",
    "\n",
    "def arg_dec(cases):\n",
    "    N = len(cases[0][0])\n",
    "    for i in range(N):\n",
    "        if all(kd.utils.is_strict_subterm(subargs[i], args[i]) for args,subargs in cases):\n",
    "            return i # ith argument is decreasing in all cases.\n",
    "    return False\n",
    "    #patterns = [[kd.util.is_subterm(x,y) for x,y zip(arg,subargs)] for args,subargs in cases]\n",
    "    #for perm in itertools.permutations(n):\n",
    "    #    if all(   )\n",
    "\n",
    "#(False, True) < (True, True, True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9493a9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lex_dec(vs, lhs, rhs):\n",
    "    if lhs.sort() == smt.IntSort():\n",
    "        kd.prove(smt.ForAll(vs, 0 <= lhs))\n",
    "        kd.prove(smt.ForAll(vs, lhs >= rhs))\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported sort for lexicographic decision procedure\")\n",
    "x,y = smt.Ints(\"x y\")\n",
    "lex_dec([x], )\n",
    "\n",
    "# for a kd.define, we need to know every subcall is less than original.\n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b61fa23",
   "metadata": {},
   "source": [
    "# copattern\n",
    "\n",
    "Extensible definitions\n",
    "Rewrite rules in simp?\n",
    "\n",
    "\n",
    "I guess a copattern is a simpler thing than full rewriting\n",
    "\n",
    "\n",
    "I guess non-deep matching is as simple\n",
    "\n",
    "add2(S(n)) = \n",
    "\n",
    "patterns[add2][S] = ([n], S(S(n)))\n",
    "\n",
    "https://wiki.c2.com/?ClosuresAndObjectsAreEquivalent\n",
    "objects and messages\n",
    "Message = Head | Tail\n",
    "Response = Int(n) | Stream(s)\n",
    "repeat(n)[Head] = \n",
    "\n",
    "define(\"repeat\", n, Lambda([Msg], If(msg == Head, n, msg==Tail, repeat(n))))\n",
    "\n",
    "A GADT could maybe make this work\n",
    "  Head : Msg Int\n",
    "  Tail : Msg Stream\n",
    "type Stream = Msg 'a -> 'a\n",
    "\n",
    "{\n",
    "    a : T # Code type?\n",
    "    head : T -> int\n",
    "    tail : T -> T\n",
    "}\n",
    "\n",
    "head = lambda x, If(stream(n) == x, n, undefined)\n",
    "But you can't extract n out of stream.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe2314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coppatterns = {}\n",
    "coppatterns[head][repeat] = ([n], n)\n",
    "coppatterns[tail][repeat] = ([n], repeat(n))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def copattern(pat, rhs, t):\n",
    "    assert pat.decl() == t.decl()\n",
    "    zip(pat.children(), t.chidren())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fe16d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "constructors = {}\n",
    "\n",
    "# honestly it might be better to do things this way. Instead of searching through junk. I dunno.\n",
    "List = smt.DeclareSort()\n",
    "nil = smt.Const(\"nil\", List)\n",
    "cons = smt.Function(\"cons\", smt.IntSort(), List, List)\n",
    "\n",
    "constructors[List] = [nil, cons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaf9138",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = {}\n",
    "\n",
    "Stream = smt.DeclareSort(\"Stream\")\n",
    "head = smt.Function(\"head\", Stream, smt.IntSort())\n",
    "tail = smt.Function(\"tail\", Stream, Stream)\n",
    "observations[Stream] = [head, tail]\n",
    "\n",
    "zeros = smt.Const(\"zeros\", Stream)\n",
    "\n",
    "codefns = {}\n",
    "def codefine(name, args, obs): # codefine is more like define_fun than it is like define.\n",
    "    T = obs[0].arg(0).arg(0).sort()\n",
    "    decl = smt.Function(name,  [arg.sort() for arg in args] ,T)\n",
    "    assert T in observations\n",
    "    axs = []\n",
    "    for n, obeq in enumerate(obs):\n",
    "        assert smt.is_eq(obeq)\n",
    "        lhs,rhs = obeq.children()\n",
    "        ob = lhs.decl()\n",
    "        assert ob == observations[T][n]\n",
    "        axs.append(smt.ForAll(args, ob))\n",
    "        codefns[(decl, ob)] = (vs, rhs)\n",
    "    return axs\n",
    "\n",
    "\n",
    "zeros = codefine(\"zeros\", [],\n",
    "         [head(zeros) == 0,\n",
    "          tail(zeros) == zeros])\n",
    "\n",
    "wrap = smt.Function(\"wrap\", StreamT, Stream)\n",
    "codefine(\"zeros\", wrap(StreamT(0, zeros)))\n",
    "\n",
    "\n",
    "#codefine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944b1e7b",
   "metadata": {},
   "source": [
    "# solver for\n",
    "\n",
    "Hmmm. Wait. This is a guassian eliminator?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "53b80b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import z3\n",
    "def solve(eqs, x):\n",
    "   s = z3.SimpleSolver()\n",
    "   s.add(eqs)\n",
    "   return s.solve_for([x])\n",
    "x,y,z = z3.Reals('x y z')\n",
    "solve([x + y == z], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6b9109c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.15.0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import z3\n",
    "x,y,z = z3.Reals('x y z')\n",
    "s = z3.Solver()\n",
    "s.add(x + y == z)\n",
    "print(z3.get_version_string())\n",
    "print(s.solve_for([x]))\n",
    "#s.solve_for1(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec3f021b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z3.IntVal(3).py_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6410485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.15.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z3.get_version_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de7d9cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(z, p + y + 5, And(y + -1*z + p <= -5, y + -1*z + p >= -5)), (x, z + -1*y, And(x + y + -1*z >= 0, x + y + -1*z <= 0))]\n"
     ]
    }
   ],
   "source": [
    "import z3\n",
    "x,y,z,p = z3.Reals('x y z p')\n",
    "s = z3.SimpleSolver()\n",
    "s.add(x + y == z)\n",
    "s.add(p + y + 5 == z)\n",
    "s.check()\n",
    "print(s.solve_for([x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb49297",
   "metadata": {},
   "source": [
    "https://github.com/Z3Prover/doc/tree/master/synthesiz3\n",
    "https://github.com/Z3Prover/doc/commit/690d88ba43a7d706d174da2c48279a5d16810a92"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7e6ea9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b81c7516",
   "metadata": {},
   "source": [
    "# Proof\n",
    "z3 proof objects were an ast.\n",
    "They even had modus ponens?\n",
    "Hmm.\n",
    "Look at z3 and cvc5 proof objects\n",
    "\n",
    "https://ceur-ws.org/Vol-3185/paper9527.pdf simple proof format for SMT\n",
    "https://ceur-ws.org/Vol-3455/invited1.pdf Challenges in SMT Proof Production and Checking for\n",
    "Arithmetic Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "27b05c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'(let ((a!1 (forall ((x Int)) (! (f x) :pattern ((f x))))))\\n(let ((a!2 (assumption (inst a!1 (not (f 1)) (bind 1) (gen 0))\\n                       (or (not a!1) (f 1)))))\\n  (proof-trail (assumption assumption a!1)\\n               (assumption assumption (not (f 1)))\\n               a!2\\n               false)))'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "s = smt.Solver()\n",
    "s.set(\"clause_proof\", True)\n",
    "f = smt.Function(\"f\", smt.IntSort(), smt.BoolSort())\n",
    "s.add(smt.ForAll([x], f(x)))\n",
    "s.add(smt.Not(f(1)))\n",
    "print(s.check())\n",
    "p = s.proof()\n",
    "p.decl()\n",
    "assert not p.sort() == smt.DeclareSort(\"Proof\")\n",
    "p.sexpr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f095d7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Proof = smt.DeclareSort(\"Proof\")\n",
    "andI = smt.Function(\"andI\", Proof, Proof, Proof) # to build multicontext\n",
    "prove = smt.Function(\"prove\", smt.BoolSort(), Proof, Proof)\n",
    "axiom = smt.Function(\"axiom\", smt.BoolSort(), Proof)\n",
    "\n",
    "#instan = smt.Function(\"instan\", Proof, Proof)\n",
    "\n",
    "# both need to be multiarity / parametric\n",
    "#T = smt.TypeVar(\"T\")\n",
    "#herb = smt.Function(\"herb\", smt.ArraySort(), Proof)\n",
    "#instan = smt.Function(\"instan\", Proof, Proof)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdde930",
   "metadata": {},
   "source": [
    "# cvxpy\n",
    "\n",
    "But really, doesn't z3 offer this? It's about scale.\n",
    "I guess it doesn't offer SDP\n",
    "We might also want to verify cvxpy transforms like that lean project?\n",
    "\n",
    "duality? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f2a39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable((1,), x)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cvxpy as cp\n",
    "from kdrag.all import *\n",
    "import operator\n",
    "\n",
    "x,y = smt.Reals(\"x y\")\n",
    "binop = {\n",
    "    (x <= y).decl() : operator.le,\n",
    "    (x >= y).decl() : operator.ge,\n",
    "    (x == y).decl() : operator.eq,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def tocvxpy(e : smt.ExprRef):\n",
    "    if isinstance(e, smt.BoolRef):\n",
    "        if e.decl() in binop:\n",
    "            return binop[e.decl()](tocvxpy(e.arg(0)), tocvxpy(e.arg(1)))\n",
    "        else:\n",
    "            return \n",
    "        return cvxpy.Constant(e.py_value())\n",
    "\n",
    "x = cp.Variable(1, name=\"x\")\n",
    "x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e36cc2",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Sum-of-squares_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06d176c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proved\n"
     ]
    }
   ],
   "source": [
    "import z3\n",
    "x,y = smt.Reals(\"x y\")\n",
    "z3.prove(x**2 - 4*x*y + 7*y**2 >= 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd565b76",
   "metadata": {},
   "source": [
    "# sympy\n",
    "We're stuck. Just let soundness go\n",
    "\n",
    "Also tying together a solver could be fun\n",
    "\n",
    "taylor series\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf4ccdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5317702a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "&#8870;cos(x)**2 + sin(x)**2 == 1"
      ],
      "text/plain": [
       "|- cos(x)**2 + sin(x)**2 == 1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kdrag as kd\n",
    "import kdrag.theories.real as real\n",
    "from kdrag.theories.real.sympy import sympify, simplify, solve, kdify\n",
    "from kdrag.all import *\n",
    "\n",
    "\n",
    "x,y,z = smt.Reals(\"x y z\")\n",
    "sympify(x + y == z)\n",
    "sympify(x + y <= z)\n",
    "#implify(real.cos(x)**2 + real.sin(x)**2 == z)\n",
    "simplify(real.cos(x) == 3)\n",
    "\n",
    "solve([real.cos(x) == 3], [x])\n",
    "#solve([real.exp(x) == x], [x])\n",
    "\n",
    "t = sympify(real.deriv(smt.Lambda([x], real.cos(real.sin(x)))))\n",
    "\n",
    "simplify(real.integrate(smt.Lambda([x], real.sin(x)), 0,x))\n",
    "\n",
    "\n",
    "sympify(real.summation(smt.Lambda([x], real.exp(-x)), 0, y)) # hmm\n",
    "simplify(real.deriv(smt.Lambda([x], real.cos(real.sin(x)))))\n",
    "import sympy\n",
    "a = sympy.Symbol('a')\n",
    "kdify(sympy.Lambda(a,a))\n",
    "simplify(smt.Lambda([x], 2 + x + 1))\n",
    "\n",
    "class Lemma(kd.Lemma):\n",
    "    def simp(self, at=None, unfold=False):\n",
    "        super().simp(at=at, unfold=unfold)\n",
    "        goalctx = self.top_goal()\n",
    "        goal = goalctx.goal\n",
    "        if at is None:\n",
    "            newgoal = simplify(goal)\n",
    "            print(newgoal)\n",
    "            self.lemmas.append(kd.axiom(goal == newgoal, by=[\"sympy simplify\"]))\n",
    "            self.goals[-1] = goalctx._replace(goal=newgoal)\n",
    "        return self.top_goal()\n",
    "    def solve(self, vs):\n",
    "        goalctx = self.goals.top_goal()\n",
    "        return solve(goalctx.ctx, vs)\n",
    "    #def solve_for(self, vs):\n",
    "    #    contraints = self.goals[-1].ctx\n",
    "    #    s = smt.SimpleSolver()\n",
    "    #    s.add(contraints)\n",
    "    #    return s.solve_for(vs)\n",
    "\n",
    "l = Lemma(real.cos(x)**2 + real.sin(x)**2 == 1)\n",
    "l.simp()\n",
    "l.qed()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f3767f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SympifyError",
     "evalue": "SympifyError: \"cannot sympify object of type <class 'kdrag.reflect.KnuckleClosure'>\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSympifyError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msimplify\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLambda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/python/knuckledragger/kdrag/theories/real/sympy.py:173\u001b[39m, in \u001b[36msimplify\u001b[39m\u001b[34m(e)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msimplify\u001b[39m(e: smt.ExprRef) -> smt.ExprRef:\n\u001b[32m    165\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    166\u001b[39m \u001b[33;03m    Simplify a z3 expression.\u001b[39;00m\n\u001b[32m    167\u001b[39m \u001b[33;03m    >>> x = smt.Real(\"x\")\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    171\u001b[39m \u001b[33;03m    1\u001b[39;00m\n\u001b[32m    172\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m kdify(\u001b[43msympy\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimplify\u001b[49m\u001b[43m(\u001b[49m\u001b[43msympify\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/philzook58.github.io/.venv/lib/python3.12/site-packages/sympy/simplify/simplify.py:588\u001b[39m, in \u001b[36msimplify\u001b[39m\u001b[34m(expr, ratio, measure, rational, inverse, doit, **kwargs)\u001b[39m\n\u001b[32m    585\u001b[39m     rv = e.doit() \u001b[38;5;28;01mif\u001b[39;00m doit \u001b[38;5;28;01melse\u001b[39;00m e\n\u001b[32m    586\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m shorter(rv, collect_abs(rv))\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m expr = \u001b[43msympify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrational\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrational\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    589\u001b[39m kwargs = {\n\u001b[32m    590\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mratio\u001b[39m\u001b[33m\"\u001b[39m: kwargs.get(\u001b[33m'\u001b[39m\u001b[33mratio\u001b[39m\u001b[33m'\u001b[39m, ratio),\n\u001b[32m    591\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmeasure\u001b[39m\u001b[33m\"\u001b[39m: kwargs.get(\u001b[33m'\u001b[39m\u001b[33mmeasure\u001b[39m\u001b[33m'\u001b[39m, measure),\n\u001b[32m    592\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrational\u001b[39m\u001b[33m\"\u001b[39m: kwargs.get(\u001b[33m'\u001b[39m\u001b[33mrational\u001b[39m\u001b[33m'\u001b[39m, rational),\n\u001b[32m    593\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minverse\u001b[39m\u001b[33m\"\u001b[39m: kwargs.get(\u001b[33m'\u001b[39m\u001b[33minverse\u001b[39m\u001b[33m'\u001b[39m, inverse),\n\u001b[32m    594\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdoit\u001b[39m\u001b[33m\"\u001b[39m: kwargs.get(\u001b[33m'\u001b[39m\u001b[33mdoit\u001b[39m\u001b[33m'\u001b[39m, doit)}\n\u001b[32m    595\u001b[39m \u001b[38;5;66;03m# no routine for Expr needs to check for is_zero\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/philzook58.github.io/.venv/lib/python3.12/site-packages/sympy/core/sympify.py:465\u001b[39m, in \u001b[36msympify\u001b[39m\u001b[34m(a, locals, convert_xor, strict, rational, evaluate)\u001b[39m\n\u001b[32m    462\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m SympifyError(\u001b[33m'\u001b[39m\u001b[33mcannot sympify object of type \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m % \u001b[38;5;28mtype\u001b[39m(a))\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparsing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msympy_parser\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (parse_expr, TokenError,\n\u001b[32m    468\u001b[39m                                         standard_transformations)\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparsing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msympy_parser\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_xor \u001b[38;5;28;01mas\u001b[39;00m t_convert_xor\n",
      "\u001b[31mSympifyError\u001b[39m: SympifyError: \"cannot sympify object of type <class 'kdrag.reflect.KnuckleClosure'>\""
     ]
    }
   ],
   "source": [
    "(smt.Lambda([x], x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60da85f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-x).decl().kind()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5f46cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "&lambda;x : x"
      ],
      "text/plain": [
       "Lambda(x, x)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(smt.Lambda([x], x))\n",
    "smt.Lambda(x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fe9601d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(a,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sympy\n",
    "a = sympy.Symbol('a')\n",
    "a.name\n",
    "def Lambda(x,y): return x,y\n",
    "#sympy.lambdify([], sympy.Lambda(a, a), modules={\"Lambda\" : Lambda})()\n",
    "sympy.E\n",
    "isinstance(sympy.Lambda(a,2+a), sympy.Lambda)\n",
    "sympy.Lambda(a,2+a).variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fefc4730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8, a}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sympy.Lambda(a, a + 7 * a).atoms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbd80329",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43ma\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c56145e",
   "metadata": {},
   "source": [
    "# eexists / uvars\n",
    "\n",
    "uvars realkly belong to the total goal state not Goals.\n",
    "tracking what is allowed in them uses the goal vars at the time.\n",
    "Yikeys.\n",
    "Can just collect junk to be included in prove(smt.Exists(uvars, ))\n",
    "\n",
    "prove(smt.Exist)\n",
    "\n",
    "kd.QExists(uvars, constraints, whatev)\n",
    "\n",
    "Kind of need uvars to use solve_for and sympy stuff?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5abe8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lemma():\n",
    "    uvars : set[smt.ExprRef]\n",
    "    constraints : list[smt.BoolRef] # or go into lemmas?\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def eexists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ead3730",
   "metadata": {},
   "source": [
    "# spacer\n",
    "\n",
    "Can we use spacer for something? Inductive theorem proving?\n",
    "https://microsoft.github.io/z3guide/programming/Z3%20Python%20-%20Readonly/Fixedpoints\n",
    "https://github.com/Z3Prover/z3/discussions/5013\n",
    "https://github.com/agurfinkel/spacer-on-jupyter/blob/master/Dagstuhl2019.ipynb\n",
    "https://github.com/agurfinkel/spacer-on-jupyter/blob/master/FSU_2023.ipynb\n",
    "https://github.com/agurfinkel/spacer-on-jupyter/blob/master/src/spacer_tutorial/solve.py\n",
    "\n",
    "\n",
    "DIY IC3 solver?\n",
    "Needs interpolation right?\n",
    "Could just use spacer for interp\n",
    "\n",
    "https://github.com/Z3Prover/z3/blob/master/examples/python/mini_ic3.py\n",
    "https://github.com/pddenhar/Z3-IC3-PDR\n",
    "\n",
    "https://github.com/arbrad/IC3ref \n",
    "\n",
    "https://github.com/JakubSarnik/geyser\n",
    "https://github.com/gipsyh/rIC3\n",
    "\n",
    "aiger and btor2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4f07281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.all import *\n",
    "def solver_horn(chc):\n",
    "    # https://github.com/agurfinkel/spacer-on-jupyter/blob/master/src/spacer_tutorial/solve.py\n",
    "    s = z3.SolverFor('HORN')\n",
    "    s.set('engine', 'spacer')\n",
    "    s.set('spacer.order_children', 2)\n",
    "    s.add(chc)\n",
    "    res = s.check()\n",
    "    if res == z3.sat:\n",
    "        return res, s.model()\n",
    "    elif res == z3.unsat:\n",
    "        return res, s.proof()\n",
    "    else:\n",
    "        return res, None\n",
    "    \n",
    "def interpolate(As, A, Bs, B, shared):\n",
    "    # Uninterpreted predicate Itp over shared symbols\n",
    "    Itp = z3.Function('Itp', [s.sort() for s in shared] + [z3.BoolSort()])\n",
    "\n",
    "    # first CHC: A ==> Itp\n",
    "    left = z3.ForAll([a for a in As], z3.Implies(A, Itp(shared)))\n",
    "    # second CHC: Itp ==> !B\n",
    "    right = z3.ForAll([b for b in Bs], z3.Implies(Itp(shared), z3.Not(B)))\n",
    "\n",
    "    # run CHC solver\n",
    "    res, answer = solve_horn([left, right])\n",
    "\n",
    "    if res == z3.sat:\n",
    "        return answer.eval(Itp(shared))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f051a0d",
   "metadata": {},
   "source": [
    "https://microsoft.github.io/z3guide/docs/fixedpoints/engineforpdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7878fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sat, [mc = [else -> True], q1 = [else -> True]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc = smt.Function(\"mc\", smt.IntSort(), smt.IntSort(), smt.BoolSort())\n",
    "n,m,p = smt.Ints(\"n m p\")\n",
    "q1 = smt.Function(\"q1\", smt.IntSort(), smt.IntSort(), smt.BoolSort())\n",
    "clauses = [\n",
    "    kd.QForAll([m], m > 100, mc(m, m - 10)),\n",
    "    kd.QForAll([m,p,n], m <= 100, mc(m + 11, p), mc(p,n), mc(m,n)),\n",
    "    #kd.QForAll([m,n], mc(m,n), n < 91, q1(m,n)),\n",
    "]\n",
    "solver_horn(clauses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1233c52",
   "metadata": {},
   "source": [
    "https://z3prover.github.io/papers/programmingz3.html#sec-horn-clause-solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8158271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sat\n",
      "And(Not(y + -1*x <= -11),\n",
      "    Not(y <= 90),\n",
      "    Or(Not(y >= 92), Not(y + -1*x >= -9)))\n"
     ]
    }
   ],
   "source": [
    "s = smt.SolverFor(\"HORN\")\n",
    "Z = smt.IntSort()\n",
    "B = smt.BoolSort()\n",
    "mc = smt.Function('mc', Z, Z, B)\n",
    "x, y, z = smt.Ints('x y z')\n",
    "s.add(smt.ForAll(x, smt.Implies(x > 100, mc(x, x - 10))))\n",
    "s.add(smt.ForAll([x, y, z], \n",
    "             smt.Implies(smt.And(x <= 100, mc(x + 11, y), mc(y, z)), \n",
    "                     mc(x, z))))\n",
    "s.add(smt.ForAll([x, y], smt.Implies(smt.And(x <= 101, mc(x, y)), y == 91)))\n",
    "s.add(smt.ForAll([x, y], smt.Implies(smt.And(x >= 101, mc(x, y)), x == y + 10)))\n",
    "print(s.check())\n",
    "print(s.model().eval(mc(x, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3adfc2",
   "metadata": {},
   "source": [
    "## popper\n",
    "https://github.com/logic-and-learning-lab/Popper/\n",
    "\n",
    "Houdini\n",
    "\n",
    "Is invariant (?)\n",
    "\n",
    "def inv(P)\n",
    "    for P in candidates()\n",
    "        try:\n",
    "            kd.prove(induct(P).arg(0))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d19ffa",
   "metadata": {},
   "source": [
    "# tableau / meson\n",
    "\n",
    "For modal logics might be nice\n",
    "Also smt boosted meson is interesting in and of itself.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dbd31f",
   "metadata": {},
   "source": [
    "# brute check\n",
    "For anything 32bit or less we ought to just brute check it.\n",
    "\n",
    "float16 for example. Would give me more confidence.\n",
    "single variable float32 ops\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adbc6f4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac37c2ab",
   "metadata": {},
   "source": [
    "# Solvers\n",
    "##  isabelle\n",
    "Graham was saying why not just download isabelle... Hmm.\n",
    "\n",
    "\n",
    "\n",
    "```bash\n",
    "emconfigure ./configure --enable-ho\n",
    "emmake make AR=\"/home/philip/Downloads/emsdk/upstream/emscripten/emar rcs\"\n",
    "```\n",
    "\n",
    " And had to comment out in Makefile.vars the forced CC and AR values\n",
    "\n",
    "\n",
    "https://github.com/philzook58/eprover/releases/download/E.3.2.5-ho/eprover-ho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77514bd3",
   "metadata": {},
   "source": [
    "bitwuzla\n",
    "cvc5 \n",
    "ytices\n",
    "pysmt\n",
    "\n",
    "bto2\n",
    "moxi\n",
    "\n",
    "implement model checking algorithms?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a427ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyboolector as btor\n",
    "\n",
    "btor.Parse(\"example.btor\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d232c3da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd55d4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import stat\n",
    "filename = \"eprover-ho\"\n",
    "#urllib.request.urlretrieve(\"https://github.com/philzook58/eprover/releases/download/E.3.2.5-ho/eprover-ho\", filename)\n",
    "st = os.stat(filename)\n",
    "    # Add execute permissions for user, group, and others\n",
    "os.chmod(filename, st.st_mode | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9add68db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'# Preprocessing class: HSSSSMSSSSSNFFN.\\n# Scheduled 4 strats onto 8 cores with 300 seconds (2400 total)\\n# Starting new_ho_10 with 1500s (5) cores\\n# Starting ho_unfolding_6 with 300s (1) cores\\n# Starting sh4l with 300s (1) cores\\n# Starting ehoh_best_nonlift_rwall with 300s (1) cores\\n# new_ho_10 with pid 996928 completed with status 9\\n# ho_unfolding_6 with pid 996929 completed with status 9\\n# sh4l with pid 996930 completed with status 9\\n# ehoh_best_nonlift_rwall with pid 996931 completed with status 9\\n# Schedule exhausted\\n# SZS status GaveUp\\n'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.solvers import EProverTHFSolver\n",
    "s = EProverTHFSolver()\n",
    "s.add(x == y)\n",
    "s.check()\n",
    "s.res.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eaebb343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "E 3.2.5-ho \"Puttabong Moondrop\"\n",
      "\n",
      "Usage: eprover [options] [files]\n",
      "\n",
      "Read a set of first-order (or, in the -ho-version, higher-order)\n",
      "clauses and formulae and try to prove the conjecture (if given)\n",
      "or show the set unsatisfiable.\n",
      "\n",
      "Options:\n",
      "\n",
      "   -h\n",
      "  --help\n",
      "    Print a short description of program usage and options.\n",
      "\n",
      "   -V\n",
      "  --version\n",
      "    Print the version number of the prover. Please include this with all bug\n",
      "    reports (if any).\n",
      "\n",
      "   -v\n",
      "  --verbose[=<arg>]\n",
      "    Verbose comments on the progress of the program. This differs from the\n",
      "    output level (below) in that technical information is printed to stderr,\n",
      "    while the output level determines which logical manipulations of the\n",
      "    clauses are printed to stdout. The short form or the long form without\n",
      "    the optional argument is equivalent to --verbose=1.\n",
      "\n",
      "   -o <arg>\n",
      "  --output-file=<arg>\n",
      "    Redirect output into the named file.\n",
      "\n",
      "   -s\n",
      "  --silent\n",
      "    Equivalent to --output-level=0.\n",
      "\n",
      "   -l <arg>\n",
      "  --output-level=<arg>\n",
      "    Select an output level, greater values imply more verbose output. Level 0\n",
      "    produces nearly no output, level 1 will output each clause as it is\n",
      "    processed, level 2 will output generating inferences, level 3 will give a\n",
      "    full protocol including rewrite steps and level 4 will include some\n",
      "    internal clause renamings. Levels >= 2 also imply PCL2 or TSTP formats\n",
      "    (which can be post-processed with suitable tools).\n",
      "\n",
      "   -p\n",
      "  --proof-object[=<arg>]\n",
      "    Generate (and print, in case of success) an internal proof object. Level\n",
      "    0 will not print a proof object, level 1 will build asimple, compact\n",
      "    proof object that only contains inference rules and dependencies, level 2\n",
      "    will build a proof object where inferences are unambiguously described by\n",
      "    giving inference positions, and level 3 will expand this to a proof\n",
      "    object where all intermediate results are explicit. This feature is under\n",
      "    development, so far only level 0 and 1 are operational. The proof object\n",
      "    will be provided in TPTP-3 or PCL syntax, depending on input format and\n",
      "    explicit settings. The --proof-graph option will suppress normal output\n",
      "    of the proof object in favour of a graphial representation. The short\n",
      "    form or the long form without the optional argument is equivalent to\n",
      "    --proof-object=1.\n",
      "\n",
      "  --proof-graph[=<arg>]\n",
      "    Generate (and print, in case of success) an internal proof object in the\n",
      "    form of a GraphViz dot graph. The optional argument can be 1 (nodes are\n",
      "    labelled with just the name of the clause/formula), 2 (nodes are labelled\n",
      "    with the TPTP clause/formula) or 3  (nodes also labelled with\n",
      "    source/inference record. The option without the optional argument is\n",
      "    equivalent to --proof-graph=3.\n",
      "\n",
      "  --proof-statistics\n",
      "    Print various statistics of the proof object.\n",
      "\n",
      "   -d\n",
      "  --full-deriv\n",
      "    Include all derived formuas/clauses in the proof graph/proof object, not\n",
      "    just the ones contributing to the actual proof.\n",
      "\n",
      "  --force-deriv[=<arg>]\n",
      "    Force output of the derivation even in cases where the prover terminates\n",
      "    in an indeterminate state. By default, the deriviation of all processed\n",
      "    clauses is included in the derivation object. With argument 2, the\n",
      "    derivation of all clauses will be printed. The option without the\n",
      "    optional argument is equivalent to --force-deriv=1.\n",
      "\n",
      "  --record-gcs\n",
      "    Record given-clause selection as separate (pseudo-)inferences and\n",
      "    preserve the form of given clauses evaluated and selected via archiving\n",
      "    for analysis and possibly machine learning.\n",
      "\n",
      "  --training-examples[=<arg>]\n",
      "    Generate and process training examples from the proof search object.\n",
      "    Implies --record-gcs. The argument is a binary or of the desired\n",
      "    processing. Bit zero prints positive exampels. Bit 1 prints negative\n",
      "    examples. Additional selectors will be added later. The option without\n",
      "    the optional argument is equivalent to --training-examples=1.\n",
      "\n",
      "  --pcl-terms-compressed\n",
      "    Print terms in the PCL output in shared representation.\n",
      "\n",
      "  --pcl-compact\n",
      "    Print PCL steps without additional spaces for formatting (safes disk\n",
      "    space for large protocols).\n",
      "\n",
      "  --pcl-shell-level[=<arg>]\n",
      "    Determines level to which clauses and formulas are suppressed in the\n",
      "    output. Level 0 will print all, level 1 will only print initial\n",
      "    clauses/formulas, level 2 will print no clauses or axioms. All levels\n",
      "    will still print the dependency graph. The option without the optional\n",
      "    argument is equivalent to --pcl-shell-level=1.\n",
      "\n",
      "  --print-statistics\n",
      "    Print the inference statistics (only relevant for output level <=1,\n",
      "    otherwise they are printed automatically.\n",
      "\n",
      "   -0\n",
      "  --print-detailed-statistics\n",
      "    Print data about the proof state that is potentially expensive to\n",
      "    collect. Includes number of term cells and number of rewrite steps. This\n",
      "    implies the previous option.\n",
      "\n",
      "   -S\n",
      "  --print-saturated[=<arg>]\n",
      "    Print the (semi-) saturated clause sets after terminating the saturation\n",
      "    process. The argument given describes which parts should be printed in\n",
      "    which order. Legal characters are 'teigEIGaA', standing for type\n",
      "    declarations, processed positive units, processed negative units,\n",
      "    processed non-units, unprocessed positive units, unprocessed negative\n",
      "    units, unprocessed non-units, and two types of additional equality\n",
      "    axioms, respectively. Equality axioms will only be printed if the\n",
      "    original specification contained real equality. In this case, 'a'\n",
      "    requests axioms in which a separate substitutivity axiom is given for\n",
      "    each argument position of a function or predicate symbol, while 'A'\n",
      "    requests a single substitutivity axiom (covering all positions) for each\n",
      "    symbol. The short form or the long form without the optional argument is\n",
      "    equivalent to --print-saturated=eigEIG.\n",
      "\n",
      "  --print-sat-info\n",
      "    Print additional information (clause number, weight, etc) as a comment\n",
      "    for clauses from the semi-saturated end system.\n",
      "\n",
      "  --filter-saturated[=<arg>]\n",
      "    Filter the  (semi-) saturated clause sets after terminating the\n",
      "    saturation process. The argument is a string describing which operations\n",
      "    to take (and in which order). Options are 'u' (remove all clauses with\n",
      "    more than one literal), 'c' (delete all but one copy of identical\n",
      "    clauses, 'n', 'r', 'f' (forward contraction, unit-subsumption only, no\n",
      "    rewriting, rewriting with rules only, full rewriting, respectively), and\n",
      "    'N', 'R' and 'F' (as their lower case counterparts, but with\n",
      "    non-unit-subsumption enabled as well). The option without the optional\n",
      "    argument is equivalent to --filter-saturated=Fc.\n",
      "\n",
      "  --syntax-only\n",
      "    Stop after parsing, i.e. only check if the input can be parsed correcly.\n",
      "\n",
      "  --prune\n",
      "    Stop after relevancy pruning, SInE pruning, and output of the initial\n",
      "    clause- and formula set. This will automatically set output level to 4 so\n",
      "    that the pruned problem specification is printed. Note that the desired\n",
      "    pruning methods must still be specified (e.g. '--sine=Auto').\n",
      "\n",
      "  --cnf\n",
      "    Convert the input problem into clause normal form and print it. This is\n",
      "    (nearly) equivalent to '--print-saturated=eigEIG\n",
      "    --processed-clauses-limit=0' and will by default perform some usually\n",
      "    useful simplifications. You can additionally specify e.g.\n",
      "    '--no-preprocessing' if you want just the result of CNF translation.\n",
      "\n",
      "  --print-pid\n",
      "    Print the process id of the prover as a comment after option processing.\n",
      "\n",
      "  --print-version\n",
      "    Print the version number of the prover as a comment after option\n",
      "    processing. Note that unlike -version, the prover will not terminate, but\n",
      "    proceed normally.\n",
      "\n",
      "  --error-on-empty\n",
      "    Return with an error code if the input file contains no clauses.\n",
      "    Formally, the empty clause set (as an empty conjunction of clauses) is\n",
      "    trivially satisfiable, and E will treat any empty input set as\n",
      "    satisfiable. However, in composite systems this is more often a sign that\n",
      "    something went wrong. Use this option to catch such bugs.\n",
      "\n",
      "   -m <arg>\n",
      "  --memory-limit=<arg>\n",
      "    Limit the memory the prover may use. The argument is the allowed amount\n",
      "    of memory in MB. If you use the argument 'Auto', the system will try to\n",
      "    figure out the amount of physical memory of your machine and claim most\n",
      "    of it. This option may not work everywhere, due to broken and/or strange\n",
      "    behaviour of setrlimit() in some UNIX implementations, and due to the\n",
      "    fact that I know of no portable way to figure out the physical memory in\n",
      "    a machine. Both the option and the 'Auto' version do work under all\n",
      "    tested versions of Solaris and GNU/Linux. Due to problems with limit data\n",
      "    types, it is currently impossible to set a limit of more than 2 GB (2048\n",
      "    MB).\n",
      "\n",
      "  --cpu-limit[=<arg>]\n",
      "    Limit the (per core) cpu time the prover should run. The optional\n",
      "    argument is the CPU time in seconds. The prover will terminate\n",
      "    immediately after reaching the time limit, regardless of internal state.\n",
      "    As a side effect, this option will inhibit core file writing. Please note\n",
      "    that if you use both --cpu-limit and --soft-cpu-limit, the soft limit has\n",
      "    to be smaller than the hard limit to have any effect.  The option without\n",
      "    the optional argument is equivalent to --cpu-limit=300.\n",
      "\n",
      "  --soft-cpu-limit[=<arg>]\n",
      "    Limit the cpu time the prover should spend in the main saturation phase.\n",
      "    The prover will then terminate gracefully, i.e. it will perform\n",
      "    post-processing, filtering and printing of unprocessed clauses, if these\n",
      "    options are selected. Note that for some filtering options (in particular\n",
      "    those which perform full subsumption), the post-processing time may well\n",
      "    be larger than the saturation time. This option is particularly useful if\n",
      "    you want to use E as a preprocessor or lemma generator in a larger\n",
      "    system. The option without the optional argument is equivalent to\n",
      "    --soft-cpu-limit=290.\n",
      "\n",
      "   -R\n",
      "  --resources-info\n",
      "    Give some information about the resources used by the prover. You will\n",
      "    usually get CPU time information. On systems returning more information\n",
      "    with the rusage() system call, you will also get information about memory\n",
      "    consumption.\n",
      "\n",
      "  --select-strategy=<arg>\n",
      "    Select one of the built-in strategies and set all proof search parameters\n",
      "    accordingly.\n",
      "\n",
      "  --print-strategy[=<arg>]\n",
      "    Print a representation of all search parameters and their setting of a\n",
      "    given strategy, then terminate. If no argument is given, the current\n",
      "    strategy is printed. Use the reserved name '>all-strats<'to get a\n",
      "    description of all built-in strategies,  '>all-names<' to get a list of\n",
      "    all names of strategies. The option without the optional argument is\n",
      "    equivalent to --print-strategy=>current-strategy<.\n",
      "\n",
      "  --parse-strategy=<arg>\n",
      "    Parse the previously printed representation of strategy and set all proof\n",
      "    search parameters accordingly.\n",
      "\n",
      "   -C <arg>\n",
      "  --processed-clauses-limit=<arg>\n",
      "    Set the maximal number of clauses to process (i.e. the number of\n",
      "    traversals of the main-loop).\n",
      "\n",
      "   -P <arg>\n",
      "  --processed-set-limit=<arg>\n",
      "    Set the maximal size of the set of processed clauses. This differs from\n",
      "    the previous option in that redundant and back-simplified processed\n",
      "    clauses are not counted.\n",
      "\n",
      "   -U <arg>\n",
      "  --unprocessed-limit=<arg>\n",
      "    Set the maximal size of the set of unprocessed clauses. This is a\n",
      "    termination condition, not something to use to control the deletion of\n",
      "    bad clauses. Compare --delete-bad-limit.\n",
      "\n",
      "   -T <arg>\n",
      "  --total-clause-set-limit=<arg>\n",
      "    Set the maximal size of the set of all clauses. See previous option.\n",
      "\n",
      "  --generated-limit=<arg>\n",
      "    Set the maximal number of generated clauses before the proof search\n",
      "    stops. This is a reasonable (though not great) estimate of the work done.\n",
      "\n",
      "  --tb-insert-limit=<arg>\n",
      "    Set the maximal number of of term bank term top insertions. This is a\n",
      "    reasonable (though not great) estimate of the work done.\n",
      "\n",
      "  --answers[=<arg>]\n",
      "    Set the maximal number of answers to print for existentially quantified\n",
      "    questions. Without this option, the prover terminates after the first\n",
      "    answer found. If the value is different from 1, the prover is no longer\n",
      "    guaranteed to terminate, even if there is a finite number of answers. The\n",
      "    option without the optional argument is equivalent to\n",
      "    --answers=2147483647.\n",
      "\n",
      "  --conjectures-are-questions\n",
      "    Treat all conjectures as questions to be answered. This is a wart\n",
      "    necessary because CASC-J6 has categories requiring answers, but does not\n",
      "    yet support the 'question' type for formulas.\n",
      "\n",
      "   -n\n",
      "  --eqn-no-infix\n",
      "    In LOP, print equations in prefix notation equal(x,y).\n",
      "\n",
      "   -e\n",
      "  --full-equational-rep\n",
      "    In LOP. print all literals as equations, even non-equational ones.\n",
      "\n",
      "  --lop-in\n",
      "    Set E-LOP as the input format. If no input format is selected by this or\n",
      "    one of the following options, E will guess the input format based on the\n",
      "    first token. It will almost always correctly recognize TPTP-3, but it may\n",
      "    misidentify E-LOP files that use TPTP meta-identifiers as logical\n",
      "    symbols.\n",
      "\n",
      "  --pcl-out\n",
      "    Set PCL as the proof object output format.\n",
      "\n",
      "  --tptp-in\n",
      "    Set TPTP-2 as the input format (but note that includes are still handled\n",
      "    according to TPTP-3 semantics).\n",
      "\n",
      "  --tptp-out\n",
      "    Print TPTP format instead of E-LOP. Implies --eqn-no-infix and will\n",
      "    ignore --full-equational-rep.\n",
      "\n",
      "  --tptp-format\n",
      "    Equivalent to --tptp-in and --tptp-out.\n",
      "\n",
      "  --tptp2-in\n",
      "    Synonymous with --tptp-in.\n",
      "\n",
      "  --tptp2-out\n",
      "    Synonymous with --tptp-out.\n",
      "\n",
      "  --tptp2-format\n",
      "    Synonymous with --tptp-format.\n",
      "\n",
      "  --tstp-in\n",
      "    Set TPTP-3 as the input format TPTP-3 syntax is still under development,\n",
      "    and any given version in E may not be fully conforming at all times. E\n",
      "    works on all TPTP 8.2.0 FOF and CNF files (including includes).\n",
      "\n",
      "  --tstp-out\n",
      "    Print output clauses in TPTP-3 syntax. In particular, for output levels\n",
      "    >=2, write derivations as TPTP-3 derivations.\n",
      "\n",
      "  --tstp-format\n",
      "    Equivalent to --tstp-in and --tstp-out.\n",
      "\n",
      "  --tptp3-in\n",
      "    Synonymous with --tstp-in.\n",
      "\n",
      "  --tptp3-out\n",
      "    Synonymous with --tstp-out.\n",
      "\n",
      "  --tptp3-format\n",
      "    Synonymous with --tstp-format.\n",
      "\n",
      "  --auto\n",
      "    Automatically determine settings for proof search.\n",
      "\n",
      "  --auto-schedule[=<arg>]\n",
      "    Use the (experimental) strategy scheduling. This will try several\n",
      "    different fully specified search strategies (aka \"Auto-Modes\"), one after\n",
      "    the other, until a proof or saturation is found, or the time limit is\n",
      "    exceeded. The optional argument is the number of CPUs on which the\n",
      "    schedule is going to be executed on. By default, the schedule is executed\n",
      "    on a single core. To execute on all cores of a system, set the argument\n",
      "    to 'Auto', but note that this will use all reported cores (even\n",
      "    low-performance efficiency cores, if available on the hardware platform\n",
      "    and reported by the OS). The option without the optional argument is\n",
      "    equivalent to --auto-schedule=1.\n",
      "\n",
      "  --force-preproc-sched=<arg>\n",
      "    When autoscheduling is used, make sure that preprocessing schedule is\n",
      "    inserted in the search categories\n",
      "\n",
      "  --serialize-schedule=<arg>\n",
      "    Convert parallel auto-schedule into serialized one.\n",
      "\n",
      "  --satauto-schedule[=<arg>]\n",
      "    Use strategy scheduling without SInE, thus maintaining completeness. The\n",
      "    option without the optional argument is equivalent to\n",
      "    --satauto-schedule=1.\n",
      "\n",
      "  --no-preprocessing\n",
      "    Do not perform preprocessing on the initial clause set. Preprocessing\n",
      "    currently removes tautologies and orders terms, literals and clauses in a\n",
      "    certain (\"canonical\") way before anything else happens. Unless limited by\n",
      "    one of the following options, it will also unfold equational definitions.\n",
      "\n",
      "  --eq-unfold-limit=<arg>\n",
      "    During preprocessing, limit unfolding (and removing) of equational\n",
      "    definitions to those where the expanded definition is at most the given\n",
      "    limit bigger (in terms of standard weight) than the defined term.\n",
      "\n",
      "  --eq-unfold-maxclauses=<arg>\n",
      "    During preprocessing, don't try unfolding of equational definitions if\n",
      "    the problem has more than this limit of clauses.\n",
      "\n",
      "  --no-eq-unfolding\n",
      "    During preprocessing, abstain from unfolding (and removing) equational\n",
      "    definitions.\n",
      "\n",
      "  --goal-defs[=<arg>]\n",
      "    Introduce Twee-style equational definitions for ground terms in\n",
      "    conjecture clauses. The argument can be None, All or Neg, which will only\n",
      "    consider ground terms from negative literals in the CNF (to be\n",
      "    implemented). The option without the optional argument is equivalent to\n",
      "    --goal-defs=All.\n",
      "\n",
      "  --goal-subterm-defs\n",
      "    Introduce goal definitions for all conjecture ground subterms. The\n",
      "    default is to only introduce them for the maximal (with respect to the\n",
      "    subterm relation) ground terms in conjecture clauses (to be implemented).\n",
      "\n",
      "  --sine[=<arg>]\n",
      "    Apply SInE to prune the unprocessed axioms with the specified filter.\n",
      "    'Auto' will automatically pick a filter. The option without the optional\n",
      "    argument is equivalent to --sine=Auto.\n",
      "\n",
      "  --rel-pruning-level[=<arg>]\n",
      "    Perform relevancy pruning up to the given level on the unprocessed\n",
      "    axioms. The option without the optional argument is equivalent to\n",
      "    --rel-pruning-level=3.\n",
      "\n",
      "  --presat-simplify[=<arg>]\n",
      "    Before proper saturation do a complete interreduction of the proof state.\n",
      "    The option without the optional argument is equivalent to\n",
      "    --presat-simplify=true.\n",
      "\n",
      "  --ac-handling[=<arg>]\n",
      "    Select AC handling mode, i.e. determine what to do with redundant AC\n",
      "    tautologies. The default is equivalent to 'DiscardAll', the other\n",
      "    possible values are 'None' (to disable AC handling), 'KeepUnits', and\n",
      "    'KeepOrientable'. The option without the optional argument is equivalent\n",
      "    to --ac-handling=KeepUnits.\n",
      "\n",
      "  --ac-non-aggressive\n",
      "    Do AC resolution on negative literals only on processing (by default, AC\n",
      "    resolution is done after clause creation). Only effective if AC handling\n",
      "    is not disabled.\n",
      "\n",
      "   -W <arg>\n",
      "  --literal-selection-strategy=<arg>\n",
      "    Choose a strategy for selection of negative literals. There are two\n",
      "    special values for this option: NoSelection will select no literal (i.e.\n",
      "    perform normal superposition) and NoGeneration will inhibit all\n",
      "    generating inferences. For a list of the other (hopefully\n",
      "    self-documenting) values run 'eprover -W none'. There are two variants of\n",
      "    each strategy. The one prefixed with 'P' will allow paramodulation into\n",
      "    maximal positive literals in addition to paramodulation into maximal\n",
      "    selected negative literals.\n",
      "\n",
      "  --no-generation\n",
      "    Don't perform any generating inferences (equivalent to\n",
      "    --literal-selection-strategy=NoGeneration).\n",
      "\n",
      "  --select-on-processing-only\n",
      "    Perform literal selection at processing time only (i.e. select only in\n",
      "    the _given clause_), not before clause evaluation. This is relevant\n",
      "    because many clause selection heuristics give special consideration to\n",
      "    maximal or selected literals.\n",
      "\n",
      "   -i\n",
      "  --inherit-paramod-literals\n",
      "    Always select the negative literals a previous inference paramodulated\n",
      "    into (if possible). If no such literal exists, select as dictated by the\n",
      "    selection strategy.\n",
      "\n",
      "   -j\n",
      "  --inherit-goal-pm-literals\n",
      "    In a goal (all negative clause), always select the negative literals a\n",
      "    previous inference paramodulated into (if possible). If no such literal\n",
      "    exists, select as dictated by the selection strategy.\n",
      "\n",
      "  --inherit-conjecture-pm-literals\n",
      "    In a conjecture-derived clause, always select the negative literals a\n",
      "    previous inference paramodulated into (if possible). If no such literal\n",
      "    exists, select as dictated by the selection strategy.\n",
      "\n",
      "  --selection-pos-min=<arg>\n",
      "    Set a lower limit for the number of positive literals a clause must have\n",
      "    to be eligible for literal selection.\n",
      "\n",
      "  --selection-pos-max=<arg>\n",
      "    Set a upper limit for the number of positive literals a clause can have\n",
      "    to be eligible for literal selection.\n",
      "\n",
      "  --selection-neg-min=<arg>\n",
      "    Set a lower limit for the number of negative literals a clause must have\n",
      "    to be eligible for literal selection.\n",
      "\n",
      "  --selection-neg-max=<arg>\n",
      "    Set a upper limit for the number of negative literals a clause can have\n",
      "    to be eligible for literal selection.\n",
      "\n",
      "  --selection-all-min=<arg>\n",
      "    Set a lower limit for the number of literals a clause must have to be\n",
      "    eligible for literal selection.\n",
      "\n",
      "  --selection-all-max=<arg>\n",
      "    Set an upper limit for the number of literals a clause must have to be\n",
      "    eligible for literal selection.\n",
      "\n",
      "  --selection-weight-min=<arg>\n",
      "    Set the minimum weight a clause must have to be eligible for literal\n",
      "    selection.\n",
      "\n",
      "  --prefer-initial-clauses\n",
      "    Always process all initial clauses first.\n",
      "\n",
      "   -x <arg>\n",
      "  --expert-heuristic=<arg>\n",
      "    Select one of the clause selection heuristics. Currently at least\n",
      "    available: Auto, Weight, StandardWeight, RWeight, FIFO, LIFO, Uniq,\n",
      "    UseWatchlist. For a full list check HEURISTICS/che_proofcontrol.c. Auto\n",
      "    is recommended if you only want to find a proof. It is special in that it\n",
      "    will also set some additional options. To have optimal performance, you\n",
      "    also should specify -tAuto to select a good term ordering. LIFO is unfair\n",
      "    and will make the prover incomplete. Uniq is used internally and is not\n",
      "    very useful in most cases. You can define more heuristics using the\n",
      "    option -H (see below).\n",
      "\n",
      "  --filter-orphans-limit[=<arg>]\n",
      "    Orphans are unprocessed clauses where one of the parents has been removed\n",
      "    by back-simolification. They are redundant and usually removed lazily\n",
      "    (i.e. only when they are selected for processing). With this option you\n",
      "    can select a limit on back-simplified clauses  after which orphans will\n",
      "    be eagerly deleted. The option without the optional argument is\n",
      "    equivalent to --filter-orphans-limit=100.\n",
      "\n",
      "  --forward-contract-limit[=<arg>]\n",
      "    Set a limit on the number of processed clauses after which the\n",
      "    unprocessed clause set will be re-simplified and reweighted.  The option\n",
      "    without the optional argument is equivalent to\n",
      "    --forward-contract-limit=80000.\n",
      "\n",
      "  --delete-bad-limit[=<arg>]\n",
      "    Set the number of storage units after which bad clauses are deleted\n",
      "    without further consideration. This causes the prover to be potentially\n",
      "    incomplete, but will allow you to limit the maximum amount of memory used\n",
      "    fairly well. The prover will tell you if a proof attempt failed due to\n",
      "    the incompleteness introduced by this option. It is recommended to set\n",
      "    this limit significantly higher than --filter-limit or\n",
      "    --filter-copies-limit. If you select -xAuto and set a memory limit, the\n",
      "    prover will determine a good value automatically. The option without the\n",
      "    optional argument is equivalent to --delete-bad-limit=1500000.\n",
      "\n",
      "  --assume-completeness\n",
      "    There are various way (e.g. the next few options) to configure the prover\n",
      "    to be strongly incomplete in the general case. E will detect when such an\n",
      "    option is selected and return corresponding exit states (i.e. it will not\n",
      "    claim satisfiability just because it ran out of unprocessed clauses). If\n",
      "    you _know_ that for your class of problems the selected strategy is still\n",
      "    complete, use this option to tell the system that this is the case.\n",
      "\n",
      "  --assume-incompleteness\n",
      "    This option instructs the prover to assume incompleteness (typically\n",
      "    because the axiomatization already is incomplete because axioms have been\n",
      "    filtered before they are handed to the system.\n",
      "\n",
      "  --disable-eq-factoring\n",
      "    Disable equality factoring. This makes the prover incomplete for general\n",
      "    non-Horn problems, but helps for some specialized classes. It is not\n",
      "    necessary to disable equality factoring for Horn problems, as Horn\n",
      "    clauses are not factored anyways.\n",
      "\n",
      "  --disable-paramod-into-neg-units\n",
      "    Disable paramodulation into negative unit clause. This makes the prover\n",
      "    incomplete in the general case, but helps for some specialized classes.\n",
      "\n",
      "  --condense\n",
      "    Enable condensing for the given clause. Condensing replaces a clause by a\n",
      "    more general factor (if such a factor exists).\n",
      "\n",
      "  --condense-aggressive\n",
      "    Enable condensing for the given and newly generated clauses.\n",
      "\n",
      "  --disable-given-clause-fw-contraction\n",
      "    Disable simplification and subsumption of the newly selected given clause\n",
      "    (clauses are still simplified when they are generated). In general, this\n",
      "    breaks some basic assumptions of the DISCOUNT loop proof search\n",
      "    procedure. However, there are some problem classes in which  this\n",
      "    simplifications empirically never occurs. In such cases, we can save\n",
      "    significant overhead. The option _should_ work in all cases, but is not\n",
      "    expected to improve things in most cases.\n",
      "\n",
      "  --simul-paramod\n",
      "    Use simultaneous paramodulation to implement superposition. Default is to\n",
      "    use plain paramodulation.\n",
      "\n",
      "  --oriented-simul-paramod\n",
      "    Use simultaneous paramodulation for oriented from-literals. This is an\n",
      "    experimental feature.\n",
      "\n",
      "  --supersimul-paramod\n",
      "    Use supersimultaneous paramodulation to implement superposition. Default\n",
      "    is to use plain paramodulation.\n",
      "\n",
      "  --oriented-supersimul-paramod\n",
      "    Use supersimultaneous paramodulation for oriented from-literals. This is\n",
      "    an experimental feature.\n",
      "\n",
      "  --split-clauses[=<arg>]\n",
      "    Determine which clauses should be subject to splitting. The argument is\n",
      "    the binary 'OR' of values for the desired classes:\n",
      "         1:  Horn clauses\n",
      "         2:  Non-Horn clauses\n",
      "         4:  Negative clauses\n",
      "         8:  Positive clauses\n",
      "        16:  Clauses with both positive and negative literals\n",
      "    Each set bit adds that class to the set of clauses which will be split.\n",
      "    The option without the optional argument is equivalent to\n",
      "    --split-clauses=7.\n",
      "\n",
      "  --split-method=<arg>\n",
      "    Determine how to treat ground literals in splitting. The argument is\n",
      "    either '0' to denote no splitting of ground literals (they are all\n",
      "    assigned to the first split clause produced), '1' to denote that all\n",
      "    ground literals should form a single new clause, or '2', in which case\n",
      "    ground literals are treated as usual and are all split off into\n",
      "    individual clauses.\n",
      "\n",
      "  --split-aggressive\n",
      "    Apply splitting to new clauses (after simplification) and before\n",
      "    evaluation. By default, splitting (if activated) is only performed on\n",
      "    selected clauses. \n",
      "\n",
      "  --split-reuse-defs\n",
      "    If possible, reuse previous definitions for splitting.\n",
      "\n",
      "  --disequality-decomposition[=<arg>]\n",
      "    Enable the disequality decomposition inference. The optional argument is\n",
      "    the maximal literal number of clauses considered for the inference. The\n",
      "    option without the optional argument is equivalent to\n",
      "    --disequality-decomposition=1024.\n",
      "\n",
      "  --disequality-decomp-maxarity[=<arg>]\n",
      "    Limit disequality decomposition to function symbols of at most the given\n",
      "    arity. The option without the optional argument is equivalent to\n",
      "    --disequality-decomp-maxarity=1.\n",
      "\n",
      "   -t <arg>\n",
      "  --term-ordering=<arg>\n",
      "    Select an ordering type (currently Auto, LPO, LPO4, KBO or KBO6). -tAuto\n",
      "    is suggested, in particular with -xAuto. KBO and KBO6 are different\n",
      "    implementations of the same ordering, KBO6 is usually faster and has had\n",
      "    more testing. Similarly, LPO4 is a new, equivalent but superior\n",
      "    implementation of LPO.\n",
      "\n",
      "   -w <arg>\n",
      "  --order-weight-generation=<arg>\n",
      "    Select a method for the generation of weights for use with the term\n",
      "    ordering. Run 'eprover -w none' for a list of options.\n",
      "\n",
      "  --order-weights=<arg>\n",
      "    Describe a (partial) assignments of weights to function symbols for term\n",
      "    orderings (in particular, KBO). You can specify a list of weights of the\n",
      "    form 'f1:w1,f2:w2, ...'. Since a total weight assignment is needed, E\n",
      "    will _first_ apply any weight generation scheme specified (or the default\n",
      "    one), and then modify the weights as specified. Note that E performs only\n",
      "    very basic sanity checks, so you probably can specify weights that break\n",
      "    KBO constraints.\n",
      "\n",
      "   -G <arg>\n",
      "  --order-precedence-generation=<arg>\n",
      "    Select a method for the generation of a precedence for use with the term\n",
      "    ordering. Run 'eprover -G none' for a list of options.\n",
      "\n",
      "  --prec-pure-conj[=<arg>]\n",
      "    Set a weight for symbols that occur in conjectures only to determinewhere\n",
      "    to place it in the precedence. This value is used for a roughpre-order,\n",
      "    the normal schemes only sort within symbols with the sameoccurrence\n",
      "    modifier. The option without the optional argument is equivalent to\n",
      "    --prec-pure-conj=10.\n",
      "\n",
      "  --prec-conj-axiom[=<arg>]\n",
      "    Set a weight for symbols that occur in both conjectures and axiomsto\n",
      "    determine where to place it in the precedence. This value is used for a\n",
      "    rough pre-order, the normal schemes only sort within symbols with the\n",
      "    same occurrence modifier. The option without the optional argument is\n",
      "    equivalent to --prec-conj-axiom=5.\n",
      "\n",
      "  --prec-pure-axiom[=<arg>]\n",
      "    Set a weight for symbols that occur in axioms only to determine where to\n",
      "    place it in the precedence. This value is used for a rough pre-order, the\n",
      "    normal schemes only sort within symbols with the same occurrence\n",
      "    modifier. The option without the optional argument is equivalent to\n",
      "    --prec-pure-axiom=2.\n",
      "\n",
      "  --prec-skolem[=<arg>]\n",
      "    Set a weight for Skolem symbols to determine where to place it in the\n",
      "    precedence. This value is used for a rough pre-order, the normal schemes\n",
      "    only sort within symbols with the same occurrence modifier. The option\n",
      "    without the optional argument is equivalent to --prec-skolem=2.\n",
      "\n",
      "  --prec-defpred[=<arg>]\n",
      "    Set a weight for introduced predicate symbols (usually via definitional\n",
      "    CNF or clause splitting) to determine where to place it in the\n",
      "    precedence. This value is used for a rough pre-order, the normal schemes\n",
      "    only sort within symbols with the same occurrence modifier. The option\n",
      "    without the optional argument is equivalent to --prec-defpred=2.\n",
      "\n",
      "   -c <arg>\n",
      "  --order-constant-weight=<arg>\n",
      "    Set a special weight > 0 for constants in the term ordering. By default,\n",
      "    constants are treated like other function symbols.\n",
      "\n",
      "  --precedence[=<arg>]\n",
      "    Describe a (partial) precedence for the term ordering used for the proof\n",
      "    attempt. You can specify a comma-separated list of precedence chains,\n",
      "    where a precedence chain is a list of function symbols (which all have to\n",
      "    appear in the proof problem), connected by >, <, or =. If this option is\n",
      "    used in connection with --order-precedence-generation, the partial\n",
      "    ordering will be completed using the selected method, otherwise the\n",
      "    prover runs with a non-ground-total ordering. The option without the\n",
      "    optional argument is equivalent to --precedence=.\n",
      "\n",
      "  --lpo-recursion-limit[=<arg>]\n",
      "    Set a depth limit for LPO comparisons. Most comparisons do not need more\n",
      "    than 10 or 20 levels of recursion. By default, recursion depth is limited\n",
      "    to 1000 to avoid stack overflow problems. If the limit is reached, the\n",
      "    prover assumes that the terms are uncomparable. Smaller values make the\n",
      "    comparison attempts faster, but less exact. Larger values have the\n",
      "    opposite effect. Values up to 20000 should be save on most operating\n",
      "    systems. If you run into segmentation faults while using LPO or LPO4,\n",
      "    first try to set this limit to a reasonable value. If the problem\n",
      "    persists, send a bug report ;-) The option without the optional argument\n",
      "    is equivalent to --lpo-recursion-limit=100.\n",
      "\n",
      "  --restrict-literal-comparisons\n",
      "    Make all literals uncomparable in the term ordering (i.e. do not use the\n",
      "    term ordering to restrict paramodulation, equality resolution and\n",
      "    factoring to certain literals. This is necessary to make\n",
      "    Set-of-Support-strategies complete for the non-equational case (It still\n",
      "    is incomplete for the equational case, but pretty useless anyways).\n",
      "\n",
      "  --literal-comparison=<arg>\n",
      "    Modify how literal comparisons are done. 'None' is equivalent to the\n",
      "    previous option, 'Normal' uses the normal lifting of the term ordering,\n",
      "    'TFOEqMax' uses the equivalent of a transfinite ordering deciding on the\n",
      "    predicate symbol and making equational literals maximal (note that this\n",
      "    setting makes the prover incomplere), and 'TFOEqMin' modifies this by\n",
      "    making equational symbols minimal.\n",
      "\n",
      "  --sos-uses-input-types\n",
      "    If input is TPTP format, use TPTP conjectures for initializing the Set of\n",
      "    Support. If not in TPTP format, use E-LOP queries (clauses of the form\n",
      "    ?-l(X),...,m(Y)). Normally, all negative clauses are used. Please note\n",
      "    that most E heuristics do not use this information at all, it is\n",
      "    currently only useful for certain parameter settings (including the\n",
      "    SimulateSOS priority function).\n",
      "\n",
      "  --destructive-er\n",
      "    Allow destructive equality resolution inferences on pure-variable\n",
      "    literals of the form X!=Y, i.e. replace the original clause with the\n",
      "    result of an equality resolution inference on this literal.\n",
      "\n",
      "  --strong-destructive-er\n",
      "    Allow destructive equality resolution inferences on literals of the form\n",
      "    X!=t (where X does not occur in t), i.e. replace the original clause with\n",
      "    the result of an equality resolution inference on this literal. Unless I\n",
      "    am brain-dead, this maintains completeness, although the proof is rather\n",
      "    tricky.\n",
      "\n",
      "  --destructive-er-aggressive\n",
      "    Apply destructive equality resolution to all newly generated clauses, not\n",
      "    just to selected clauses. Implies --destructive-er.\n",
      "\n",
      "  --forward-context-sr\n",
      "    Apply contextual simplify-reflect with processed clauses to the given\n",
      "    clause.\n",
      "\n",
      "  --forward-context-sr-aggressive\n",
      "    Apply contextual simplify-reflect with processed clauses to new clauses.\n",
      "    Implies --forward-context-sr.\n",
      "\n",
      "  --backward-context-sr\n",
      "    Apply contextual simplify-reflect with the given clause to processed\n",
      "    clauses.\n",
      "\n",
      "   -g\n",
      "  --prefer-general-demodulators\n",
      "    Prefer general demodulators. By default, E prefers specialized\n",
      "    demodulators. This affects in which order the rewrite  index is\n",
      "    traversed.\n",
      "\n",
      "   -F <arg>\n",
      "  --forward-demod-level=<arg>\n",
      "    Set the desired level for rewriting of unprocessed clauses. A value of 0\n",
      "    means no rewriting, 1 indicates to use rules (orientable equations) only,\n",
      "    2 indicates full rewriting with rules and instances of unorientable\n",
      "    equations. Default behavior is 2.\n",
      "\n",
      "  --demod-under-lambda=<arg>\n",
      "    Demodulate *closed* subterms under lambdas.\n",
      "\n",
      "  --strong-rw-inst\n",
      "    Instantiate unbound variables in matching potential demodulators with a\n",
      "    small constant terms.\n",
      "\n",
      "   -u\n",
      "  --strong-forward-subsumption\n",
      "    Try multiple positions and unit-equations to try to equationally subsume\n",
      "    a single new clause. Default is to search for a single position.\n",
      "\n",
      "  --satcheck-proc-interval[=<arg>]\n",
      "    Enable periodic SAT checking at the given interval of main loop\n",
      "    non-trivial processed clauses. The option without the optional argument\n",
      "    is equivalent to --satcheck-proc-interval=5000.\n",
      "\n",
      "  --satcheck-gen-interval[=<arg>]\n",
      "    Enable periodic SAT checking whenever the total proof state size\n",
      "    increases by the given limit. The option without the optional argument is\n",
      "    equivalent to --satcheck-gen-interval=10000.\n",
      "\n",
      "  --satcheck-ttinsert-interval[=<arg>]\n",
      "    Enable periodic SAT checking whenever the number of term tops insertions\n",
      "    matches the given limit (which grows exponentially). The option without\n",
      "    the optional argument is equivalent to\n",
      "    --satcheck-ttinsert-interval=5000000.\n",
      "\n",
      "  --satcheck[=<arg>]\n",
      "    Set the grounding strategy for periodic SAT checking. Note that to enable\n",
      "    SAT checking, it is also necessary to set the interval with one of the\n",
      "    previous two options. The option without the optional argument is\n",
      "    equivalent to --satcheck=FirstConst.\n",
      "\n",
      "  --satcheck-decision-limit[=<arg>]\n",
      "    Set the number of decisions allowed for each run of the SAT solver. If\n",
      "    the option is not given, the built-in value is 10000. Use -1 to allow\n",
      "    unlimited decision. The option without the optional argument is\n",
      "    equivalent to --satcheck-decision-limit=100.\n",
      "\n",
      "  --satcheck-normalize-const\n",
      "    Use the current normal form (as recorded in the termbank rewrite cache)\n",
      "    of the selected constant as the term for the grounding substitution.\n",
      "\n",
      "  --satcheck-normalize-unproc\n",
      "    Enable re-simplification (heuristic re-revaluation) of unprocessed\n",
      "    clauses before grounding for SAT checking.\n",
      "\n",
      "  --watchlist[=<arg>]\n",
      "    Give the name for a file containing clauses to be watched for during the\n",
      "    saturation process. If a clause is generated that subsumes a watchlist\n",
      "    clause, the subsumed clause is removed from the watchlist. The prover\n",
      "    will terminate when the watchlist is empty. If you want to use the\n",
      "    watchlist for guiding the proof, put the empty clause onto the list and\n",
      "    use the built-in clause selection heuristic 'UseWatchlist' (or build a\n",
      "    heuristic yourself using the priority functions 'PreferWatchlist' and\n",
      "    'DeferWatchlist'). Use the argument 'Use inline watchlist type' (or no\n",
      "    argument) and the special clause type 'watchlist' if you want to put\n",
      "    watchlist clauses into the normal input stream. This is only supported\n",
      "    for TPTP input formats. The option without the optional argument is\n",
      "    equivalent to --watchlist='Use inline watchlist type'.\n",
      "\n",
      "  --static-watchlist[=<arg>]\n",
      "    This is identical to the previous option, but subsumed clauses willnot be\n",
      "    removed from the watchlist (and hence the prover will not terminate if\n",
      "    all watchlist clauses have been subsumed. This may be more useful for\n",
      "    heuristic guidance. The option without the optional argument is\n",
      "    equivalent to --static-watchlist='Use inline watchlist type'.\n",
      "\n",
      "  --no-watchlist-simplification\n",
      "    By default, the watchlist is brought into normal form with respect to the\n",
      "    current processed clause set and certain simplifications. This option\n",
      "    disables simplification for the watchlist.\n",
      "\n",
      "  --fw-subsumption-aggressive\n",
      "    Perform forward subsumption on newly generated clauses before they are\n",
      "    evaluated. This is particularly useful if heuristic evaluation is very\n",
      "    expensive, e.g. via externally connected neural networks.\n",
      "\n",
      "  --conventional-subsumption\n",
      "    Equivalent to --subsumption-indexing=None.\n",
      "\n",
      "  --subsumption-indexing=<arg>\n",
      "    Determine choice of indexing for (most) subsumption operations. Choices\n",
      "    are 'None' for naive subsumption, 'Direct' for direct mapped FV-Indexing,\n",
      "    'Perm' for permuted FV-Indexing and 'PermOpt' for permuted FV-Indexing\n",
      "    with deletion of (suspected) non-informative features. Default behaviour\n",
      "    is 'Perm'.\n",
      "\n",
      "  --fvindex-featuretypes=<arg>\n",
      "    Select the feature types used for indexing. Choices are \"None\" to disable\n",
      "    FV-indexing, \"AC\" for AC compatible features (the default) (literal\n",
      "    number and symbol counts), \"SS\" for set subsumption compatible features\n",
      "    (symbol depth), and \"All\" for all features.Unless you want to measure the\n",
      "    effects of the different features, I suggest you stick with the default.\n",
      "\n",
      "  --fvindex-maxfeatures[=<arg>]\n",
      "    Set the maximum initial number of symbols for feature computation.\n",
      "    Depending on the feature selection, a value of X here will convert into\n",
      "    2X+2 features (for set subsumption features), 2X+4 features (for\n",
      "    AC-compatible features) or 4X+6 features (if all features are used, the\n",
      "    default). Note that the actually used set of features may be smaller than\n",
      "    this if the signature does not contain enough symbols.For the Perm and\n",
      "    PermOpt version, this is _also_ used to set the maximum depth of the\n",
      "    feature vector index. Yes, I should probably make this into two separate\n",
      "    options. If you select a small value here, you should probably not use\n",
      "    \"Direct\" for the --subsumption-indexing option. The option without the\n",
      "    optional argument is equivalent to --fvindex-maxfeatures=200.\n",
      "\n",
      "  --fvindex-slack[=<arg>]\n",
      "    Set the number of slots reserved in the index for function symbols that\n",
      "    may be introduced into the signature later, e.g. by splitting. If no new\n",
      "    symbols are introduced, this just wastes time and memory. If PermOpt is\n",
      "    chosen, the slackness slots will be deleted from the index anyways, but\n",
      "    will still waste (a little) time in computing feature vectors. The option\n",
      "    without the optional argument is equivalent to --fvindex-slack=0.\n",
      "\n",
      "  --rw-bw-index[=<arg>]\n",
      "    Select fingerprint function for backwards rewrite index. \"NoIndex\" will\n",
      "    disable paramodulation indexing. For a list of the other values run\n",
      "    'eprover --pm-index=none'. FPX functions will use a fingerprint of X\n",
      "    positions, the letters disambiguate between different fingerprints with\n",
      "    the same sample size. The option without the optional argument is\n",
      "    equivalent to --rw-bw-index=FP7.\n",
      "\n",
      "  --pm-from-index[=<arg>]\n",
      "    Select fingerprint function for the index for paramodulation from indexed\n",
      "    clauses. \"NoIndex\" will disable paramodulation indexing. For a list of\n",
      "    the other values run 'eprover --pm-index=none'. FPX functionswill use a\n",
      "    fingerprint of X positions, the letters disambiguate between different\n",
      "    fingerprints with the same sample size. The option without the optional\n",
      "    argument is equivalent to --pm-from-index=FP7.\n",
      "\n",
      "  --pm-into-index[=<arg>]\n",
      "    Select fingerprint function for the index for paramodulation into the\n",
      "    indexed clauses. \"NoIndex\" will disable paramodulation indexing. For a\n",
      "    list of the other values run 'eprover --pm-index=none'. FPX functionswill\n",
      "    use a fingerprint of X positions, the letters disambiguate between\n",
      "    different fingerprints with the same sample size. The option without the\n",
      "    optional argument is equivalent to --pm-into-index=FP7.\n",
      "\n",
      "  --fp-index[=<arg>]\n",
      "    Select fingerprint function for all fingerprint indices. See above. The\n",
      "    option without the optional argument is equivalent to --fp-index=FP7.\n",
      "\n",
      "  --fp-no-size-constr\n",
      "    Disable usage of size constraints for matching with fingerprint indexing.\n",
      "\n",
      "  --pdt-no-size-constr\n",
      "    Disable usage of size constraints for matching with perfect\n",
      "    discrimination trees indexing.\n",
      "\n",
      "  --pdt-no-age-constr\n",
      "    Disable usage of age constraints for matching with perfect discrimination\n",
      "    trees indexing.\n",
      "\n",
      "  --detsort-rw\n",
      "    Sort set of clauses eliminated by backward rewriting using a total\n",
      "    syntactic ordering.\n",
      "\n",
      "  --detsort-new\n",
      "    Sort set of newly generated and backward simplified clauses using a total\n",
      "    syntactic ordering.\n",
      "\n",
      "   -D <arg>\n",
      "  --define-weight-function=<arg>\n",
      "    Define  a weight function (see manual for details). Later definitions\n",
      "    override previous definitions.\n",
      "\n",
      "   -H <arg>\n",
      "  --define-heuristic=<arg>\n",
      "    Define a clause selection heuristic (see manual for details). Later\n",
      "    definitions override previous definitions.\n",
      "\n",
      "  --free-numbers\n",
      "    Treat numbers (strings of decimal digits) as normal free function symbols\n",
      "    in the input. By default, number now are supposed to denote domain\n",
      "    constants and to be implicitly different from each other.\n",
      "\n",
      "  --free-objects\n",
      "    Treat object identifiers (strings in double quotes) as normal free\n",
      "    function symbols in the input. By default, object identifiers now\n",
      "    represent domain objects and are implicitly different from each other\n",
      "    (and from numbers, unless those are declared to be free).\n",
      "\n",
      "  --definitional-cnf[=<arg>]\n",
      "    Tune the clausification algorithm to introduces definitions for\n",
      "    subformulae to avoid exponential blow-up. The optional argument is a\n",
      "    fudge factor that determines when definitions are introduced. 0 disables\n",
      "    definitions completely. The default works well. The option without the\n",
      "    optional argument is equivalent to --definitional-cnf=24.\n",
      "\n",
      "  --fool-unroll=<arg>\n",
      "    Enable or disable FOOL unrolling. Useful for some SH problems.\n",
      "\n",
      "  --miniscope-limit[=<arg>]\n",
      "    Set the limit of sub-formula-size to miniscope. The build-indefault is\n",
      "    256. Only applies to the new (default) clausification algorithm The\n",
      "    option without the optional argument is equivalent to\n",
      "    --miniscope-limit=2147483648.\n",
      "\n",
      "  --print-types\n",
      "    Print the type of every term. Useful for debugging purposes.\n",
      "\n",
      "  --app-encode\n",
      "    Encodes terms in the proof state using applicative encoding, prints\n",
      "    encoded input problem and exits.\n",
      "\n",
      "  --arg-cong=<arg>\n",
      "    Turns on ArgCong inference rule. Excepts an argument \"all\" or \"max\" that\n",
      "    applies the rule to all or only literals that are eligible for\n",
      "    resolution.\n",
      "\n",
      "  --neg-ext=<arg>\n",
      "    Turns on NegExt inference rule. Excepts an argument \"all\" or \"max\" that\n",
      "    applies the rule to all or only literals that are eligible for\n",
      "    resolution.\n",
      "\n",
      "  --pos-ext=<arg>\n",
      "    Turns on PosExt inference rule. Excepts an argument \"all\" or \"max\" that\n",
      "    applies the rule to all or only literals that are eligible for\n",
      "    resolution.\n",
      "\n",
      "  --ext-sup-max-depth=<arg>\n",
      "    Sets the maximal proof depth of the clause which will be considered for \n",
      "    Ext-family of inferences. Negative value disables the rule.\n",
      "\n",
      "  --inverse-recognition\n",
      "    Enables the recognition of injective function symbols. If such a symbol\n",
      "    is recognized, existence of the inverse function is asserted by adding a\n",
      "    corresponding axiom.\n",
      "\n",
      "  --replace-inj-defs\n",
      "    After CNF and before saturation, replaces all clauses that are\n",
      "    definitions  of injectivity by axiomatization of inverse function.\n",
      "\n",
      "  --lift-lambdas=<arg>\n",
      "    Should the lambdas be replaced by named fuctions?\n",
      "\n",
      "  --eta-normalize=<arg>\n",
      "    Which form of eta normalization to perform?\n",
      "\n",
      "  --ho-order-kind=<arg>\n",
      "    Do we use simple LFHO order or a more advanced Boolean free lambda-KBO?\n",
      "\n",
      "  --cnf-lambda-to-forall=<arg>\n",
      "    Do we turn equations of the form ^X.s (!)= ^X.t into (?)!X. s (!)= t ?\n",
      "\n",
      "  --kbo-lam-weight=<arg>\n",
      "    Weight of lambda symbol in KBO.\n",
      "\n",
      "  --kbo-db-weight=<arg>\n",
      "    Weight of DB var in KBO.\n",
      "\n",
      "  --eliminate-leibniz-eq=<arg>\n",
      "    Maximal proof depth of the clause on which Leibniz equality elimination\n",
      "    should be applied; -1 disaables Leibniz equality elimination altogether\n",
      "\n",
      "  --unroll-formulas-only=<arg>\n",
      "    Set to true if you want only formulas to be recognized as definitions\n",
      "    during CNF. Default is true.\n",
      "\n",
      "  --prim-enum-mode=<arg>\n",
      "    Choose the mode of primitive enumeration \n",
      "\n",
      "  --prim-enum-max-depth=<arg>\n",
      "    Maximal proof depth of a clause on which primitive enumeration is\n",
      "    applied. -1 disables primitive enumeration\n",
      "\n",
      "  --inst-choice-max-depth=<arg>\n",
      "    Maximal proof depth of a clause which is going to be scanned for\n",
      "    occurrences of defined choice symbol -1 disables scanning for choice\n",
      "    symbols\n",
      "\n",
      "  --local-rw=<arg>\n",
      "    Enable/disable local rewriting: if the clause is of the form s != t |  C,\n",
      "    where s > t, rewrite all occurrences of s with t in C.\n",
      "\n",
      "  --prune-args=<arg>\n",
      "    Enable/disable pruning arguments of applied variables.\n",
      "\n",
      "  --func-proj-limit=<arg>\n",
      "    Maximal number of functional projections\n",
      "\n",
      "  --imit-limit=<arg>\n",
      "    Maximal number of imitations\n",
      "\n",
      "  --ident-limit=<arg>\n",
      "    Maximal number of identifications\n",
      "\n",
      "  --elim-limit=<arg>\n",
      "    Maximal number of eliminations\n",
      "\n",
      "  --unif-mode=<arg>\n",
      "    Set the mode of unification: either single or multi.\n",
      "\n",
      "  --pattern-oracle=<arg>\n",
      "    Turn the pattern oracle on or off.\n",
      "\n",
      "  --fixpoint-oracle=<arg>\n",
      "    Turn the pattern oracle on or off.\n",
      "\n",
      "  --max-unifiers=<arg>\n",
      "    Maximal number of imitations\n",
      "\n",
      "  --max-unif-steps=<arg>\n",
      "    Maximal number of variable bindings that can be done in one single call\n",
      "    to copmuting the next unifier.\n",
      "\n",
      "  --classification-timeout-portion=<arg>\n",
      "    Which percentage (from 1 to 99) of the total CPU time will be devoted to\n",
      "    problem classification?\n",
      "\n",
      "  --preinstantiate-induction=<arg>\n",
      "    Abstract unit clauses coming from conjecture and use the abstractions to\n",
      "    instantiate clauses that look like the ones coming from induction axioms.\n",
      "\n",
      "  --bce=<arg>\n",
      "    Turn blocked clause elimination on or off\n",
      "\n",
      "  --bce-max-occs=<arg>\n",
      "    Stop tracking symbol after it occurs in <arg> clauses Set <arg> to -1\n",
      "    disable this limit\n",
      "\n",
      "  --pred-elim=<arg>\n",
      "    Turn predicate elimination on or off\n",
      "\n",
      "  --pred-elim-max-occs=<arg>\n",
      "    Stop tracking symbol after it occurs in <arg> clauses Set <arg> to -1\n",
      "    disable this limit\n",
      "\n",
      "  --pred-elim-tolerance=<arg>\n",
      "    Tolerance for predicate elimination measures.\n",
      "\n",
      "  --pred-elim-recognize-gates=<arg>\n",
      "    Turn gate recognition for predicate elimination on or off\n",
      "\n",
      "  --pred-elim-force-mu-decrease=<arg>\n",
      "    Require that the square number of distinct free variables decreases when\n",
      "    doing predicate elimination. Helps avoid creating huge clauses.\n",
      "\n",
      "  --pred-elim-ignore-conj-syms=<arg>\n",
      "    Disable eliminating symbols that occur in the conjecture.\n",
      "\n",
      "\n",
      "\n",
      "Copyright 1998-2024 by Stephan Schulz, schulz@eprover.org,\n",
      "and the E contributors (see DOC/CONTRIBUTORS).\n",
      "\n",
      "This program is a part of the distribution of the equational theorem\n",
      "prover E. You can find the latest version of the E distribution\n",
      "as well as additional information at\n",
      "http://www.eprover.org\n",
      "\n",
      "This program is free software; you can redistribute it and/or modify\n",
      "it under the terms of the GNU General Public License as published by\n",
      "the Free Software Foundation; either version 2 of the License, or\n",
      "(at your option) any later version.\n",
      "\n",
      "This program is distributed in the hope that it will be useful,\n",
      "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
      "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
      "GNU General Public License for more details.\n",
      "\n",
      "You should have received a copy of the GNU General Public License\n",
      "along with this program (it should be contained in the top level\n",
      "directory of the distribution in the file COPYING); if not, write to\n",
      "the Free Software Foundation, Inc., 59 Temple Place, Suite 330,\n",
      "Boston, MA  02111-1307 USA\n",
      "\n",
      "We welcome bug reports and even reasonable questions. If the prover\n",
      "behaves in an unexpected way, please include the following\n",
      "information:\n",
      "\n",
      "- What did you observe?\n",
      "- What did you expect?\n",
      "- The output of `eprover --version`\n",
      "- The full commandline that lead to the unexpected behaviour\n",
      "- The input file(s) that lead to the unexpected behaviour\n",
      "\n",
      "Most bug reports should be send to <schulz@eprover.org>. Bug reports with \n",
      "respect to the HO-version should be send to or at least copied to \n",
      "<jasmin.blanchette@gmail.com>. Please remember that this is an unpaid\n",
      "volunteer service.\n",
      "\n",
      "The original copyright holder can be contacted via email or as\n",
      "\n",
      "Stephan Schulz\n",
      "DHBW Stuttgart\n",
      "Fakultaet Technik\n",
      "Informatik\n",
      "Lerchenstrasse 1\n",
      "70174 Stuttgart\n",
      "Germany\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['./eprover-ho', '--help'], returncode=0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.run([\"./eprover-ho\", \"--help\"], check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f41943a",
   "metadata": {},
   "source": [
    "# egraph\n",
    "\n",
    "Accept prolog and smtlib syntax?\n",
    "like the good old days\n",
    "\n",
    "\n",
    "\n",
    "## Mixins vs subclassing\n",
    "\n",
    "GaussMixin()\n",
    "t = GaussTheory()\n",
    "EGraph(GaussTheory(), SympyTheory(), )\n",
    "\n",
    "self.theories = []\n",
    "\n",
    "def find(self, x):\n",
    "    for t in theories:\n",
    "        t.find(x)\n",
    "\n",
    "def union():\n",
    "    todo = []\n",
    "    for t in theories:\n",
    "        todo.extend(t.union())\n",
    "\n",
    "\n",
    "## Lambda\n",
    "alpha_norm before using add term.\n",
    "\n",
    "Recursively carry params down through?\n",
    "Eta long form.\n",
    "\n",
    "A normal form?\n",
    "\n",
    "Do slotted. Add some knd of permutation egraph?\n",
    "\n",
    "\n",
    "eta_maximal form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0373cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eta_long(ctx, t : smt.ExprRef):\n",
    "    if isinstance(t, smt.QuantifierRef):\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda89a9c",
   "metadata": {},
   "source": [
    "## coegraph\n",
    "\n",
    "Maybe use cvc5 codatypes\n",
    "Datatypes already achieve the cocongruence propagation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2414d9fa",
   "metadata": {},
   "source": [
    "## aptroot\n",
    "https://mastodon.gamedev.place/@harold/114586279569895001\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9de621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.all import *\n",
    "Fruit = kd.Enum(\"Fruit\", [\"A\", \"B\"])\n",
    "import kdrag.theories.seq as seq_\n",
    "\n",
    "FString = seq_.SeqSort(Fruit)\n",
    "\n",
    "seq_.SeqVal([Fruit.A]*3) == seq_.SeqVal([Fruit.A, Fruit.B, Fruit.A])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146db2a8",
   "metadata": {},
   "source": [
    "## ILP extract\n",
    "cvxpy translation?\n",
    "\n",
    "\n",
    "import extraction gym?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316d1d19",
   "metadata": {},
   "source": [
    "## Gauss\n",
    "\n",
    "Sympy, solve_for, passaegmath msolve\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16b9a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussEGraph():\n",
    "    def __init__(self):\n",
    "        self.eqs = smt.SimpleSolver() # Or sympy grobner basis.\n",
    "    def union(self, x, y):\n",
    "        if isinstance(smt.ArithRef):\n",
    "            self.eqs\n",
    "\n",
    "class GrobnerEGraph(EGraph):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8010392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sympy_simplify(self):\n",
    "    for t in self.terms:\n",
    "        if t.sort() == smt.RealSort():\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63af2d2c",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76265cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from kdrag.all import *\n",
    "from kdrag.solvers.egraph import EGraph\n",
    "from collections import defaultdict\n",
    "def extract(self, t0 : smt.ExprRef, cost_fun = (lambda _: 1)):\n",
    "    inf = float(\"inf\")\n",
    "    best_cost = defaultdict(lambda: inf)\n",
    "    best = {}\n",
    "    while True:\n",
    "        done = True\n",
    "        # Terms are taking the place of enodes.\n",
    "        for t in self.terms.values():\n",
    "            eid = self.find(t)\n",
    "            cost = cost_fun(t) + sum([best_cost[self.find(c)] for c in t.children()]) # cost_fun(t.decl()) ?\n",
    "            if cost < best_cost[eid]:\n",
    "                best_cost[eid] = cost\n",
    "                best[eid] = t\n",
    "                done = False\n",
    "        if done:\n",
    "            break\n",
    "    #@functools.cache\n",
    "    def build_best(t):\n",
    "        t1 = best[self.find(t)]\n",
    "        return t1.decl()(*[build_best(c) for c in t1.children()])\n",
    "    return build_best(t0)\n",
    "\n",
    "E = EGraph()\n",
    "x,y,z = smt.Ints('x y z')\n",
    "E.add_term(x + y)\n",
    "E.rebuild()\n",
    "assert extract(E, x + y).eq(x + y)\n",
    "E.union(x + y, y)\n",
    "E.rebuild()\n",
    "assert extract(E, x + y).eq(y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63464a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f4a948c",
   "metadata": {},
   "source": [
    "## Proof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "209fb6b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "z3.z3.BoolRef"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = smt.Solver()\n",
    "s.set(unsat_core=True)\n",
    "a,b,c,d, e = smt.Ints('a b c d e')\n",
    "id_map = {}\n",
    "def tassert(a):\n",
    "    tid = a.get_id()\n",
    "    id_map[tid] = a\n",
    "    #s.assert_and_track(a, smt.Bool(str(a)))\n",
    "    s.assert_and_track(a, smt.Bool(str(tid)))\n",
    "def core():\n",
    "    core = s.unsat_core()\n",
    "    return [id_map[int(str(c))] for c in core]\n",
    "\n",
    "\n",
    "tassert(a == b)\n",
    "tassert(b == c)\n",
    "tassert(e == d)\n",
    "#s.add(a == b)\n",
    "#s.add(b == c)\n",
    "#s.assert_and_track(a == b)\n",
    "#s.assert_and_track(b == c, b == c)\n",
    "s.add(a != c)\n",
    "s.check()\n",
    "#s.unsat_core()\n",
    "type(core()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3b7b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EgraphProof(EGraph):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reasons = {}\n",
    "        self.solver.set(\"unsat_core\", True)\n",
    "    def union(self, e1, e2, reason=None):\n",
    "        super().union(e1, e2)\n",
    "        if reason is not None:\n",
    "            p = smt.FreshConst(smt.BoolSort())\n",
    "            self.reasons[p.get_id()] = (e1,e2,reason)\n",
    "            self.solver.assert_and_track(e1 == e2, p) \n",
    "    def add(self, expr, reason=None): # Use this indriectio nin Egrpha, so we can use assert and track\n",
    "        tid = expr.get_id()\n",
    "        self.terms[tid] = expr\n",
    "        p = smt.FreshConst(smt.BoolSort())\n",
    "        self.reasons[p.get_id()] = reason\n",
    "        self.solver.assert_and_track(expr, p)\n",
    "    def core(self):\n",
    "        core = self.solver.unsat_core()\n",
    "        return [self.terms[int(str(c))] for c in core]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1be3b65",
   "metadata": {},
   "source": [
    "Return instantiations of rules that make this possible\n",
    "(vs, rule, lhs = rhs)\n",
    "\n",
    "\n",
    "return ground rewrite system that'll do it? But then each rule needs to be itself dignified. bleh.\n",
    "\n",
    "I could also use the trick from the third post of using z3 ematcher and grab the instans\n",
    "\n",
    "Also it'd be neat to extract those into a reified proof object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f856ca67",
   "metadata": {},
   "source": [
    "\n",
    "## Context\n",
    "Egraph does support hypothetical equalities?\n",
    "But I won't ematch unless I'm in that hypothetical situation\n",
    "\n",
    "ctxs = []\n",
    "ctx rebuilding - which ctx subsume, which \n",
    "Implies(ctx1, ctx2)\n",
    "Implies(ctx2, ctx1)  ---> \n",
    "\n",
    "contextual rewrite rules.\n",
    "\n",
    "Brute force contextual egraph\n",
    "\n",
    "Ok so i can build it.\n",
    "But then what is it for?\n",
    "Well, if then else is a good example.\n",
    "\n",
    "add_term(self, ctx, t):\n",
    "    if smt.is_ite(t):\n",
    "        ctx.append(t.arg(0)), t.arg(1)\n",
    "        ctx.append(smt.Not(t.arg(1))), t.arg(0)\n",
    "\n",
    "\n",
    "\n",
    "There's a lot of pruning possible in these queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29d847e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsat\n",
      "sat\n"
     ]
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "\n",
    "s = smt.Solver()\n",
    "with s:\n",
    "    s.add(False)\n",
    "    print(s.check())\n",
    "print(s.check())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a03701",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def rebuild(self):\n",
    "        super().rebuild()\n",
    "        ctxs = self.roots[smt.BoolSort()] & self.ctxs\n",
    "        for ctx1 in ctxs:\n",
    "            for ctx2 in ctxs:\n",
    "                if ctx1 != ctx2 and self.subsumes(ctx1, ctx2):\n",
    "                    self.solver.add(smt.Not(smt.Implies(ctx1, ctx2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db50284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.all import *\n",
    "from kdrag.solvers.egraph import EGraph\n",
    "def ctx_order(ctxs):\n",
    "    s = smt.Solver()\n",
    "    eq = []\n",
    "    le = []\n",
    "    for ctx1 in ctxs:\n",
    "        for ctx2 in ctxs:\n",
    "            s.push()\n",
    "            s.add(smt.Not(ctx1 == ctx2))\n",
    "            res = s.check()\n",
    "            s.pop()\n",
    "            if res == smt.unsat:\n",
    "                eq.append((ctx1,ctx2))\n",
    "            s.push()\n",
    "            s.add(smt.Not(smt.Implies(ctx1, ctx2)))\n",
    "            res = s.check()\n",
    "            s.pop()\n",
    "            if res == smt.unsat:\n",
    "                le.append((ctx2,ctx1))\n",
    "\n",
    "def subsumes(ctx1, ctx2):\n",
    "    s = smt.Solver()\n",
    "    s.add(smt.Not(smt.Implies(ctx1, ctx2)))\n",
    "    return s.check() == smt.unsat\n",
    "def iff(ctx1, ctx2):\n",
    "    s = smt.Solver()\n",
    "    s.add(smt.Not(ctx1 == ctx2))\n",
    "    return s.check() == smt.unsat            \n",
    "\n",
    "\n",
    "x,y,z = smt.Ints('x y z')\n",
    "\n",
    "ctx1 = smt.And(x == y, y == z)\n",
    "ctx2 = x == z\n",
    "assert subsumes(ctx1, ctx2)\n",
    "assert not subsumes(ctx2, ctx1)\n",
    "iff(ctx1, ctx1)\n",
    "\n",
    "class CtxEGraph(EGraph):\n",
    "    ctxs : set[int]\n",
    "    subsume : dict[int, set[int]] # \"path\" transitive closure\n",
    "\n",
    "    # there's two versions. One where you have pattern vars in ctx or not. or if contexrt is pattern.\n",
    "    # suearch over all subsumed contexts.\n",
    "    # def ematch_ctx(self, vs, pctx, lhs):\n",
    "    def ematch_ctx(self, vs, lhs):\n",
    "        res = []\n",
    "        for ctx in self.ctxs:\n",
    "            #self.substitute(ctx, vs)\n",
    "            with self.solver: # takes the push?\n",
    "                self.solver.add(self.terms[ctx])\n",
    "                res.extend((ctx, match_) for match_ in self.ematch(vs, lhs))\n",
    "        return res\n",
    "    #def ctx_sub():\n",
    "    def rebuild(self):\n",
    "        super().rebuild()\n",
    "        oldctxs = self.ctxs\n",
    "        for ctx1 in self.ctxs:\n",
    "            for ctx2 in self.ctxs:\n",
    "                if ctx2 in self.subsume[ctx1]:\n",
    "                    continue\n",
    "                else:\n",
    "                    self.solver.push()\n",
    "                    self.solver.add(smt.Not(smt.Implies(ctx1, ctx2)))\n",
    "                    self.solver.pop()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0d78c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ceea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_term_quant(term):\n",
    "    t = alpha_norm(term)\n",
    "    todo = [([], t)]\n",
    "    while todo:\n",
    "        ctx, t = todo.pop()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d549a6a3",
   "metadata": {},
   "source": [
    "# datalog\n",
    "z3 has a datalog, but whatev. Take snakelog approach https://github.com/philzook58/snakelog\n",
    "\n",
    "Also homommorphism finder. A la CSP / sqlite blog post\n",
    "\n",
    "Pretty print into ASP?\n",
    "\n",
    "spacer?\n",
    "\n",
    "\n",
    "sqlite dump of binary\n",
    "sqlite dump of clang ast or treesitter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09f68cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    INSERT OR IGNORE INTO path SELECT DISTINCT edge0.x0 AS x0, edge0.x1 AS x1\n",
      "    FROM edge AS edge0\n",
      "    \n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    INSERT OR IGNORE INTO edge SELECT DISTINCT 1 AS x0, 2 AS x1\\n    \\n    \\n    '"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "x,y,z = smt.Ints(\"x y z\")\n",
    "edge = smt.Function(\"edge\", smt.IntSort(), smt.IntSort(), smt.BoolSort())\n",
    "path = smt.Function(\"path\", smt.IntSort(), smt.IntSort(), smt.BoolSort())\n",
    "edgepath = rw.rule_of_expr(kd.QForAll([x,y], edge(x,y), path(x,y)))\n",
    "trans = rw.rule_of_expr(kd.QForAll([x,y,z], edge(x,y), path(y,z), path(x,z)))\n",
    "\n",
    "\n",
    "def compile_body(vs : list[smt.ExprRef], body : smt.BoolRef) -> str:\n",
    "    todo = [body]\n",
    "    env = {}\n",
    "    froms = []\n",
    "    wheres = []\n",
    "    counter = 0\n",
    "    while todo:\n",
    "        rel = todo.pop()\n",
    "        if smt.is_eq(rel):\n",
    "            raise ValueError(\"Equality not supported\")\n",
    "        elif smt.is_not(rel):\n",
    "            raise ValueError(\"Negation not supported\")\n",
    "        elif smt.is_or(rel):\n",
    "            raise ValueError(\"Disjunction not supported\")\n",
    "        elif smt.is_and(rel):\n",
    "            todo.extend(rel.children())\n",
    "        elif smt.is_true(rel):\n",
    "            continue\n",
    "        elif smt.is_app(rel):\n",
    "            name = rel.decl().name()\n",
    "            args = rel.children()\n",
    "            row_name = name + str(counter)\n",
    "            counter += 1 \n",
    "            froms.append(f\"{name} AS {row_name}\")\n",
    "            for n, arg in enumerate(args):\n",
    "                if arg in vs:\n",
    "                    if arg in env:\n",
    "                        wheres.append(f\"{env[arg]} = {row_name}.x{n}\")\n",
    "                    else:\n",
    "                        env[arg] = f\"{row_name}.x{n}\"\n",
    "                else:\n",
    "                    wheres.append(f\"{row_name}.x{n} = {str(arg)}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported expression: {rel}\")\n",
    "    return env, froms, wheres\n",
    "\n",
    "def compile_rule(rule : kd.rewrite.Rule) -> str:\n",
    "    env, froms, wheres = compile_body(rule.vs, rule.hyp)\n",
    "    name = rule.conc.decl().name()\n",
    "    selects = []\n",
    "    for n,arg in  enumerate(rule.conc.children()):\n",
    "        if arg in rule.vs:\n",
    "            if arg in env:\n",
    "                selects.append(f\"{env[arg]} AS x{n}\") # maybe select as keyword\n",
    "            else:\n",
    "                raise ValueError(f\"Variable {arg} not found in body\")\n",
    "        else:\n",
    "            selects.append(f\"{arg} AS x{n}\")\n",
    "    froms = \", \".join(froms)\n",
    "    wheres = \" AND \".join(wheres)\n",
    "    selects = \", \".join(selects)\n",
    "    return f\"\"\"\n",
    "    INSERT OR IGNORE INTO {name} SELECT DISTINCT {selects}\n",
    "    {\"FROM \" + froms if froms else \"\"}\n",
    "    {\"WHERE \" + wheres if wheres else \"\"}\n",
    "    \"\"\"\n",
    "\n",
    "print(compile_rule(edgepath))\n",
    "compile_rule(kd.rewrite.rule_of_expr(edge(1,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbe97cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (2, 3), (1, 3)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "class Datalog():\n",
    "    def __init__(self):\n",
    "        self.db = sqlite3.connect(\":memory:\")\n",
    "    \n",
    "    def declare_sig(self, sig : list[smt.FuncDeclRef]):\n",
    "        for f in sig:\n",
    "            primkey = \"(\" + \", \".join([f\"x{i}\" for i in range(f.arity())]) + \")\"\n",
    "            self.db.execute(f\"\"\"CREATE TABLE IF NOT EXISTS {f.name()} \n",
    "                            ({', '.join([f'x{i} {f.range().name()}' for i in range(f.arity())])}, \n",
    "                             PRIMARY KEY {primkey})\"\"\")\n",
    "\n",
    "    def run(self, rule : kd.rewrite.Rule | smt.BoolRef):\n",
    "        if isinstance(rule, smt.BoolRef):\n",
    "            rule = kd.rewrite.rule_of_expr(rule)\n",
    "        sql = compile_rule(rule)\n",
    "        self.db.execute(sql)\n",
    "\n",
    "s = Datalog()\n",
    "s.declare_db([edge, path])\n",
    "s.run(edge(1,2))\n",
    "s.run(edge(2,3))\n",
    "s.run(edgepath)\n",
    "s.run(trans)\n",
    "s.run(trans)\n",
    "s.db.execute(\"SELECT * FROM path\").fetchall()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa779ea",
   "metadata": {},
   "source": [
    "# compile out of smt2\n",
    "\n",
    "Look at basic compiler books.\n",
    "Tiger\n",
    "Essentials\n",
    "nanopass\n",
    "\n",
    "smtcc :)\n",
    "prescheme\n",
    "\n",
    "undefined behavior.\n",
    "\n",
    "\n",
    "We can make a meta layer list\n",
    "https://pypy.org/posts/2024/07/toy-abstract-interpretation.html\n",
    "https://pypy.org/posts/2022/07/toy-optimizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73696c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ret(x):\n",
    "    return \"mov rdi, \" + str(x) + \"\\n\" + \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61242393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /tmp/test.c\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/test.c\n",
    "#include <stdint.h>\n",
    "uint64_t mytest(){\n",
    "    return 42;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e08681a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t.file\t\"test.c\"\n",
      "\t.text\n",
      "\t.globl\tmytest\n",
      "\t.type\tmytest, @function\n",
      "mytest:\n",
      ".LFB0:\n",
      "\t.cfi_startproc\n",
      "\tendbr64\n",
      "\tpushq\t%rbp\n",
      "\t.cfi_def_cfa_offset 16\n",
      "\t.cfi_offset 6, -16\n",
      "\tmovq\t%rsp, %rbp\n",
      "\t.cfi_def_cfa_register 6\n",
      "\tmovl\t$42, %eax\n",
      "\tpopq\t%rbp\n",
      "\t.cfi_def_cfa 7, 8\n",
      "\tret\n",
      "\t.cfi_endproc\n",
      ".LFE0:\n",
      "\t.size\tmytest, .-mytest\n",
      "\t.ident\t\"GCC: (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0\"\n",
      "\t.section\t.note.GNU-stack,\"\",@progbits\n",
      "\t.section\t.note.gnu.property,\"a\"\n",
      "\t.align 8\n",
      "\t.long\t1f - 0f\n",
      "\t.long\t4f - 1f\n",
      "\t.long\t5\n",
      "0:\n",
      "\t.string\t\"GNU\"\n",
      "1:\n",
      "\t.align 8\n",
      "\t.long\t0xc0000002\n",
      "\t.long\t3f - 2f\n",
      "2:\n",
      "\t.long\t0x3\n",
      "3:\n",
      "\t.align 8\n",
      "4:\n"
     ]
    }
   ],
   "source": [
    "! gcc -S -o /tmp/test.s /tmp/test.c && cat /tmp/test.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ca4c92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87b048a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/test.S\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/test.S\n",
    "\n",
    ".globl mytest\n",
    "mytest:\n",
    "    mov $42, %rax\n",
    "    ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00bf8a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/test.so:     file format elf64-x86-64\n",
      "\n",
      "\n",
      "Disassembly of section .text:\n",
      "\n",
      "0000000000001000 <mytest>:\n",
      "    1000:\t48 c7 c0 2a 00 00 00 \tmov    $0x2a,%rax\n",
      "    1007:\tc3                   \tret\n"
     ]
    }
   ],
   "source": [
    "!gcc -c -fPIC -o /tmp/test.o /tmp/test.S && ld -shared -o /tmp/test2.so /tmp/test.o && objdump -d /tmp/test.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ddd434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "import cffi\n",
    "\n",
    "ffi = cffi.FFI()\n",
    "ffi.cdef(\"\"\"uint64_t mytest();\"\"\")\n",
    "lib = ffi.dlopen(\"/tmp/test2.so\")\n",
    "dir(lib)\n",
    "print(lib.mytest())\n",
    "del lib\n",
    "\n",
    "def \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a57841",
   "metadata": {},
   "outputs": [],
   "source": [
    "World = smt.DeclareSort(\"World\")\n",
    "BV64 = smt.BitVecSort(64)\n",
    "mem = smt.Function(\"mem\", World, smt.ArraySort(BV64, BV64))\n",
    "\n",
    "ret = smt.Function(\"ret\", BV64, World, World)\n",
    "\n",
    "\n",
    "type Block = list[smt.ExprRef]\n",
    "\n",
    "class Module():\n",
    "    \n",
    "\n",
    "#class Block():\n",
    "#   stmts : list[smt.ExprRef]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ccef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[x + y, x + y + z, x + y - (x + y + z)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y,z = smt.BitVecs(\"x y z\", 64)\n",
    "getarg = smt.Function(\"getarg\", smt.IntSort(), smt.BitVecSort(64))\n",
    "copy = smt.Function(\"copy\", smt.BitVecSort(64), smt.BitVecSort(64)) # kd.define(\"copy\", [x], x)\n",
    "prog = [\n",
    "    a := x + y,\n",
    "    b := a + z,\n",
    "    c := a - b,\n",
    "]\n",
    "def address_code(prog):\n",
    "    seen = set()\n",
    "    for stmt in prog:\n",
    "        if all(c in seen for c in stmt.children()):\n",
    "            seen.add(stmt)\n",
    "        else:\n",
    "            return False\n",
    "    return True\n",
    "# path assumptions could be interesting.\n",
    "\n",
    "def esimplify(prog):\n",
    "    uf = {}\n",
    "    new_prog = []\n",
    "    for n,stmt in prog:\n",
    "        s = smt.Solver()\n",
    "\n",
    "\n",
    "def register(prog):\n",
    "    live = set()\n",
    "    regalloc = {}\n",
    "    availreg = [\"r8\", \"rsi\",\"rdi\",\"rax\"]\n",
    "    for stmt in reversed(prog):\n",
    "        availreg.append(regalloc[stmt])\n",
    "        live.remove(stmt)\n",
    "        for c in stmt.children():\n",
    "            if c not in live:\n",
    "                live.add(c)\n",
    "                if availreg:\n",
    "                    regalloc[c] = availreg.pop()\n",
    "                else:\n",
    "                    # spill\n",
    "                    raise Exception(\"No registers available\")\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec58a266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1 + 0"
      ],
      "text/plain": [
       "1 + 0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "one = smt.BitVecVal(1, 64)\n",
    "zero = smt.BitVecVal(0, 64)\n",
    "\n",
    "one + zero\n",
    "\n",
    "def to_asm(e : smt.ExprRef):\n",
    "    if isinstance(e, smt.BitVecNumRef):\n",
    "        return \"mov rdi, %d\" % e.as_long()\n",
    "    elif smt.is_add(e):\n",
    "        to_asm(e.args[0])\n",
    "        return [\n",
    "            f\"pop %rdi\",\n",
    "            r\"add rdi, %d\" % e.args[1].as_long()\n",
    "        ]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b646e2ea",
   "metadata": {},
   "source": [
    "# vectorize\n",
    "\n",
    "pshufb\n",
    "pext pdep\n",
    "\n",
    "Aptroot's bot.\n",
    "\n",
    "These chess guys are nuts\n",
    "https://www.chessprogramming.org/BMI2#PEXTBitboards \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2c1032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://jamesbornholt.com/papers/diospyros-asplos21.pdf\n",
    "BV16 = smt.BitVecSort(16)\n",
    "BV8 = smt.BitVecSort(8)\n",
    "\n",
    "x,y,z = smt.BitVecs(\"x y z\", 16)\n",
    "vadd = smt.Function('vadd', BV16, BV16, BV16)\n",
    "vsub = smt.Function('vsub', BV16, BV16, BV16)\n",
    "vmul = smt.Function('vmul', BV16, BV16, BV16)\n",
    "vneg = smt.Function('vneg', BV16, BV16)\n",
    "vmac = smt.Function('vmac', BV16, BV16, BV16, BV16)\n",
    "\n",
    "vadd(x,y) == smt.Concat(smt.Extract(15, 8, x) + smt.Extract(15, 8, y), \n",
    "                        smt.Extract(7, 0, x) + smt.Extract(7, 0, y))\n",
    "\n",
    "vsub(x,y) == smt.Concat(smt.Extract(15, 8, x) - smt.Extract(15, 8, y), \n",
    "                        smt.Extract(7, 0, x) - smt.Extract(7, 0, y))\n",
    "vmul(x,y) == smt.Concat(smt.Extract(15, 8, x) * smt.Extract(15, 8, y),\n",
    "                        smt.Extract(7, 0, x) * smt.Extract(7, 0, y))\n",
    "vneg(x) == smt.Concat(-smt.Extract(15, 8, x), -smt.Extract(7, 0, x))\n",
    "vmac(x,y,z) == smt.Concat(smt.Extract(15, 8, x) * smt.Extract(15, 8, y) + smt.Extract(15, 8, z),\n",
    "                        smt.Extract(7, 0, x) * smt.Extract(7, 0, y) + smt.Extract(7, 0, z))\n",
    "\n",
    "smt.prove(smt.Concat(smt.Extract(15, 8, x), smt.Extract(7, 0, x)) == x)\n",
    "\n",
    "vadd(vmul(x,y),z) == vmac(x,y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5a9556",
   "metadata": {},
   "source": [
    "# asymptotic\n",
    "\n",
    "https://github.com/teorth/estimates\n",
    "https://en.wikipedia.org/wiki/Big_O_notation \n",
    "https://www.andrew.cmu.edu/user/avigad/Papers/bigo.pdf  Formalizing O notation in Isabelle/HOL\n",
    "\n",
    "eqaulity isn't equality (unless it is?)\n",
    "\n",
    "f(x) = O(g(x)) is really\n",
    "O(g)[f]\n",
    "\n",
    "But to do this is to ignore the wisdom of the notation perhaps. because formalists can't fit a notation into their rigid paradgims doesn't mean its bad\n",
    "\n",
    "I could do custom overloading of == to mean asymptotic.\n",
    "Didn't I have some idea about O ~ id\n",
    "\n",
    "\n",
    "\n",
    "nonstandard reals\n",
    "Kind of a pain in the ass to do it this way. Is the injectivity it offers us even that useful?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef76ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NonR0 = smt.DeclareSort(\"NonR0\")\n",
    "NonR = kd.Inductive(\"NonR\")\n",
    "NonR.declare(\"Std\", (\"R\", smt.RealSort()))\n",
    "NonR.declare(\"NonStd\", (\"Nr\", NonR0))\n",
    "NonR = NonR.create()\n",
    "\n",
    "# std predicate is now is_Std\n",
    "x,y = smt.Consts(\"x y\", NonR)\n",
    "add = kd.notation.add.define([x,y],\n",
    "                             kd.cond(\n",
    "                                (smt.And(smt.is_Std(x), smt.is_Std(y)), x + y),\n",
    "                                (smt.And(smt.is_Std(x), smt.is_NonStd(y)), x + y),\n",
    "                                (smt.And(smt.is_NonStd(x), smt.is_Std(y)), x + y),\n",
    "                                (smt.And(smt.is_NonStd(x), smt.is_NonStd(y)), x + y\n",
    "                             )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa1ff0d",
   "metadata": {},
   "source": [
    "# pysmt\n",
    "I never _really_ gave pysmt a fair shake.\n",
    "It doesn't support lambda. That is a pretty tough blow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c807787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pysmt.shortcuts import Symbol, And, Not, is_sat\n",
    "\n",
    "varA = Symbol(\"A\") # Default type is Boolean\n",
    "varB = Symbol(\"B\")\n",
    "f = And(varA, Not(varB))\n",
    "is_sat(f)\n",
    "g = f.substitute({varB: varA})\n",
    "is_sat(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca139021",
   "metadata": {},
   "source": [
    "# lambda unify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc66f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_huet():\n",
    "    todo = []\n",
    "    frozen = [] #flexflex?\n",
    "    subst = {}\n",
    "    while True:\n",
    "        while todo:\n",
    "            current = todo.pop()\n",
    "            # do unification.\n",
    "\n",
    "        for p in frozen:\n",
    "            if flexflex(p):\n",
    "                continue\n",
    "            else:\n",
    "                frozen.remove(p)\n",
    "                todo.append(p)\n",
    "                break\n",
    "        else:\n",
    "            return subst, frozen\n",
    "    \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54be818",
   "metadata": {},
   "source": [
    "# GAT / refinement\n",
    "see types.ipynb also\n",
    "\n",
    "\n",
    "The property of being a proper telescoping mapping requires an smt solve?\n",
    "\n",
    "why bother teelscoping? Isabelle pure has no telescoping effect? CVody says that helps build model but did not elaborate\n",
    "https://argo.matf.bg.ac.rs/events/2009/fatpa2009/slides/Wenzel_PureLogicalReasoning%20in%20Isabelle-Isar.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1911.00399 hott in pure\n",
    "https://arxiv.org/pdf/cs/9301105 pualson foundation of generic theorem prover\n",
    "\n",
    "\n",
    "So a conditional judgement can be seen as a fiber just as much as types can (?)\n",
    "A /\\ B /\\ C ===> D\n",
    "\n",
    "|- goal(p)  as a marker. Always provable goal(p) == True\n",
    " \n",
    "unify(pf1, pf2)\n",
    "\n",
    "Rather than an equalizer, a pullback. t1 as a substituion mapping anyway?\n",
    "G1 -> G2\n",
    "G3 -> G2\n",
    "Two telescope mappings that go to common context G2. Can I build a pullback?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8d0d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[y] [y >= -1] y + 1 >= 0\n",
      "[y] [y >= -1] y + 10 >= y + 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[|- ForAll(y, Implies(And(y >= -1), y + 1 >= 0)),\n",
       " |- ForAll(y, Implies(And(y >= -1), y + 10 >= y + 1))]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Telescope():\n",
    "    \"\"\" x | A(x), y | B(x,y), ... \"\"\"\n",
    "    vs : list[smt.ExprRef]\n",
    "    preds : list[smt.BoolRef]\n",
    "    # preds : list[kd.Proof] ? |- ForAll([x], P1), ForAll([x,y], P1 => P2), ...  \n",
    "    # No but the context should be proof recievining, not proof producing.\n",
    "\n",
    "    def expr(self, P):\n",
    "        print(self.vs, self.preds, P)\n",
    "        return kd.QForAll(self.vs, smt.And(self.preds), P)\n",
    "    \n",
    "\n",
    "\n",
    "x,y,z = smt.Reals(\"x y z\")\n",
    "Telescope([x,y], [x > 0, y > x])\n",
    "\n",
    "@dataclass\n",
    "class TeleSubst():\n",
    "    dom : Telescope\n",
    "    cod : Telescope\n",
    "    subst: dict[smt.ExprRef, smt.ExprRef]\n",
    "    # pf : list[smt.Proof] # same length as dom.preds\n",
    "\n",
    "    def check(self,by=[]):\n",
    "        pfs = []\n",
    "        pfs.extend(by)\n",
    "        for P in self.dom.preds:\n",
    "            pfs.append(kd.prove(self.cod.expr(smt.substitute(P, *self.subst.items())), by=pfs))\n",
    "        return pfs\n",
    "    def __call__(self, P):\n",
    "        # P is in context dom\n",
    "        return smt.substitute(P, *self.subst.items())\n",
    "    def __matmul__(self, other):\n",
    "        # substutition forms a category\n",
    "        assert self.dom == other.cod\n",
    "        TeleSubst(other.dom, self.cod, {smt.substitute(...)})\n",
    "\n",
    "# allows subtype weakening.\n",
    "# if it only allowed syntactic substitutions, then we don't really need the proofs\n",
    "\n",
    "ctx1 = Telescope([x,z], [x >= 0, z >= x])\n",
    "ctx2 = Telescope([y], [y >= -1])\n",
    "TeleSubst(ctx1, ctx2, {x: y + 1, z : y + 10}).check()\n",
    "\n",
    "\n",
    "# is there a unification procedure for making TeleSubst?\n",
    "# G1 |- t1 =? t2 -| G2\n",
    "# result is G1 -> G2 substitution? It's assymmetric?\n",
    "# doesn't seem like the right shape.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9f6a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "&#8870;ForAll([y, z], And(z == z, y + 1 == y + 1))"
      ],
      "text/plain": [
       "|- ForAll([y, z], And(z == z, y + 1 == y + 1))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "\n",
    "def subst(pf : kd.Proof, vs : list[smt.ExprRef], subst : list[smt.ExprRef]) -> kd.Proof:\n",
    "    vs1, ab = kd.kernel.herb(smt.ForAll(vs, smt.substitute_vars(pf.thm.body(), *reversed(subst))))\n",
    "    a = kd.kernel.instan([smt.substitute(t, *zip(vs, vs1)) for t in subst], pf)\n",
    "    return kd.kernel.modus(ab, a)\n",
    "x,y,z = smt.Reals(\"x y z\")\n",
    "p = kd.prove(smt.ForAll([x,z], smt.And(z == z, x == x)))\n",
    "subst(p, [y, z], [y + 1, z])\n",
    "\n",
    "def weaken(pf, x):\n",
    "\n",
    "\n",
    "def unify(pf1, pf2) -> Optional[kd.Proof]:\n",
    "    # unify the two proofs forall x, p1(x) and forall y, p2(y)\n",
    "    # return a new proof\n",
    "    vs1, p1 = kd.utils.open_binder(pf1.thm)\n",
    "    vs2, p2 = kd.utils.open_binder(pf2.thm)\n",
    "    vs = vs1 + vs2\n",
    "    subst = kd.utils.unify(vs1+vs2,p1,p2)\n",
    "    if subst is not None:\n",
    "        vs = set(vs) - set(subst.keys()) # maybe keep 'em ordered\n",
    "        return subst_tac(pf1, vs, )\n",
    "\n",
    "def build_telescope(pf : kd.Proof, vs, hyps, conc):\n",
    "    # find a substitution based on unifying conc\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "def chain(pf1, pf2):\n",
    "    # decompose into rules.\n",
    "    # unify\n",
    "    # rebuild\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41112098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "&#8870;ForAll(x, fact(x) == If(0 >= x, 1, x*fact(x - 1)))"
      ],
      "text/plain": [
       "|- ForAll(x, fact(x) == If(0 >= x, 1, x*fact(x - 1)))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kdrag.reflect as reflect\n",
    "from kdrag.all import *\n",
    "x = smt.Bool(\"x\")\n",
    "@reflect.reflect\n",
    "def fact(x : int) -> int:\n",
    "    if x <= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return x*fact(x-1)\n",
    "fact.defn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f19366",
   "metadata": {},
   "source": [
    "# verilog extract\n",
    "\n",
    "Silviu makes a good point.\n",
    "If you're going to be comparing test case outputs,\n",
    "No need to \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69d6744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// Generated by knuckledragger\n",
      "module test (\n",
      "   input x,\n",
      "   input y,\n",
      "   output z\n",
      ");\n",
      "assign z = (x && y);\n",
      "endmodule\n",
      "\n",
      "// Generated by knuckledragger\n",
      "module test (\n",
      "   input [7:0] a,\n",
      "   input [7:0] b,\n",
      "   output z\n",
      ");\n",
      "assign z = ((a & (b + 8'd7)) != b);\n",
      "endmodule\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x,y,z = smt.Bools(\"x y z\")\n",
    "a,b,c = smt.BitVecs(\"a b c\", 8)\n",
    "print(to_verilog(\"test\", [x,y], {z : x & y}))\n",
    "print(to_verilog(\"test\", [a,b], {z : a & b + 7 != b}))\n",
    "#(a & b != b).decl().name()\n",
    "\n",
    "def test():\n",
    "    with open(\"/tmp/test.v\", \"w\") as f:\n",
    "        f.write(to_verilog(\"test\", [x,y], {z : x & y}))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a48664",
   "metadata": {},
   "source": [
    "To say that a verilog file has a property is an axiom schema?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592dbe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sby_axiom(modfile, name, ins, outs):\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c384cc",
   "metadata": {},
   "source": [
    "# diff\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bad30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.all import *\n",
    "\n",
    "def diff(e, x):\n",
    "    if e.eq(x):\n",
    "        return 1\n",
    "    elif smt.is_value(e):\n",
    "        return 0\n",
    "    elif smt.is_add(e):\n",
    "        return smt.Sum([diff(c,x) for c in e.children()])\n",
    "    elif e.decl() == real.sin:\n",
    "        return real.cos(e) * diff(e, x)\n",
    "    elif e.decl() == real.cos:\n",
    "        return -real.sin(e) * diff(e, x)\n",
    "    elif e.decl() == real.exp:\n",
    "        return real.exp(e) * diff(e, x)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884b9aa2",
   "metadata": {},
   "source": [
    "# knuckelproblems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06bcd4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "&#8870;ForAll([n, m],\n",
       "       add(n, m) ==\n",
       "       If(is(Zero, n),\n",
       "          m,\n",
       "          If(is(Succ, n),\n",
       "             Succ(add(pred(n), m)),\n",
       "             unreachable!6)))"
      ],
      "text/plain": [
       "|- ForAll([n, m],\n",
       "       add(n, m) ==\n",
       "       If(is(Zero, n),\n",
       "          m,\n",
       "          If(is(Succ, n),\n",
       "             Succ(add(pred(n), m)),\n",
       "             unreachable!6)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from kdrag.all import *\n",
    "# Knuckledragger support algebraic datatypes and induction\n",
    "Nat = kd.Inductive(\"MyNat\")\n",
    "Zero = Nat.declare(\"Zero\")\n",
    "Succ = Nat.declare(\"Succ\", (\"pred\", Nat))\n",
    "Nat = Nat.create()\n",
    "# We can define an addition function by cases\n",
    "n,m = smt.Consts(\"n m\", Nat)\n",
    "add = smt.Function(\"add\", Nat, Nat, Nat)\n",
    "add = kd.define(\"add\", [n,m], \n",
    "    kd.cond(\n",
    "        (n.is_Zero, m),\n",
    "        (n.is_Succ, Nat.Succ(add(n.pred, m)))\n",
    "))\n",
    "\n",
    "\"\"\"\n",
    "add = kd.define(\"add\", [n,m], \n",
    "    n.match_(\n",
    "        (Nat.Zero, m),\n",
    "        (Nat.Succ(n), Nat.Succ(add(n, m)))\n",
    "))\n",
    "add.defn\n",
    "\"\"\"\n",
    "add.defn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0831560e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "&#8870;ForAll(x, fact(x) == If(0 >= x, 1, x*fact(x - 1)))"
      ],
      "text/plain": [
       "|- ForAll(x, fact(x) == If(0 >= x, 1, x*fact(x - 1)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kdrag.reflect as reflect\n",
    "\n",
    "@reflect.reflect\n",
    "def fact(x : int) -> int:\n",
    "    if x <= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return x*fact(x-1)\n",
    "fact.defn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2daa3cb",
   "metadata": {},
   "source": [
    "# vectors\n",
    "\n",
    "Bitvector operations\n",
    "\n",
    "V4 style of \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d38e7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "BV32 = smt.BitVecSort(32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c68ba81",
   "metadata": {},
   "source": [
    "# Type resgistry\n",
    "\n",
    "Some \n",
    "\n",
    "add_assoc\n",
    "add_comm\n",
    "mul_assoc\n",
    "mul_comm\n",
    "\n",
    "\n",
    "COuld reaplce sortdispatch using T.add, T.mul and just have ExprRef.__add__ = lambda x,y: x.sort().add(x,y)\n",
    "\n",
    "\n",
    "\n",
    "BoolSort\n",
    "RealSort\n",
    "StringSort\n",
    "etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fabcc16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "T = smt.DeclareSort(\"T\")\n",
    "T1 = smt.DeclareSort(\"T\")\n",
    "id(T1) == id(T)\n",
    "T1.get_id() == T.get_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "191cebbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2147483659: Int,\n",
       " 2147483648: Bool,\n",
       " 2147483658: Real,\n",
       " 2147483815: NatI,\n",
       " 2147483814: Nat,\n",
       " 2147483704: BitVec(1),\n",
       " 2147483711: BitVec(8),\n",
       " 2147483898: Seq(BitVec(1)),\n",
       " 2147483841: BitVecN}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "smt.sort_registry\n",
    "import kdrag.theories.nat as nat\n",
    "smt.sort_registry\n",
    "import kdrag.theories.bitvec as bv\n",
    "smt.sort_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ca8125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hash cons the types so that we can tag useful stuff on them\n",
    "types = {}\n",
    "\n",
    "def DeclareSort(name):\n",
    "    if name not in types:\n",
    "        types[name] = type(name, (object,), {})\n",
    "    return types[name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a5313e",
   "metadata": {},
   "source": [
    "# Schematic Vars\n",
    "Explicitly pulling schematic variables out, may let me refer to them in subproofs (How?)\n",
    "\n",
    "   G |- A\n",
    "------------- weaken\n",
    "     G, v fresh |- A\n",
    "Well that's annoying.\n",
    "\n",
    "app(forall x, A, t)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "forall x, A  \n",
    "\n",
    "Maybe I should consider this as A Proof extension rather than proof replacement, likke refinement types\n",
    "\n",
    "\n",
    "```\n",
    "Gam |- t   x not in t\n",
    "-----------\n",
    "Gam, x |- t \n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "If I merged forall intro and removal\n",
    "\n",
    "\n",
    "This is just |- forall x, P(x) but with some extra junk.\n",
    "\n",
    "capture avoiding\n",
    "\n",
    "https://ncatlab.org/nlab/show/substitution\n",
    "\n",
    "https://en.wikipedia.org/wiki/Admissible_rule\n",
    "https://cstheory.stackexchange.com/questions/54600/admissible-rules-in-dependent-type-theory\n",
    "\n",
    "Gam |- A then sigma Gam |- sigma A\n",
    "\n",
    "\n",
    "The point was that\n",
    "\n",
    "prove(t, )\n",
    "\n",
    "def cprove(vs, p, by=)\n",
    "\n",
    "\n",
    "a curried form of backward proof tracking.\n",
    "modus for leaves\n",
    "comp for moves.\n",
    "but yeah, split\n",
    "A /\\ B\n",
    "(A => B => A /\\ B)\n",
    "(A => A \\/ B)\n",
    "(B => A \\/ B)\n",
    "\n",
    "A => B => C\n",
    "\n",
    "but then aplpying move in context is annoying. Hmm.\n",
    "And I don't give a shit about anything except quantifier moves so it's wasteful effort.\n",
    "\n",
    "Maybe the callback method is easier. But it'll have so many expensive calls\n",
    "\n",
    "\n",
    "def intros():\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c7b4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modus(ab, a):\n",
    "    assert smt.is_implies(ab) and ab.arg(0).eq(a)\n",
    "    assert isinstance(ab, Proof) and isinstance(a, Proof)\n",
    "    return Proof(ab.arg(1), reasons=[ab, a])\n",
    "\n",
    "def impl_refl(a):\n",
    "    return Proof(smt.Implies(a,a))\n",
    "\n",
    "def comp(ab, bc): # cut sort of\n",
    "    assert smt.is_implies(ab) and smt.is_implies(bc) and ab.arg(1).eq(bc.arg(0))\n",
    "    assert isinstance(ab, Proof) and isinstance(bc, Proof)\n",
    "    return Proof(smt.Implies(ab.arg(0), bc.arg(1)), reasons=[ab, bc])\n",
    "\n",
    "\n",
    "class Lemma():\n",
    "    self.backward_proof = impl_refl(goal)\n",
    "    self.topgoal = goal\n",
    "    self.curgoal = goal\n",
    "    \n",
    "\n",
    "def qed():\n",
    "    assert self.backwardproof.thm.eq(self.topgoal)\n",
    "    return self.backwardproof\n",
    "def fixes():\n",
    "    herb(self.topgoal)\n",
    "    self.backwardproof = comp(  , self.backwardproof)(modus(ab,a)))\n",
    "def prove():\n",
    "    p = self.prove(curgoal)\n",
    "    self.backwardproof = modus(self.backwardproof, self.proof)\n",
    "def intros():\n",
    "    self.curgoal = self.curgoal.arg(0)\n",
    "    # goal is unchanged?\n",
    "    # (a -> b) -> topgoal. uhhh. G -> \n",
    "    # \n",
    "    # /\\ (forall vs, hyps => conc) -> topgoal\n",
    "    # (hyp1 => conc1) => (hyp2 => conc2) => hyp3 => topgoal\n",
    "    # goal1 => goal2 => topgoal\n",
    "\n",
    "\n",
    "\n",
    "Goal\n",
    "  def to_expr\n",
    "   \n",
    "\n",
    "                                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32936903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deinstan(pf):\n",
    "    # get substution if last thing was an instan?\n",
    "    # Super weird idea.\n",
    "\n",
    "def cprove(\n",
    "    vs : list[smt.ExprRef],\n",
    "    thm: smt.BoolRef,\n",
    "    by = lambda *args: [] #Callable[smt.ExprRefglist[kd.Proof],\n",
    "    **kwargs\n",
    ") -> kd.kernel.Proof:\n",
    "    \"\"\"Contextual proof. Open up variable binders and give by lemmas access to them in callback\"\"\"\n",
    "    goal = smt.ForAll(vs, thm)\n",
    "    vs1, pf = kd.kernel.herb(goal)\n",
    "    subproof = kd.prove(pf.thm.arg(0), by(*vs1))\n",
    "    return kd.kernel.modus(subproof, pf)\n",
    "\n",
    "\n",
    "\n",
    "def indprove(v, thm):\n",
    "    \"\"\"Inductive proof. Open up variable binders and give by lemmas access to them in callback\"\"\"\n",
    "    goal = smt.ForAll(v, thm)\n",
    "    vs1, pf = kd.kernel.herb(goal)\n",
    "    subproof = kd.prove(pf.thm.arg(0), by(*vs1))\n",
    "    return kd.kernel.modus(subproof, pf)\n",
    "\n",
    "def indprove(v : smt.ExprRef, thm, by=None, using=None):\n",
    "    l = kd.Lemma(smt.ForAll(v, thm))\n",
    "    v1 = l.fix()\n",
    "    l.induct(v1, using=using)\n",
    "    l.auto(by=by)\n",
    "    return l.qed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e2c644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subst(vs, p : kd.Proof, subst):\n",
    "    assert isinstance(p, kd.Proof)\n",
    "    vs1, body = kd.utils.open_binder_unhygienic(p.fm)\n",
    "    assert kd.utils.free_in(vs - vs1, body)\n",
    "\n",
    "# vs\n",
    "\n",
    "# ok so we can achieve of substutiton by combining herb and instan.\n",
    "def subst(vs, p : kd.Proof, subst):\n",
    "    goal = smt.ForAll(vs, smt.substitute(p.fm, *subst.items()))\n",
    "    l = kd.Lemma(goal)\n",
    "    vs = l.fixes()\n",
    "    l.qed(by=p(subst[v] for v in vs))\n",
    "    #vs, pf = kd.kernel.herb(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf5837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Proof():\n",
    "    ctx : dict[smt.SortRef, int] # How many de bruijn indices are allowed?\n",
    "    fm : smt.BoolRef\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6262110",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Proof():\n",
    "    vs : list[smt.ExprRef] # ctx\n",
    "    fm : smt.BoolRef | smt.QuantifierRef\n",
    "    reasons : list[object]\n",
    "    def __call__(self, *args, vs=[]):\n",
    "        smt.substitute(self.fm, *zip(self.vs, args))\n",
    "\n",
    "def free(vs, fm):\n",
    "    #fm2 = smt.substitute(fm, *[(v, smt.FreshConst(v.sort())) for v in vs])\n",
    "    return smt.Lambda(vs, fm).body().eq(fm)\n",
    "    #return fm2.eq(fm)\n",
    "\n",
    "def lift(p : kd.Proof) -> Proof:\n",
    "    assert isinstance(p, kd.Proof)\n",
    "    return Proof(\n",
    "        vs = [],\n",
    "        fm = p.fm,\n",
    "        reasons = [p]\n",
    "    )\n",
    "def lift_forall(p : kd.Proof) -> Proof:\n",
    "    assert isinstance(p, kd.Proof)\n",
    "    vs, fm = kd.utils.open_binder_unhiegenic(p.fm)\n",
    "    return Proof(\n",
    "        vs = vs,\n",
    "        fm = fm,\n",
    "        reasons = [p]\n",
    "    )\n",
    "def lift_free(ctx, p : kd.Proof) -> Proof:\n",
    "    assert isinstance(p, kd.Proof)\n",
    "    assert all(v in ctx for v in p.vs)\n",
    "    assert free(ctx, p.fm)\n",
    "    return Proof(\n",
    "        vs = ctx,\n",
    "        fm = p.fm,\n",
    "        reasons = [p]\n",
    "    )\n",
    "\n",
    "\"\"\"\n",
    "  Gam |- forall x, P\n",
    "---------------\n",
    " Gam, x |- P\n",
    "\n",
    " This is reversed intro rule. Feels odd.\n",
    "\"\"\"\n",
    "def open(p : Proof) -> Proof:\n",
    "    vs, fm = kd.utils.open_binder_unhiegenic(p.fm)\n",
    "    Proof(p.vs + vs, fm, [p])\n",
    "\n",
    "def intro(n, p : Proof):\n",
    "    return Proof(p.vs[n:], smt.ForAll(p.vs[:n], p.fm), [p])\n",
    "\n",
    "def extend(vs, p : Proof) -> Proof:\n",
    "    s = smt.Solver()\n",
    "    s.add(smt.ForAll(p.vs, p.fm))\n",
    "    s.add(smt.Not(smt.ForAll(p.vs + vs, p.fm)))\n",
    "    res = s.check()\n",
    "    if res == smt.unsat:\n",
    "        return Proof(\n",
    "            vs = p.vs + vs,\n",
    "            fm = p.fm,\n",
    "            reasons = [p]\n",
    "        )\n",
    "    else:\n",
    "        raise Exception(\"Unknown result from solver\")\n",
    "\n",
    "\n",
    "def subst(p : Proof, ctx : list[smt.ExprRef], subst : dict[smt.ExprRef, smt.ExprRef]):\n",
    "    assert isinstance(p, Proof)\n",
    "    assert all(v in p.vs for v in  subst.keys())\n",
    "    assert free(ctx - p.ctx, p.fm)\n",
    "    #fm = smt.substitute(p.fm, *[(v, smt.FreshConst(v.sort())) for v in ctx])\n",
    "    fm = smt.substitute(p.fm, *subst.items())\n",
    "    # I need to check that ctx2 does not appear in fm. Otherwise I could |- even(zero) ---> zero |- even(zero)\n",
    "    return Proof(\n",
    "        vs = ctx,\n",
    "        fm = fm,\n",
    "        reasons = [p]\n",
    "    )\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "G |- p1    G |- p2 ... \n",
    "-------\n",
    "    G |- p\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def prove(ctx, expr, by=None):\n",
    "    allctx = set(ctx)\n",
    "    for p in by:\n",
    "        assert isinstance(p, Proof)\n",
    "        assert p.ctx == ctx\n",
    "    s.add(smt.Not(smt.ForAll([ctx], smt.Implies(smt.And(hyp.fm for hyp in by), expr))))\n",
    "    s.check()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e114fb5",
   "metadata": {},
   "source": [
    "Ok so yes, any forall infecting the lemmas is a problem.\n",
    "And some things get foralls because its hard an annoying \n",
    "\n",
    "qed should \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe69def9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.all import *\n",
    "import kdrag.theories.real as real\n",
    "x,y = smt.Reals(\"x y\")\n",
    "cos = real.cos\n",
    "sin = real.sin\n",
    "#os_diff = kd.prove(smt.ForAll([x,y], cos(x - y) == cos(x)*cos(y) + sin(x)*sin(y)), [real.cos_add, real.cos_neg, real.sin_neg])\n",
    "\n",
    "_l = kd.Lemma(smt.ForAll([x,y], cos(x - y) == cos(x)*cos(y) + sin(x)*sin(y)))\n",
    "_x, _y = _l.fixes()\n",
    "_l.symm()\n",
    "_l.eq(cos(_x + (-_y)))\n",
    "#_l.rw(kd.prove(cos(_x - _y) == cos(_x + (-_y))))\n",
    "#_l.rw(kd.prove(smt.ForAll([x,y], x - y == (x + (-y))))(_x, _y))\n",
    "_l.rw(real.cos_add(_x, -_y))\n",
    "#_l.auto(by=[real.cos_add, real.sin_add])\n",
    "_l.auto(by=[real.cos_neg(_y), real.sin_neg(_y)])\n",
    "_l.lemmas\n",
    "_l.qed()\n",
    "cos_diff = _l.lemmas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd2f219",
   "metadata": {},
   "source": [
    "# Homomorphism theorems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8dd031",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Not registered in typeclass', (A,))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m id_, assoc, id_left, inv_left\n\u001b[32m     19\u001b[39m B = smt.DeclareSort(\u001b[33m'\u001b[39m\u001b[33mB\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mgroup\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGroup\u001b[49m\u001b[43m.\u001b[49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m idA, assocA, id_leftA, inv_leftA = Group(A)\n\u001b[32m     22\u001b[39m idB, assocB, id_leftB, inv_leftB = Group(B)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/python/knuckledragger/kdrag/property.py:66\u001b[39m, in \u001b[36mTypeClass.register\u001b[39m\u001b[34m(cls, *L, **kwargs)\u001b[39m\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAlready registered key\u001b[39m\u001b[33m\"\u001b[39m, L)\n\u001b[32m     65\u001b[39m registry[L] = kwargs\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mL\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/python/knuckledragger/kdrag/property.py:42\u001b[39m, in \u001b[36mTypeClass.__init__\u001b[39m\u001b[34m(self, *L)\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, k, v)\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcheck\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mL\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/python/knuckledragger/kdrag/theories/algebra/group.py:74\u001b[39m, in \u001b[36mGroup.check\u001b[39m\u001b[34m(self, T)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck\u001b[39m(\u001b[38;5;28mself\u001b[39m, T):\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     \u001b[38;5;28mself\u001b[39m.Monoid = \u001b[43mMonoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mself\u001b[39m.e = \u001b[38;5;28mself\u001b[39m.Monoid.e\n\u001b[32m     76\u001b[39m     \u001b[38;5;28mself\u001b[39m.assoc = \u001b[38;5;28mself\u001b[39m.Monoid.assoc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/python/knuckledragger/kdrag/property.py:38\u001b[39m, in \u001b[36mTypeClass.__init__\u001b[39m\u001b[34m(self, *L)\u001b[39m\n\u001b[32m     36\u001b[39m registry = \u001b[38;5;28mself\u001b[39m.get_registry()\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m L \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m registry:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNot registered in typeclass\u001b[39m\u001b[33m\"\u001b[39m, L)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m registry[L].items():\n\u001b[32m     40\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, k, v)\n",
      "\u001b[31mValueError\u001b[39m: ('Not registered in typeclass', (A,))"
     ]
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "import kdrag.property as prop\n",
    "import kdrag.theories.algebra.group as group\n",
    "\n",
    "A = smt.DeclareSort('A')\n",
    "def Group(A):\n",
    "    mul = smt.Function('mul', A, A, A)\n",
    "    inv = smt.Function('inv', A, A)\n",
    "    id_ = smt.Const('id', A)\n",
    "    x,y,z = smt.Consts('x y z', A)\n",
    "    kd.notation.mul.register(A, mul)\n",
    "    kd.notation.invert.register(A, inv)\n",
    "    assoc = kd.axiom(smt.ForAll([x,y,z], x * (y * z) == (x * y) * z))\n",
    "    id_left = kd.axiom(smt.ForAll([x], id_ * x == x))\n",
    "    inv_left = kd.axiom(smt.ForAll([x], inv(x) * x == id_))\n",
    "    return id_, assoc, id_left, inv_left\n",
    "\n",
    "\n",
    "B = smt.DeclareSort('B')\n",
    "group.Group.register(A)\n",
    "idA, assocA, id_leftA, inv_leftA = Group(A)\n",
    "idB, assocB, id_leftB, inv_leftB = Group(B)\n",
    "\n",
    "h = smt.Function('h', A, B)\n",
    "def homo(id_, h):\n",
    "    A = h.domain(0)\n",
    "    B = h.range()\n",
    "    x,y,z = smt.Consts(\"x y z\", A)\n",
    "    mul = smt.ForAll([x,y], h(x * y) == h(x) * h(y))\n",
    "    id_ = h(idA) == idB\n",
    "    inv = smt.ForAll([x], h(~x) == ~h(x))\n",
    "    return mul, id_, inv\n",
    "homo(h)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eb2f2b",
   "metadata": {},
   "source": [
    "Universe of groups.\n",
    "\n",
    "I was saying construct it as permuations  Int -> Int\n",
    "\n",
    "Nontrivial\n",
    "But we could also driectly axiomatize\n",
    "\n",
    "* is composition\n",
    "id is  x -> x\n",
    "homomorphisms need to... be careful here. Only push homo through on particular Group?\n",
    "SetGrp \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Grp = smt.DeclareSort(\"Grp\")\n",
    "SetGrp = set_.SetSort(Grp)\n",
    "inv = smt.Function(\"inv\", Grp, Grp)\n",
    "# inv = smt.Function(\"inv\", GrpSet, GrpSet)\n",
    "mul = smt.Function(\"mul\", Grp, Grp) # We just leave mul un\n",
    "\n",
    "Closed = smt.QForAll([x,y, S], S[x], S[y], S[x * y], S[inv(x)])\n",
    "\n",
    "smt.QForAll([S], Closed[S], S[x], S[y], S[z],  x*(y*z) == (x * y) * z) # Is there a model where mul can be associative and always defined? \n",
    "smt.QForAll([S], Closed[S], S[x], inv(x) * x == x)  # maybe unconditionally actually\n",
    "smt.QForAll([S], id_ * x == x) # also unconditiojnality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
