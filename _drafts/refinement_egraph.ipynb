{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca97a8cc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "478e38d2",
   "metadata": {},
   "source": [
    "My subsort checker database is basically a congryuence database?\n",
    "\n",
    "cong = {\n",
    "    set.Union: kd.ForAll([A,B,C,D], A <= B, C <= D, Union(A,C) <= Union(B, D))\n",
    "    set.Inter:\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c22c35",
   "metadata": {},
   "source": [
    "Var trick for opening binders? Is it sound?\n",
    "Use original lambda as \"name\" of variable.\n",
    "lam(var(i) + 1) -->  fvar(lam(var(i) + 1)) + 1\n",
    "Don't use numbers when you don't have to\n",
    "\"Skolemization\"\n",
    "\"Use the reason it exists\"\n",
    "\"provenance\"\n",
    "\n",
    "Analog of the `let` trick.\n",
    "The free varaible was certainly \"caused\" by opening the binder.\n",
    "\n",
    "Is 0*bvar(0) = 0 a refinement? Kind of feels that way (if looking up a variable is )\n",
    "0*bvar(0) --> 0\n",
    "It errors out in strictly less contexts.\n",
    "\n",
    "\n",
    "The point of refinment/undef behavior is to enable more rewriting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b421372",
   "metadata": {},
   "source": [
    "https://archive.computerhistory.org/resources/access/text/2024/01/102805327-05-01-acc.pdf Henglein \"semi-unification\"\n",
    "\n",
    "https://pure.mpg.de/rest/items/item_1834874_3/component/file_1857517/content Is this the same or a different semi unification?\n",
    "https://www.sciencedirect.com/science/article/pii/0304397591901899 Kapur semi unification\n",
    "sig phi t = phi s\n",
    "a unification and a matching\n",
    "https://types.pl/@flippac/115102336973734248\n",
    "\n",
    "or sig t <= sig s  equivalently. \n",
    "\n",
    "https://dl.acm.org/doi/10.1145/169701.169687 type reconstruction in the presence of polymorphic recursion\n",
    "https://cormack.uwaterloo.ca/rasup.pdf  A Larger Decidable Semiunification Problem\n",
    "\n",
    " Amortized efficiency of a path retrieval data structure\n",
    "https://www.sciencedirect.com/science/article/pii/0304397586900988 \n",
    "\n",
    "https://chaozhang-cs.github.io/files/sigmod23-tutorial-short.pdf An Overview of Reachability\n",
    "Indexes on Graphs\n",
    "- tree cover indices\n",
    "- 2-hop indices - hmm. Kind of like a union find to root, away from root. Finding good quasi roots\n",
    "- approximate reachability\n",
    "\n",
    "This does match my paradigm of rebuild or approximate.\n",
    "\n",
    "https://drops.dagstuhl.de/storage/00lipics/lipics-vol221-sand2022/LIPIcs.SAND.2022.1/LIPIcs.SAND.2022.1.pdf Recent Advances in Fully Dynamic Graph\n",
    "Algorithms\n",
    "\n",
    "\n",
    "https://github.com/facebook/flow/blob/main/src/typing/tvar_resolver.ml \n",
    "https://github.com/facebook/flow/blob/d076b30cfc3635ff8c38d43bee0b08c66cb9ec4f/src/typing/context.ml#L1209 find_root? I dunno. This seems problematic.\n",
    "\n",
    "\n",
    "That lattice textbook\n",
    "\n",
    "\n",
    "Where in compilers is there an example of a contravaraint symbol?\n",
    "Inputs to function calls?\n",
    "Call site f(x,y,z)\n",
    "bind site\n",
    "def f(x,y,z):  \n",
    "\n",
    "t <= pat <= rhs\n",
    "\n",
    "`t <bisubst= pat <= rhs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "E-graph trinitarianism - hash cons <-> union find <-> egraph\n",
    "\n",
    "Ordered chaining\n",
    "https://www.philipzucker.com/le_find/\n",
    "\n",
    "```\n",
    "tSu          vSw\n",
    "-----------------\n",
    "  sig[t] S sig[w]\n",
    "```\n",
    "\n",
    "But with the usual restrction that we only need to do inferences that increase something?\n",
    "\n",
    "\n",
    "ground ordered chaining. maybe there is some path compression that can work here?\n",
    "\n",
    "\n",
    "https://inria.hal.science/inria-00073205/document Pottier thesis\n",
    "\n",
    "\n",
    "Higher order Bi-Unfication\n",
    "F(x) <= x\n",
    "\n",
    "https://docs.google.com/document/d/15amCalh9CSOWbbZ3d_haNad0Pw_jJ7vYcjMLkp7r-AA/edit?tab=t.0\n",
    "\n",
    "\n",
    "icfp gilbert something knitting groupoid. Hmm.\n",
    "\n",
    "2 more\n",
    "- refinement reasoning in algerab of programming. Relational spec. functional implementation. The calculated typer https://people.cs.nott.ac.uk/pszgmh/typer.pdf . Program Construction: Calculating Implementation  from Specifications . Mathmeth http://www.mathmeth.com/ https://www.cs.ox.ac.uk/publications/books/PfS/ . Gries?\n",
    "- Cycluic proofs.  We get the theoremwe're trying to rpover as a inequality guarded rule. Would not numerical ineq be good enough?1\n",
    "\n",
    "https://en.wikipedia.org/wiki/Relation_algebra\n",
    "https://www.philipzucker.com/a-short-skinny-on-relations-towards-the-algebra-of-programming/\n",
    "https://www.di.uminho.pt/~jno/ps/pdbc.pdf\n",
    "Gibbons book?\n",
    "agda aop\n",
    "Backhouse calculation book\n",
    "\n",
    "https://staff.math.su.se/anders.mortberg/papers/refinements.pdf refinement for free\n",
    "dense poly to sparse poly\n",
    "https://link.springer.com/content/pdf/10.1007/978-3-031-57262-3_10.pdf  Trocq: Proof Transfer for Free, With or Without Univalence 2024. Hmm. 2 versions of bitvec\n",
    "CoqEAL library https://github.com/rocq-community/coqeal\n",
    "\n",
    "Automatic and Transparent Transfer of\n",
    "Theorems along Isomorphisms\n",
    "in the Coq Proof Assistant  Theo Zimmermann1 and Hugo Herbelin 2015\n",
    "\n",
    "Data vs Program rtefinement. Cahnge the program or change the datatype.\n",
    "quot(X) = Y  fine. mod out permutations.\n",
    "canon(Y) = X , pick one somewhat arbitrarily vs\n",
    "Y -> X    . Kind of expressing containment in quoitent set. It is possible to refine Y to many possible X.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Dénès, M., Mörtberg, A., Siles, V.: A refnement-based approach to computational\n",
    "algebra in coq\n",
    "\n",
    "Generaliuzed rewriting https://rocq-prover.org/doc/v8.18/refman/addendum/generalized-rewriting.html \n",
    "https://jfr.unibo.it/article/download/1574/1077/3383 A New Look at Generalized Rewriting in Type Theory Sozeau\n",
    "Subst (being <=) and diff being a fun symbol. That's a good one. since diff is `->` in some heyting sense, also makes sense.\n",
    "\n",
    "Indeed A cup B <= C  is the same as A <= C  and B <= C . Is that useful? Does that fight an AC problem?\n",
    "So set algebra. A = B, C = D,  diff, union, complement, intersection . Some of these do have anti modality. \n",
    "set constraints\n",
    "clp set\n",
    "{a} <= A  is open set with a in it.  elem(a,A) == sing(a) <= A\n",
    "\n",
    "\"mediated\" equality is very much exactly gewneralized rewriting in sozeau sense\n",
    "The variance / compatibility rules are the custom congruence rules.\n",
    "\n",
    "[Bas94] David A. Basin. Generalized Rewriting in Type Theory\n",
    "A Semi-reflexive Tactic for (Sub-)Equational Reasoning  Claudio Sacerdoti Coen\n",
    "\n",
    "Andrew McCreight. Practical tactics for separation logic\n",
    "Nick Benton and Nicolas Tabareau. Compiling Functional Types to Relational Specifications for Low Level Imperative Code. used generalized rewriting for their tactics?\n",
    "\n",
    "\n",
    "https://maude.cs.illinois.edu/w/images/0/0f/BMgrt_2003.pdf  Generalized Rewrite Theories -Roberto Bruni12 and Jos´e Mesegue . Maude. Kind of hartd to read. This might be getting at some of the same stuff. Yes.  E and R.\n",
    "\n",
    "\n",
    "https://en.wikipedia.org/wiki/Refinement_calculus\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d35b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.all import *\n",
    "State = smt.DeclareSort(\"State\")\n",
    "Rel = smt.ArraySort(State, State, smt.BoolSort()) # Pair -> Bool?\n",
    "\n",
    "comp = smt.Function(\".\", Rel, Rel, Rel)\n",
    "kd.notation.matmul.register(Rel, comp)\n",
    "id = smt.Const(\"id\", Rel)\n",
    "R,S,T = smt.Consts(\"R S T\", Rel)\n",
    "id.left = kd.axiom(smt.ForAll([R], id @ R == R))\n",
    "id.right = kd.axiom(smt.ForAll([R], R @ id == R))\n",
    "comp.assoc = kd.axiom(smt.ForAll([R, S, T], (R @ S) @ T == R @ (S @ T)))\n",
    "\n",
    "le = smt.Function(\"<=\", Rel, smt.BoolSort())\n",
    "kd.notation.le.register(Rel, le)\n",
    "\n",
    "le.trans = kd.axiom(kd.QForAll([R, S, T], le(R, S) & le(S, T), le(R, T)))\n",
    "le.refl = kd.axiom(kd.QForAll([R], le(R, R)))\n",
    "le.antisym = kd.axiom(kd.QForAll([R, S],\n",
    "    le(R, S) & le(S, R) >> (R == S)))\n",
    "\n",
    "# I could define them, but yolo\n",
    "\n",
    "Set = smt.ArraySort(State, smt.BoolSort())\n",
    "dom = smt.Function(\"dom\", Rel, Set)\n",
    "cod = smt.Function(\"cod\", Rel, Set)\n",
    "\n",
    "conv = smt.Function(\"conv\", Rel, Rel)\n",
    "conv.id = kd.axiom(smt.ForAll([R], conv(id) == id))\n",
    "conv.comp = kd.axiom(smt.ForAll([R, S], conv(R @ S) == conv(S) @ conv(R)))\n",
    "conv.inv = kd.axiom(smt.ForAll([R], conv(conv(R)) == R))\n",
    "\n",
    "join = smt.Function(\"join\", Rel, Rel, Rel)\n",
    "kd.notation._or.register(Rel, join)\n",
    "join.comm = kd.axiom(smt.ForAll([R, S], R | S == S | R))\n",
    "join.assoc = kd.axiom(smt.ForAll([R, S, T], (R | S) | T == R | (S | T)))\n",
    "join.le = kd.axiom(smt.ForAll([R, S], R <= R | S))\n",
    "join.univ = kd.axiom(smt.ForAll([R,S,T], ((R | S) <= T) == (R <= T) & (S <= T)))\n",
    "\n",
    "top = smt.Const(\"top\", Rel)\n",
    "bot = smt.Const(\"bot\", Rel)\n",
    "\n",
    "const = smt.Function(\"const\", State, Rel)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096b31da",
   "metadata": {},
   "source": [
    "# Setlog and set constraints\n",
    "See clp_set notes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542bea6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fccbadd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /tmp/stuff.pl\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/stuff.pl\n",
    "\n",
    "hello(\"world\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "179a04c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[w,o,r,l,d]"
     ]
    }
   ],
   "source": [
    "! scryer-prolog /tmp/stuff.pl -g 'hello(X), write(X), halt.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76a685d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/minikan.rkt\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/minikan.rkt\n",
    "#lang racket\n",
    "(require minikanren)\n",
    "\n",
    "(run* (q) (== q 'hello-world))\n",
    "(run* (q) (fresh (x) (== x 'hello) (== q x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a98e400f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'(hello-world)\n",
      "'(hello)\n"
     ]
    }
   ],
   "source": [
    "! racket /tmp/minikan.rkt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc368f6b",
   "metadata": {},
   "source": [
    "# Refinement Closure\n",
    "---\n",
    "title: Congruence Closure becomes Refinement Closure for Refinement E-graphs\n",
    "---\n",
    "Using the term E-graph maybe is a bit of a misnomer.\n",
    "\n",
    "Even in refinement reasoning, equalities are pretty prevalent.\n",
    "\n",
    "Congruence closure generalizes to refinement closure\n",
    "\n",
    "cong close saturates\n",
    "x = y -> f(x) = f(y)\n",
    "\n",
    "\n",
    "ref closure saturates\n",
    "x <= y -> f(x) <= f(y) for monotonic\n",
    "x <= y -> f(y) <= f(x) for anti-monotonic\n",
    "\n",
    "\n",
    "x0 <=^p0 y0, x1 <=^p1 y1, ... -> f(x0,x1,x2,...) <= f(y0, y1, y2,...)\n",
    "\n",
    "\n",
    "Where pn are the polarity of position n in the function symbol f.\n",
    "\n",
    "Arrow in subtyping has polarity signature\n",
    "arr(-,+)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "parents and upper are similar beasts kind of.\n",
    "\n",
    "Is there a relationship between the dpeendent egraph and refinement egraph. Types kind of givey ou a handle on partiality.\n",
    "\n",
    "\n",
    "Yea, maybe this is a point towards egglog.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858f3cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class REGraph():\n",
    "    def __init__(self):\n",
    "        self.enodes = {}\n",
    "\n",
    "    def rebuild(self):\n",
    "        # The quadatic loop version\n",
    "        for enode1 in enodes:\n",
    "            for node2 in enodes:\n",
    "                if all(self.uf.is_le(x,y) in zip(enode.args, enodes1.args)):\n",
    "                    self.uf.assert_le(enode1, enode2)\n",
    "        \n",
    "        for enode1 in enodes:\n",
    "            # search through all upper sets of args\n",
    "            # we can prune though things with smallest args set\n",
    "            # indeed, good joins cure a lot of wounds.\n",
    "        \n",
    "        # alternative: Fill out the upper set of args\n",
    "        for enode in enodes:\n",
    "            for a in self.uf.le_set(enode.args[0]):\n",
    "                e1 = self.enodes.get_make(enode with a)\n",
    "                self.uf.assert_le(a, e1)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a111c2",
   "metadata": {},
   "source": [
    "# Datalog Model\n",
    "Datalog / Relational / Flattened model\n",
    "\n",
    "Egglog also has datalog model. brute force eq(x,y) relation with symmettry and transitivity moves.\n",
    "\n",
    "Refinement closure can either brute fore\n",
    "\n",
    "```\n",
    "f(x,y) ~  f(x,y,res) relation\n",
    "\n",
    "% refinement closure\n",
    "\n",
    "% don't generate new symbols\n",
    " le(z,z1) :- f(x, z), le(x, y), f(y, z1)\n",
    "\n",
    "% Do generate new f ids\n",
    "set f(y) <= z :- f(x) = z, x <= y\n",
    "\n",
    "```\n",
    "\n",
    "Generalized rewriting coq\n",
    "FOLDS.\n",
    "Lessons that baking in boring congruence may not be what you want. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed5da8b",
   "metadata": {},
   "source": [
    "# Ground Ordered Chaining\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf6ad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "type le = list[tuple[object,object]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9b7dee",
   "metadata": {},
   "source": [
    "## Chain UF\n",
    "\n",
    "The idea of an approximate LE via carefully picking how parents work is interesting.\n",
    "Is there a domain where this can be thought of as precise? Not general partial order.\n",
    "Maybe it can be precise if we guarantee a maximum width?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e2c421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do you best to try and store good chains. https://en.wikipedia.org/wiki/Partially_ordered_set#Derived_notions\n",
    "# chains are kind of like parent\n",
    "class LEFind():\n",
    "  chain0 : list[int]\n",
    "  chain1 : list[int]\n",
    "\n",
    "  def union(self, a, b): ...\n",
    "    # seek lowest common ancestor?\n",
    "\n",
    "  # .. chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff3d110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac9ce36e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63584077",
   "metadata": {},
   "source": [
    "# biunify kata\n",
    "\n",
    "Everything I can do with terms\n",
    "- matching\n",
    "- unification\n",
    "- egraphs\n",
    "- knuth bendix\n",
    "- subterm\n",
    "\n",
    "\n",
    "Can i extend to \"bi\" versions?\n",
    "\n",
    "- BiProlog . BiKanren\n",
    "\n",
    "Based on the LEfind, should bi substutuitions be done as\n",
    "{eq : , upper : [] , lower : []}\n",
    "Presumably the equality case is more common (?) so should be pulled out. \n",
    "`(<= a b)` in minikanren would branch or assert?\n",
    "bi is the analog of e-unification in many respects.\n",
    "So look more towards FLP for inspiration?\n",
    "\n",
    "Would LEFind be useful for a CLP(Set)?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6876024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type bisubst = tuple[dict,dict]\n",
    "def apply(pat, bisubst): ...\n",
    "def bimatch(t, pat): ...\n",
    "def biunify(): ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6752befc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.all import *\n",
    "def le_unify(t1, t2): \n",
    "    upsubst : dict[object, list[object]]= {} # nondet substitution\n",
    "    downsubst = {}\n",
    "    eqsubst : dict[object, object] = {} # equality substitution\n",
    "\n",
    "    todo = [[(t1,t2)]]\n",
    "    while todo:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0636b356",
   "metadata": {},
   "source": [
    "# smt egraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39dc7ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "@dataclass\n",
    "class LEFind():\n",
    "    parents : dict\n",
    "    upper : defaultdict(set)\n",
    "    lower : defaultdict(set)\n",
    "    def __init__(self):\n",
    "        self.parents = {}\n",
    "        self.upper = defaultdict(set)\n",
    "        self.lower = defaultdict(set)\n",
    "    def assert_le(self, x, y): # assert to LEFind that x <= y\n",
    "        x,y = self.find(x), self.find(y)\n",
    "        if x == y:\n",
    "            return\n",
    "        self.upper[x].add(y)\n",
    "        self.lower[y].add(x)\n",
    "        if self.is_le(y, x): # propagate antisymmettry x <= y and y <= x implies x == y\n",
    "            self.union(x, y)\n",
    "            for z in self.le_set(x) & self.ge_set(y): # anything between the two is squeezed\n",
    "                self.union(z, y)\n",
    "            for z in self.le_set(y) & self.ge_set(x): # anything between the two is squeezed. Is this redundant?\n",
    "                self.union(z, x)\n",
    "    def assert_ge(self, x, y): # assert to LEFind that x >= y\n",
    "        self.assert_le(y, x)\n",
    "    def union(self, x, y): # assert that x == y\n",
    "        x, y = self.find(x), self.find(y)\n",
    "        if x != y:\n",
    "            self.parents[x] = y # refular union find\n",
    "            self.upper[y].update(self.upper[x]) # merge upper sets\n",
    "            self.lower[y].update(self.lower[x]) # merge lower sets\n",
    "    def find(self, x : int) -> int:\n",
    "        while x in self.parents:\n",
    "            x = self.parents[x]\n",
    "        return x\n",
    "    # The next 3 functions are very similar. is_le can early stop when it hits y.\n",
    "    def is_le(self, x, y) -> bool:\n",
    "        # DFS search for y in upper set of x\n",
    "        x,y = self.find(x), self.find(y)\n",
    "        if x == y:\n",
    "            return True\n",
    "        todo = [x]\n",
    "        seen = set(todo)\n",
    "        while todo:\n",
    "            x = todo.pop() # invariant is that x is already representative\n",
    "            for z in self.upper[x]:\n",
    "                # Is there a way to use lower set for pruning?\n",
    "                z = self.find(z)   # compression could be updating z in place in upper[x]\n",
    "                if z == y:\n",
    "                    return True\n",
    "                elif z not in seen:\n",
    "                    seen.add(z)\n",
    "                    todo.append(z)\n",
    "        return False\n",
    "    def le_set(self, x) -> set[int]: # all solutions to x <= ?\n",
    "        x = self.find(x)\n",
    "        todo = [x]\n",
    "        seen = set(todo)\n",
    "        while todo:\n",
    "            x = todo.pop()\n",
    "            for z in self.upper[x]:\n",
    "                z = self.find(z)\n",
    "                if z not in seen:\n",
    "                    seen.add(z)\n",
    "                    todo.append(z)\n",
    "        return seen\n",
    "    def ge_set(self, x) -> set[int]: # all solutions to x >= ?\n",
    "        x = self.find(x)\n",
    "        todo = [x]\n",
    "        seen = set(todo)\n",
    "        while todo:\n",
    "            x = todo.pop()\n",
    "            for z in self.lower[x]:\n",
    "                z = self.find(z)\n",
    "                if z not in seen:\n",
    "                    seen.add(z)\n",
    "                    todo.append(z)\n",
    "        return seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a86b74",
   "metadata": {},
   "source": [
    "Hmm. You know, if there is no further interpretation of le, Having the solver backed version does not help anything.\n",
    "\n",
    "FALSE. Kind of. Refinement closure. But we can't express monotonicty to smt without using quantiufiers.\n",
    "\n",
    "forall x <= y -> f(x) <= f(y)\n",
    "\n",
    "There is also an issue that I don't really know how to encode a model of undefinedness into SMT.\n",
    "The relational model? That's more like the contextual egraph right?\n",
    "The option model?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3be81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.solvers.egraph import EGraph\n",
    "\n",
    "class LEGraph(EGraph):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lefind = LEFind()\n",
    "        self.le_prim = smt.Function(\"le\", smt.IntSort(), smt.IntSort(), smt.BoolSort())\n",
    "        self.le = smt.TransitiveClosure(self.le_prim)\n",
    "    \n",
    "    def assert_le(self, x, y):\n",
    "        self.lefind.assert_le(x, y)\n",
    "        self.solver.add(self.le_prim(x, y))\n",
    "\n",
    "    def is_le(self, x, y):\n",
    "        return self.lefind.is_le(x, y)\n",
    "        with self.solver:\n",
    "            self.solver.add(smt.Not(self.le(x, y)))\n",
    "            return self.solver.check() == smt.unsat\n",
    "    def le_set(self, x):\n",
    "        return self.lefind.le_set(x)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6559ece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EGraph():\n",
    "    lefind : LEFind\n",
    "    enodes : dict\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "philzook58.github.io",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
