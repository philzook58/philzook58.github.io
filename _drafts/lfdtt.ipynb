{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9520b6e6",
   "metadata": {},
   "source": [
    "Lambda : The Ultimate Pain in the Ass\n",
    "Lambda free dependent type theory\n",
    "\n",
    "\n",
    "Replace the complexity of lambda evaluation with the complexity of definitions.\n",
    "\n",
    "Make an rpython interpreter\n",
    "\n",
    "Cody said it's possible to avoid lambda, but incoherent to avoid pi.\n",
    "\n",
    "Why do I get tripped up on Pi?\n",
    "\n",
    "\n",
    "app(Vec, n)\n",
    "app(Fin, n)\n",
    "\n",
    "\n",
    "head : {n} -> Vec succ n -> int\n",
    "\n",
    "head(N) : head_type(N)\n",
    "has_type(head(N), head_type(N))\n",
    "head_type(N) = vec(succ(N))\n",
    "head(N)(cons()) = \n",
    "\n",
    "pi(forall X, ) ?\n",
    "\n",
    "head_type(N) : unin(z)\n",
    "univ(z) : univ(succ(z))\n",
    "\n",
    "\n",
    "concat_type(N, M) = arr(vec(N), vec(M), vec(N + M))\n",
    "\n",
    "so no pi?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47a72e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "class Defn(NamedTuple):\n",
    "    name: str\n",
    "    args: list[str]\n",
    "    body: object\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1107e2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sexp*'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;129m@pg\u001b[39m.production(\u001b[33m\"\u001b[39m\u001b[33msexp : ATOM\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msexp_atom\u001b[39m(p):\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m p[\u001b[32m0\u001b[39m].getstr()\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m parser = \u001b[43mpg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse\u001b[39m(s):\n\u001b[32m     26\u001b[39m     tokens = lexer.lex(s)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/philzook58.github.io/.venv/lib/python3.12/site-packages/rply/parsergenerator.py:176\u001b[39m, in \u001b[36mParserGenerator.build\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    169\u001b[39m     warnings.warn(\n\u001b[32m    170\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mProduction \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m is not reachable\u001b[39m\u001b[33m\"\u001b[39m % unused_prod,\n\u001b[32m    171\u001b[39m         ParserGeneratorWarning,\n\u001b[32m    172\u001b[39m         stacklevel=\u001b[32m2\u001b[39m\n\u001b[32m    173\u001b[39m     )\n\u001b[32m    175\u001b[39m g.build_lritems()\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m \u001b[43mg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_first\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m g.compute_follow()\n\u001b[32m    179\u001b[39m table = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/philzook58.github.io/.venv/lib/python3.12/site-packages/rply/grammar.py:148\u001b[39m, in \u001b[36mGrammar.compute_first\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    146\u001b[39m changed = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nonterminals:\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprod_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[32m    149\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._first(p.prod):\n\u001b[32m    150\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.first[n]:\n",
      "\u001b[31mKeyError\u001b[39m: 'sexp*'"
     ]
    }
   ],
   "source": [
    "import rply\n",
    "lg = rply.LexerGenerator()\n",
    "\n",
    "lg.add(\"LPAREN\", r\"\\(\")\n",
    "lg.add(\"RPAREN\", r\"\\)\")\n",
    "lg.add(\"ATOM\", r\"[a-zA-Z_][a-zA-Z0-9_]*\")\n",
    "#lg.add(\"NUMBER\", r\"[0-9]+\")\n",
    "lg.ignore(r\"\\s+\")\n",
    "lexer = lg.build()\n",
    "\n",
    "pg = rply.ParserGenerator(\n",
    "    # A list of all token names, accepted by the parser.\n",
    "    [\"LPAREN\", \"RPAREN\", \"ATOM\"],\n",
    ")\n",
    "@pg.production(\"sexp : LPAREN sexp RPAREN\")\n",
    "def sexp_paren(p):\n",
    "    return p[1:-1]\n",
    "\n",
    "@pg.production(\"sexp : ATOM\")\n",
    "def sexp_atom(p):\n",
    "    return p[0].getstr()\n",
    "\n",
    "parser = pg.build()\n",
    "\n",
    "def parse(s):\n",
    "    tokens = lexer.lex(s)\n",
    "    return parser.parse(tokens)\n",
    "\n",
    "parse(\"(hello (my name) is philip)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "philzook58.github.io",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
