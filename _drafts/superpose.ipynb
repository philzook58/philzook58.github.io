{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Superposition\n",
    "\n",
    "atomic ground superposition - a contextual union find\n",
    "ground superposition\n",
    "\n",
    "colored egraphs\n",
    "\n",
    "brainiac\n",
    "\n",
    "cruanes slides https://simon.cedeela.fr/assets/jetbrains_2021.pdf\n",
    "\n",
    "blanchette slides https://www.tcs.ifi.lmu.de/lehre/ws-2024-25/atp/slides12-superposition.pdf\n",
    "\n",
    "model is ground rewrite rules = egraph?\n",
    "\n",
    "\n",
    "weidenbach draft?\n",
    "SCL simple clause\n",
    "cdcl and superposition\n",
    "\n",
    "The layering of ordering resolution (set knuth bendix) + equations (term knuth bendix) reminds me of my idea of egraph modulo theory / theory union finds as layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Horn\n",
    "class Clause():\n",
    "    hyps : list[tuple[int,int]] # negative literals\n",
    "    conc : tuple[int,int]\n",
    "\n",
    "\n",
    "\n",
    "def superpose(c1 : Clause, c2 : Clause):\n",
    "    if c1.conc[0] == c2.conc[0]:\n",
    "        x,y = c1.conc[1], c2.conc[1]\n",
    "        if x < y:\n",
    "            x,y = y,x\n",
    "        return Clause(sorted(set(c1.hyps + c2.hyps)), (x,y))\n",
    "\n",
    "def neg_superpose(c1 : Clause, c2 : Clause):\n",
    "\n",
    "def equality_res():\n",
    "    # delete all hyps of the form x=x\n",
    "\n",
    "def factor():\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordered Ground Resolution\n",
    "### Model Building and Completeness\n",
    "Model Existence.\n",
    "\n",
    "We want to pick a particular herbrand model. There are many. Pick an ordering.\n",
    "\n",
    "Minimal herbrand makes sense in the context of datalog / horn clauses...\n",
    "\n",
    "refutation Completeness proofs in general involve building models from saturated clauses (?) Robinson https://web.stanford.edu/class/linguist289/robinson65.pdf\n",
    "\n",
    "In egraphs, we rag on completeness as silly. How silly is it?\n",
    "\n",
    "### Knuth Bendix Analogy\n",
    "Ordered Resolution completes a set of clauses into rules.\n",
    "The rules can convert a ground database into a normal implied form. (The intensional to extensional database. The base facts to the ).\n",
    "\n",
    "Consistency checks `:- a,b,c.` may mean that it is insistent to add certain base facts.\n",
    "\n",
    "\n",
    "\n",
    "Alternative usage.\n",
    "\n",
    "set rewriting = datalog\n",
    "ordered resolution = knuth bendix for set rewriting\n",
    "rewriting (ground) herbrand models.\n",
    "\n",
    "Take a set of extra ground facts and close them out to minimal model that contains them, or possibly say they are inconstiant.\n",
    "\n",
    "certain ground facts are equivalent under the axioms. ordered resolution builds the decision procedure.\n",
    "\n",
    "strata ordering\n",
    "accumulating semantics. obviously confluent if no negation.\n",
    "{a, c} not b --> {d}\n",
    "\n",
    "Convert clauses into datalog rules\n",
    "\n",
    "datalog rules are like rewrite rules. They are oriented clauses.\n",
    "You can run a base set of facts into a caonnical model.\n",
    "Confluence.\n",
    "\n",
    "\n",
    "dually, resolution/superposition is perhaps a generalized e-unification. Negated `p(A) != p(B)` can factor into stuff.\n",
    "\n",
    "### SAT solving comparison\n",
    "sat solvers do not take it an a priori literal ordering. They discover a useful one via heuristics and pivoting.\n",
    "\n",
    "\n",
    "\n",
    "https://types.pl/@sandmouth/113528558531822923\n",
    "\"\"\"\n",
    "there’s a fascinating viewpoint I’ve only become aware of in the last week that sat solvers in a sense do output a minimal model, they just don’t accept a definition of minimality in the form of a literal ordering nor do they output the ordering they discovered (which exists in the form of their internal decision and propagation trail). Ordered resolution by constrast https://lawrencecpaulson.github.io/papers/bachmair-hbar-resolution.pdf takes in an a priori definition of which literals you prefer to be true/false, which in turn tells you how to orient clauses into rules. The maximum positive literal of the clause is the head and any other positive literals become negations in the rule body. It’s a really interesting knob to travel between prolog and datalog and in between. It’s kind of like user defined datalog strata or something. I think this stuff is under explained nor properly translated to a logic programming viewpoint (at least in any reference I’ve read so far)\n",
    "\"\"\"\n",
    "\n",
    "ASP maybe is like SAT except the rule orientations are chosen.\n",
    "What is conflict vs producing is preordianned by user.\n",
    "\n",
    "### Splitting\n",
    "\n",
    "\n",
    "### Logic Programming\n",
    "The combination of the ordering and selection feels like a knob to tweak between prolog and datalog and other things. It would be nice to have a crisper picture of this.\n",
    "\n",
    "- hyperresolution\n",
    "- locking resolution https://www.doc.ic.ac.uk/%7Ekb/MACTHINGS/SLIDES/2013Notes/7LControl4up13.pdf boyer 1973 https://www.cs.utexas.edu/~boyer/boyer-dissertation.pdf\n",
    "- unit resulting resolution\n",
    "\n",
    "ordered resolution as a logic programming language\n",
    "\n",
    "\n",
    "negative literals are goals. The Factoring rule is prolog style unification.\n",
    "\n",
    "\n",
    "```python\n",
    "# idea. preprocessor to convert to clauses + ordering + selection function.\n",
    "# Or write own ordered resolution\n",
    "\n",
    "import lark\n",
    "grammar = \"\"\"\n",
    "rule: head \":-\" selected \"|\" unselected.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "Marking particular predicates as selected or unselected.\n",
    "```\n",
    ":- constraint foo/2.  % means it isn't selected?\n",
    "```\n",
    "\n",
    "Or make it work like LPO. \n",
    "```\n",
    "decl foo : bar. % means it is a constructor and therefore at the bottom precedence.\n",
    "```\n",
    "\n",
    "Interactively saturate with every new definition? That would be a termination check (?)\n",
    "It's kind of like elf or the termination arugments given to dafny / coq / lean etc.\n",
    "\n",
    "\n",
    "`head  -| ctx  :- body.` hypothetical datalog. Maybe a notation for\n",
    "`maxposliteral |  selected   | other`  CHR kind of has a multipart thing. I think in principle its just multiset rewrite rules. Its a conveience to not depelte and reinsert.\n",
    "It is then the theorem provers job to discharge a term ordering that makes the max pos literal, selected literals work.\n",
    "selected literals can emulate hyperresolution.\n",
    "\n",
    "prolog vs E https://wwwlehre.dhbw-stuttgart.de/~sschulz/E/FAQ.html\n",
    "\n",
    "https://web4.ensiie.fr/~guillaume.burel/download/LFAT.pdf focusing and atp. Focusing is a mechanism for describing the imperative nature of prolog or how the sequent claculus is like an imperative machine. https://drops.dagstuhl.de/storage/00lipics/lipics-vol117-mfcs2018/LIPIcs.MFCS.2018.9/LIPIcs.MFCS.2018.9.pdf\n",
    "\n",
    "\n",
    "Termination checking of logic programs.\n",
    "https://www.sciencedirect.com/science/article/pii/0743106692900455  Proving termination properties of prolog programs: A semantic approach\n",
    "https://www.metalevel.at/prolog/termination \n",
    "https://www.cs.unipr.it/cTI/  cTI: A Termination Inference Engine\n",
    "https://github.com/atp-lptp/automated-theorem-proving-for-prolog-verification\n",
    "\n",
    "elf had termination checking. But like simple syntactic.\n",
    "\n",
    "IC3 and CHC.\n",
    "\n",
    "\n",
    "### Ordering\n",
    "\n",
    "Ordering = datalog strata presciprtion\n",
    "\n",
    "Using other term orderings -> datalog termination proofs\n",
    "Or datalog consistency? Having negation but showing you won't derive then underive something.\n",
    "\"dynamic\" stratification\n",
    "This doesn't have a unique minimal model\n",
    "```\n",
    "b :- not a.\n",
    "a :- not b.\n",
    "```\n",
    "\n",
    "This does. Stratification can't cover it though. So how to prove? Term ordering maybe.\n",
    "```\n",
    "b(n) :- not a(n).\n",
    "a(n + 1) :- not b(n), n < 10.\n",
    "```\n",
    "d(1, N)\n",
    "d(2, N) etc\n",
    "\n",
    "There is some kind of redundancy symmettry in brute resolution and people have been fighting it from the beginning basically. Rewynolds, slagle, kowalski\n",
    "\n",
    "https://www.cs.upc.edu/~%7B%7Dalbert/cpo.zip https://arxiv.org/abs/1506.03943 computbility path ordering. compare types first\n",
    "LPO RPO\n",
    "KBO\n",
    "\n",
    "\n",
    "### Selection Functions\n",
    "\n",
    "SL SLD resolution. They use the term selection function.\n",
    "https://www.sciencedirect.com/science/article/abs/pii/0004370271900129 Linear resolution with selection function kowalski kuehner\n",
    "https://en.wikipedia.org/wiki/SLD_resolution SLD resolution is so named S is for selection\n",
    "\n",
    "\n",
    "Selection functions. \n",
    "p :- not p, not q, z | a,b,c.\n",
    "Some kind of CLP like syntax. \n",
    "Maximalnegative/minimal does perhaps seem the most prolog like.  \n",
    "\n",
    "Selection is like a goal ordering. a prolog rule p :- q,r,s. tries to deal with q, r, s in syntactic order. q would be selected.\n",
    "But if prolog had more delcarative semantics, there might be some way for the system to pick from q,r,s as the next direction work on.\n",
    "\n",
    "\n",
    "### Saturation and Proof by Consistency\n",
    "inductionless induction\n",
    "\n",
    "\n",
    "If we have a termination criteria / strata criteria for our prolog / datalog program, can we convert that to selection functions and a term ordering.\n",
    "\n",
    "The prcendence gnerating routines of E seem like a nice way to fill in gaps. Syntax for constraints that put precedence or weight constraints.\n",
    "\n",
    "Inductionless induction could be used to prove negations at lower levels?\n",
    "The similaity of using induction to prove consistent (has model) is mentioned in paramodulation chapter of handbook\n",
    "\n",
    "\n",
    "### Sequents\n",
    "Resolution doesn't seem to really be about classical first order logic.\n",
    "neg and positive literals can be interpreted as parts of sequent. Resolution is cut.\n",
    "Bachmair and ganzinger vaguely allude to macro proof steps\n",
    "\n",
    "\n",
    "### Chaining\n",
    "\n",
    "\"bi-rweriting a term rewriting techniqyue for monotonic order relaTIONS\" levy and agusty https://www.iiia.csic.es/~levy/papers/RTA93.pdf\n",
    "https://pdf.sciencedirectassets.com/272990/1-s2.0-S1571066100X00631/1-s2.0-S1571066104002968/main.pdf Knuth-Bendix Completion for Non-Symmetric\n",
    "Transitive Relations struith\n",
    "https://opus.bibliothek.uni-augsburg.de/opus4/frontdoor/index/index/year/2006/docId/229 Termination of ground non-symmetric Knuth-Bendix completion\n",
    "\n",
    "chaining slagle 72\n",
    "infinitary depth first search... ?\n",
    "two rewrite relations. < + termorder and < + opptermorder\n",
    "\n",
    "ordered chaining for total orderings https://link.springer.com/chapter/10.1007/3-540-58156-1_32\n",
    "\n",
    "Rewrite Techniques for Transitive Relations\n",
    "\n",
    "\n",
    "\n",
    "## Misc\n",
    "\n",
    "\n",
    "\n",
    "https://people.mpi-inf.mpg.de/~mfleury/paper/Weidenback_Book_CDCL.pdf\n",
    "Weidenbach chapter 2 draft\n",
    "\n",
    "https://core.ac.uk/download/303691264.pdf  Formalizing the metatheory of logical calculi and automatic provers in Isabelle/HOL\n",
    "(invited talk)\n",
    "Blanchette, Jasmin Christian\n",
    "\n",
    "https://www.tcs.ifi.lmu.de/lehre/ws-2024-25/atp/paper.pdf  Automated Theorem Proving∗ Dr. Uwe Waldmann\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Types are dsichagred differently. see weidnebach chapter.\n",
    "Type check ~ static. \n",
    "A stratification of inference.\n",
    "Stratification either comes from orderings, or explicit quasiquote thingy. Like z3py meta. Like two level type kovacs. like metaocaml. like HOL quote carette and farmer https://arxiv.org/abs/1802.00405\n",
    "One could implement a quote mechanism inside of an ATP. Kind of an interesting idea.\n",
    "\n",
    "\n",
    "\n",
    "Saturated clauses -> minimal model (according to that ordering)\n",
    "Alterantive - push pop search in order of ordering to SAT solver.\n",
    "Can cut out branches that are unsat.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Bachmair and ganzinger in handbook\n",
    "https://www.isa-afp.org/entries/Functional_Ordered_Resolution_Prover.html\n",
    "\n",
    "hypothetical datalog?\n",
    " |- \n",
    "Ground database\n",
    "\n",
    "\n",
    "minimal proofs\n",
    "\n",
    "\n",
    "https://rg1-teaching.mpi-inf.mpg.de/autrea-ws21/notes-3d.pdf ordered resolution with selection waldemann.\n",
    "\n",
    "https://www.tcs.ifi.lmu.de/lehre/ws-2024-25/atp_de.html\n",
    "https://www.tcs.ifi.lmu.de/lehre/ws-2024-25/atp/slides05-resolution.pdf\n",
    "ordering stratifies clause set by their maximal atom\n",
    "\n",
    "polynomial unification. Restrict unfication to do small terms first\n",
    "(guassian pivoting?)\n",
    "\n",
    "\n",
    "https://dl.acm.org/doi/pdf/10.1145/321420.321428 slagle 1967\n",
    "\n",
    "Building a model from a saturation.\n",
    "\n",
    "switching from ground to nonground makes > become !<=\n",
    "\n",
    "sequent calculus and resolution. Cut or macro rules?\n",
    "The multiset chjaracter of alsues makes permutation symettry\n",
    "\n",
    "\n",
    "stratified resolution\n",
    "\n",
    "\n",
    "2-sat ~ congruence closure?\n",
    "\n",
    "`a | b` orients to `a :- b`\n",
    "\n",
    "a | b | c. is a 3 way symmettric thing.\n",
    "\n",
    "Multiequations a = b = c ? Could that be cogent?\n",
    "a = b = c as a triangle. higher dimesional rewriting. ab -> c oriented.\n",
    "Hmm. kind of jives with the equations = paths stuff.\n",
    "unification sometimes uses the term.\n",
    "a = b | c = d\n",
    "\n",
    "Bachmair\n",
    "Ganzigner\n",
    "Niewenhuis https://www.cs.upc.edu/~roberto/\n",
    "Rubio https://www.cs.upc.edu/~albert/ https://link.springer.com/chapter/10.1007/978-3-642-31585-5_21 nominal completion\n",
    "waldemann https://dblp.org/pid/w/UweWaldmann.html\n",
    "weidenbach\n",
    "stickel\n",
    "wayne snyder\n",
    "hillenbrand\n",
    "kuehner\n",
    "kowalski\n",
    "slagle\n",
    "veroff\n",
    "wos\n",
    "suda\n",
    "loveland\n",
    "blanchette\n",
    "bledsoe\n",
    "gallier\n",
    "baader\n",
    "nipkow\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "https://resources.mpi-inf.mpg.de/SATURATE/Saturate.html\n",
    "https://resources.mpi-inf.mpg.de/SATURATE/doc/Saturate/node11.html\n",
    "transitive relations have special inference rule. chaining. paramdodulation is an instance...\n",
    "\n",
    "Loveland book\n",
    "\n",
    "https://link.springer.com/article/10.1007/BF01190829 1994 ganziner bachmair waldeman\n",
    "\n",
    "whoa. this is insane https://people.mpi-inf.mpg.de/alumni/ag2/2011/hg/index/index7.html\n",
    "I need to read like ganzinger's entire work\n",
    "especially part 2.\n",
    "\n",
    "mcallester. steensgard analysis\n",
    "\n",
    "https://www3.risc.jku.at/conferences/rta2008/slides/Slides_Hillenbrand.pdf hillenbrand waldmeisetrt. in mathematica?\n",
    "\n",
    "lock resolution\n",
    "\"the inverse method can also be encoded\"\n",
    "\n",
    "Bachmair and Ganzinger\n",
    "\"non-clausal reoslution and superposition wioth seelction and redunancy criteri\"\n",
    "\"perfoect model semantics for logic programs with equality\"\n",
    "\"rewirte based equational theorem proving with selection and simplification\"\n",
    "\"rewrite techniques with transitive relations\"\n",
    "\"ordered chaining for total orderings\"\n",
    "\n",
    "\n",
    "\n",
    "https://www.sciencedirect.com/science/article/pii/S0890540106000617?via%3Dihub  Modular proof systems for partial functions with Evans equality. Total and partial functions\n",
    "Kuper  https://www.sciencedirect.com/science/article/pii/S0890540183710631  An Axiomatic Theory for Partial Functions\n",
    "https://www21.in.tum.de/students/set_theory_partial_functions/index.html Formalising Set Theory Based on Partial Functions\n",
    "https://page.mi.fu-berlin.de/cbenzmueller/papers/C57.pdf  Automating Free Logic in Isabelle/HOL\n",
    "\n",
    "Man a return to form of category theory blog post 0. Flat is good anyway.\n",
    "Avoiding junk elements is good.\n",
    "Fun,El,El choiuce is like SEAR\n",
    "Fun,Fun,Fun choice is like ETCS\n",
    "\n",
    "subsets are partial functions to bool.\n",
    "f(x) undef means x isn't in domain.\n",
    "f(x) = false means not in subset\n",
    "f(x) = true means in subset\n",
    "\n",
    "\n",
    "```\n",
    "DeclareSort(\"Fun\")\n",
    "# apply as ternary\n",
    "apply = Function(\"apply\", Fun, El, El, BoolSort()) # Fun Fun Fun?\n",
    "undef = define(\"undef\", [f,x], Not(Exists([y], apply(f,x,y))))\n",
    "# f.x ~ y   notation for apply(f,x,y) is nice. Hard to see how to do this in python. Could make parser. Or overload __eq__ to check for a call. Hmmmm.\n",
    "\n",
    "\"\"\" put partial application at metalevel.\"\"\"\n",
    "\n",
    "class PApply():\n",
    "    f : Fun\n",
    "    x : PApply | Fun # enable recursive expressions.\n",
    "    def __eq__(self, y):\n",
    "        if isinstance(y, ExprRef):\n",
    "            return apply(self.f, self.x, y)\n",
    "    def __call__(self, y):\n",
    "        return PApply(self, y)\n",
    "    def defined(self):\n",
    "        return Exists([y], self == y)\n",
    "\n",
    "def apply_eq(fx,y):\n",
    "    if is_app(fx) and  fx.decl() == apply:\n",
    "        return return fx[2] == y\n",
    "    else:\n",
    "    return apply(fx[0],fx[1],y)\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "https://github.com/NikolajBjorner/ShonanArtOfSAT/blob/main/AkihisaYamada-slides.pdf \n",
    "satisfiability modulo rewriting\n",
    "WP\n",
    "CPO\n",
    "HORPO\n",
    "\n",
    "\n",
    "\n",
    "books \n",
    "troesltra\n",
    "pohlers proof thoery\n",
    "takeuti\n",
    "zach proof theory\n",
    "handbook of proof theory\n",
    "girard\n",
    "\n",
    "kleene metamartrhemtics\n",
    "computability theory by \n",
    "\n",
    "\n",
    "theory resolution stickel 1985\n",
    "\n",
    "vampire for QBF?\n",
    "```\n",
    "cnf( v(B) | v(c) )\n",
    "v(skolem(A))\n",
    "```\n",
    "\n",
    "vampire for modal / intuitonsitc? Judicious choice of ordering /precdence to help?\n",
    "https://ieeexplore.ieee.org/document/848641 Chaining techniques for automated theorem proving in many-valued logics\n",
    "\n",
    "\n",
    "nonclausal resolution\n",
    "https://www.sciencedirect.com/science/article/pii/S0890540105000258 Superposition with equivalence reasoning and delayed clause normal form transformation\n",
    "\n",
    "### Saturate\n",
    "https://resources.mpi-inf.mpg.de/SATURATE/Saturate.html\n",
    "INteresting system. Interesting example files.\n",
    "I doubt I can get this running\n",
    "\n",
    "Saturation of first-order (constrained) clauses with the Saturate system https://dl.acm.org/doi/10.5555/647193.720661\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clauses as sorted list\n",
    "# use integer ids. negative for negative literals if we want those to come first?\n",
    "atoms = []\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pick the (name, neg) encoding because in python \n",
    "{A,A} is neg lit\n",
    "{A} is pos lit\n",
    "\n",
    "is the same ordering as\n",
    "\n",
    "(A, True) is neg lit\n",
    "(A, False) is pos lit\n",
    "\n",
    "\n",
    "Lesser things are \"simpler\" in some sense. \"Smaller\". We try to eliminate to lesser things.\n",
    "\n",
    "Given saturated clause set, contruct model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('0b', False), ('0a', False)],\n",
       " [('1a', False), ('0b', False)],\n",
       " [('1a', False), ('0b', True)],\n",
       " [('1b', False), ('1b', False), ('0b', True), ('0b', True)],\n",
       " [('2a', False), ('1b', False), ('0b', True)],\n",
       " [('2a', True), ('1b', False), ('0b', True)],\n",
       " [('2b', False), ('1b', True)]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def c(*ls): return sorted(ls,reverse=True, key=lambda x: (x[0], x[1]))\n",
    "def l(atom, neg=False): return (atom,neg)\n",
    "def cset(*cs): return sorted(cs)\n",
    "def maxlit(c): return c[0]\n",
    "def maxatom(c): return c[0][0]\n",
    "\n",
    "b0,a0,b1,a1,b2,a2 = map(lambda x: l(x), \"0b 0a 1b 1a 2b 2a\".split())\n",
    "nb0, na0, nb1, na1, nb2, na2 = map(lambda x: l(x, neg=True),  \"0b 0a 1b 1a 2b 2a\".split())\n",
    "\n",
    "N = cset(\n",
    "    c(b0, a1),\n",
    "    c(a0, b0),\n",
    "    c(nb0, a1),\n",
    "    c(nb0, b1, nb0, b1),\n",
    "    c(nb0, a2, b1),\n",
    "    c(nb0, na2, b1),\n",
    "    c(nb1, b2),\n",
    ")\n",
    "N\n",
    "#def Ic(n): return sum(epsC(n) for i in range(n))\n",
    "#def epsC(n): return {maximal(N[n])} if  else set()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set() [('0b', False), ('0a', False)] False\n",
      "{'0b'} [('1a', False), ('0b', False)] True\n",
      "{'0b'} [('1a', False), ('0b', True)] False\n",
      "{'1a', '0b'} [('1b', False), ('1b', False), ('0b', True), ('0b', True)] False\n",
      "{'1a', '0b', '1b'} [('2a', False), ('1b', False), ('0b', True)] True\n",
      "{'1a', '0b', '1b'} [('2a', True), ('1b', False), ('0b', True)] True\n",
      "{'1a', '0b', '1b'} [('2b', False), ('1b', True)] False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0b', '1a', '1b', '2b'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def interp(model, clause): \n",
    "    for atom, neg in clause:\n",
    "        if neg:\n",
    "            if atom not in model:\n",
    "                return True\n",
    "        else:\n",
    "            if atom in model:\n",
    "                return True\n",
    "    return False\n",
    "    #return any(atom not in model if neg else atom in model for (atom, neg) in model)\n",
    "Ic = set()\n",
    "for c in N:\n",
    "    print(Ic, c, interp(Ic, c))\n",
    "    if not interp(Ic, c):\n",
    "        atom,neg = maxlit(c)\n",
    "        if neg:\n",
    "            raise Exception(\"counterexample\", c, Ic)\n",
    "        Ic.add(atom)\n",
    "Ic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selection functions take in clause and select some subset of the negative literals.\n",
    "\n",
    "Negative and positive literals are not treated symmetrically by the model generation process.\n",
    "A little odd. I think we could have the model generation have everything true by default and derive not trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allsel(c): return [atom for (atom, neg) in c if neg]\n",
    "def nonesel(c): return []\n",
    "def maxsel(c): return max(allsel(c))\n",
    "def minsel(c): return min(allset(c))\n",
    "\n",
    "def ordered_resolve(pc,nc): # positive and negative clause\n",
    "    (a,neg) = maxlit(pc)\n",
    "    assert not neg\n",
    "    (b,neg) = maxlit(nc)\n",
    "    assert neg\n",
    "    assert a == b\n",
    "    return cset(pc[1:] + nc[1:])\n",
    "\n",
    "# https://www.tcs.ifi.lmu.de/lehre/ws-2024-25/atp/slides07-more-resolution.pdf\n",
    "def resolve_osel(pc,nc,sel):\n",
    "    assert len(sel(pc)) == 0\n",
    "    a,neg = maxlit(pc)\n",
    "    assert not neg\n",
    "    bs = sel(nc)\n",
    "    if len(bs) == 0:\n",
    "        b,neg = maxlit(nc)\n",
    "        assert neg\n",
    "        return cset(pc[1:] + nc[1:])\n",
    "    else:\n",
    "        for b in bs:\n",
    "            if b == a:\n",
    "                c = nc.copy().remove((b,True))\n",
    "                c.extend(pc[1:])\n",
    "                return cset(c)\n",
    "\n",
    "def factor(c,sel):\n",
    "    a,neg = maxlit(c)\n",
    "    assert c[1] == (a, neg)\n",
    "    assert len(sel(c) == 0)\n",
    "    return c[2:]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the any subsumption/redundant rules that work on ordered ground resolution?\n",
    "\n",
    "Connection to SAT search (counterexample clauses? unit propagate )\n",
    "Connection to sequents and other logics. Mega steps of inference\n",
    "\n",
    "abstract dpll\n",
    "https://gist.github.com/kmicinski/17dffc8b2cbbd4f3264071e19ae75dfa See this paper: https://homepage.cs.uiowa.edu/~tinelli/papers/NieOT-JACM-06.pdf\n",
    "\n",
    "Otter vs discount loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def clausedict(cs):\n",
    "    pcs,ncs = defaultdict(list),defaultdict(list)\n",
    "    for c in cs:\n",
    "        a,neg = maxlit(c)\n",
    "        if neg:\n",
    "            ncs[a].append(c)\n",
    "        else:\n",
    "            pcs[a].append(c)\n",
    "    return pcs,ncs\n",
    "\n",
    "def saturate(N):\n",
    "    passive = N\n",
    "    active = []\n",
    "    while passive:\n",
    "        passive.pop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A term ordering gives a clause ordering.\n",
    "\n",
    "Producing clauses.\n",
    "A tern ordering turns a set of clauses into a model generating datalog / prolog program\n",
    "The produced maximal atom is the head of a clause. \n",
    "The strata are the levels.\n",
    "\n",
    "This is ASP like.\n",
    "\n",
    "blanchette had those slides about completeness discussing how models get built\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METIS\n",
    "https://www.gilith.com/metis/\n",
    "ordered paramodulation\n",
    "https://github.com/gilith/metis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eprover\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Union find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/uf.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/uf.p\n",
    "\n",
    "cnf(ax1, axiom, a = b).\n",
    "cnf(ax2, axiom, b = c).\n",
    "cnf(ax2, axiom, z = c).\n",
    "cnf(ax3, axiom, d = e).\n",
    "%cnf(ax4, axiom, d != a)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--print-saturated=teigEIGaA --print-sat-info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eprover: Wrong argument to option -G (--order-precedence-generation). Possible values: none, unary_first, unary_freq, arity, invarity, const_max, const_min, freq, invfreq, invconjfreq, invfreqconjmax, invfreqconjmin, invfreqconstmin, invfreqhack, typefreq, invtypefreq, combfreq, invcombfreq, arrayopt, orient_axioms\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --order-precedence-generation=none"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\"invfreq: Sort symbols by frequency (frequently occurring symbols are smaller).\n",
    "In our experience, this is one of the best general-purpose precedence gen-\n",
    "eration schemes.\"\n",
    "\n",
    "\"The option --literal-comparison=<arg> allow the user to select alterna-\n",
    "tive literal comparison schemes. In particular, literals will be first compared by\n",
    "predicate symbol, and only then by full terms. This is a poor man’s version of\n",
    "transfinite KBO [LW07, KMV11], applied to literals only, but also extended to\n",
    "LPO.\"\n",
    "\n",
    "Ah, if I use `>` unquoted bash thinks its a file redirect\n",
    "\n",
    "\"There are two uses for a watchlist: To guide the proof search (using a heuris-\n",
    "tic that prefers clauses on the watchlist), or to find purely constructive proofs\n",
    "for clauses on the watchlist.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnf(ax1, axiom, (a=b), file('/tmp/uf.p', ax1)).\n",
      "cnf(ax2, axiom, (b=c), file('/tmp/uf.p', ax2)).\n",
      "cnf(ax2, axiom, (z=c), file('/tmp/uf.p', ax2)).\n",
      "cnf(ax3, axiom, (d=e), file('/tmp/uf.p', ax3)).\n",
      "# Initializing proof state\n",
      "# Scanning for AC axioms\n",
      "cnf(c_0_5, plain, (a=c),inference(rw, [status(thm)],[c_0_-9223372036854775799,c_0_-9223372036854775798])).\n",
      "cnf(c_0_6, plain, (b=z),inference(rw, [status(thm)],[c_0_-9223372036854775798,c_0_-9223372036854775797])).\n",
      "cnf(c_0_7, plain, (a=z),inference(rw, [status(thm)],[c_0_5,c_0_-9223372036854775797])).\n",
      "cnf(c_0_8, plain, (c=z), c_0_-9223372036854775797,['final']).\n",
      "cnf(c_0_9, plain, (d=e), c_0_-9223372036854775796,['final']).\n",
      "cnf(c_0_10, plain, (a=z), c_0_7,['final']).\n",
      "cnf(c_0_11, plain, (b=z), c_0_6,['final']).\n",
      "\n",
      "# No proof found!\n",
      "# SZS status Satisfiable\n",
      "# Processed positive unit clauses:\n",
      "cnf(c_0_8, plain, (c=z)).\n",
      "cnf(c_0_9, plain, (d=e)).\n",
      "cnf(c_0_10, plain, (a=z)).\n",
      "cnf(c_0_11, plain, (b=z)).\n",
      "\n",
      "# Processed negative unit clauses:\n",
      "\n",
      "# Processed non-unit clauses:\n",
      "\n",
      "# Unprocessed positive unit clauses:\n",
      "\n",
      "# Unprocessed negative unit clauses:\n",
      "\n",
      "# Unprocessed non-unit clauses:\n",
      "\n",
      "\n",
      "# Parsed axioms                        : 4\n",
      "# Removed by relevancy pruning/SinE    : 0\n",
      "# Initial clauses                      : 4\n",
      "# Removed in clause preprocessing      : 0\n",
      "# Initial clauses in saturation        : 4\n",
      "# Processed clauses                    : 6\n",
      "# ...of these trivial                  : 0\n",
      "# ...subsumed                          : 0\n",
      "# ...remaining for further processing  : 6\n",
      "# Other redundant clauses eliminated   : 0\n",
      "# Clauses deleted for lack of memory   : 0\n",
      "# Backward-subsumed                    : 0\n",
      "# Backward-rewritten                   : 2\n",
      "# Generated clauses                    : 0\n",
      "# ...of the previous two non-redundant : 2\n",
      "# ...aggressively subsumed             : 0\n",
      "# Contextual simplify-reflections      : 0\n",
      "# Paramodulations                      : 0\n",
      "# Factorizations                       : 0\n",
      "# NegExts                              : 0\n",
      "# Equation resolutions                 : 0\n",
      "# Disequality decompositions           : 0\n",
      "# Total rewrite steps                  : 3\n",
      "# ...of those cached                   : 1\n",
      "# Propositional unsat checks           : 0\n",
      "#    Propositional check models        : 0\n",
      "#    Propositional check unsatisfiable : 0\n",
      "#    Propositional clauses             : 0\n",
      "#    Propositional clauses after purity: 0\n",
      "#    Propositional unsat core size     : 0\n",
      "#    Propositional preprocessing time  : 0.000\n",
      "#    Propositional encoding time       : 0.000\n",
      "#    Propositional solver time         : 0.000\n",
      "#    Success case prop preproc time    : 0.000\n",
      "#    Success case prop encoding time   : 0.000\n",
      "#    Success case prop solver time     : 0.000\n",
      "# Current number of processed clauses  : 4\n",
      "#    Positive orientable unit clauses  : 4\n",
      "#    Positive unorientable unit clauses: 0\n",
      "#    Negative unit clauses             : 0\n",
      "#    Non-unit-clauses                  : 0\n",
      "# Current number of unprocessed clauses: 0\n",
      "# ...number of literals in the above   : 0\n",
      "# Current number of archived formulas  : 0\n",
      "# Current number of archived clauses   : 2\n",
      "# Clause-clause subsumption calls (NU) : 0\n",
      "# Rec. Clause-clause subsumption calls : 0\n",
      "# Non-unit clause-clause subsumptions  : 0\n",
      "# Unit Clause-clause subsumption calls : 0\n",
      "# Rewrite failures with RHS unbound    : 0\n",
      "# BW rewrite match attempts            : 2\n",
      "# BW rewrite match successes           : 2\n",
      "# Condensation attempts                : 0\n",
      "# Condensation successes               : 0\n",
      "# Termbank termtop insertions          : 32\n",
      "# Search garbage collected termcells   : 0\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --output-level=4  --print-saturated --term-ordering=KBO6 --precedence=\"a>b>c>d>e>z\" /tmp/uf.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnf(ax1, axiom, (a=b), file('/tmp/uf.p', ax1)).\n",
      "cnf(ax2, axiom, (b=c), file('/tmp/uf.p', ax2)).\n",
      "cnf(ax2, axiom, (z=c), file('/tmp/uf.p', ax2)).\n",
      "cnf(ax3, axiom, (d=e), file('/tmp/uf.p', ax3)).\n",
      "setting user weights\n",
      "# Initializing proof state\n",
      "# Scanning for AC axioms\n",
      "cnf(c_0_5, plain, (a=c),inference(rw, [status(thm)],[c_0_-9223372036854775799,c_0_-9223372036854775798])).\n",
      "cnf(c_0_6, plain, (b=z),inference(rw, [status(thm)],[c_0_-9223372036854775798,c_0_-9223372036854775797])).\n",
      "cnf(c_0_7, plain, (a=z),inference(rw, [status(thm)],[c_0_5,c_0_-9223372036854775797])).\n",
      "cnf(c_0_8, plain, (c=z), c_0_-9223372036854775797,['final']).\n",
      "cnf(c_0_9, plain, (d=e), c_0_-9223372036854775796,['final']).\n",
      "cnf(c_0_10, plain, (a=z), c_0_7,['final']).\n",
      "cnf(c_0_11, plain, (b=z), c_0_6,['final']).\n",
      "\n",
      "# No proof found!\n",
      "# SZS status Satisfiable\n",
      "# Processed positive unit clauses:\n",
      "cnf(c_0_8, plain, (c=z)).\n",
      "cnf(c_0_9, plain, (d=e)).\n",
      "cnf(c_0_10, plain, (a=z)).\n",
      "cnf(c_0_11, plain, (b=z)).\n",
      "\n",
      "# Processed negative unit clauses:\n",
      "\n",
      "# Processed non-unit clauses:\n",
      "\n",
      "# Unprocessed positive unit clauses:\n",
      "\n",
      "# Unprocessed negative unit clauses:\n",
      "\n",
      "# Unprocessed non-unit clauses:\n",
      "\n",
      "\n",
      "# Parsed axioms                        : 4\n",
      "# Removed by relevancy pruning/SinE    : 0\n",
      "# Initial clauses                      : 4\n",
      "# Removed in clause preprocessing      : 0\n",
      "# Initial clauses in saturation        : 4\n",
      "# Processed clauses                    : 6\n",
      "# ...of these trivial                  : 0\n",
      "# ...subsumed                          : 0\n",
      "# ...remaining for further processing  : 6\n",
      "# Other redundant clauses eliminated   : 0\n",
      "# Clauses deleted for lack of memory   : 0\n",
      "# Backward-subsumed                    : 0\n",
      "# Backward-rewritten                   : 2\n",
      "# Generated clauses                    : 0\n",
      "# ...of the previous two non-redundant : 2\n",
      "# ...aggressively subsumed             : 0\n",
      "# Contextual simplify-reflections      : 0\n",
      "# Paramodulations                      : 0\n",
      "# Factorizations                       : 0\n",
      "# NegExts                              : 0\n",
      "# Equation resolutions                 : 0\n",
      "# Disequality decompositions           : 0\n",
      "# Total rewrite steps                  : 3\n",
      "# ...of those cached                   : 1\n",
      "# Propositional unsat checks           : 0\n",
      "#    Propositional check models        : 0\n",
      "#    Propositional check unsatisfiable : 0\n",
      "#    Propositional clauses             : 0\n",
      "#    Propositional clauses after purity: 0\n",
      "#    Propositional unsat core size     : 0\n",
      "#    Propositional preprocessing time  : 0.000\n",
      "#    Propositional encoding time       : 0.000\n",
      "#    Propositional solver time         : 0.000\n",
      "#    Success case prop preproc time    : 0.000\n",
      "#    Success case prop encoding time   : 0.000\n",
      "#    Success case prop solver time     : 0.000\n",
      "# Current number of processed clauses  : 4\n",
      "#    Positive orientable unit clauses  : 4\n",
      "#    Positive unorientable unit clauses: 0\n",
      "#    Negative unit clauses             : 0\n",
      "#    Non-unit-clauses                  : 0\n",
      "# Current number of unprocessed clauses: 0\n",
      "# ...number of literals in the above   : 0\n",
      "# Current number of archived formulas  : 0\n",
      "# Current number of archived clauses   : 2\n",
      "# Clause-clause subsumption calls (NU) : 0\n",
      "# Rec. Clause-clause subsumption calls : 0\n",
      "# Non-unit clause-clause subsumptions  : 0\n",
      "# Unit Clause-clause subsumption calls : 0\n",
      "# Rewrite failures with RHS unbound    : 0\n",
      "# BW rewrite match attempts            : 2\n",
      "# BW rewrite match successes           : 2\n",
      "# Condensation attempts                : 0\n",
      "# Condensation successes               : 0\n",
      "# Termbank termtop insertions          : 32\n",
      "# Search garbage collected termcells   : 0\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --output-level=4  --print-saturated --term-ordering=KBO6 --order-weights=a:9,b:8,c:7,d:6,e:5,z:4 /tmp/uf.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## edge path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/path.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/path.p\n",
    "\n",
    "cnf(ax1, axiom, edge(a,b)).\n",
    "cnf(ax2, axiom, edge(b,c)).\n",
    "cnf(ax2, axiom, path(X,Y) | ~edge(X,Y)).\n",
    "cnf(ax1, axiom, path(X,Z) | ~edge(X,Y) | ~path(Y,Z))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NoSelection - doesm't terminate\n",
    "NoGeneration\n",
    "SelectNegativeLiterals\n",
    "SelectLargestNegLit\n",
    "--precedence=\"path>edge\" \n",
    "-term-ordering=LPO4\n",
    "\n",
    "--literal-selection-strategy=\"SelectSmallestNegLit\" \n",
    "\n",
    "--auto doesn't process the path\n",
    "No selection doesn't terminate.\n",
    "\n",
    "--print-strategy \n",
    "\n",
    "Oh yea. Those non ground are necessary if there is no multi-resolution rule.\n",
    "\n",
    "precedence does not seem to matter to final result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eprover: Wrong argument to option -W (--literal-selection-strategy). Possible values: NoSelection, NoGeneration, SelectNegativeLiterals, PSelectNegativeLiterals, SelectPureVarNegLiterals, PSelectPureVarNegLiterals, SelectLargestNegLit, PSelectLargestNegLit, SelectSmallestNegLit, PSelectSmallestNegLit, SelectLargestOrientable, PSelectLargestOrientable, MSelectLargestOrientable, SelectSmallestOrientable, PSelectSmallestOrientable, MSelectSmallestOrientable, SelectDiffNegLit, PSelectDiffNegLit, SelectGroundNegLit, PSelectGroundNegLit, SelectOptimalLit, PSelectOptimalLit, SelectMinOptimalLit, PSelectMinOptimalLit, SelectMinOptimalNoTypePred, PSelectMinOptimalNoTypePred, SelectMinOptimalNoXTypePred, PSelectMinOptimalNoXTypePred, SelectMinOptimalNoRXTypePred, PSelectMinOptimalNoRXTypePred, SelectCondOptimalLit, PSelectCondOptimalLit, SelectAllCondOptimalLit, PSelectAllCondOptimalLit, SelectOptimalRestrDepth2, PSelectOptimalRestrDepth2, SelectOptimalRestrPDepth2, PSelectOptimalRestrPDepth2, SelectOptimalRestrNDepth2, PSelectOptimalRestrNDepth2, SelectNonRROptimalLit, PSelectNonRROptimalLit, SelectNonStrongRROptimalLit, PSelectNonStrongRROptimalLit, SelectAntiRROptimalLit, PSelectAntiRROptimalLit, SelectNonAntiRROptimalLit, PSelectNonAntiRROptimalLit, SelectStrongRRNonRROptimalLit, PSelectStrongRRNonRROptimalLit, SelectUnlessUniqMax, PSelectUnlessUniqMax, SelectUnlessPosMax, PSelectUnlessPosMax, SelectUnlessUniqPosMax, PSelectUnlessUniqPosMax, SelectUnlessUniqMaxPos, PSelectUnlessUniqMaxPos, SelectComplex, PSelectComplex, SelectComplexExceptRRHorn, PSelectComplexExceptRRHorn, SelectLComplex, PSelectLComplex, SelectMaxLComplex, PSelectMaxLComplex, SelectMaxLComplexNoTypePred, PSelectMaxLComplexNoTypePred, SelectMaxLComplexNoXTypePred, PSelectMaxLComplexNoXTypePred, SelectComplexPreferNEQ, PSelectComplexPreferNEQ, SelectComplexPreferEQ, PSelectComplexPreferEQ, SelectComplexExceptUniqMaxHorn, PSelectComplexExceptUniqMaxHorn, MSelectComplexExceptUniqMaxHorn, SelectNewComplex, PSelectNewComplex, SelectNewComplexExceptUniqMaxHorn, PSelectNewComplexExceptUniqMaxHorn, SelectMinInfpos, PSelectMinInfpos, HSelectMinInfpos, GSelectMinInfpos, SelectMinInfposNoTypePred, PSelectMinInfposNoTypePred, SelectMin2Infpos, PSelectMin2Infpos, SelectComplexExceptUniqMaxPosHorn, PSelectComplexExceptUniqMaxPosHorn, SelectUnlessUniqMaxSmallestOrientable, PSelectUnlessUniqMaxSmallestOrientable, SelectDivLits, SelectDivPreferIntoLits, SelectMaxLComplexG, SelectMaxLComplexAvoidPosPred, SelectMaxLComplexAPPNTNp, SelectMaxLComplexAPPNoType, SelectMaxLComplexAvoidPosUPred, SelectComplexG, SelectComplexAHP, PSelectComplexAHP, SelectNewComplexAHP, PSelectNewComplexAHP, SelectComplexAHPExceptRRHorn, PSelectComplexAHPExceptRRHorn, SelectNewComplexAHPExceptRRHorn, PSelectNewComplexAHPExceptRRHorn, SelectNewComplexAHPExceptUniqMaxHorn, PSelectNewComplexAHPExceptUniqMaxHorn, SelectNewComplexAHPNS, SelectVGNonCR, SelectCQArEqLast, SelectCQArEqFirst, SelectCQIArEqLast, SelectCQIArEqFirst, SelectCQAr, SelectCQIAr, SelectCQArNpEqFirst, SelectCQIArNpEqFirst, SelectGrCQArEqFirst, SelectCQGrArEqFirst, SelectCQArNTEqFirst, SelectCQIArNTEqFirst, SelectCQArNTNpEqFirst, SelectCQIArNTNpEqFirst, SelectCQArNXTEqFirst, SelectCQIArNXTEqFirst, SelectCQArNTNp, SelectCQIArNTNp, SelectCQArNT, SelectCQIArNT, SelectCQArNp, SelectCQIArNp, SelectCQArNpEqFirstUnlessPDom, SelectCQArNTEqFirstUnlessPDom, SelectCQPrecW, SelectCQIPrecW, SelectCQPrecWNTNp, SelectCQIPrecWNTNp, SelectMaxLComplexAvoidAppVar, SelectMaxLComplexStronglyAvoidAppVar, SelectMaxLComplexPreferAppVar\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --literal-selection-strategy=none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eprover: Illegal argument to option --filter-saturated\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --print-saturated --output-level=6 --filter-saturated='u' --literal-selection-strategy=\"SelectSmallestNegLit\" --precedence=\"path<edge\"   /tmp/path.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unification\n",
    "Raw usage. Equality resolution rule ought to put unifier into ans predicate.\n",
    "\n",
    "`er` is equality resolution. Interesting.\n",
    "I needed to give it a selection to make it do this\n",
    "\n",
    "Ah, side condition says u != v has to be eligibile for resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/unify.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/unify.p\n",
    "\n",
    "cnf(ax1, axiom, unifier(a(A),b(B)) | f(g(A)) != f(B)).\n",
    "%cnf(ax1, axiom, g(A) != B  | f(g(A)) != f(B)).\n",
    "% cnf(, ocnjecture, ?[A,B] : f(g(A)) = f(B)).  negate. ![A,B]: ~(f(g(A)) = f(B)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnf(ax1, axiom, (unifier(a(X1),b(X2))|f(g(X1))!=f(X2)), file('/tmp/unify.p', ax1)).\n",
      "cnf(c_0_2, plain, (unifier(a(X1),b(X2))|f(g(X1))!=f(X2)),inference(fof_simplification, [status(thm)],[c_0_1])).\n",
      "# Initializing proof state\n",
      "cnf(c_0_3, plain, (unifier(a(X1),b(X2))|f(g(X1))!=f(X2)), c_0_-9223372036854775804,['eval']).\n",
      "# Scanning for AC axioms\n",
      "cnf(c_0_4, plain, (unifier(a(X1),b(X2))|f(g(X1))!=f(X2)), c_0_3,['new_given']).\n",
      "cnf(c_0_5, plain, (unifier(a(X1),b(g(X1)))),inference(er,[status(thm)],[c_0_4])).\n",
      "cnf(c_0_6, plain, (unifier(a(X1),b(g(X1)))), c_0_5,['eval']).\n",
      "cnf(c_0_7, plain, (unifier(a(X1),b(g(X1)))), c_0_6,['new_given']).\n",
      "cnf(c_0_8, plain, (unifier(a(X1),b(g(X1)))), c_0_7,['final']).\n",
      "cnf(c_0_9, plain, (unifier(a(X1),b(X2))|f(g(X1))!=f(X2)), c_0_4,['final']).\n",
      "\n",
      "# No proof found!\n",
      "# SZS status Satisfiable\n",
      "# SZS output start Saturation\n",
      "cnf(ax1, axiom, (unifier(a(X1),b(X2))|f(g(X1))!=f(X2)), file('/tmp/unify.p', ax1)).\n",
      "cnf(c_0_1, plain, (unifier(a(X1),b(X2))|f(g(X1))!=f(X2)), inference(fof_simplification,[status(thm)],[ax1])).\n",
      "cnf(c_0_2, plain, (unifier(a(X1),b(X2))|f(g(X1))!=f(X2)), c_0_1, ['final']).\n",
      "cnf(c_0_3, plain, (unifier(a(X1),b(g(X1)))), inference(er,[status(thm)],[c_0_2]), ['final']).\n",
      "# SZS output end Saturation\n",
      "# Processed positive unit clauses:\n",
      "cnf(c_0_3, plain, (unifier(a(X1),b(g(X1))))).\n",
      "\n",
      "# Processed negative unit clauses:\n",
      "\n",
      "# Processed non-unit clauses:\n",
      "cnf(c_0_9, plain, (unifier(a(X1),b(X2))|f(g(X1))!=f(X2))).\n",
      "\n",
      "# Unprocessed positive unit clauses:\n",
      "\n",
      "# Unprocessed negative unit clauses:\n",
      "\n",
      "# Unprocessed non-unit clauses:\n",
      "\n",
      "\n",
      "# Parsed axioms                        : 1\n",
      "# Removed by relevancy pruning/SinE    : 0\n",
      "# Initial clauses                      : 1\n",
      "# Removed in clause preprocessing      : 0\n",
      "# Initial clauses in saturation        : 1\n",
      "# Processed clauses                    : 2\n",
      "# ...of these trivial                  : 0\n",
      "# ...subsumed                          : 0\n",
      "# ...remaining for further processing  : 2\n",
      "# Other redundant clauses eliminated   : 0\n",
      "# Clauses deleted for lack of memory   : 0\n",
      "# Backward-subsumed                    : 0\n",
      "# Backward-rewritten                   : 0\n",
      "# Generated clauses                    : 1\n",
      "# ...of the previous two non-redundant : 1\n",
      "# ...aggressively subsumed             : 0\n",
      "# Contextual simplify-reflections      : 0\n",
      "# Paramodulations                      : 0\n",
      "# Factorizations                       : 0\n",
      "# NegExts                              : 0\n",
      "# Equation resolutions                 : 1\n",
      "# Disequality decompositions           : 0\n",
      "# Total rewrite steps                  : 0\n",
      "# ...of those cached                   : 0\n",
      "# Propositional unsat checks           : 0\n",
      "#    Propositional check models        : 0\n",
      "#    Propositional check unsatisfiable : 0\n",
      "#    Propositional clauses             : 0\n",
      "#    Propositional clauses after purity: 0\n",
      "#    Propositional unsat core size     : 0\n",
      "#    Propositional preprocessing time  : 0.000\n",
      "#    Propositional encoding time       : 0.000\n",
      "#    Propositional solver time         : 0.000\n",
      "#    Success case prop preproc time    : 0.000\n",
      "#    Success case prop encoding time   : 0.000\n",
      "#    Success case prop solver time     : 0.000\n",
      "# Current number of processed clauses  : 2\n",
      "#    Positive orientable unit clauses  : 1\n",
      "#    Positive unorientable unit clauses: 0\n",
      "#    Negative unit clauses             : 0\n",
      "#    Non-unit-clauses                  : 1\n",
      "# Current number of unprocessed clauses: 0\n",
      "# ...number of literals in the above   : 0\n",
      "# Current number of archived formulas  : 0\n",
      "# Current number of archived clauses   : 0\n",
      "# Clause-clause subsumption calls (NU) : 0\n",
      "# Rec. Clause-clause subsumption calls : 0\n",
      "# Non-unit clause-clause subsumptions  : 0\n",
      "# Unit Clause-clause subsumption calls : 0\n",
      "# Rewrite failures with RHS unbound    : 0\n",
      "# BW rewrite match attempts            : 0\n",
      "# BW rewrite match successes           : 0\n",
      "# Condensation attempts                : 0\n",
      "# Condensation successes               : 0\n",
      "# Termbank termtop insertions          : 53\n",
      "# Search garbage collected termcells   : 3\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --print-saturated --output-level=6 --literal-selection-strategy=\"SelectLargestNegLit\" --proof-object /tmp/unify.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prolog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/prolog.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/prolog.p\n",
    "\n",
    "cnf(add_succ, axiom, add(s(X),Y,s(Z)) | ~add(X, Y, Z)).\n",
    "cnf(add_z, axiom, add(z, Y, Y)).\n",
    "fof(add_g, conjecture, ?[X,Y]: add(X,Y,s(s(z)))).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Initializing proof state\n",
      "# Scanning for AC axioms\n",
      "#\n",
      "#cnf(i_0_4, plain, (add(z,X1,X1))).\n",
      "#\n",
      "#cnf(i_0_3, plain, (add(s(X1),X2,s(X3))|~add(X1,X2,X3))).\n",
      "#\n",
      "#cnf(i_0_5, negated_conjecture, ($answer(esk1_2(X1,X2))|~add(X1,X2,s(s(z))))).\n",
      "## SZS status Theorem\n",
      "# SZS answers Tuple [[z, s(s(z))]|_]\n",
      "\n",
      "#cnf(i_0_6, negated_conjecture, ($answer(esk1_2(z,s(s(z)))))).\n",
      "#\n",
      "#cnf(i_0_7, negated_conjecture, ($answer(esk1_2(s(X1),X2))|~add(X1,X2,s(z)))).\n",
      "## SZS answers Tuple [[s(z), s(z)]|_]\n",
      "\n",
      "#cnf(i_0_8, negated_conjecture, ($answer(esk1_2(s(z),s(z))))).\n",
      "#\n",
      "#cnf(i_0_9, negated_conjecture, ($answer(esk1_2(s(s(X1)),X2))|~add(X1,X2,z))).\n",
      "## SZS answers Tuple [[s(s(z)), z]|_]\n",
      "\n",
      "# Proof found!\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --conjectures-are-questions  --answers=3 /tmp/prolog.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional programs.\n",
    "\n",
    "Constructors should come less in the precendence.\n",
    "LPO is more like functional programming.\n",
    "KBO is more like simplification\n",
    "\n",
    "\n",
    "Without the precendence annotations, eprover is not terminating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /tmp/add.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/add.p\n",
    "\n",
    "cnf(add_succ, axiom, add(s(X),Y) = s(add(X,Y))).\n",
    "cnf(add_z, axiom, add(z, Y) = Y).\n",
    "cnf(addn, axiom, add())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! eprover-ho --print-saturated  /tmp/add.p % non terminating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "auto is not better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Preprocessing class: FSSSSMSSSSSNFFN.\n",
      "# Scheduled 1 strats onto 1 cores with 300 seconds (300 total)\n",
      "# Starting G-E--_302_C18_F1_URBAN_RG_S04BN with 300s (1) cores\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --print-saturated --auto-schedule /tmp/add.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Initializing proof state\n",
      "# Scanning for AC axioms\n",
      "#\n",
      "#cnf(i_0_4, plain, (add(z,X1)=X1)).\n",
      "#\n",
      "#cnf(i_0_3, plain, (add(s(X1),X2)=s(add(X1,X2)))).\n",
      "\n",
      "# No proof found!\n",
      "# SZS status Satisfiable\n",
      "# Processed positive unit clauses:\n",
      "cnf(i_0_4, plain, (add(z,X1)=X1)).\n",
      "cnf(i_0_3, plain, (add(s(X1),X2)=s(add(X1,X2)))).\n",
      "\n",
      "# Processed negative unit clauses:\n",
      "\n",
      "# Processed non-unit clauses:\n",
      "\n",
      "# Unprocessed positive unit clauses:\n",
      "\n",
      "# Unprocessed negative unit clauses:\n",
      "\n",
      "# Unprocessed non-unit clauses:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --print-saturated --term-ordering=LPO4 --precedence=\"add>s>z\" /tmp/add.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Older notes\n",
    "E prover\n",
    "enormalizer is an interesting sounding program. Give it a pile of unit equalities and it will normalize with respect to thm EPR grounder to DIMACS The e calculus is a bit puzzling. I haven’t seen the analog for vampire\n",
    "\n",
    "2.6 manual It’s also in the github repo if you make doc\n",
    "\n",
    "I like how –answer mode works a little better for e.\n",
    "\n",
    "Database printing feature -S. Doesn’t print stuff I would expect though? Kind of prints everything by default right? Early stopping conditions clause size\n",
    "\n",
    "eprover --help | less\n",
    "--watchlist - “constructive” proofs that aren’t seeded by refuation training - you can train it if you have a database of indicative theorems. This might be useful if you have a sequence of increasingly hard theorems, or if you are making a tool that spits out formula. -S print saturated clause set -W literaeelection stretagory NoGeneration will inhibit all generating instances “Each of the strategies that do actually select negative literals has a corresponding counterpart starting with P that additionally allows paramodulation into maximal positive literals”\n",
    "\n",
    "echo \"\n",
    "fof(ground, axiom,\n",
    "    edge(a,b) & edge(b,c)\n",
    ").\n",
    "fof(path1, axiom,\n",
    "    ![X,Y]: (edge(X,Y) => path(X,Y))\n",
    ").\n",
    "fof(path2, axiom,\n",
    "    ![X,Y,Z]:  ((edge(X,Y) & path(Y,Z)) => path(X,Z))\n",
    ").\n",
    "\" | eprover  --literal-selection-strategy=SelectNegativeLiterals\n",
    "--generated-limit=100 Ok this basically did what i wanted. I’m not sure what it is though?\n",
    "\n",
    "“The most natural clause representation for E is probably a literal disjunction: a=\n",
    "true;c!=$true.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vampire\n",
    "\n",
    "Maybe I should play with these.\n",
    "--memory\n",
    "--cores\n",
    "\n",
    "--selection (-s)\n",
    "        Selection methods 2,3,4,10,11 are complete by virtue of extending Maximal \n",
    "        i.e. they select the best among maximal. Methods 1002,1003,1004,1010,1011 \n",
    "        relax this restriction and are therefore not complete.\n",
    "         0     - Total (select everything)\n",
    "         1     - Maximal\n",
    "         2     - ColoredFirst, MaximalSize then Lexicographical\n",
    "         3     - ColoredFirst, NoPositiveEquality, LeastTopLevelVariables,\n",
    "                  LeastDistinctVariables then Lexicographical\n",
    "         4     - ColoredFirst, NoPositiveEquality, LeastTopLevelVariables,\n",
    "                  LeastVariables, MaximalSize then Lexicographical\n",
    "         10    - ColoredFirst, NegativeEquality, MaximalSize, Negative then Lexicographical\n",
    "         11    - Lookahead\n",
    "         666   - Random\n",
    "         1002  - Incomplete version of 2\n",
    "         1003  - Incomplete version of 3\n",
    "         1004  - Incomplete version of 4\n",
    "         1010  - Incomplete version of 10\n",
    "         1011  - Incomplete version of 11\n",
    "         1666  - Incomplete version of 666\n",
    "        Or negated, which means that reversePolarity is true i.e. for selection \n",
    "        we treat all negative non-equality literals as positive and vice versa \n",
    "        (can only apply to non-equality literals).\n",
    "        \n",
    "        default: 10\n",
    "\n",
    "--symbol_precedence (-sp)\n",
    "        Vampire uses term orderings which require a precedence relation between \n",
    "        symbols.\n",
    "        Arity orders symbols by their arity (and reverse_arity takes the reverse \n",
    "        of this) and occurrence orders symbols by the order they appear in the \n",
    "        problem. Then we have a few precedence generating schemes adopted from \n",
    "        E: frequency - sort by frequency making rare symbols large, reverse does \n",
    "        the opposite, (For the weighted versions, each symbol occurrence counts \n",
    "        as many times as is the length of the clause in which it occurs.) unary_first \n",
    "        is like arity, except that unary symbols are maximal (and ties are broken \n",
    "        by frequency), unary_frequency is like frequency, except that unary symbols \n",
    "        are maximal, const_max makes constants the largest, then falls back to \n",
    "        arity, const_min makes constants the smallest, then falls back to reverse_arity, \n",
    "        const_frequency makes constants the smallest, then falls back to frequency.\n",
    "        default: arity\n",
    "        values: arity,occurrence,reverse_arity,unary_first,const_max,const_min,scramble,\n",
    "                frequency,unary_frequency,const_frequency,reverse_frequency,\n",
    "                weighted_frequency,reverse_weighted_frequency\n",
    "--term-rdering kbo lpo\n",
    "--induction = none, stuct, int,both\n",
    "\n",
    "default on rules\n",
    "\n",
    "--backward_demodulation (-bd)\n",
    "        Oriented rewriting of kept clauses by newly derived unit equalities\n",
    "        s = t     L[sθ] \\/ C\n",
    "        ---------------------   where sθ > tθ (replaces RHS)\n",
    "         L[tθ] \\/ C\n",
    "        \n",
    "        default: all\n",
    "        values: all,off,preordered\n",
    "--binary_resolution (-br)\n",
    "        Standard binary resolution i.e.\n",
    "        C \\/ t     D \\/ s\n",
    "        ---------------------\n",
    "        (C \\/ D)θ\n",
    "        where θ = mgu(t,-s) and t selected\n",
    "        default: on\n",
    "--demodulation_redundancy_check (-drc)\n",
    "        The following cases of backward and forward demodulation do not preserve \n",
    "        completeness:\n",
    "        s = t     s = t1 \\/ C    s = t     s != t1 \\/ C\n",
    "        ---------------------    ---------------------\n",
    "        t = t1 \\/ C              t != t1 \\/ C\n",
    "        where t > t1 and s = t > C (RHS replaced)\n",
    "        With `on`, we check this condition and don't demodulate if we could violate \n",
    "        completeness.\n",
    "        With `encompass`, we treat demodulations (both forward and backward) as \n",
    "        encompassment demodulations (as defined by Duarte and Korovin in 2022's \n",
    "        IJCAR paper).\n",
    "        With `off`, we skip the checks, save time, but become incomplete.\n",
    "        default: on\n",
    "        values: off,encompass,on\n",
    "    --forward_demodulation (-fd)\n",
    "        Oriented rewriting of newly derived clauses by kept unit equalities\n",
    "        s = t     L[sθ] \\/ C\n",
    "        ---------------------  where sθ > tθ\n",
    "         L[tθ] \\/ C\n",
    "        If 'preordered' is set, only equalities s = t where s > t are used for \n",
    "        rewriting.\n",
    "        default: all\n",
    "        values: all,off,preordered\n",
    "--forward_subsumption (-fs)\n",
    "        Perform forward subsumption deletion.\n",
    "        default: on\n",
    "--forward_subsumption_resolution (-fsr)\n",
    "        Perform forward subsumption resolution.\n",
    "        default: on\n",
    "--simultaneous_superposition (-sims)\n",
    "        Rewrite the whole RHS clause during superposition, not just the target \n",
    "        literal.\n",
    "        default: on\n",
    "--superposition (-sup)\n",
    "        Control superposition. Turning off this core inference leads to an incomplete \n",
    "        calculus on equational problems.\n",
    "        default: on\n",
    "--superposition_from_variables (-sfv)\n",
    "        Perform superposition from variables.\n",
    "        default: on\n",
    "\n",
    "--unit_resulting_resolution (-urr)\n",
    "        Uses unit resulting resolution only to derive empty clauses (may be useful \n",
    "        for splitting). 'ec_only' only derives empty clauses, 'on' does everything \n",
    "        (but implements a heuristic to skip deriving more than one empty clause), \n",
    "        'full' ignores this heuristic and is thus complete also under AVATAR.\n",
    "        default: off\n",
    "        values: ec_only,off,on,full\n",
    "\n",
    "--show_ordering\n",
    "--show_induction\n",
    "--manual_cs clause select manually\n",
    "--show_everything\n",
    "\n",
    "\n",
    "Pretty interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! vampire --show_everything on --manual_cs on /tmp/path.p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
