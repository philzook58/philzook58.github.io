{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.philipzucker.com/egraph2024_talk_done/\n",
    "- https://www.philipzucker.com/linear_grobner_egraph/\n",
    "- https://www.philipzucker.com/coegraph/\n",
    "- https://www.philipzucker.com/string_knuth/\n",
    "- https://www.philipzucker.com/smart_constructor_aegraph/\n",
    "- https://www.philipzucker.com/multiset_rw/\n",
    "- https://www.philipzucker.com/bottom_up/ normalizing containers\n",
    "\n",
    "\n",
    "Enodes ~ syntax\n",
    "eids ~ semantics\n",
    "\n",
    "When you ask z3 for a model, it returns numerical semantic values.\n",
    "\n",
    "Equality saturation starts as pure syntactic equality and gradually moves over closer to semantic equality (which is often never reaches).\n",
    "\n",
    "There are two main approaches I've been trying (or that I'm aware of):\n",
    "\n",
    "- Containers as smarter enodes\n",
    "- structured / semantic eids\n",
    "\n",
    "The enode structure I used is a function symbol + an ordered list of arguments. This is already kind of smart compared to a function symbol + a binary tuple of args. This tuple form can be interesting if you want to talk about partial application.\n",
    "\n",
    "\n",
    "Destructive rewriting as a theory.\n",
    "If you have a good rewrite theory over a system (terminating and confluent), you can already effectively quotient the syntax trees by that notion of equivalence be greedily applying the rules.\n",
    "\n",
    "```\n",
    "add(succ(X), Y) -> succ(add(X,Y))\n",
    "add(Z, Y) -> Y\n",
    "```\n",
    "\n",
    "\n",
    "Combination problems\n",
    "https://www.sciencedirect.com/science/article/pii/S0890540101931189 Deciding the Word Problem in the Union of Equational Theories\n",
    "\n",
    "Canonization for disjoint unions of theories Sava Krstic  Sylvain Conchon\n",
    "\n",
    "Disjoint signatures\n",
    "Termination is not modular\n",
    "Confluence is modular\n",
    "Normalizing is modular\n",
    "\n",
    "Ground rewrite rules / equalities are quite special.\n",
    "\n",
    "The following no go counterexample crushes most hopes of generic good results.\n",
    "\n",
    "Associativity + ground term equations = string equality and is undecidable.\n",
    "\n",
    "You can build a normalizing rewrite rule system for associativity by associating to the right.\n",
    "`(x . y) . z -> x . (y . z)`\n",
    "\n",
    "Ok but actually string rewrite systems are rules of form (yadayda . X) -> (something . X). They are not ground. Yeah but associatvity can make them non ground\n",
    "A ground _term_ equation corresponds more directly to the string rewrite that only applies at the end of the string. \n",
    "\n",
    "For disjoint signatures, there doesn't seem like their should be a problem. Why were eids integers in the first place? Who cares? The pieces of the other signature completely block rules from applying.\n",
    "\n",
    "\n",
    "Pick a ground total termination ordering compatible with the rewrite relation.\n",
    "COnsider the particular stratgey: orient the built in rules, All confluence pairs are now redundant by assumption.\n",
    "Start orienting the ground equations. simplify reduces by the built ins. This is \"putting into the egraph\".\n",
    "Any symbol not part of built ins can have a generated guy.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Ok, so we want non-disjoint signatures.\n",
    "\n",
    "\n",
    "What terms are \"in\" the egraph:\n",
    "1. A generative point of view (top down production of terms). Given an eid, we can build. The view is related to top down ematching\n",
    "2. An acceptor point of view. If we insert of term bottom up into the egraph, does it change it or leave it the same? This view is related to bottom up ematching.\n",
    "\n",
    "We can consider maybe adding new function symbols over \n",
    "\n",
    "\n",
    "Can we put eids and enodes on the same footing? If I had 3 theories I wanted to bake in. Does baked in go into eids? Or 2 notions of eids?\n",
    "\n",
    "https://egraphs.zulipchat.com/#narrow/channel/328972-general/topic/Linear.20and.20Polynomial.20Equations/near/477290392\n",
    "\n",
    "\n",
    "https://egraphs.zulipchat.com/#narrow/channel/424128-egg.2Fgeneral/topic/Translating.20between.20languages.20in.20an.20egraph/near/499111241 translation between mutiple languages slows stuff down.\n",
    "Related to refinement egraph ideas?\n",
    "\n",
    "\n",
    "|           |   UF    | Theory |\n",
    "| ---       |  ---    |        |\n",
    "| Sorts     | \n",
    "| Enodes    |\n",
    "| Eclasses  |\n",
    "| Functions |\n",
    "| Rules     |   \n",
    "\n",
    "\n",
    "Egraph modulo theories:\n",
    "What is a theory?\n",
    "\n",
    "https://pldi25.sigplan.org/home/egraphs-2025\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SortRef():\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.uf = []\n",
    "        # self.utree # to maintain eclasses\n",
    "        # self.reason # to maintain provencnance / proof\n",
    "    def find(self, i): # canonize\n",
    "        while self.uf[i] != i:\n",
    "            i = self.uf[i]\n",
    "        return i\n",
    "    def union(self, i, j):\n",
    "        i = self.find(i)\n",
    "        j = self.find(j)\n",
    "        if i != j:\n",
    "            self.uf[i] = j\n",
    "    def make(self): # Const?\n",
    "        self.uf.append(len(self.uf))\n",
    "        return len(self.uf)-1\n",
    "        \n",
    "\n",
    "class FuncDeclRef(): # MergeDict\n",
    "    def __init__(self, name, *sorts):\n",
    "        self.data = {}\n",
    "        self.sorts = sorts\n",
    "    def __getitem__(self, args):\n",
    "        assert len(args) == len(self.sorts) - 1\n",
    "        return self.data[args]\n",
    "    def __call__(self, *args):\n",
    "        assert len(args) == len(self.sorts) - 1\n",
    "        res = self.data.get(args)\n",
    "        if res is None:\n",
    "            res = self.default()\n",
    "            self.data[args] = res\n",
    "            return res\n",
    "        else:\n",
    "            return res\n",
    "    def __setitem__(self, key, value):\n",
    "        assert len(key) == len(self.sorts) - 1\n",
    "        res = self.data.get(key)\n",
    "        if res is None:\n",
    "            self.data[key] = value\n",
    "        else:\n",
    "            self.data[key] = self.merge(res, value)\n",
    "    def default(self):\n",
    "        return self.sorts[-1].make()\n",
    "    def merge(self,i,j):\n",
    "        return self.sorts[-1].union(i,j)\n",
    "    def rebuild(self):\n",
    "        fnew = FuncDeclRef(self.name, *self.sorts)\n",
    "        for k,v in self.data.items():\n",
    "            newk = tuple(sort.canon(k) for k,sort in zip(k,self.sorts[:-1]))\n",
    "            fnew[newk] = self.sorts[-1].canon(v)\n",
    "        return fnew\n",
    " \n",
    "Int = SortRef(\"Int\")\n",
    "add = FuncDeclRef(\"add\", Int, Int, Int)\n",
    "x = FuncDeclRef(\"x\", Int)()\n",
    "add(x,x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MergeDict(dict):\n",
    "    def __setitem__(self, key, value):\n",
    "        res = self.get(key)\n",
    "        if res is None:\n",
    "            super().__setitem__(key, value)\n",
    "        else:\n",
    "            super().__setitem__(key, self.merge(res, value))\n",
    "    def merge(self, i, j):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "class MinDict(MergeDict):\n",
    "    def merge(self, i, j):\n",
    "        return min(i, j)\n",
    "\n",
    "class MaxDict(MergeDict):\n",
    "    def merge(self, i, j):\n",
    "        return max(i, j)\n",
    "\n",
    "d = MinDict()\n",
    "d[1] = 2\n",
    "d[1] = 3\n",
    "assert d[1] == 2\n",
    "d[1] = 1\n",
    "assert d[1] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSFuncDeclRef(FuncDeclRef):\n",
    "    # multiset funcdecl ref. \n",
    "    # Putting the \"ACness\" into the functions\n",
    "    # Containers ~ enodes\n",
    "    def rebuild(self):\n",
    "        fnew = MSFuncDeclRef(self.name, *self.sorts)\n",
    "        for k,v in self.data.items():\n",
    "            fnew[k] = v\n",
    "        return fnew\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACSort():\n",
    "    # putting the \"ACness\" in the sort.\n",
    "    # structured eids which are multisets\n",
    "    # containers ~ eids\n",
    "    def __init__(self, name, inner):\n",
    "        self.name = name\n",
    "        self.inner = inner\n",
    "    def rebuild(self, xs : tuple): # rebuild / re-canonize\n",
    "        return tuple(sorted([self.inner.rebuild(x) for x in xs]))\n",
    "\n",
    "class ACISort():\n",
    "    # ACI ~ sets\n",
    "    def __init__(self, name, inner):\n",
    "        self.name = name\n",
    "        self.inner = inner\n",
    "    def rebuild(self, xs : tuple): # rebuild / re-canonize\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notion of \"kinds\". Sorts may have different structured ids. The description or data of thse may lie in the Kind data strucctures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UninterpretedKind():\n",
    "    def __init__(self, name):\n",
    "        self.uf = []\n",
    "    def make(self):\n",
    "        self.uf.append(len(self.uf))\n",
    "        return len(self.uf)-1\n",
    "    def union(self, i, j):\n",
    "        return i\n",
    "    def canon(self, i):\n",
    "        return i\n",
    "    def rebuild(self, i):\n",
    "        return self.find(i)\n",
    "\n",
    "\n",
    "class SortRef():\n",
    "    def __init__(self, name, kind=None):\n",
    "        self.name = name\n",
    "        if kind is None:\n",
    "            kind = UninterpretedKind()\n",
    "        else:\n",
    "            self.kind = kind\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could easily have multiple notions of equality.\n",
    "They don't necessarily have to have much to do with each other. But we can't normalize across them except at the commonality.\n",
    "There is a truly baked in equality that can be destructive.\n",
    "\n",
    "We could only canonize when they agree they canonize. Or maintain a fixpoint of the canonization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtomicEq():\n",
    "    def __init__(self, sort):\n",
    "        self.sort = sort\n",
    "        self.uf = []\n",
    "    def canon(self, i):\n",
    "        pass\n",
    "    def rebuild():\n",
    "\n",
    "class LinearEq():\n",
    "    def __init__(self, sort):\n",
    "        self.sort = sort\n",
    "        self.uf = []\n",
    "    def canon(self, i):\n",
    "        pass\n",
    "    def rebuild():\n",
    "        pass # do gauss elim?\n",
    "\n",
    "class RecursiveEq(): # FixEq\n",
    "    pass # todo\n",
    "\n",
    "\n",
    "class GroupActEq():\n",
    "    pass # Can have group actions on the side of the UF\n",
    "\n",
    "class StringEq(): ...\n",
    "\n",
    "class FixEq(): ...\n",
    "\n",
    "class UnionEq():\n",
    "    def __init__():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are quotienting by different equalities.\n",
    "Having them play nice with each other is a theory combination problem.\n",
    "\n",
    "Partitions ~ equaiovlanece relations.\n",
    "Finest partition or corasest partition that contains the equivalence relations.\n",
    "Equivalence relations form a lattice.\n",
    "https://en.wikipedia.org/wiki/Equivalence_relation\n",
    "\n",
    "We can bounce around two equivalence relations is we have a notion of well founded ordering we are following and get the canonizer for the combo (the coarser partition with more equalities).\n",
    "\n",
    "I don't know how we'd get a canonizer for the intersection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuotientSort():\n",
    "    def __init__(self, sort, eq):\n",
    "        self.sort = sort\n",
    "        self.eq = eq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueKind():\n",
    "    # literals like literal integers\n",
    "    def rebuild(self, i):\n",
    "        return i\n",
    "    \n",
    "# This makes sense for Int where we have abstract Int expressions, but also sometimes literal int values. \"Lifting\" is somewhat awkward.\n",
    "# Perhaps related to my notion of observation table for coegraphs. A ground value is a very powerful observation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnionKind(): # union or disjoint union / tagged union?\n",
    "    def __init__(self, *kinds):\n",
    "        self.kinds = kinds\n",
    "    def rebuild(self, i):\n",
    "        tag, inner = i\n",
    "        return (tag, self.kinds[tag].rebuild(inner))\n",
    "    def make(self, tag): # Hmm. Make takes stuff now...\n",
    "        return (tag, self.kinds[tag].make())\n",
    "\n",
    "class IntersectionKind():\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the ground rewrite system perspective, what are we doing?\n",
    "\n",
    "A specialized notion of overlap\n",
    "a compositional form of term ordering. Making a term ordering from a term ordering of the contained elements.\n",
    "a notion of pattern matching and replacement / removal\n",
    "\n",
    "\n",
    "\n",
    "TermKind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ACDict():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ExprRef():\n",
    "    def __init__(self, id_, sort):\n",
    "        self.sort = sort\n",
    "        self.id_ = id_\n",
    "    def __eq__(self, other):\n",
    "        assert self.sort is other.sort\n",
    "        self.sort.union(self, other)\n",
    "    def eq(self, other):\n",
    "        assert self.sort is other.sort\n",
    "        return self.sort.find(self.id_) == self.sort.find(other.id_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
