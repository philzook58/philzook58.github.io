{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a graph?\n",
    "\n",
    "What do you want to do on it?\n",
    "\n",
    "\n",
    "Search a graph\n",
    "spanning tree\n",
    "routing on a graph\n",
    "shortest path\n",
    "maximum flow\n",
    "minimum cut\n",
    "maximum matching\n",
    "minimum spanning tree\n",
    "strongly connected components\n",
    "biconnected components\n",
    "articulation points\n",
    "bridges\n",
    "2-edge connected components\n",
    "\n",
    "\n",
    "colorings\n",
    "covers\n",
    "\n",
    "# Tree Decomposition\n",
    "\n",
    "https://dl.acm.org/doi/10.1145/3689801  Fast and Optimal Extraction for Sparse Equality Graphs\n",
    "https://github.com/mabseher/htd hypertree decomposition\n",
    "https://github.com/PACE-challenge/Treewidth\n",
    "https://pypi.org/project/treedecomp/\n",
    "https://networkx.org/documentation/latest/reference/algorithms/approximation.html#module-networkx.algorithms.approximation.treewidth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree decomp\n",
    "class Node():\n",
    "    bag: set[V]\n",
    "    bagedges : set[E]\n",
    "    children: set[Node]\n",
    "\n",
    "    def treewidth(self):\n",
    "        return max(len(self.bag) - 1, max([c.treewidth() for c in self.children]))\n",
    "    \n",
    "\n",
    "class GraphTree():\n",
    "    here: set[V] # nodes only here\n",
    "    edges: set[E] #egdes between only here and children\n",
    "    children: set[tuple[set[V], GraphTree]]\n",
    "\n",
    "    def color(self, colors):\n",
    "       # take in a list of colors \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = int\n",
    "Edge = tuple[V,V]\n",
    "\n",
    "# flat reps\n",
    "Graph1 = set[Edge]\n",
    "Graph2 = list[Edge]\n",
    "Graph3 = dict[V, set[V]]\n",
    "\n",
    "\n",
    "# structured representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kerngihan Lin\n",
    "\n",
    "def kl(edges):\n",
    "    A = set()\n",
    "    B = set()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph canonicalization\n",
    "\n",
    "## group theory\n",
    "This is neither here nor there kind of. It's \"just\" for symmettry breaking during search, which is especially painful in canonization search\n",
    "\n",
    "\n",
    "caonicalizing graphs  via brute force. Come up with a system of serialzing, sort those strings. Not necessarily stable in any sense though\n",
    "graph isomorphism\n",
    "Sims-schreiers\n",
    "\n",
    "schreir vectors = spanning tree. (?) store group element that would connect to previous node of spanning tree. \n",
    "This is the group union find? Huh.\n",
    "\n",
    "schreir sims - a canonical form of group element.\n",
    "\n",
    "Stabilizer = subgroup defined as the the group elements that leave a particular elemement unchanged\n",
    "\n",
    "Schreir generators. If we pick representatives of the cosets of a subgroup, we can generate the subgroup using combined generators and repsdentatives as generators.\n",
    "\n",
    "Return stabilizer of initial point as collection of schreier generatoras. Orbit stabilizer algorithm\n",
    "\n",
    "undirected Graph where every neighborhood has the same moves = group action on vertex set. edge pattern is generators. \n",
    "https://en.wikipedia.org/wiki/Cayley_graph\n",
    "Origin is special or no?\n",
    "Stabilizer group of origin are loops.\n",
    "rubiks cube\n",
    "\n",
    "https://terrytao.wordpress.com/2010/07/10/cayley-graphs-and-the-geometry-of-groups/\n",
    "subgroups and bundles\n",
    "\n",
    "a base, special points.\n",
    "What if graph is disconnected?\n",
    "\n",
    "Consider general graphs as mangled cayley graphs.\n",
    "Even if I was given two cayley graphs is it obvious how to canonicaslize it?\n",
    "The point of gropup theory is to cut down on boring symmettry explosion. Where is this?\n",
    "\n",
    "cosets partition... partition refinement using group tags?\n",
    "\n",
    "g = (h, g')  where h is element of subgroup and g' is caonoical represdentiatvie of coset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "@dataclass(frozen=True)\n",
    "class Perm():\n",
    "    perm : list[int]\n",
    "    @classmethod  \n",
    "    def e(self, n):\n",
    "        return Perm(list(range(n)))\n",
    "    def __mul__(self, other):\n",
    "        return Perm([self.perm[p] for p in other.perm])\n",
    "    \n",
    "e3 = Perm.e(3)\n",
    "assert e3 * e3 == e3\n",
    "p = Perm([1,0])\n",
    "assert p * p == Perm.e(2)\n",
    "assert Perm([1,2,0]) * Perm([2,0,1]) == Perm([0,1,2])\n",
    "\n",
    "\n",
    "def naive()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(number_of_vertices=3, directed=False,\n",
      " adjacency_dict = {\n",
      "  0: [1],\n",
      "  1: [2],\n",
      " },\n",
      " vertex_coloring = [\n",
      " ],\n",
      ")\n",
      "([[2, 1, 0]], 2.0, 0, [0, 1, 0], 2)\n",
      "b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00 \\x00\\x00\\x00\\x00\\x00\\x00\\x00 \\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0'\n",
      "Graph(number_of_vertices=3, directed=False,\n",
      " adjacency_dict = {\n",
      "  0: [2],\n",
      "  1: [2],\n",
      "  2: [0, 1],\n",
      " },\n",
      " vertex_coloring = [\n",
      " ],\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import pynauty\n",
    "g = pynauty.Graph(3, directed=False)\n",
    "g.connect_vertex(0, [1])\n",
    "g.connect_vertex(1, [2])\n",
    "print(g)\n",
    "print(pynauty.autgrp(g)) #  (generators, grpsize1, grpsize2, orbits, numorbits)\n",
    "print(pynauty.certificate(g))\n",
    "print(pynauty.canon_graph(g))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## brute force\n",
    "\n",
    "You can turn a graph of n vertices into a n^2/2 string by listing out all the possible edges\n",
    "This is the same thing as `{{v1,v2}}` representation.\n",
    "https://cs.stackexchange.com/questions/14354/simple-graph-canonization-algorithm\n",
    "\n",
    "https://arxiv.org/abs/1301.1493  Practical graph isomorphism, II\n",
    "\n",
    "https://cgm.cs.mcgill.ca/~breed/2015COMP362/canonicallabellingpaper.pdf McKay’s Canonical Graph Labeling Algorithm\n",
    "\n",
    "A key point here is that the representation is really useful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (1, 3), (2, 3)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#G = {{1.2},{2,3},{1,3}}  # can't hash sets. could use frozenset. Anyway\n",
    "def e(i,j):\n",
    "    return (i,j) if i < j else (j,i)\n",
    "def graph(edges):\n",
    "    return list(sorted(set(edges))) # dedup and sort\n",
    "\n",
    "G = graph({e(1,2), e(2,3), e(1,3)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (0, 2)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "min([ graph([e(p[0], p[1]), e(p[1], p[2])])  for p in permutations(range(3))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (0, 2)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min([ graph([e(p[1], p[0]), e(p[0], p[2])])  for p in permutations(range(3))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a functional rep of graph as a thing permutations can act on.\n",
    "\n",
    "#G = Callable[perm, list[tuple[int,int]]]\n",
    "def perm_graph(perm, G): # a permutation acting on a labelled graph\n",
    "    return [ (p[i], p[j]) for (i,j) in G ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose I wanted the automorphism group.\n",
    "Can I generate it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "range object index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: range object index out of range"
     ]
    }
   ],
   "source": [
    "range(3)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0), (2, 1)]\n",
      "((0, 3), (1, 3))\n",
      "((0, 3), (1, 3))\n",
      "(0, 1, 2) ((0, 2), (2, 3))\n",
      "(0, 2, 1) ((0, 2), (2, 3))\n",
      "(1, 0, 2) ((0, 2), (2, 3))\n",
      "(1, 2, 0) ((0, 2), (2, 3))\n",
      "(2, 0, 1) ((0, 2), (2, 3))\n",
      "(2, 1, 0) ((0, 2), (2, 3))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], ((0, 2), (2, 3)))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = sorted([(2,1), (1,0)])\n",
    "import itertools\n",
    "def perm_graph(perm, G): # a permutation acting on a labelled graph\n",
    "    return tuple(sorted([ tuple(sorted([p[i], p[j]])) for (i,j) in G ]))\n",
    "print(G)\n",
    "G = perm_graph(range(3), G)\n",
    "print(G)\n",
    "# explicitly list the automorphisms of a graph\n",
    "def canon(G, N):\n",
    "    autogrp = []\n",
    "    min_graph = G\n",
    "    print(G)\n",
    "    for p in itertools.permutations(range(N)):\n",
    "        G1 = perm_graph(p, G)\n",
    "        print(p,G1)\n",
    "        if G1 == G:\n",
    "            autogrp.append(p)\n",
    "        elif G1 < min_graph:\n",
    "            min_graph = G1\n",
    "    return autogrp, min_graph\n",
    "canon(G, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " swaps\n",
    "Generate permutation group. swaps\n",
    "\n",
    "Also, swaps are kind of an incrementalo strcturue which is good for functional programming maybe.\n",
    "\n",
    "note that this is a method to generate permutations too. swap to decide which element of remaining in in nth position.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Steinhaus%E2%80%93Johnson%E2%80%93Trotter_algorithm  Steinhaus–Johnson–Trotter algorithm\n",
    "https://en.wikipedia.org/wiki/Heap%27s_algorithm\n",
    "https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle randomly genrate a permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def canon(G, N):\n",
    "    swaps = [(i,j) for i in range(N) for j in range(i)]\n",
    "    for \n",
    "    for p in permutations(range(3)):\n",
    "        yield perm_graph(p, G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do a more careful backtracking search, we can prune a lot.\n",
    "We learn partial order constraints as we go. Maybe a difference logic thing would be helpful.\n",
    "We get good strings by ordering the vertices by degree first.\n",
    "We can do a lot of propagation.\n",
    "We can do prefix comparison because we're being lexicographic.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lt(G1,G2):\n",
    "    [G1[i,j] and not G2[i,j] for i in len(G1) for j in len(G2)]\n",
    "\n",
    "# recursive form of lex comparison\n",
    "# turn if into If. i and j are static.\n",
    "def lt(G1,G2,i,j):\n",
    "    if i == len(G1) and j == len(G2):\n",
    "        return False\n",
    "    \n",
    "    if G1[i,j] and not G2[i,j]:\n",
    "        return True\n",
    "    elif not G1[i,j] and G2[i,j]:\n",
    "        return False\n",
    "    else:\n",
    "        if i+1 == len(G1):\n",
    "            return lt(G1,G2,0,j+1)\n",
    "        else:\n",
    "            return lt(G1,G2,i+1, j)\n",
    "\n",
    "# or bottom up loop form\n",
    "def lt(G1,G2):\n",
    "    acc = False\n",
    "    for i in reversed(range(len(G1))):\n",
    "        for j in reversed(len(G1)):\n",
    "            if G1[i][j] == G2[i][j]:\n",
    "                acc = acc\n",
    "            elif G[i,j] and not G2[i,j]:\n",
    "                return \n",
    "            if not G1[i][j] and G2[i][j]:\n",
    "                return True\n",
    "    \n",
    "def lt(perm,G2,N):\n",
    "    acc = BoolVal(False)\n",
    "    for i in reversed(range(N)):\n",
    "        for j in reversed(range(N)):\n",
    "            t = G1\n",
    "            acc = If(\n",
    "                t[i,j] == G2[i,j],\n",
    "                acc,\n",
    "                If(\n",
    "                    And(Not(t[i,j]), G2[i,j]),\n",
    "                    BoolVal(True),\n",
    "                    acc\n",
    "                )\n",
    "            )\n",
    "            if G1(perm(i),perm(j)) == G2(i,j):\n",
    "                acc = acc\n",
    "            elif G[i,j] and not G2[i,j]:\n",
    "                return \n",
    "            if not G1[i][j] and G2[i][j]:\n",
    "                return True\n",
    "\n",
    "def to_matrix(G):\n",
    "    mat = [[False]*len(G)] * len(G)\n",
    "    for (i,j) in G:\n",
    "        mat[i][j] = True\n",
    "        mat[j][i] = True\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have other representations of graphs. A tree representation follows naturally from Tree Decomposition (kind of. We also need to create a unique tree decomp... or use an ordering that doesn't care which tree decomp we picked. Hmmmm. best Spanning tree? Again tie breaking here brings in graph canonization. These things need to be considered bolted together).\n",
    "We could then use total tree orderings instead of string orderings.\n",
    "\n",
    "\"Natrual graph orderings\" like that minor homomorphism thing. https://en.wikipedia.org/wiki/Robertson%E2%80%93Seymour_theorem\n",
    "\n",
    "Maybe this is more sensical for tree with backref ids. Which numbers do we put in the backref ids to make canonical. Then the tree structure exists a priori.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import z3\n",
    "\n",
    "\n",
    "\n",
    "def compare_graph(G1,G2):\n",
    "\n",
    "def canon(G):\n",
    "    s = z3.Solver()\n",
    "    Gsym = Function(\"G\", IntSort(), IntSort(), BoolSort())\n",
    "    Function(\"perm\", IntSort(), IntSort())\n",
    "    for i in len(G):\n",
    "        for j in range(i):\n",
    "            s.add(perm(i) != perm(j)) # must be permutation\n",
    "    for i,j in G:\n",
    "        s.add(Gsym(i,j) == True) # \"need\" to make graph symbolic because perm is symbilic.\n",
    "    perm = Function(\"perm\", IntSort(), IntSort())\n",
    "    def lt(perm,G):\n",
    "        acc = BoolVal(False) # all equal\n",
    "        for i in range(len(G)):\n",
    "            for j in range(i):\n",
    "                acc = If(G[perm[i], perm[j]] < G[i,j], True, acc)\n",
    "                    \n",
    "    \n",
    "    while True:\n",
    "        m = s.model()\n",
    "        s.add(compare_graph(G, m))\n",
    "        if s.check() == unsat:\n",
    "            return G\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so there is some way of doing that. And maybe this is an example where SAT solvers can really shine. (They have more symmettry breaking in them?)\n",
    "\n",
    "\n",
    "Clauses as graphs. ordered resolution\n",
    "Queries as graphs\n",
    "Tensor Expressions as graphs\n",
    "\n",
    "Breaking up the permutations via features\n",
    "\n",
    "Can we use tree decomposition to make a natural graph canonization that elegant moves on from tree like problems. This is like Caleb's thing.\n",
    "Dynamic programming approach to canonical ordering.\n",
    "\n",
    "brute force approach to searching all tree decompositions? Exact solvers must be doing this in some sense.\n",
    "\n",
    "It'd be nice to not a priori fix the ordering. If some particular graph has a particular unique feature, obviously we want to use that.\n",
    "\n",
    "{foo(A,B), foo(B,C)}\n",
    "[(\"foo\", p[1], p[2]), (\"foo\", p[2], p[3])]\n",
    "We could choose \"foo\" tags to come later but that'd be crazy (?)\n",
    "\n",
    "Group union find for labelled graphs being interconnected to each other.\n",
    "\n",
    "\n",
    "Refinement: order coarsely by colors first.\n",
    "\n",
    "A pile of ground tensor equations would work.\n",
    "G --> (P, canon(G))\n",
    "\n",
    "This is a canonical form of a labelled graph. It's a normalizer. Is this the group union find?\n",
    "\n",
    "\n",
    "\n",
    "TijKij = Rijkk\n",
    "\n",
    "tensor instruction selection\n",
    "\n",
    "\n",
    "true global variables are \"observed\". They aren't known distinct though.\n",
    "\n",
    "https://automorphisms.org/\n",
    "https://arxiv.org/pdf/2406.13557 satsuma Structure-based Symmetry\n",
    "Breaking in SAT\n",
    "\n",
    "\n",
    "seress permutation group algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1], [2]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get cycles. Orbits under subgroup consisting of p^n. Generated by <p>\n",
    "def cycles(p):\n",
    "    found = set()\n",
    "    for i in range(len(p)):\n",
    "        if i not in found:\n",
    "            cycle = []\n",
    "            j = i\n",
    "            while j not in cycle:\n",
    "                cycle.append(j)\n",
    "                j = p[j]\n",
    "            yield cycle\n",
    "            found.update(cycle)\n",
    "\n",
    "list(cycles([1,0,2]))\n",
    "\n",
    "def inv(p):\n",
    "    inv = [0]*len(p)\n",
    "    for i in range(len(p)):\n",
    "        inv[p[i]] = i\n",
    "    return inv\n",
    "\n",
    "def orbit(ps, n):\n",
    "    found = set()\n",
    "    done = False\n",
    "    while not done:\n",
    "        done = False\n",
    "        for f in found:\n",
    "            for p in ps:\n",
    "                e = p[f]\n",
    "                if e not in found:\n",
    "                    done = False\n",
    "                    found.add(e)\n",
    "\n",
    "Perm = list[int]\n",
    "# orbit of is fixed point of this operation starting from {x}.\n",
    "def step(G : list[Perm], s : set[int]) -> set[int]: # G is list/set of permutations\n",
    "    return s | {p[i] for p in G for i in s}\n",
    "\n",
    "def is_inv(G,s):\n",
    "    return s == step(G,s)\n",
    "\n",
    "# can apply standard seminaive trick\n",
    "# can retain \"proof\" / path as group union find.\n",
    "\n",
    "# schreier vectors\n",
    "\n",
    "\n",
    "# base\n",
    "# strong generating set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensor canon\n",
    "https://docs.sympy.org/latest/modules/combinatorics/tensor_can.html\n",
    "\n",
    "https://docs.sympy.org/latest/modules/tensor/tensor.html#sympy.tensor.tensor.TensAdd.canon_bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy.tensor.tensor import TensorIndexType, tensor_indices, TensorHead, TensorManager, TensorSymmetry\n",
    "IType = TensorIndexType('IType')\n",
    "i,j,k,l = tensor_indices('i j k l', IType)\n",
    "A = TensorHead('A', [IType, IType])\n",
    "A\n",
    "G = TensorHead('G', [IType], TensorSymmetry.no_symmetry(1), 'Gcomm')\n",
    "G(j)\n",
    "t = A(i,j)*A(-j,k)*A(-k,l)\n",
    "t2 = A(-k,j)*A(i,k)*A(-j,l)\n",
    "t.canon_bp() == t2.canon_bp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "i,j,k,l = range(4)\n",
    "t = [(\"A\", i,k), (\"A\", j,l), (\"A\", k,l)]\n",
    "\n",
    "def act(p, t):\n",
    "    return sorted([(head,*[p[a] for a in args]) for head,*args in t])\n",
    "\n",
    "def normal(t, N):\n",
    "    return min([ (p, act(p,t)) for p in itertools.permutations(range(N))], key=lambda x: x[1])\n",
    "\n",
    "assert act([0,1,2,3], t) == t\n",
    "\n",
    "p,t1 = normal(t, 4)\n",
    "assert act(p,t) == t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A symmettric tensor has a multiset of indices. This is a graph? multigraph? hypergraph?\n",
    "```\n",
    "def act(p, t):\n",
    "    return sorted([(head,*sorted([p[a] for a in args])) for head,*args in t])\n",
    "```\n",
    "\n",
    "\n",
    "foo(g(i), k(j), l(i)) -> (\"foo\", (\"g\", i), (\"k\", j), (\"l\", i)). Permutation action + min. Brute force search is silly because we will just get the dpeth first relabelling ordering.\n",
    "\n",
    "But this is vistiation lex ordering.\n",
    "\n",
    "What about KBO, LPO etc\n",
    "KBO - they will all be the same size. Unless we weight the indice choice. This could make sense. We want fewer repeated indices. They represent coupling.\n",
    "Order by number of appareances. Tie break by recursion. https://www.philipzucker.com/ground_kbo/ This is not substitution stable.\n",
    "Can be lazy about pushing permutations down once determined.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def termact(p, t):\n",
    "    head,*args = t\n",
    "    return (head,*[termact(p,a) for a in args])\n",
    "def canon(t, N):\n",
    "    # a silly implementation.\n",
    "    min([ termact(p,t) for p in itertools.permutations(range(N))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cadbra\n",
    "https://cadabra.science/\n",
    "\n",
    "https://docs.sympy.org/latest/modules/combinatorics/tensor_can.html\n",
    "\"\n",
    "The Butler-Portugal algorithm [3] is an efficient algorithm to put tensors in canonical form, solving the above problem.\n",
    "\n",
    "Portugal observed that a tensor can be represented by a permutation, and that the class of tensors equivalent to it under slot and dummy symmetries is equivalent to the double coset \n",
    " (Note: in this documentation we use the conventions for multiplication of permutations p, q with (p*q)(i) = p[q[i]] which is opposite to the one used in the Permutation class)\n",
    " \"\n",
    "https://arxiv.org/abs/1702.08114 Faster Tensor Canonicalization\n",
    "https://www.sciencedirect.com/science/article/abs/pii/S001046550800221X xPerm: fast index canonicalization for tensor computer algebra\n",
    "\n",
    "https://pure.mpg.de/rest/items/item_1833414/component/file_2047302/content  xTras: A field-theory inspired xAct package for mathematica\n",
    "https://europepmc.org/article/pmc/pmc6105178  Computer algebra in gravity research. This paper rules\n",
    "redberry is a tensor CAS?\n",
    "https://durham-repository.worktribe.com/OutputFile/1927714 Hiding canonicalisation in tensor computer algebra\n",
    "https://etheses.dur.ac.uk/14811/1/thesis.pdf?DDD21+  thesis version\n",
    "cadabra peeters\n",
    "\n",
    "https://www.frontiersin.org/journals/astronomy-and-space-sciences/articles/10.3389/fspas.2020.00058/full intropductin to numerical relativity\n",
    "https://github.com/wojciechczaja/GraviPy Tensor Calculus Package for General Relativity based on SymPy (python library for symbolic mathematics).\n",
    "\n",
    "`sudo apt install cadabra2`\n",
    "\n",
    "young projectors\n",
    "\n",
    "HJe uses latex `$` asa quote for metaprogramming. Interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle A_{m n} B^{m n}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle D_{m r} D^{r}_{n} B^{m p} C_{p q}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle D_{m r} D^{r}_{n} B^{m p} C_{p q}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://cadabra.science/static/cadabra_in_ipython.nb.html\n",
    "from cadabra2 import *\n",
    "from IPython.display import display, Math, Latex\n",
    "ex=Ex(r\"A_{m n} B^{m n}\") # latex expressions\n",
    "display(Math(str(ex)))\n",
    "\n",
    "# assign properties to symbols\n",
    "Symmetric(Ex(r\"A_{m n}\"))\n",
    "AntiSymmetric(Ex(r\"B_{m n\"))\n",
    "\n",
    "display(Math(str(canonicalise(ex))))\n",
    "\n",
    "Indices(Ex(r\"{m,n,p,q,r,s,t}\"))\n",
    "ex=Ex(r\"A_{m n} B^{m p} C_{p q}\")\n",
    "display(Math(str(substitute(ex, Ex(r\"A_{m n} -> D_{m q} D^{q}_{n}\")))))\n",
    "display(Math(str(substitute(ex, Ex(r\"A_{k n} -> D_{k q} D^{q}_{n}\"))))) # so it looks like it is matching modulo names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://josmar493.dreamhosters.com/ xACT. mathemtica analog?\n",
    "https://www.youtube.com/watch?v=qOaJxzezU8w&list=PLdIcYTEZ4S8TSEk7YmJMvyECtF-KA1SQ2&ab_channel=WolframR%26D web series 20 year of "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
