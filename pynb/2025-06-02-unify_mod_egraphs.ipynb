{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Unification Modulo E-Graphs\n",
    "date: 2025-06-02\n",
    "---\n",
    "\n",
    "I think there are reasonable ways to add an e-graph to [unification](https://en.wikipedia.org/wiki/Unification_(computer_science)) algorithms. \n",
    "\n",
    "This would correspond to e-unification https://www.cs.bu.edu/fac/snyder/publications/UnifChapter.pdf with the theory E being the ground equalities the e-graph represents. That's a reasonably well formed notion. Carrying a changing e-graph in the state would support logic programming and theorem provers with a slightly richer notion of `=`. One could call it maybe CLP(EGraph).\n",
    "\n",
    "I don't have how to do this exactly nailed down, but the way we make progress is by saying stuff. So here we go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Unification\n",
    "\n",
    "First let's look at an implementation of basic syntactic unification\n",
    "\n",
    "Unification processes a set of goals equations. It chews on them, adding them to a substitution when it can.\n",
    "\n",
    "The loop based version of it corresponds fairly directly to the declarative rule system. I use eager substitution to retain clarity, although it's probably less efficient.\n",
    "\n",
    "![](https://www.philipzucker.com/assets/traat/unify_rules.png)\n",
    "\n",
    "For a deeper dive, see this blog post https://www.philipzucker.com/unify/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.all import *\n",
    "\n",
    "def unify(vs: list[smt.ExprRef], p1: smt.ExprRef, p2: smt.ExprRef) -> Optional[dict[smt.ExprRef, smt.ExprRef]]:\n",
    "    subst = {}\n",
    "    todo = [(p1, p2)]\n",
    "\n",
    "    def is_var(x):\n",
    "        return any(x.eq(v) for v in vs)\n",
    "\n",
    "    while todo:\n",
    "        p1, p2 = todo.pop()  # we could pop _any_ of the todos, not just the top.\n",
    "        if p1.eq(p2):  # delete\n",
    "            continue\n",
    "        elif is_var(p1):  # elim\n",
    "            if occurs(p1, p2):\n",
    "                return None\n",
    "            todo = [\n",
    "                (smt.substitute(t1, (p1, p2)), smt.substitute(t2, (p1, p2)))\n",
    "                for (t1, t2) in todo\n",
    "            ]\n",
    "            subst = {k: smt.substitute(v, (p1, p2)) for k, v in subst.items()}\n",
    "            subst[p1] = p2\n",
    "        elif is_var(p2):  # orient\n",
    "            todo.append((p2, p1))\n",
    "        elif smt.is_app(p1):  # decompose\n",
    "            if not smt.is_app(p2) or p1.decl() != p2.decl():\n",
    "                return None\n",
    "            todo.extend(zip(p1.children(), p2.children()))\n",
    "        else:\n",
    "            raise Exception(\"unexpected case\", p1, p2)\n",
    "    return subst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Unification Modulo E-Graphs\n",
    "\n",
    "A naive method is to replace the failure point of disequal function symbols `f != g` with instead adding it to a constraints list. Then at the end, this constraints list may be solved by e-matching against an egraph `E`. After all, just because `foo(X)` can't be syntactically unified with `bar(z)` doesn't mean there aren't groundings that make it work in the egraph.\n",
    "\n",
    "I'm using the egraph implementation based around z3 I described here https://www.philipzucker.com/brute_eggmt/ . It's been very nice having a simple egraph I have in a library to play with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.all import *\n",
    "from kdrag.solvers.egraph import EGraph\n",
    "from typing import Optional\n",
    "\n",
    "def eunify_naive(vs: list[smt.ExprRef], p1: smt.ExprRef, p2: smt.ExprRef, E : EGraph) -> list[dict[smt.ExprRef, smt.ExprRef]]:\n",
    "    subst = {}\n",
    "    todo = [(p1, p2)]\n",
    "    constrs = []\n",
    "\n",
    "    def is_var(x):\n",
    "        return any(x.eq(v) for v in vs)\n",
    "\n",
    "    while todo:\n",
    "        p1, p2 = todo.pop()\n",
    "        if p1.eq(p2):  # delete\n",
    "            continue\n",
    "        elif is_var(p1):  # elim\n",
    "            if kd.utils.occurs(p1, p2):\n",
    "                constrs.append((p1, p2))\n",
    "            else:\n",
    "                todo = [\n",
    "                    (smt.substitute(t1, (p1, p2)), smt.substitute(t2, (p1, p2)))\n",
    "                    for (t1, t2) in todo\n",
    "                ]\n",
    "                subst = {k: smt.substitute(v, (p1, p2)) for k, v in subst.items()}\n",
    "                subst[p1] = p2\n",
    "        elif is_var(p2):  # orient\n",
    "            todo.append((p2, p1))\n",
    "        elif smt.is_app(p1):  # decompose\n",
    "            if not smt.is_app(p2) or p1.decl() != p2.decl():\n",
    "                constrs.append((p1, p2))\n",
    "            todo.extend(zip(p1.children(), p2.children()))\n",
    "        else:\n",
    "            raise Exception(\"unexpected case\", p1, p2)\n",
    "    constrs = [\n",
    "                (smt.substitute(t1, *subst.items()), smt.substitute(t2, *subst.items()))\n",
    "                    for (t1, t2) in constrs\n",
    "                ]\n",
    "    print(\"constrs\", constrs)\n",
    "    if all(E.is_eq(c1, c2) for c1, c2 in constrs):\n",
    "        return [subst]\n",
    "    else:\n",
    "        rem_vs = list(set(vs) - set(subst.keys()))\n",
    "        if len(rem_vs) == 0:\n",
    "            return []\n",
    "        substs = []\n",
    "        # Bottom up ematching to solve the constraints\n",
    "        for ts in E.iter(rem_vs):\n",
    "            if all(E.is_eq(smt.substitute(c1,*zip(rem_vs, ts)), smt.substitute(c1,zip(rem_vs, ts))) for c1,c2 in constrs):\n",
    "                substs.append({**subst, **dict(zip(rem_vs, ts))})\n",
    "        return substs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example succeeds in a normal way using syntactic unification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constrs []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{x: a}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = EGraph()\n",
    "x,y,z = smt.Ints(\"x y z\")\n",
    "a,b,c = smt.Ints(\"a b c\")\n",
    "\n",
    "eunify_naive([x], x ** a, a ** x, E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example fails to unify syntactically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constrs [(b, a)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = EGraph()\n",
    "eunify_naive([x], x ** b, a ** x, E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But under the assumption `a = b` going into the egraph now it can succeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constrs [(a, b)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{x: a}]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = EGraph()\n",
    "E.union(a, b)\n",
    "eunify_naive([x], x ** a, b ** x, E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better (or just different?)\n",
    "This naive approach is incomplete in at least this sense: We cannot eagerly take the decompose moves. The egraph offers a new rule \n",
    "`EMatch : {t1 = t2} uplus S  ===>  {sigma uplus sigma(S) | sigma in E.ematch(vs,t1,t2) }`  where the substitutions come from e-matching against the e-graph.\n",
    "\n",
    "We have a nondeterminism because this e-matching rule is nondeterminstic and because we don't know whether to apply decompose and this rule. Huge bummer.\n",
    "\n",
    "As an example of the failure consider the goal equation `foo(X,a) =? foo(b,c)` and an egraph containing the equality `foo(b, a) = foo(b,c)`. We take a decompose move  to `{X =? b, a =? c}` and have solved `X` now. But we have unification failure on `a =? c` so we switch to e-matching. But we don't have `a = c` in the egraph either, so the above naive procedure fails. Nevertheless, the substitution `X = b` does actually solve the goal equation modulo the egraph equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constrs [(a, c)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = smt.Function(\"foo\", smt.IntSort(), smt.IntSort(), smt.IntSort())\n",
    "E = EGraph()\n",
    "E.union(foo(b,a), foo(b,c))\n",
    "eunify_naive([x], foo(x, a), foo(b, c), E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you have to do is actually search instead of eagerly taking the decompose step. At every possible decompose step, you should also switch into e-matching mode at that point too. I _think_ this methodology would get you a complete set of solutions for unification modulo e-graphs.\n",
    "\n",
    "What I think makes the most sense is a deeply integrated unifier and top down ematcher. That isn't really what I have here though. I have avoided writing top down ematchers recently. I should try though.\n",
    "\n",
    "Instead, here is the brute force form of just taking every possible ematch vs decompose move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{x: b}]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eunify2(vs: list[smt.ExprRef], p1: smt.ExprRef, p2: smt.ExprRef, E : EGraph) -> list[dict[smt.ExprRef, smt.ExprRef]]:\n",
    "    subst0 = {}\n",
    "    todo0 = [(p1, p2)]\n",
    "    constrs0 = []\n",
    "    branches = [(todo0, subst0, constrs0)]\n",
    "    res = []\n",
    "\n",
    "    def is_var(x):\n",
    "        return any(x.eq(v) for v in vs)\n",
    "\n",
    "    while branches:\n",
    "        todo, subst, constrs = branches.pop()\n",
    "        while todo:\n",
    "            p1, p2 = todo.pop()\n",
    "            if p1.eq(p2):  # delete\n",
    "                continue\n",
    "            elif is_var(p1):  # elim\n",
    "                #if kd.utils.occurs(p1, p2):\n",
    "                #    return None\n",
    "                todo = [\n",
    "                    (smt.substitute(t1, (p1, p2)), smt.substitute(t2, (p1, p2)))\n",
    "                    for (t1, t2) in todo\n",
    "                ]\n",
    "                subst = {k: smt.substitute(v, (p1, p2)) for k, v in subst.items()}\n",
    "                subst[p1] = p2\n",
    "            elif is_var(p2):  # orient\n",
    "                todo.append((p2, p1))\n",
    "            elif smt.is_app(p1):  # decompose\n",
    "                branches.append((todo.copy(), subst.copy(), constrs + [(p1,p2)]))\n",
    "                if smt.is_app(p2) and p1.decl() == p2.decl():\n",
    "                    todo.extend(zip(p1.children(), p2.children()))\n",
    "            else:\n",
    "                raise Exception(\"unexpected case\", p1, p2)\n",
    "        constrs = [\n",
    "                    (smt.substitute(t1, *subst.items()), smt.substitute(t2, *subst.items()))\n",
    "                        for (t1, t2) in constrs\n",
    "                    ]\n",
    "        if all(E.is_eq(c1, c2) for c1, c2 in constrs):\n",
    "            res.append(subst)\n",
    "        else:\n",
    "            rem_vs = list(set(vs) - set(subst.keys()))\n",
    "            if len(rem_vs) == 0:\n",
    "                continue\n",
    "            for ts in E.iter(rem_vs):\n",
    "                if all(E.is_eq(smt.substitute(c1,*zip(rem_vs, ts)), smt.substitute(c1,zip(rem_vs, ts))) for c1,c2 in constrs):\n",
    "                    res.append({**subst, **dict(zip(rem_vs, ts))})\n",
    "    return res\n",
    "\n",
    "foo = smt.Function(\"foo\", smt.IntSort(), smt.IntSort(), smt.IntSort())\n",
    "E = EGraph()\n",
    "E.union(foo(b,a), foo(b,c))\n",
    "eunify2([x], foo(x, a), foo(b, c), E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bottom Up E-Unification\n",
    "\n",
    "I have been pushing bottom up e-matching https://arxiv.org/abs/2504.14340 . It also seems to work for unification. You can guess unification solutions because they are seeded out of the unification problem terms themselves.\n",
    "\n",
    "I can just use my dumb dumb bottom up ematching to perform E-unification by adding the pattern terms as possible seeds in the egraph.\n",
    "\n",
    "I think this kind of works. I'm not so sure about completeness.\n",
    "\n",
    "It also does get you theory understanding from z3 which is also pretty awesome. And damn tootin is this some short code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{x: b}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "from kdrag.solvers.egraph import EGraph\n",
    "from kdrag.all import *\n",
    "\n",
    "def eunify(vs, t1, t2, E=None):\n",
    "    if E is None:\n",
    "        E = EGraph()\n",
    "    else:\n",
    "        E = E.copy()\n",
    "    E.add_term(t1)\n",
    "    E.add_term(t2)\n",
    "    E.rebuild()\n",
    "    res = [] \n",
    "    for ts in E.iter(vs):\n",
    "            lhs = smt.substitute(t1, *zip(vs, ts))\n",
    "            rhs = smt.substitute(t2, *zip(vs, ts))\n",
    "            with E.solver:\n",
    "                E.solver.add([v == t for v,t in zip(vs, ts)])\n",
    "                if E.solver.check() == smt.unsat: # substitution is semantically viable\n",
    "                    continue\n",
    "                E.solver.add(lhs != rhs) # substitution does force lhs == rhs\n",
    "                if E.solver.check() == smt.unsat:\n",
    "                    res.append(dict(zip(vs, ts)))\n",
    "    return res\n",
    "\n",
    "x,y,z = smt.Ints(\"x y z\")\n",
    "a,b,c = smt.Ints(\"a b c\")\n",
    "foo = smt.Function(\"foo\", smt.IntSort(), smt.IntSort(), smt.IntSort())\n",
    "E = EGraph()\n",
    "E.union(foo(b,a), foo(b,c))\n",
    "eunify([x], foo(x, a), foo(b, c), E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bits and Bobbles \n",
    "\n",
    "Pavel has been making the connection that pattern matching modulo theories is related to quantifier elimination. Syntactic unification is kind of quantifier elimination for the theory of algebraic datatypes (which have the injectivity to support \"decompose\" and have wellfoundedness enforced by the occurs check).\n",
    "\n",
    "\n",
    "- https://pavpanchekha.com/blog/lin-graphs.html\n",
    "- https://pavpanchekha.com/blog/egraph-t.html\n",
    "- https://pavpanchekha.com/blog/p-graphs.html\n",
    "\n",
    " I have actually felt this while building pattern matchers in knuckledragger. Pattern variables are implicitly existentially quantified. If smt had a choice quantifier, that'd be great.\n",
    "\n",
    "Functional Logic programming would be the better target of integration I'd think. Are egraphs useful as part of tabling in FLP?\n",
    "\n",
    "One place where equalities have shown up in LP is for trait resolution in Rust with associated types. https://doc.rust-lang.org/rust-by-example/generics/assoc_items/types.html These become introduced equalities during the prolog like trait resolution search https://rust-lang.github.io/chalk/book/what_is_chalk.html\n",
    " https://github.com/rust-lang/chalk . Maybe unification modulo egraphs could help here. Not so sure.\n",
    "\n",
    "I've seen some discussion of bottom up unification for higher order unification in Gilles dowek's chapter in the handbook of automated reasoning. It is introduced as merely a conceptual device though. Maybe one should implement it? But also I should implement actual Huet unification.\n",
    "\n",
    "Unification is double sided pattern matching. It's logic talk for equation solving. You are presented a set of goals equations with variables and you want to produce a substitution (at least in the narrow sense of equation solving) to those variables to make the equations hold.\n",
    "\n",
    "Unification powers logic programming like prolog and more so than the other ingredient of backtracking/search, powers the bidirectional flavor of the subject.\n",
    "\n",
    "Unification usually starts from a standpoint of syntactic unification where every function symbol is considered to be injective akin to an algebraic datatype. This makes life easier.\n",
    "\n",
    "There is also E-unification, unification modulo some background theory E, like baked in linearity, booleans, associativity etc.\n",
    "\n",
    "Unification modulo E-graphs is E-unification modulo the theory E of ground equations the egraph represents.\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Unification_(computer_science)\n",
    "- https://www.philipzucker.com/unify/\n",
    "\n",
    "\n",
    "I would think that e-graphs might also be used as a form of tabling for functional logic programming.\n",
    "\n",
    "\n",
    "One version of this might be to try regular unification and if at any point that fails at pattern `p1 =? p2`, try to solve the unsolvable equation by double sided e-matching in an E-graph (ie is the a grounding of the variables in p1 and p2 such that the egraph asserts them equal).\n",
    "\n",
    "This isn't particularly complete but has the advantage of less search compared to other methods.\n",
    "\n",
    "Ok, I could switch over to ematching in a simple way becasue ematching is multivalued.\n",
    "\n",
    "\n",
    "\n",
    "It is nice to make your unify just punt some stuff into a constraints list.\n",
    "\n",
    "Ultimately, the substitutions of unification are seeded out of the original terms.\n",
    "A bottom up form of unification if to guess every possible substitution out of some over approximation of the possible substitutions.\n",
    "\n",
    "This is crazily inefficient from a syntactic unification perspective, but the more you add on theories, the more compelling it becomes.\n",
    "\n",
    "The EGraph itself can become a unifier by adding the patterns to the egraph and performing regular bottom up ematching.\n",
    "\n",
    "I think that non well-founded substitutions \n",
    "\n",
    "To what degree is an non well-founded substitution better than the incoming goals? It represents a solution as a kind of rational tree.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify(vs: list[smt.ExprRef], p1: smt.ExprRef, p2: smt.ExprRef) -> Optional[dict[smt.ExprRef, smt.ExprRef]]:\n",
    "    subst = {}\n",
    "    todo = [(p1, p2)]\n",
    "    constrs = []\n",
    "\n",
    "    def is_var(x):\n",
    "        return any(x.eq(v) for v in vs)\n",
    "\n",
    "    while todo:\n",
    "        p1, p2 = todo.pop()  # we could pop _any_ of the todos, not just the top.\n",
    "        if p1.eq(p2):  # delete\n",
    "            continue\n",
    "        elif is_var(p1):  # elim\n",
    "            if occurs(p1, p2):\n",
    "                return None\n",
    "            todo = [\n",
    "                (smt.substitute(t1, (p1, p2)), smt.substitute(t2, (p1, p2)))\n",
    "                for (t1, t2) in todo\n",
    "            ]\n",
    "            subst = {k: smt.substitute(v, (p1, p2)) for k, v in subst.items()}\n",
    "            subst[p1] = p2\n",
    "        elif is_var(p2):  # orient\n",
    "            todo.append((p2, p1))\n",
    "        elif smt.is_app(p1):  # decompose\n",
    "            if not smt.is_app(p2) or p1.decl() != p2.decl():\n",
    "                constrs.append((p1, p2))\n",
    "            todo.extend(zip(p1.children(), p2.children()))\n",
    "        else:\n",
    "            raise Exception(\"unexpected case\", p1, p2)\n",
    "    return subst, constrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weak_eunify(\n",
    "    vs: list[smt.ExprRef], p1: smt.ExprRef, p2: smt.ExprRef, E : EGraph\n",
    ") -> Optional[dict[smt.ExprRef, smt.ExprRef]]:\n",
    "    \"\"\"Unification\"\"\"\n",
    "    def is_var(x):\n",
    "            return any(x.eq(v) for v in vs)\n",
    "    branches = [({}, [(p1,p2)])]\n",
    "    \n",
    "    while branches:\n",
    "        subst, todo = branches.pop()\n",
    "        while todo:\n",
    "            p1, p2 = todo.pop()  # we could pop _any_ of the todos, not just the top.\n",
    "            if p1.eq(p2):  # delete\n",
    "                continue\n",
    "            elif is_var(p1):  # elim\n",
    "                if occurs(p1, p2):\n",
    "                    return None\n",
    "                todo = [\n",
    "                    (smt.substitute(t1, (p1, p2)), smt.substitute(t2, (p1, p2)))\n",
    "                    for (t1, t2) in todo\n",
    "                ]\n",
    "                subst = {k: smt.substitute(v, (p1, p2)) for k, v in subst.items()}\n",
    "                subst[p1] = p2\n",
    "            elif is_var(p2):  # orient\n",
    "                todo.append((p2, p1))\n",
    "            elif smt.is_app(p1):  # decompose\n",
    "                #if not smt.is_app(p2) or p1.decl() != p2.decl():\n",
    "                # find vs in p1, p2\n",
    "                for match_ in E.ematch(p1,p2):\n",
    "                    tcopy = [\n",
    "                        (smt.substitute(t1, match_), smt.substitute(t2, match_))\n",
    "                        for (t1, t2) in todo.copy()\n",
    "                    ]\n",
    "                    scopy = subst.copy()\n",
    "                    branches.append((scopy, tcopy))\n",
    "                todo.extend(zip(p1.children(), p2.children()))\n",
    "            else:\n",
    "                raise Exception(\"unexpected case\", p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weak_eunify(vs,t1,t2,E):\n",
    "    todo = [(t1,t2)]\n",
    "    subst = {}\n",
    "    while todo:\n",
    "        t1, t2 = todo.pop()\n",
    "        if t1.eq(t2):\n",
    "            continue\n",
    "        if isinstance(t1, str) and isinstance(t2, str):\n",
    "            if t1 in vs or t2 in vs:\n",
    "                E.append((t1, t2))\n",
    "            else:\n",
    "                return False\n",
    "        elif isinstance(t1, list) and isinstance(t2, list):\n",
    "            if len(t1) != len(t2):\n",
    "                return False\n",
    "            todo.extend(zip(t1, t2))\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "def better\n",
    "def bottom_up_eunify()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full lambda unification\n",
    "context unification\n",
    "secord order unification\n",
    "linear lambda unification\n",
    "\n",
    "https://stackoverflow.com/questions/1936432/higher-order-unification\n",
    "\n",
    "unif conference https://www.irif.fr/~treinen/unif/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unification modulo egraphs\n",
    "We can recurse down and choose to match subterms by either ematching or syntactic unification\n",
    "\n",
    "Or we can go bottom up\n",
    "\n",
    "Why?\n",
    "E-KB is interesting.\n",
    "Side car egraph in a prolog might be interesting.\n",
    "\n",
    "\n",
    "You might think you can eagerly take\n",
    "\n",
    "f(t) = f(s) ---> t = s\n",
    "But you can't\n",
    "\n",
    "consider an egraph f(a) = f(b)\n",
    "\n",
    "and now we want to solve f(a) = f(b). We process it via the unification head rule to \n",
    "\n",
    "\n",
    "https://www.philipzucker.com/unify/\n",
    "![](https://www.philipzucker.com/assets/traat/unify_rules.png)\n",
    "\n",
    "```\n",
    "{t = s, S}  --->  sigma S ematch\n",
    "```\n",
    "\n",
    "We can't just eagerly take head peeling moves. The egraph may have f(x) = f(y) but not x = y. In which case peeling off f is a bad move.\n",
    "\n",
    "We could pick different worlds at the outset. Is x a var or grounded?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(set-logic ALL)\n",
      "\n",
      "(declare-sort T 0)\n",
      "\n",
      ";;declarations\n",
      "\n",
      "(declare-fun y_98 () T)\n",
      "\n",
      "(declare-fun x_97 () T)\n",
      "\n",
      ";;axioms\n",
      "\n",
      "(assert (distinct x_97 y_98))\n",
      "\n",
      "(check-sat)\n",
      "\n",
      "b'WARNING Broken Constraint: if inner_rewriting(on) has been set then saturation_algorithm(fmb) is equal to lrs or saturation_algorithm(fmb) is equal to otter or saturation_algorithm(fmb) is equal to discount\\nWARNING Broken Constraint: if inline_let(on) has been set then newcnf(off) is equal to on\\nWARNING Broken Constraint: if inline_let(on) has been set then newcnf(off) is equal to on\\nWARNING Broken Constraint: if inline_let(on) has been set then newcnf(off) is equal to on\\nWARNING Broken Constraint: if inline_let(on) has been set then newcnf(off) is equal to on\\nWARNING Broken Constraint: if inline_let(on) has been set then newcnf(off) is equal to on\\nWARNING Broken Constraint: if symbol_precedence(reverse_arity) has been set then saturation_algorithm(fmb) is equal to lrs or saturation_algorithm(fmb) is equal to otter or saturation_algorithm(fmb) is equal to discount\\nWARNING Broken Constraint: if sos(all) has been set then saturation_algorithm(fmb) is equal to lrs or saturation_algorithm(fmb) is equal to otter or saturation_algorithm(fmb) is equal to discount\\nWARNING Broken Constraint: if literal_maximality_aftercheck(on) has been set then saturation_algorithm(fmb) is equal to lrs or saturation_algorithm(fmb) is equal to otter or saturation_algorithm(fmb) is equal to discount\\nWARNING Broken Constraint: if lrs_weight_limit_only(on) has been set then saturation_algorithm(discount) is equal to lrs\\nWARNING Broken Constraint: if literal_comparison_mode(predicate) has been set then saturation_algorithm(fmb) is equal to lrs or saturation_algorithm(fmb) is equal to otter or saturation_algorithm(fmb) is equal to discount\\nWARNING Broken Constraint: if nongoal_weight_coefficient(1.7) has been set then saturation_algorithm(fmb) is equal to lrs or saturation_algorithm(fmb) is equal to otter or saturation_algorithm(fmb) is equal to discount\\nWARNING Broken Constraint: if avatar(off) has been set then saturation_algorithm(fmb) is equal to lrs or saturation_algorithm(fmb) is equal to otter or saturation_algorithm(fmb) is equal to discount\\nWARNING Broken Constraint: if inline_let(on) has been set then newcnf(off) is equal to on\\nWARNING Broken Constraint: if lrs_weight_limit_only(on) has been set then saturation_algorithm(discount) is equal to lrs\\nWARNING Broken Constraint: if inline_let(on) has been set then newcnf(off) is equal to on\\nWARNING Broken Constraint: if inline_let(on) has been set then newcnf(off) is equal to on\\nWARNING Broken Constraint: if inline_let(on) has been set then newcnf(off) is equal to on\\nWARNING Broken Constraint: if inline_let(on) has been set then newcnf(off) is equal to on\\nWARNING Broken Constraint: if inline_let(on) has been set then newcnf(off) is equal to on\\nsat\\n'\n",
      "b''\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>sat</b>"
      ],
      "text/plain": [
       "sat"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.solvers import VampireSolver\n",
    "import z3\n",
    "T = z3.DeclareSort(\"T\")\n",
    "x,y,z = z3.Consts(\"x y z\", T)\n",
    "s = VampireSolver()\n",
    "s.add(x != y)\n",
    "s.check()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "from kdrag.solvers.egraph import EGraph\n",
    "\n",
    "def eunify(vs, t1, t2):\n",
    "    todo = [(t1,t2)]\n",
    "    while todo:\n",
    "        t1, t2 = todo.pop()\n",
    "        if t1.eq(t2):\n",
    "            continue\n",
    "\n",
    "# a different approach. Variables are preselected as to be ematched vs unified.\n",
    "def eunify(avs, evs, t1, t2, E):\n",
    "    def is_ground(t):\n",
    "        return kd.utils.free_in(avs, t)\n",
    "    if is_ground(t1):\n",
    "        if is_ground(t2):\n",
    "            if E.find(t1) != E.find(t2):\n",
    "                return\n",
    "        else:\n",
    "            ematch(\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add top down capabilities.\n",
    "eid + decl -> children\n",
    "or decl -> (i,j,k) children and parent.\n",
    "\n",
    "This would be good for an apples to apples comparison of the technqiues of top down vs bottom up.\n",
    "\n",
    "\n",
    "Bottom up unification.\n",
    "Can I bound all possible substitutions a priori?\n",
    "Pick ordering\n",
    "v1 = all subterms\n",
    "subst back in \n",
    "\n",
    "I think maybe v goes to all possible subterms?\n",
    "Some well founded some not. But we don't want only well founded. Occurs check is for datatypes\n",
    "\n",
    "Apply a substitution to the egraph that holds unification vars...\n",
    "Maybe. It's a violent thing to do.\n",
    "\n",
    "\n",
    "Hmm. Should I be checking that the unsats aren't because of impossibilities? Rather than the matching condition?\n",
    "\n",
    "\n",
    "\n",
    "Wait. This isn't just unification modulo egraphs. It's unification modulo all the theories of z3. Just not a most general unifier.\n",
    "\n",
    "Hmm. The theory of uninterpreted functions makes nearly everything a _possible_ solution? Except patent impossibilities.\n",
    "Oh. Oh dear. Maybe that is a problem. \n",
    "No. I'm insane.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({x: x, y: z}, x + z, x + z),\n",
       " ({x: y, y: z}, y + z, y + z),\n",
       " ({x: x + y, y: z}, x + y + z, x + y + z),\n",
       " ({x: x + z, y: z}, x + z + z, x + z + z),\n",
       " ({x: z, y: x}, z + x, z + z),\n",
       " ({x: z, y: z}, z + z, z + z)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "from kdrag.solvers.egraph import EGraph\n",
    "from kdrag.all import *\n",
    "\n",
    "def eunify(vs, t1, t2, E=None):\n",
    "    if E is None:\n",
    "        E = EGraph()\n",
    "    else:\n",
    "        E = E.copy()\n",
    "    E.add_term(t1)\n",
    "    E.add_term(t2)\n",
    "    E.rebuild()\n",
    "    res = [] \n",
    "    for eids in itertools.product(*[E.roots[v.sort()] for v in vs]):\n",
    "            ts = [E.terms[eid] for eid in eids]\n",
    "            lhs = smt.substitute(t1, *zip(vs, ts))\n",
    "            rhs = smt.substitute(t2, *zip(vs, ts))\n",
    "            #if E.is_eq(lhs, rhs):\n",
    "            with E.solver:\n",
    "                E.solver.add([v == t for v,t in zip(vs, ts)])\n",
    "                if E.solver.check() == smt.unsat: # substitution is semantically viable\n",
    "                    continue\n",
    "                E.solver.add(lhs != rhs) # substitution does force lhs == rhs\n",
    "                if E.solver.check() == smt.unsat:\n",
    "                    res.append((dict(zip(vs, ts)), lhs, rhs))\n",
    "    return res\n",
    "\n",
    "x,y,z = smt.Reals(\"x y z\")\n",
    "eunify([x,y], x + y, x + z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({x: x, y: z}, x + z, x + z),\n",
       " ({x: y, y: z}, y + z, y + z),\n",
       " ({x: x + y, y: z}, x + y + z, x + y + z)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def subsume(subst1, subst2, E): # subst1 implies subst2\n",
    "    with E.solver:\n",
    "        E.solver.add([v == t for v,t in subst1.items()])\n",
    "        if all(E.is_eq(t1,t2) for t1, t2 in subst2.items()):\n",
    "            return True\n",
    "        else: \n",
    "            return False\n",
    "        \n",
    "def prune(substs, E=None):\n",
    "    if E is None:\n",
    "        E = EGraph()\n",
    "    res = []\n",
    "    for (subst, lhs, rhs) in substs:\n",
    "        if any(subsume(s[0], subst, E) and subsume(subst, s[0], E) for s in res): # equivalent substitutions\n",
    "            continue\n",
    "        else:\n",
    "            res.append((subst,lhs,rhs))\n",
    "    return res\n",
    "prune(eunify([x,y], x + y, x + z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({x: x, y: z}, foo(x, z), foo(x, z)),\n",
       " ({x: y, y: z}, foo(y, z), foo(y, z)),\n",
       " ({x: foo(x, z), y: z}, foo(foo(x, z), z), foo(foo(x, z), z)),\n",
       " ({x: z, y: x}, foo(z, x), foo(z, z)),\n",
       " ({x: z, y: z}, foo(z, z), foo(z, z)),\n",
       " ({x: foo(x, y), y: z}, foo(foo(x, y), z), foo(foo(x, y), z))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = smt.Function(\"foo\", smt.RealSort(), smt.RealSort(), smt.RealSort())\n",
    "eunify([x,y], foo(x, y), foo(x, z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([({n: k, m: k, k: add(S(m), n)}, add(S(k), k), add(S(m), n)),\n",
       "  ({n: k, m: m, k: add(S(m), n)}, add(S(m), k), add(S(m), n)),\n",
       "  ({n: k, m: n, k: add(S(m), n)}, add(S(n), k), add(S(m), n)),\n",
       "  ({n: k, m: add(S(m), n), k: m}, add(S(add(S(m), n)), k), m),\n",
       "  ({n: k, m: add(S(m), n), k: add(S(m), n)},\n",
       "   add(S(add(S(m), n)), k),\n",
       "   add(S(m), n)),\n",
       "  ({n: m, m: k, k: add(S(m), n)}, add(S(k), m), add(S(m), n)),\n",
       "  ({n: m, m: m, k: add(S(m), n)}, add(S(m), m), add(S(m), n)),\n",
       "  ({n: m, m: n, k: add(S(m), n)}, add(S(n), m), add(S(m), n)),\n",
       "  ({n: m, m: add(S(m), n), k: m}, add(S(add(S(m), n)), m), m),\n",
       "  ({n: m, m: add(S(m), n), k: n}, add(S(add(S(m), n)), m), n),\n",
       "  ({n: m, m: add(S(m), n), k: add(S(m), n)},\n",
       "   add(S(add(S(m), n)), m),\n",
       "   add(S(m), n)),\n",
       "  ({n: n, m: k, k: add(S(m), n)}, add(S(k), n), add(S(m), n)),\n",
       "  ({n: n, m: m, k: add(S(m), n)}, add(S(m), n), add(S(m), n)),\n",
       "  ({n: n, m: n, k: add(S(m), n)}, add(S(n), n), add(S(m), n)),\n",
       "  ({n: n, m: add(S(m), n), k: m}, add(S(add(S(m), n)), n), m),\n",
       "  ({n: n, m: add(S(m), n), k: add(S(m), n)},\n",
       "   add(S(add(S(m), n)), n),\n",
       "   add(S(m), n)),\n",
       "  ({n: add(S(m), n), m: k, k: n}, add(S(k), add(S(m), n)), n),\n",
       "  ({n: add(S(m), n), m: k, k: add(S(m), n)},\n",
       "   add(S(k), add(S(m), n)),\n",
       "   add(S(m), n)),\n",
       "  ({n: add(S(m), n), m: m, k: n}, add(S(m), add(S(m), n)), n),\n",
       "  ({n: add(S(m), n), m: m, k: add(S(m), n)},\n",
       "   add(S(m), add(S(m), n)),\n",
       "   add(S(m), n)),\n",
       "  ({n: add(S(m), n), m: n, k: m}, add(S(n), add(S(m), n)), m),\n",
       "  ({n: add(S(m), n), m: n, k: n}, add(S(n), add(S(m), n)), n),\n",
       "  ({n: add(S(m), n), m: n, k: add(S(m), n)},\n",
       "   add(S(n), add(S(m), n)),\n",
       "   add(S(m), n)),\n",
       "  ({n: add(S(m), n), m: add(S(m), n), k: m},\n",
       "   add(S(add(S(m), n)), add(S(m), n)),\n",
       "   m),\n",
       "  ({n: add(S(m), n), m: add(S(m), n), k: n},\n",
       "   add(S(add(S(m), n)), add(S(m), n)),\n",
       "   n),\n",
       "  ({n: add(S(m), n), m: add(S(m), n), k: add(S(m), n)},\n",
       "   add(S(add(S(m), n)), add(S(m), n)),\n",
       "   add(S(m), n)),\n",
       "  ({n: S(m), m: k, k: add(S(m), n)}, add(S(k), S(m)), add(S(m), n)),\n",
       "  ({n: S(m), m: m, k: add(S(m), n)}, add(S(m), S(m)), add(S(m), n)),\n",
       "  ({n: S(m), m: add(S(m), n), k: m}, add(S(add(S(m), n)), S(m)), m),\n",
       "  ({n: S(m), m: add(S(m), n), k: add(S(m), n)},\n",
       "   add(S(add(S(m), n)), S(m)),\n",
       "   add(S(m), n))],\n",
       " [({n: k, m: k, k: add(S(m), n)}, add(S(k), k), add(S(m), n)),\n",
       "  ({n: k, m: m, k: add(S(m), n)}, add(S(m), k), add(S(m), n)),\n",
       "  ({n: m, m: m, k: add(S(m), n)}, add(S(m), m), add(S(m), n)),\n",
       "  ({n: n, m: k, k: add(S(m), n)}, add(S(k), n), add(S(m), n)),\n",
       "  ({n: n, m: m, k: add(S(m), n)}, add(S(m), n), add(S(m), n)),\n",
       "  ({n: S(m), m: k, k: add(S(m), n)}, add(S(k), S(m)), add(S(m), n)),\n",
       "  ({n: S(m), m: m, k: add(S(m), n)}, add(S(m), S(m)), add(S(m), n))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kdrag.theories.nat as nat\n",
    "\n",
    "n,m,k = smt.Consts(\"n m k\", nat.Nat)\n",
    "E = EGraph()\n",
    "#E.union(nat.Z + nat.Z, nat.Z)\n",
    "#E.union(nat.S(nat.Z) + nat.Z, nat.S(nat.Z))\n",
    "#E.union(nat.Z + nat.S(nat.Z), nat.S(nat.Z))\n",
    "#E.solver.add(nat.add.defn.thm)\n",
    "eunify([n,m, k], nat.S(m) + n, k, E)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([({n: A, m: n}, Foo(A, A), Foo(n, A)),\n",
       "  ({n: A, m: A}, Foo(A, A), Foo(A, A)),\n",
       "  ({n: m, m: A}, Foo(m, m), Foo(A, A))],\n",
       " [({n: A, m: n}, Foo(A, A), Foo(n, A))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kdrag.theories.nat as nat\n",
    "\n",
    "Expr = kd.Inductive(\"Expr\")\n",
    "Expr.declare(\"A\")\n",
    "Expr.declare(\"B\")\n",
    "Expr.declare(\"Foo\", (\"f1\", Expr), (\"f2\", Expr))\n",
    "Expr = Expr.create()\n",
    "Foo,A,B = Expr.Foo, Expr.A, Expr.B\n",
    "n,m,k = smt.Consts(\"n m k\", Expr)\n",
    "#E = EGraph()\n",
    "#E.union(nat.Z + nat.Z, nat.Z)\n",
    "#E.union(nat.S(nat.Z) + nat.Z, nat.S(nat.Z))\n",
    "#E.union(nat.Z + nat.S(nat.Z), nat.S(nat.Z))\n",
    "#E.solver.add(nat.add.defn.thm)\n",
    "eunify([n,m], Foo(n,n), Foo(m,A)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x + y) + z  ==  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (46329317.py, line 6)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mE.\u001b[39m\n      ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "from kdrag.solvers.egraph import EGraph\n",
    "def eunify(vs, E, t1, t2):\n",
    "    todo = [(t1,t2)]\n",
    "    subst = {}\n",
    "    def is_var(t):\n",
    "        return any(v.eq(t) for v in vs)\n",
    "    while todo:\n",
    "        t1, t2 = todo.pop()\n",
    "        if E.is_eq(t1,t2):\n",
    "            continue\n",
    "        else:\n",
    "            if is_var(t1):\n",
    "\n",
    "            # It's the decompose move that needs egraph expansion.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.all import *\n",
    "\n",
    "Egraph = dict[int, smt.ExprRef]\n",
    "\n",
    "def find(egraph, expr):\n",
    "    while expr.get_id() in egraph:\n",
    "        expr = egraph[expr.get_id()]\n",
    "    return expr\n",
    "\n",
    "def union(egraph, e1, e2):\n",
    "    e1 = find(egraph, e1)\n",
    "    e2 = find(egraph, e2)\n",
    "    if e1.eq(e2):\n",
    "        return e1\n",
    "    egraph[e1.get_id()] = e2\n",
    "    return e2\n",
    "\n",
    "def rebuild(egraph):\n",
    "    # Rebuild the egraph\n",
    "    new_egraph = {}\n",
    "    for expr in egraph.values():\n",
    "        \n",
    "    return new_egraph\n",
    "\n",
    "def \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The brute force egraph.\n",
    "bottom up ematching turns patterns into guards\n",
    "\n",
    "\n",
    "could maybe use contexts as unsat cores? \n",
    "\n",
    "ctxs : list[smt.BoolRef]\n",
    "\n",
    "rebuild removes impossible contexts. hmhm\n",
    "coalescing contexts also. Some are equivalent. Some imply the others.\n",
    "\n",
    "\n",
    "for ctx in ctxs:\n",
    "\n",
    "\n",
    "SMT Solvers as theories. I said that for SMT modulo SMT you can use smt as a pure theory solver.\n",
    "sunsat cores communicate back.\n",
    "\n",
    "Egraphs modulo theorie but the theory is smt. Egraph modulo SMT. Now we're getting insane. The \"value\" object is smtexpr. We don't have a normalizer, but we do have an equality oracle. You can still work with this. \n",
    "Shostak is normalizer. Nelson-Oppen is equality oracle (slash propagator).\n",
    "\n",
    "SMTmodel |= SMT |= Eqs\n",
    "\n",
    "https://microsoft.github.io/z3guide/programming/Example%20Programs/Formula%20Simplification/\n",
    "Well, there ya go.\n",
    "He;'s also using model based pruning.\n",
    "This makes a term bank out of the single term to be simplified. It replaces subterms with other equivalent subterms. A nice kind of semantic cse.\n",
    "Whereas the eqsat approach is generating new nice subterms.\n",
    "\n",
    "It's kind of a knob towards https://www.pypy.org/posts/2024/07/finding-simple-rewrite-rules-jit-z3.html or ruler but as the egraph itself. Ruler discovers non ground rules. We're discovering the egraph.\n",
    "\n",
    "What are egraphs: Yes they are bipartite graph, a data structure.\n",
    "They are models. Show z3 model.\n",
    "Uninterpreted models.\n",
    "\n",
    "\n",
    "Egraphs aren't complete. the \"only\" wya to make them complete is to have a generation process or go unification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_equal(s, t1, t2):\n",
    "    s.push()\n",
    "    s.add(t1 != t2)\n",
    "    r = s.check()\n",
    "    s.pop()\n",
    "    return r == unsat\n",
    "\n",
    "def simplify(slv, mdl, t):\n",
    "    subs = subterms(t)\n",
    "    values = { s : mdl.eval(s) for s in subs }\n",
    "    values[t] = mdl.eval(t)\n",
    "    def simplify_rec(t):        \n",
    "        subs = subterms(t)\n",
    "        for s in subs:\n",
    "            if s.sort().eq(t.sort()) and values[s].eq(values[t]) and are_equal(slv, s, t):\n",
    "                return simplify_rec(s)\n",
    "        chs = [simplify_rec(ch) for ch in t.children()]\n",
    "        return t.decl()(chs)\n",
    "    return simplify_rec(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimal version doesn't even need union find\n",
    "@dataclass\n",
    "class EGraph():\n",
    "    terms : dict[int, smt.ExprRef]\n",
    "    solver : smt.Solver\n",
    "    def __init__(self):\n",
    "        self.terms = {}\n",
    "        self.solver = smt.Solver()\n",
    "    def add_term(self, t):\n",
    "        if t.get_id() not in self.terms:\n",
    "            self.terms[t.get_id()] = t\n",
    "            for c in t.children():\n",
    "                self.add_term(c)\n",
    "    def is_eq(self, t, s):\n",
    "        self.solver.push()\n",
    "        self.solver.add(t != s)\n",
    "        res = self.solver.check()\n",
    "        self.solver.pop()\n",
    "        return res == smt.unsat\n",
    "    def ematch(self, vs, p):\n",
    "        for ts in itertools.product(self.terms.values(), len(vs)):\n",
    "            s = smt.substitute(p, *zip(vs, ts))\n",
    "            for t in self.terms.values():\n",
    "                if self.is_eq(t, s):\n",
    "                    yield (ts, t) # maybe return s or p also. They are easily derived.?\n",
    "                    break\n",
    "\n",
    "E = EGraph()\n",
    "E.add_term()\n",
    "E.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EGraph():\n",
    "    canon_terms : dict[int, smt.ExprRef]\n",
    "    terms : dict[int, smt.ExprRef]\n",
    "    uf : dict[int, int]\n",
    "    solver : smt.Solver\n",
    "    #models : list[m]\n",
    "    #sigs : dict[tuple[Value,...], list[TermRef]]\n",
    "    #explain :   #  dict[(int,int), unsat cores]\n",
    "\n",
    "    def add_term(self, t):\n",
    "        if t.get_id() not in self.terms:\n",
    "            self.terms[t.get_id()] = t\n",
    "            for c in t.children():\n",
    "                self.add_term(c)\n",
    "    def term_matches(self, t): # guard=None\n",
    "        #self.solver.push()\n",
    "        #self.solver.add(cond)\n",
    "        # prune by models?\n",
    "        for s in self.canon_terms.values():\n",
    "            self.solver.push()\n",
    "            self.solver.add(t != s)\n",
    "            res = self.solver.check()\n",
    "            self.solver.pop()\n",
    "            if res == smt.unsat:\n",
    "                yield s\n",
    "\n",
    "    def union(self, e1, e2):\n",
    "        self.solver.add(e1 == e2)\n",
    "        # orient by smaller depth or sexpr size. Kind of could get some sharing action\n",
    "        # maybe immediately remove e1 e2\n",
    "        \"\"\"\n",
    "        e1 = self.find(e1)\n",
    "        e2 = self.find(e2)\n",
    "        if e1.eq(e2):\n",
    "            return e1\n",
    "        else:\n",
    "            del self.canon_terms[e1.get_id()]\n",
    "            self.terms[e1.get_id()] = e1\n",
    "        \"\"\"\n",
    "\n",
    "    def rebuild(self):\n",
    "        for t in self.canon_terms.values():\n",
    "            for s in self.matches(t):\n",
    "                self.union(t, s)\n",
    "                \n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.all import *\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class EGraph():\n",
    "    terms : dict[int, smt.ExprRef]\n",
    "    uf : dict[int, int]\n",
    "\n",
    "    def add_term(self, t):\n",
    "        if t.get_id() not in self.terms:\n",
    "            self.terms[t.get_id()] = t\n",
    "            for c in t.get_children():\n",
    "                self.add_term(c)\n",
    "    def find_id(self, eid):\n",
    "        while eid in self.uf:\n",
    "            eid = self.uf[eid]\n",
    "        return eid\n",
    "    def find(self, t):\n",
    "        if t.get_id() in self.terms:\n",
    "            return self.terms[self.find_id(t.get_id())]\n",
    "        else:\n",
    "            raise ValueError(f\"Term {t} not in egraph\")\n",
    "            #return t # maybe. Or error?\n",
    "    def canon(self, t):\n",
    "        args = [self.canon(c) for c in t.children()]\n",
    "        return self.find(t.decl()(*args))\n",
    "    def union(self, t1, t2):\n",
    "        t1 = self.find(t1)\n",
    "        t2 = self.find(t2)\n",
    "        if t1.eq(t2):\n",
    "            return t1\n",
    "        self.uf[t1.get_id()] = t2.get_id()\n",
    "        return t2\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EGraph():\n",
    "    terms : dict[int, smt.ExprRef]\n",
    "    uf : dict[int, int | smt.ExprRef] # constructor egraph. int represents keep going, expref means is canonical.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{f(a): a, a: f(f(f(a))), f(f(f(f(a)))): f(f(f(a)))}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "\n",
    "Egraph = dict[smt.ExprRef, smt.ExprRef]\n",
    "\n",
    "def find(egraph, expr):\n",
    "    while expr in egraph:\n",
    "        expr = egraph[expr]\n",
    "    return expr\n",
    "\n",
    "def union(egraph, e1, e2):\n",
    "    e1 = find(egraph, e1)\n",
    "    e2 = find(egraph, e2)\n",
    "    if e1.eq(e2):\n",
    "        return e1\n",
    "    egraph[e1] = e2\n",
    "    return e2\n",
    "\n",
    "def rebuild(egraph): # hmmm.\n",
    "    new_egraph = {}\n",
    "    for expr in egraph.keys():\n",
    "        new_expr = expr.decl()(*(find(egraph, c) for c in expr.children()))\n",
    "        if new_expr.eq(expr):\n",
    "            new_egraph[new_expr] = find(egraph, expr)\n",
    "    return new_egraph\n",
    "\n",
    "def rebuild(egraph):\n",
    "    todo = set(egraph.keys()) | set(egraph.values())\n",
    "    while todo:\n",
    "        e = todo.pop()\n",
    "        new_expr = e.decl()(*(find(egraph, c) for c in e.children()))\n",
    "        union(egraph, new_expr, e)\n",
    "    return egraph\n",
    "\n",
    "egg = {}\n",
    "\n",
    "a,b,c = smt.Ints('a b c')\n",
    "union(egg, a, b)\n",
    "union(egg, b, c)\n",
    "find(egg, a)\n",
    "rebuild(egg)\n",
    "\n",
    "f = smt.Function('f', smt.IntSort(), smt.IntSort())\n",
    "egg = {}\n",
    "union(egg, f(a), a)\n",
    "union(egg, a , f(f(f(a))))\n",
    "rebuild(egg)\n",
    "rebuild(egg)\n",
    "rebuild(egg)\n",
    "\n",
    "def enorm(egraph, t):\n",
    "    return find(egraph, t.decl()(*[enorm(c) for c in t.children()]))\n",
    "\n",
    "\n",
    "\n",
    "def rec_add(termbank, t):\n",
    "    if t not in termbank:\n",
    "        termbank.add(t)\n",
    "        for c in t.children():\n",
    "            rec_add(termbank, c)\n",
    "\n",
    "def compress_termbank(termbank):\n",
    "    tbank = {}\n",
    "    for t in termbank:\n",
    "        rec_add(tbank, enorm(egraph, t))\n",
    "    return tbank   \n",
    "\n",
    "def rebuild(egraph, termbank):\n",
    "    for t in termbank:\n",
    "        new_expr = t.decl()(*(find(egraph, c) for c in t.children()))\n",
    "        union(egraph, new_expr, t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'itertools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rules:\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subst, lhs \u001b[38;5;129;01min\u001b[39;00m \u001b[43mematch\u001b[49m\u001b[43m(\u001b[49m\u001b[43megraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtermbank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlhs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     26\u001b[0m         rhs \u001b[38;5;241m=\u001b[39m enorm(egraph, smt\u001b[38;5;241m.\u001b[39msubstitute(r\u001b[38;5;241m.\u001b[39mrhs, \u001b[38;5;241m*\u001b[39msubst))\n\u001b[1;32m     27\u001b[0m         termbank\u001b[38;5;241m.\u001b[39madd(rhs)\n",
      "Cell \u001b[0;32mIn[23], line 17\u001b[0m, in \u001b[0;36mematch\u001b[0;34m(egraph, termbank, vs, t)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mematch\u001b[39m(egraph, termbank, vs, t):\n\u001b[1;32m     16\u001b[0m     res \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ts \u001b[38;5;129;01min\u001b[39;00m \u001b[43mitertools\u001b[49m\u001b[38;5;241m.\u001b[39mproduct(termbank, (vs)):\n\u001b[1;32m     18\u001b[0m         subst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(vs, ts))\n\u001b[1;32m     19\u001b[0m         t1 \u001b[38;5;241m=\u001b[39m enorm(egraph, smt\u001b[38;5;241m.\u001b[39msubstitute(t, \u001b[38;5;241m*\u001b[39msubst))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'itertools' is not defined"
     ]
    }
   ],
   "source": [
    "import kdrag.theories.int as int_\n",
    "\n",
    "rules = [\n",
    "    int_.add_assoc,\n",
    "    int_.add_comm,\n",
    "    int_.add_zero,\n",
    "    int_.mul_assoc,\n",
    "    int_.mul_comm,\n",
    "    int_.mul_zero,\n",
    "]\n",
    "rules = [rw.rewrite_of_expr(r) for r in rules]\n",
    "termbank = { a + a + a}\n",
    "egraph = {}\n",
    "\n",
    "def ematch(egraph, termbank, vs, t):\n",
    "    res = []\n",
    "    for ts in itertools.product(termbank, (vs)):\n",
    "        subst = list(zip(vs, ts))\n",
    "        t1 = enorm(egraph, smt.substitute(t, *subst))\n",
    "        if t1 in termbank:\n",
    "            res.append((subst, t1))\n",
    "    return res\n",
    "\n",
    "def erewrite1(egraph, termbank, rules):\n",
    "    for r in rules:\n",
    "        for subst, lhs in ematch(egraph, termbank, r.vs, r.lhs):\n",
    "            rhs = enorm(egraph, smt.substitute(r.rhs, *subst))\n",
    "            termbank.add(rhs) # recursive?\n",
    "            union(egraph, lhs, rhs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def esolve(egraph, termbank, vs, t, s):\n",
    "    res = []\n",
    "    for ts in itertools.product(termbank, (vs)):\n",
    "        subst = list(zip(vs, ts))\n",
    "        t1 = smt.substitute(t, *subst)\n",
    "        s1 = smt.substitute(s, *subst)\n",
    "        if enorm(t1).eq(enorm(s1)):\n",
    "            res.append(subst)\n",
    "    return res\n",
    "\n",
    "def ematch(egraph, termbank, vs, t):\n",
    "    res = []\n",
    "    for ts in itertools.product(termbank, (vs)):\n",
    "        subst = list(zip(vs, ts))\n",
    "        t1 = enorm(egraph, smt.substitute(t, *subst))\n",
    "        if t1 in termbank:\n",
    "            res.append((subst, t1))\n",
    "    return res\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, claude is pretty good.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sympy eunify\n",
    "Unification is Equation Solving.\n",
    "\n",
    "\n",
    "Go ground. Go flat\n",
    " multiset equations\n",
    "\n",
    "\n",
    "Nearly flat lambda unification and slotted egraphs.\n",
    "\n",
    "\n",
    "p == q ---->  [  othereqs ]\n",
    "\n",
    "Cody and Max are kind of into KB ~ e-unify.\n",
    "\n",
    "Wheels within wheels. We can have a KB running inside of e-unify to solve steps modulo a theory\n",
    "But also we could have e-unify running inside KB to do narrowing / overlap modulo equations.\n",
    "Could I actually make an implementation that reflects this tower?\n",
    "\n",
    "\n",
    "subsumption and inductionless induction. What \"counts\" as being subsumed and implicit. Could have a theorem prover called at every resolution step.\n",
    "Another example of wheels within wheels.\n",
    "\n",
    "Syntactic unification is a nice base case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2314640992.py, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 28\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "import itertools \n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class MultiSet():\n",
    "    elmts : list # sorted list\n",
    "    def __init__(self, elts):\n",
    "        self.elmts = sorted(elts)\n",
    "    def solve(self, other):\n",
    "        assert isinstance(other, MultiSet)\n",
    "        if len(self.elmts) != len(other.elmts):\n",
    "            return\n",
    "        for p in itertools.permutations(other.elmts):\n",
    "            yield zip(self.elmts, p)\n",
    "\n",
    "@dataclass\n",
    "def Var():\n",
    "    # I'm mixing my styles here. This is a mutational style. Whatev.\n",
    "    val : Optional[object]\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def solve(self, other):\n",
    "        if v.val is None:\n",
    "            self.val = other\n",
    "            yield []\n",
    "        yield [(self, other)]\n",
    "\n",
    "@dataclass\n",
    "class Lit():\n",
    "    val : object\n",
    "    def __init__(self, val):\n",
    "        self.val = val\n",
    "    def solve(self, other):\n",
    "        assert isinstance(other, Lit)\n",
    "        if self.val == other.val:\n",
    "            yield [(self.val, other.val)]\n",
    "        else:\n",
    "            return\n",
    "\n",
    "class MySet():\n",
    "    elmts : list\n",
    "    def __init__(self, elts):\n",
    "        self.elmts = sorted(elts)\n",
    "    def solve(self, other):\n",
    "        pass #allow repeats\n",
    "\n",
    "list(MultiSet([1,2,3]).solve(MultiSet([3,2,1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[y]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import *\n",
    "\n",
    "f = Function('f')\n",
    "x,y = symbols('x y')\n",
    "solveset(f(x) - f(y), x)\n",
    "solve(f(x) - f(y), x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substitution intersection also requires unification / is unification.\n",
    "Non threaded / bottom up unification needs to merge branches.\n",
    "\n",
    "\n",
    "\n",
    "Threads:\n",
    "\n",
    "\n",
    "\n",
    "unitary finitary inifintary and type 0. how big set of miniaml unifiers is\n",
    "elemenary, with constants and general. Whether there are extra symnbols not in E.\n",
    "X1 + X2 + X3 = X4\n",
    "X1 + a = X4\n",
    "X1 + f(X2) = X4 \n",
    "\n",
    "single vs multiple equations.\n",
    "\n",
    "\n",
    "KB + eunify.\n",
    "\n",
    "```\n",
    "------------------------\n",
    "kbE, kbR |- euP, euE, euS  ===> \n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "categoruy theory: find best sig. equalizer.\n",
    "f . sig = g . sig\n",
    "e-unification will be the same in a lawvere theory\n",
    "\n",
    "https://www.cs.bu.edu/fac/snyder/publications/UnifChapter.pdf chapter from handbook\n",
    "huh. wayne snyder is in boston\n",
    "[Jouannaud and Kirchner 1991, \n",
    "Baader and Siekmann 1994 https://dl.acm.org/doi/abs/10.5555/185705.185711\n",
    "\n",
    "approximate unification - we can minsat the multiequations. Or consider Least squares solutions as an anlogy. Put some kind of metric on how badly an equation is viotlated rather that descirtee 0 1. maybe go neural. neural logic pgroamming. neural unification\n",
    "\n",
    "\n",
    "Bottom up eunification - Guess over a database what you'll unify on.\n",
    "\n",
    "E-unification and narrowing\n",
    "HO pattern unify\n",
    "Full HO unify\n",
    "\n",
    "I've said that higher order != has syntactic lambdas. Higher order unification could maybe seen as E-unify modulo combinator equations?\n",
    "\n",
    "Unification modulo egraphs\n",
    "\n",
    "\n",
    "boolean unification\n",
    "\n",
    "Rational tree unification. Non well founded equations. Rationals themselves as coalgebra?\n",
    "\n",
    "most general unifier as a greatest fixed point? Greatest something.\n",
    "\n",
    "Categorical perspectives on substitutions.\n",
    "Arrows. sure. between what? Variable sets? Term sets? Something else?\n",
    "\n",
    "\n",
    "Guassian elimination means two things.\n",
    "Add rows. - This is more like knuth bendix. ForAll uvars and bottom up, forward chaining\n",
    "isolate variable and subst. More like unify. Exists uvars and top down, back chaining\n",
    "\n",
    "\n",
    "equation breakdown. We could keep the old equations in a saturation process.\n",
    "sin(x) = y --> x = arcsin(y)\n",
    "\n",
    "\n",
    "\n",
    "Unify with branching as clauses?\n",
    "\n",
    "\n",
    "https://www.cs.cmu.edu/Groups/fox/people/fp/papers/ppcp93.pdf  Higher-Order Logic Programming as Constraint Logic Programming\n",
    "flex flex pairs as constraints\n",
    "\n",
    "\n",
    "e-unify via ATP\n",
    "factoring rules do the analog of solving unification (?) in a prolog\n",
    "```\n",
    "cnf(axiom, plus(X,Y) = plus(Y,X)). % The E-ness\n",
    "cnf(conjecture, ~(f(X) = g(Y))).\n",
    "```\n",
    "\n",
    "ATP already unifies E-unification with knuth bendix\n",
    "facotring rules\n",
    "```\n",
    "t != s | u = v\n",
    "----------------\n",
    "   s[u] = s[v]\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Traat chapter uses something akin to multiset knuth bendix for Ac-unify\n",
    "\n",
    "higher order unification vs higher order atp vs lambda prolog\n",
    "\n",
    "\n",
    "As awlays \n",
    "\n",
    "\n",
    "I was suggesting in co-egraphs\n",
    "\n",
    "unification modulo derivatives?\n",
    "That plotkin thing\n",
    "integrals?\n",
    "trig?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comm_unify(vs,t1, t2):\n",
    "    # todo quee is not in DNF. An and of ors...\n",
    "    # Hmm. Not sufficient.\n",
    "    # ok so an or of and ands\n",
    "    todo = [[(t1,t2)]]\n",
    "    if is_add(t):\n",
    "        if is_add(s):\n",
    "            if len(t.children()) = len(s.children())\n",
    "                # The chilrren choices are correlated here.\n",
    "                # ok, so we do need to\n",
    "                # probably here we should delay this unification as long as possible\n",
    "                todo = [todo.copy() + [(t[i], s[perm[i]])  for i in range(n) ] for perm in permutations(n)]\n",
    "                \n",
    "\n",
    "\n",
    "# unification arranged as a given clause algorithm\n",
    "def given_clause_unify():\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ematch\n",
    "As always, we should consider ematching first.\n",
    "Here again we get a flavor of unification's complication anyway and having a global queue to look at is useful.\n",
    "We can delay hard destructions until later\n",
    "prolog freeze\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AC\n",
    "\n",
    "AC unify is exact opposite of AC KB?\n",
    "Multiset something\n",
    "\n",
    "\n",
    "matrices of subsitutions. \"multply\" is subst composition, add is multiset combine?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean\n",
    "That recent typechekcing paper flix https://dl.acm.org/doi/10.1145/3485487 Relational nullable types with Boolean unification\n",
    "https://www.youtube.com/watch?v=BPW-92b7j7A&ab_channel=ACMSIGPLAN fast and efficient boolean unification for hindley milner\n",
    "\n",
    "boolean unification the sotry so far https://www.cs.rice.edu/~javaplt/411/23-spring/NewReadings/Unfication%20Theory/Boolean-unification---The-story-so-far_1989_Journal-of-Symbolic-Computation.pdf\n",
    "\n",
    "\n",
    "Reduce to f(x) = g(x) becomes f(x) + g(x) = 0.\n",
    "\n",
    "loweneim and booles method\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Narrowing\n",
    "\n",
    "System G\n",
    "{e[u]} ==> {l = u, e[r]}\n",
    "lazy paramdoulation is bruteforce\n",
    "u can't be a variable\n",
    "It avoids needing unification to perform narrowing.\n",
    "\n",
    "unification modulo egraphs\n",
    "\n",
    "\n",
    "Fey and Hullot\n",
    "narrow\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional Logic Programming\n",
    "\n",
    "https://www.curry-language.org/docs/tutorial/tutorial.pdf curry a ttutorial introduction\n",
    "\n",
    "https://www.michaelhanus.de/papers/GanzingerFestschrift.pdf from narrowing to curry\n",
    "\n",
    "\n",
    "functional logic programming\n",
    "https://dl.acm.org/doi/pdf/10.1145/1721654.1721675 review article\n",
    "\n",
    "inductively sequential\n",
    "definition trees\n",
    "\n",
    "weakly orthogonal. There is non trivial overlap but all critical pairs are immiedately good.\n",
    "\n",
    "flattening. append(x,y) = z --> append(x,y,z) Different orderings of flattenings make different eval strategies\n",
    "`t = e` :- \n",
    "\n",
    "flp minikanren?\n",
    "curry\n",
    "verse\n",
    "\n",
    "lambda flp?\n",
    "\n",
    "narrowing\n",
    "residuization\\\n",
    "\n",
    "functional logic programming.\n",
    "ground flp proplog\n",
    "https://web.cecs.pdx.edu/~antoy/homepage/publications/narrowing/paper.pdf \n",
    "\n",
    "https://simon.peytonjones.org/assets/pdfs/verse-conf.pdf verse\n",
    "\n",
    "https://arxiv.org/pdf/2405.10801  The Relational Machine Calculus\n",
    "\n",
    "https://maude.lcc.uma.es/manual271/maude-manualch16.html Narrwoing maude\n",
    "https://maude.lcc.uma.es/maude31-manual-html/maude-manualch15.html\n",
    "[77]   Joseph Goguen and Jos Meseguer. Eqlog: Equality, types and generic modules for logic programming. \n",
    "]   Michael Hanus. The integration of functions into logic programming: From theory to practice\n",
    " Jos Meseguer. Multiparadigm logic programming\n",
    "] James R. Slagle. Automated Theorem-Proving for Theories with Simplifiers\n",
    "Commutativity, and Associativity\n",
    "\n",
    "\n",
    " https://dl.acm.org/doi/abs/10.1145/1016850.1016865  Implementing functional logic languages using multiple threads and stores\n",
    "\n",
    " https://pdxscholar.library.pdx.edu/cgi/viewcontent.cgi?article=7501&context=open_access_etds  Implementing a Functional Logic Programming Language via the Fair Scheme\n",
    "\n",
    "What about a functional logic programming approach to marshall? We had these taylor series approximations. It's kind of intuitiopnsitc in some sense. Maybe bring in unification modulo polynomials? Modulo polynomial inequalities?\n",
    "\n",
    "sergio antoy https://web.cecs.pdx.edu/~antoy/\n",
    "michael hanus\n",
    "\n",
    "https://web.cecs.pdx.edu/~antoy/homepage/theses/A_Peters.pdf  The Basic Scheme for the Evaluation of Functional Logic Programs . relatively simple ocaml\n",
    "\n",
    "cloning\n",
    "needed narrowing - https://www.informatik.uni-kiel.de/~mh/papers/JACM00.pdf\n",
    "bubbling\n",
    "pull tabbing\n",
    "\n",
    "goedel\n",
    "\n",
    "maybe kics is the way to go.\n",
    "\n",
    "\n",
    "Could be fun to mix evaluation a la unfold with narrowing via rules. That's the idea right?\n",
    "Or evaluation via reify + narrow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_search(t, rules):\n",
    "    seen = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.all import *\n",
    "import kdrag.rewrite as rw\n",
    "\n",
    "#def ground(vs, t): / is_value?\n",
    "# \n",
    "\n",
    "\n",
    "# could do a rewriting\n",
    "#  search similarly you know.\n",
    "def flp(vs, t, rules):\n",
    "    rules = [\n",
    "        rule if isinstance(rule, rw.RewriteRule) else rw.rewrite_of_expr(rule)\n",
    "        for rule in rules\n",
    "    ]\n",
    "    subst = {}\n",
    "    todo = [(vs, t, subst)] # could have mutiple t?\n",
    "    while todo:\n",
    "        vs,t,subst = todo.pop()\n",
    "        progress = False\n",
    "        for rule in rules:\n",
    "            rule = rule.freshen()\n",
    "            narrows = rw.all_narrows(vs + rule.vs, t, rule.lhs, rule.rhs)\n",
    "            if len(narrows) != 0: # no. I don't want this just because \n",
    "                progress = True\n",
    "            for t1, subst1 in rw.all_narrows(vs, t, rule.lhs, rule.rhs):\n",
    "                # combine subst and subst1\n",
    "                # reduce vs maybe\n",
    "                # maybe yield here if reach some condition\n",
    "                todo.append((vs, t1, subst | subst1))\n",
    "        if not progress:\n",
    "            yield vs, t, subst\n",
    "\n",
    "import kdrag.theories.nat as nat\n",
    "rules = [\n",
    "    nat.add_zero,\n",
    "    nat.add_succ,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COuld be fun to table too. Variant tabling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([], {y: S(Z), x: Z}), ([], {x: S(Z), y: Z})]\n",
      "[([], {y: S(Z), x: Z}), ([], {x: S(Z), y: Z})]\n",
      "[]\n",
      "[([z], {y: S(z), x: Z}), ([y], {x: S(Z), z: y}), ([y], {x: S(S(Z)), z: S(y)}), ([y], {x: S(S(S(Z))), z: S(S(y))})]\n"
     ]
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "def prolog(vs0 : list[smt.ExprRef], goals : smt.BoolRef, rules : list[rw.RewriteRule]):\n",
    "    rules = [\n",
    "        rule if isinstance(rule, rw.Rule) else rw.rule_of_expr(rule)\n",
    "        for rule in reversed(rules)\n",
    "    ]\n",
    "    todo = [(vs0, goals, {})]\n",
    "    while todo:\n",
    "        vs, goals, subst = todo.pop()\n",
    "        if len(goals) == 0:\n",
    "            yield vs, {k : t for k,t in subst.items() if any(k.eq(v) for v in vs0)}\n",
    "            continue\n",
    "        else:\n",
    "            goal = goals.pop()\n",
    "            if smt.is_true(goal):\n",
    "                todo.append((vs, goals, subst))\n",
    "            elif smt.is_false(goal):\n",
    "                continue\n",
    "            elif smt.is_and(goal):\n",
    "                goals.extend(reversed(goal.children()))\n",
    "                todo.append((vs, goals, subst))\n",
    "            elif smt.is_or(goal):\n",
    "                for child in goal.children():\n",
    "                    newgoals = goals + [child]\n",
    "                    todo.append((vs, newgoals, subst))\n",
    "            else:\n",
    "                for rule in rules:\n",
    "                    rule = rule.freshen()\n",
    "                    vs1 = vs + rule.vs\n",
    "                    subst1 = kd.utils.unify(vs1, rule.conc, goal)\n",
    "                    if subst1 is None:\n",
    "                        continue\n",
    "                    else:\n",
    "                        newgoals = goals + [smt.substitute(rule.hyp, *subst1.items())]\n",
    "                        newsubst = {**{k : smt.substitute(v, *subst1.items()) for k,v in subst.items()}, **subst1}\n",
    "                        newvs = list(set(vs1) - set(subst1.keys()))\n",
    "                        todo.append((newvs, newgoals, newsubst))\n",
    "\n",
    "import kdrag.theories.list as list_\n",
    "import kdrag.theories.nat as nat\n",
    "ListInt = list_.List(smt.IntSort())\n",
    "x,y,z = smt.Ints(\"x y z\")\n",
    "\n",
    "x,y,z = smt.Consts(\"x y z\", nat.Nat)\n",
    "plus = smt.Function(\"plus\", nat.Nat, nat.Nat, nat.Nat, smt.BoolSort())\n",
    "rules = [\n",
    "kd.QForAll([y], plus(nat.Z, y, y)),\n",
    "kd.QForAll([x,y,z], smt.Implies(\n",
    "    plus(x, y, z), \n",
    "    plus(nat.S(x), y, nat.S(z))\n",
    "))\n",
    "]\n",
    "print(list(prolog([x,y], [plus(x, y, nat.S(nat.Z))], rules)))\n",
    "print(list(prolog([x,y], [plus(x, y, nat.S(nat.Z))], rules)))\n",
    "print(list(prolog([x,y], [plus(nat.Z, nat.Z, nat.S(nat.Z))], rules)))\n",
    "import itertools\n",
    "print(list(itertools.islice(prolog([x,y,z], [plus(x, y, nat.S(z))], rules), 4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datalog(facts, rules):\n",
    "    db = {fact.get_id() : fact for fact in facts}\n",
    "    rules = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/hello.curry\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/hello.curry\n",
    "\n",
    "{-# LANGUAGE NoImplicitPrelude #-}\n",
    "data Nat = Z | S Nat\n",
    "data MyBool = False | True\n",
    "-- Addition on natural numbers.\n",
    "add :: Nat -> Nat -> Nat\n",
    "add Z n = n\n",
    "add (S m) n = S (add m n)\n",
    "-- Less-or-equal predicate on natural numbers.\n",
    "leq :: Nat -> Nat -> MyBool\n",
    "leq Z _ = True\n",
    "leq (S _) Z = False\n",
    "leq (S x) (S y) = leq x y\n",
    "\n",
    "\n",
    "just_doit = 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: kics2: command not found\n"
     ]
    }
   ],
   "source": [
    "!kics2 :eval just_doit :quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/hello.curry\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/hello.curry\n",
    "main = IO.println \"hello world\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/hello.curry\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/hello.curry\n",
    "main = print \"hello world\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! runcurry /tmp/hello.curry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cypm install runcurry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
