{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5c1e689",
   "metadata": {},
   "source": [
    "---\n",
    "title: Semantic Refinement/Dependent Typing for Knuckledragger/SMTLIB Pt 1\n",
    "date: 2025-08-04\n",
    "---\n",
    "\n",
    "It has been a question from the beginning how to emulate dependent types in Knuckledragger. \n",
    "\n",
    "[Knuckledragger](https://github.com/philzook58/knuckledragger) is an interactive proof assistant designed as a python library very shallowly around the [Z3py](https://ericpony.github.io/z3py-tutorial/guide-examples.htm) library. It can also be viewed as a minimal layer on top of [SMTLIB](https://smt-lib.org/) to make it scale as an interactive proof system. While much attention has been paid to the proof objects the justify individual smt calls, relatively little attention has been paid to the big steps linking multiple calls. The thing people do try to do is export SMT proofs to their system (coq, lean, isabelle, metamath, etc) and then do the linking in that system. It seems to me it is at least worthwhile to attempt to remove this indirection. Indirections are often a lot of effort and cost to maintain.\n",
    "\n",
    "The theory of Arrays in SMTLIB is a theory of first class functions and lambda notation was recently added to the standard although it's been available in Z3 for a while. This makes SMTLIB basically a higher order logic (HOL), although you shouldn't expect good things to happen if you get too funky with it.\n",
    "\n",
    "SMTLIB is also basically a functional programming language.\n",
    "\n",
    "The refinement typing approach as exemplified by [Liquid Haskell](https://ucsd-progsys.github.io/liquidhaskell/), is a paradigm that can add annotations to a preexisting language in order to add verification capabilities https://arxiv.org/pdf/1610.04641 . Basically you can add extra tags describing the subsets of the base types you expect to allow as inputs and emit as outputs of base language functions. \n",
    "\n",
    "Since SMTLIB is a functional programming language, it makes sense to attempt to add refinement type to it. Why not? One can hope that this will actually be somewhat elegant, since Refinement typing is achieved in systems\n",
    "\n",
    "The code of the post is extracted from the development [here](https://github.com/philzook58/knuckledragger/blob/9eca63380b52731e8eec5b71551e6837d0b02ba5/kdrag/contrib/telescope.py) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f85035d",
   "metadata": {},
   "source": [
    "# Types as Subsets\n",
    "\n",
    "Pretty much any syntactic logical system has to demonstrate how it can actually mean something, by giving examples of a semantics aka interpretations into something we're more familiar with. If I tell you a bunch of syntactic rules about \"bleep\" \"blorp\" and \"bizzle\", that won't hold your attention for long.\n",
    "\n",
    "Dependent types and type systems generally are presented syntactically. They are a syntax for terms, a syntax for types, and an operational semantics / baked in notion of definitional equality. Because they want to claim themselves as a foundation, models are somewhat under emphasized. \n",
    "\n",
    "There are a number of possibilities for [models](https://www.cs.uoregon.edu/research/summerschool/summer14/rwh_notes/ssdt.pdf) of dependent type theory. In the most basic model, types are basically interpreted sets.  The (a?) subset model interprets types as a a pair of a set and a subset of that set. For example, the type `[[Pos]] = {x : Nat | x > 0}` is the subset of integers greater than zero. .\n",
    "\n",
    "I want to shallowly embed this model into SMTLIB. Subsets can be represented in smtlib/HOL as characteristic functions `Pos = smt.Lambda([x], x > 0)`. This is probably closest in spirit to PVS's approach https://www.csl.sri.com/papers/tse98/tse98.pdf . The set you're cutting the subset out of is implicitly there are the SMTLIB sort of the variable. It is perfectly possible to have a parametrized family of subsets like the set of all numbers greater than `n` `GE(n) = {x : Int | x >= n}` or in python as\n",
    "\n",
    "```python\n",
    "x = smt.Int(\"x\")\n",
    "def GE(n):\n",
    "    return Lambda([x], x >= n)\n",
    "```\n",
    "\n",
    "## Telescopes\n",
    "\n",
    "In ordinary z3/HOL metaprograming, it was often useful to pass around a list of variables `[x, y, z]` as a notion of context. These lists are handed to the Z3py functions `ForAll` and `Exists` for example.\n",
    "\n",
    "Generalizing this, the data of a dependent context (a telescope) can be given as a list of tuples of variables and what subset they are expected to be in. For example `[(x, Pos), (y, GE(x))]`. These telescopes can be given meaning into the logic of z3 by a combinator `TForAll` which interleaves applying `ForAll` of the variables and `Implies` for the subset constraint.\n",
    "\n",
    "It is convenient to generalize this telescope to allow intermixing subsets, propositions, and no constraints.  If you use proposition style, it looks like refinement typing `[(x, x > 0, (y, y >= x))]`. If you use subset style, it looks like dependent typing. They are very similar systems. Refinement typing systems a la Liquid Haskell are dependently typed in this sense. This generalization can be normalized away by a function `normalize` which puts the more user pleasant form of the telescope into the propositional refinement form.\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "User telescope type.\n",
    "\n",
    "Telescopes are dependent or refined contexts of variables.\n",
    "They can tag variables with SubSet expressions or formulas that involve the bound variable.\n",
    "Internally, the are normalized to _Tele, which is a list of (variable, formula) pairs.\n",
    "\"\"\"\n",
    "type Telescope = list[\n",
    "    tuple[smt.ExprRef, smt.BoolRef] | tuple[smt.ExprRef, SubSort] | smt.ExprRef\n",
    "]\n",
    "# Internal normalized telescope\n",
    "type _Tele = list[tuple[smt.ExprRef, smt.BoolRef]]\n",
    "\n",
    "\n",
    "def normalize(xs: Telescope) -> _Tele:\n",
    "    \"\"\"\n",
    "    Normalize a telescope to a list of (variable, formula) pairs.\n",
    "\n",
    "    >>> x, y, z = smt.Ints(\"x y z\")\n",
    "    >>> normalize([x, y, z])\n",
    "    [(x, True), (y, True), (z, True)]\n",
    "    >>> normalize([(x, x > 0), (y, y > x), z])\n",
    "    [(x, x > 0), (y, y > x), (z, True)]\n",
    "    >>> normalize([(x, smt.Lambda([x], x > 0)), (y, smt.Lambda([y], y > x)), z])\n",
    "    [(x, x > 0), (y, y > x), (z, True)]\n",
    "    \"\"\"\n",
    "    res: _Tele = []\n",
    "    for v in xs:\n",
    "        if isinstance(v, tuple):\n",
    "            (v, T) = v\n",
    "            if T.sort() == smt.BoolSort():\n",
    "                assert isinstance(T, smt.BoolRef)\n",
    "                res.append((v, T))\n",
    "            elif isinstance(T, smt.ArrayRef) or (\n",
    "                isinstance(T, smt.QuantifierRef) and T.is_lambda()\n",
    "            ):\n",
    "                P = T(v)\n",
    "                assert isinstance(P, smt.BoolRef)\n",
    "                res.append((v, P))\n",
    "            else:\n",
    "                raise TypeError(f\"Unsupported type for quantifier: {T}\")\n",
    "        else:\n",
    "            res.append((v, smt.BoolVal(True)))\n",
    "    return res\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "def TForAll(xs: Telescope, P: smt.BoolRef) -> smt.BoolRef:\n",
    "    \"\"\"\n",
    "    Dependent forall quantifier for a telescope of variables.\n",
    "    Kind of like a proof irrelevant Pi type.\n",
    "\n",
    "    Subtype / Refinement style usage\n",
    "\n",
    "    >>> x, y, z = smt.Reals(\"x y z\")\n",
    "    >>> TForAll([(x, x > 0), (y, y > x)], y > -1)\n",
    "    ForAll(x, Implies(x > 0, ForAll(y, Implies(y > x, y > -1))))\n",
    "\n",
    "    \"Dependent type\" style usage\n",
    "\n",
    "    >>> Pos = smt.Lambda([x], x > 0)\n",
    "    >>> GT = lambda x: smt.Lambda([y], y > x)\n",
    "    >>> TForAll([(x, Pos), (y, GT(x))], y > -1)\n",
    "    ForAll(x, Implies(x > 0, ForAll(y, Implies(y > x, y > -1))))\n",
    "    \"\"\"\n",
    "    for v in reversed(xs):\n",
    "        if isinstance(v, tuple):\n",
    "            (v, T) = v\n",
    "            if T.sort() == smt.BoolSort():\n",
    "                P = kd.QForAll([v], T, P)\n",
    "            elif isinstance(T, smt.ArrayRef) or (\n",
    "                isinstance(T, smt.QuantifierRef) and T.is_lambda()\n",
    "            ):\n",
    "                P = kd.QForAll([v], T(v), P)\n",
    "            else:\n",
    "                raise TypeError(f\"Unsupported type for quantifier: {T}\")\n",
    "        else:\n",
    "            P = kd.QForAll([v], P)\n",
    "    return P\n",
    "\n",
    "```\n",
    "## Semantic Typing\n",
    "\n",
    "The soundness of the model says that for each syntactic typing rule `|-`, there ought to be a theorem we can write for the model `|=` that follows along. The type system rules in the way can be seen as a higher level tactic system or macro rules for the model. This is the semantic approach to typing. One place you can see this is in papers on foundational proof carrying code. https://link.springer.com/chapter/10.1007/978-3-540-32033-3_29 https://www.cs.princeton.edu/~appel/papers/fpcc.pdf https://www.cs.princeton.edu/techreports/2000/629.pdf\n",
    "\n",
    "It appears that most facilities and combinators in knuckledragger can be generalized to have a telescoped counterpart (define, Proof, prove, axiom, ForAll, Exists, Lambda, Calc, Lemma, etc). I like the conceptual simplicity of the current core, so I think I am not inclined to make this telescoped form the default of the entire system yet.\n",
    "\n",
    "An interesting tactic one can write is a `has_type` tactic. This tactic takes in a telescope `tele`, term `t`, and subset `T`, and tries to prove that `TForAll(tele, T[t])`. By having a registry of semantic types associated to `FuncDeclRef`, we can accumulate subset constraints from the body of `t`.\n",
    "\n",
    "```python\n",
    "\n",
    "def has_type(ctx: Telescope, t0: smt.ExprRef, T: SubSort, by=None) -> kd.Proof:\n",
    "    \"\"\"\n",
    "    Tactic to check that an expression `t0` has type `T` in a context `ctx`.\n",
    "\n",
    "    >>> x = smt.Int(\"x\")\n",
    "    >>> Nat = smt.Lambda([x], x >= 0)\n",
    "    >>> has_type([(x, Nat)], x+1, Nat)\n",
    "    |= Implies(And(x >= 0), Lambda(x, x >= 0)[x + 1])\n",
    "    \"\"\"\n",
    "    tele = normalize(ctx)\n",
    "    pctx = [P for _, P in tele]\n",
    "    if by is None:\n",
    "        by = []\n",
    "    seen = set()\n",
    "    todo = [t0]\n",
    "    while todo:\n",
    "        t = todo.pop()\n",
    "        if smt.is_app(t):\n",
    "            children = t.children()\n",
    "            decl = t.decl()\n",
    "            for c in children:\n",
    "                if c not in seen:\n",
    "                    todo.append(c)\n",
    "                    seen.add(c)\n",
    "            # TODO. Could recursively cut the children. Localize type error better.\n",
    "            if decl.name() == \"ann\":\n",
    "                try:\n",
    "                    x, T = children\n",
    "                    by.append(has_type(ctx, x, T, by=by))\n",
    "                    # TODO: unfold ann. by.append(kd.kernel.defn)\n",
    "                    # actually with new definition, ann is in _tsig\n",
    "                except Exception as e:\n",
    "                    raise TypeError(f\"Invalid annotation {t} in context {ctx}\", e)\n",
    "            if decl in _tsig:\n",
    "                by.append(_tsig[decl](*children))\n",
    "\n",
    "    return kd.prove(smt.Implies(smt.And(pctx), T[t0]), by=by)\n",
    "```\n",
    "\n",
    "## Partial Definitions\n",
    "\n",
    "Another interesting thing to do is generalize `define` to take a input telescope and an output subset. This puts some guard rails on partially defined functions. It also adds the typing annotations into the registry inside the body of `prove_sig`\n",
    "\n",
    "\n",
    "```python\n",
    "def define(\n",
    "    name: str, args: Telescope, T: SubSort, body: smt.ExprRef, by=None\n",
    ") -> smt.FuncDeclRef:\n",
    "    \"\"\"\n",
    "    Define a function with a precondition given by a telescope of arguments\n",
    "    and a postcondition given by a subset that output will lie in.\n",
    "\n",
    "    Automatically\n",
    "\n",
    "    >>> n = kd.kernel.SchemaVar(\"n\", smt.IntSort())\n",
    "    >>> m = smt.Int(\"m\")\n",
    "    >>> Nat = smt.Lambda([n], n >= 0)\n",
    "    >>> Pos = smt.Lambda([n], n > 0)\n",
    "    >>> inc = define(\"test_inc\", [(n,Nat)], Pos, n + 1)\n",
    "    >>> inc.pre_post\n",
    "    |= ForAll(n!...,\n",
    "        Implies(And(n!... >= 0),\n",
    "            Lambda(n!..., n!... > 0)[test_inc(n!...)]))\n",
    "    >>> pred = define(\"pred\", [(n, Pos)], Nat, n - 1)\n",
    "    >>> myid = define(\"myid\", [(n, Nat)], Nat, pred(inc(n)))\n",
    "    \"\"\"\n",
    "    P1 = has_type(args, body, T, by=by)\n",
    "    tele = normalize(args)\n",
    "    vs = [v for (v, _) in tele]\n",
    "    for v in vs:\n",
    "        if not kd.kernel.is_schema_var(v):\n",
    "            raise TypeError(f\"Arguments must be schema variables: {v}\")\n",
    "    f = kd.define(name, vs, body)\n",
    "    prove_sig(f, args, T, by=[P1, f.defn(*vs)])\n",
    "    return f\n",
    "```\n",
    "\n",
    "## Examples\n",
    "\n",
    "Here is some mild usage of these tools. We can define functions `inc` and `pred` over these subsets. Inside of `define`, these definitions are being semantically type checked that they meet the appropriate subset conditions. Everything also takes an optional `by` parameter, allowing them to be handed useful extra lemmas in case Z3 can't do it all in one shot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2b2ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.contrib.telescope import *\n",
    "from kdrag.all import *\n",
    "\n",
    "x,n,m = kd.tactics.SchemaVars(\"x n m\", smt.IntSort())\n",
    "Nat = smt.Lambda([x], x >= 0)\n",
    "Pos = smt.Lambda([x], x > 0)\n",
    "\n",
    "n = kd.kernel.SchemaVar(\"n\", smt.IntSort())\n",
    "inc = define(\"test_inc\", [(n,Nat)], Pos, n + 1)\n",
    "inc.pre_post\n",
    "pred = define(\"pred\", [(n, Pos)], Nat, n - 1)\n",
    "myid = define(\"myid\", [(n, Nat)], Nat, pred(inc(n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71dc226",
   "metadata": {},
   "source": [
    "Here is using Z3's built in notion of Sequence to make length indexed lists.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c017177",
   "metadata": {},
   "outputs": [],
   "source": [
    "SeqInt = smt.SeqSort(smt.IntSort())\n",
    "l,u,v = kd.tactics.SchemaVars(\"l u v\", SeqInt)\n",
    "Vec = smt.Lambda([x], smt.Lambda([l], smt.Length(l) == x))\n",
    "# A Vector of Nat? Awkward\n",
    "\n",
    "app = define(\"myappend\", [(n,Nat), (m, Nat), (u, Vec(n)), (v, Vec(m))], Vec(n + m), \n",
    "                    smt.Concat(u,v))\n",
    "has_type([(l, Vec(x)), (v, Vec(n)), (u, Vec(m))], \n",
    "        app(x, n + m, l, app(n, m, v, u)), \n",
    "        Vec(n + m + x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ae8e74",
   "metadata": {},
   "source": [
    "It is somewhat awkward that `n` and `m` need to be explicitly passed in to `app`. This can be removed at least in this case by replacing the parameters by their constrained values manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee9c4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ulen = smt.Length(u)\n",
    "\n",
    "app = define(\"myappend\", [(u, Vec(ulen)), (v, Vec(smt.Length(v)))], Vec(ulen + smt.Length(v)), \n",
    "                    smt.Concat(u,v))\n",
    "app.pre_post"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f40523e",
   "metadata": {},
   "source": [
    "A Pi combinator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3de1dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pi(tele0: Telescope, B: SubSort) -> SubSort:\n",
    "    \"\"\"\n",
    "    Multiarity Pi. Dependent Function subsort\n",
    "    B is a family because it may include parameters from tele0.\n",
    "\n",
    "    >>> x, y = smt.Ints(\"x y\")\n",
    "    >>> GE = lambda x: smt.Lambda([y], y >= x)\n",
    "    >>> Pi([(x, Nat)], GE(x))\n",
    "    Lambda(f!...,\n",
    "        ForAll(x, Implies(x >= 0, Lambda(y, y >= x)[f!...[x]])))\n",
    "    >>> smt.simplify(Pi([(x, Nat)], GE(x))[smt.Lambda([x], x)])\n",
    "    True\n",
    "    \"\"\"\n",
    "    tele = normalize(tele0)\n",
    "    vs = [v for v, _ in tele]\n",
    "    # TB: SubSort = B(*vs)  # B is a family of sorts\n",
    "    sorts = [v.sort() for (v, _) in tele]\n",
    "    fsort = smt.ArraySort(*sorts, subsort_domain(B))\n",
    "    f = smt.FreshConst(fsort, prefix=\"f\")\n",
    "    return smt.Lambda([f], TForAll(tele0, B[f(*vs)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592849ed",
   "metadata": {},
   "source": [
    "An identity type combinator. It is a little weird to have a unit type that is basically irrelevant. More informative identity proof objects might be interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba745e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "Unit = kd.Inductive(\"Unit\")\n",
    "Unit.declare(\"tt\")\n",
    "Unit = Unit.create()\n",
    "\n",
    "def Id(x: smt.ExprRef, y: smt.ExprRef) -> SubSort:\n",
    "    \"\"\"\n",
    "    >>> x, y = smt.Ints(\"x y\")\n",
    "    >>> p = smt.Const(\"p\", Unit)\n",
    "    >>> has_type([x], Unit.tt, Id(x, x))\n",
    "    |= Implies(And(True), Lambda(p!..., x == x)[tt])\n",
    "    >>> has_type([x, y, (p, Id(x,y))], Unit.tt, Id(y, x))\n",
    "    |= Implies(And(True, True, x == y), Lambda(p!..., y == x)[tt])\n",
    "    \"\"\"\n",
    "    p = smt.FreshConst(Unit, prefix=\"p\")\n",
    "    return smt.Lambda([p], x == y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4427a23d",
   "metadata": {},
   "source": [
    "A hack to add annotation metadata like an interior `foo : T` annotation is to make special identity (or projection) functions that the metasystem knows to do something with. I saw something similar in the Lean typeclass mode annotations. The projection functions are pretty similar to EGraph ASSUME nodes. https://arxiv.org/pdf/2205.14989 . Is there a better name for the semantic concept? Kind of they are similar to projection functions too, except I've chosen to leave being outside the range undefined rather than projecting into the subset (how would you project into an empty subset anyway?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167bb436",
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache(maxsize=None)\n",
    "def _gen_annotate(S: smt.SortRef):\n",
    "    x, y = kd.tactics.SchemaVars(\"x y\", S)\n",
    "    T = kd.kernel.SchemaVar(\"T\", smt.ArraySort(S, smt.BoolSort()))\n",
    "    assert isinstance(T, smt.ArrayRef)\n",
    "    return define(\n",
    "        \"ann\",\n",
    "        [(x, T), T],  # This is breaking telescoping rules. Is that ok?\n",
    "        smt.Lambda([y], y == x),\n",
    "        smt.If(T[x], x, smt.FreshFunction(S, S)(x)),\n",
    "    )\n",
    "\n",
    "\n",
    "def ann(x: smt.ExprRef, T: SubSort) -> smt.ExprRef:\n",
    "    \"\"\"\n",
    "    Annotate an expression with a type.\n",
    "\n",
    "    >>> x = smt.Int(\"x\")\n",
    "    >>> Nat = smt.Lambda([x], x >= 0)\n",
    "    >>> ann(x, Nat)\n",
    "    ann(x, Lambda(x, x >= 0))\n",
    "    \"\"\"\n",
    "    return _gen_annotate(x.sort())(x, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5219eea8",
   "metadata": {},
   "source": [
    "# Schema Vars\n",
    "\n",
    "On a slightly different tact, a new feature in Knuckledragger that I'm very excited about is Schematic Variables.\n",
    "\n",
    "The big thing that SMT solvers need guidance on is quantifiers. By and large, they can deal with unquantified formula very well on their own.\n",
    "\n",
    "So, Knuckledragger has some other inference rules bolted on. You can instantiate universally quantified proofs to eliminate forall.\n",
    "\n",
    "```\n",
    "|= forall x, P(x)\n",
    "------------------- instan\n",
    "      |= P(c)\n",
    "```\n",
    "\n",
    "To introduce forall is more complicated. Previously, I've been using a hebrandization axiom schema. Given any formula `forall x, P(x)` I can give you the axiom.\n",
    "\n",
    "```\n",
    "---------------------------------- herb\n",
    "   |= P(c_fresh) => forall x, P(x)\n",
    "```\n",
    "\n",
    "Now if you can prove `P(c_fresh)`, you get the quantifier by modus ponens. This is [implemented](https://github.com/philzook58/knuckledragger/blob/9eca63380b52731e8eec5b71551e6837d0b02ba5/kdrag/kernel.py#L399) as a function that returns the fresh constant \n",
    "\n",
    "\n",
    "```python\n",
    "def herb(thm: smt.QuantifierRef) -> tuple[list[smt.ExprRef], Proof]:\n",
    "    \"\"\"\n",
    "    Herbrandize a theorem.\n",
    "    It is sufficient to prove a theorem for fresh consts to prove a universal.\n",
    "    Note: Perhaps lambdaized form is better? Return vars and lamda that could receive `|= P[vars]`\n",
    "    \"\"\"\n",
    "    assert smt.is_quantifier(thm) and thm.is_forall()\n",
    "    herbs = fresh_const(thm)  # We could mark these as schema variables? Useful?\n",
    "    return herbs, axiom(\n",
    "        smt.Implies(smt.substitute_vars(thm.body(), *reversed(herbs)), thm),\n",
    "        [\"herband\"],\n",
    "    )\n",
    "```\n",
    "\n",
    "Knuckledragger is implemented in an LCF style, where inference rules correspond to python functions. The things above the horizontal line are inputs to the function and it produces the thing below the line in a protected datatype. These kernel functions can be seen as smart constructors for a protected `Proof` datatype that wraps the formula and other metadata.\n",
    "\n",
    "A more natural rule for introducing is\n",
    "\n",
    "```\n",
    "   |= P(c_fresh)\n",
    "-------------------\n",
    " |= forall x, P(x)\n",
    "```\n",
    "\n",
    "But there is an implementation problem here. What do we mean by `c_fresh` if I don't get to generate them? `|= P(c_fresh)` comes in as an input to my kernel function, so I don't get to pick it. One solution would be to insist that `c_fresh` is a different syntactic category of the formula, a schematic variable. This is not really possible because I'm using Z3's AST for my formulas, which I cannot change. Another solution is to explicitly add a context `Gamma |= P` to my proof judgements that tracks all the variables at play. This is a big change and complex.\n",
    "\n",
    "What I realized on a walk the other day is that I need a new judgement `fresh` that you receive when you create a fresh variable. To some degree, the variable have a name with an exclamation point `foo!852` is suggestive that it was freshly generated, but this is more systematic.\n",
    "\n",
    "\n",
    "```\n",
    "   |= P(c)       c fresh\n",
    "------------------------ generalize\n",
    " |= forall x, P(x)\n",
    "```\n",
    "\n",
    "This is the current implementation https://github.com/philzook58/knuckledragger/blob/9eca63380b52731e8eec5b71551e6837d0b02ba5/kdrag/kernel.py#L517 of this rule.\n",
    "\n",
    "\n",
    "```python \n",
    "@dataclass(frozen=True)\n",
    "class _SchemaVarEvidence(Judgement):\n",
    "    \"\"\"\n",
    "    Do not instantiate this class directly.\n",
    "    Use `SchemaVar`. This class should always be created with a fresh variable.\n",
    "    Holding this data type is considered evidence analogous to the `Proof` type that the var was generated freshly\n",
    "    and hence is generic / schematic.\n",
    "\n",
    "    One can prove theorem using this variable as a constant, but once it comes to generalize, you need to supply the evidence\n",
    "    That it was originally generated freshly.\n",
    "    \"\"\"\n",
    "\n",
    "    v: smt.ExprRef\n",
    "\n",
    "\n",
    "def is_schema_var(v: smt.ExprRef) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a variable is a schema variable.\n",
    "    Schema variables are generated by SchemaVar and have a _SchemaVarEvidence attribute.\n",
    "\n",
    "    >>> is_schema_var(SchemaVar(\"x\", smt.IntSort()))\n",
    "    True\n",
    "    \"\"\"\n",
    "    if not hasattr(v, \"schema_evidence\"):\n",
    "        return False\n",
    "    else:\n",
    "        evidence = getattr(v, \"schema_evidence\")\n",
    "        return isinstance(evidence, _SchemaVarEvidence) and evidence.v.eq(v)\n",
    "\n",
    "\n",
    "def SchemaVar(prefix: str, sort: smt.SortRef) -> smt.ExprRef:\n",
    "    \"\"\"\n",
    "    Generate a fresh variable\n",
    "\n",
    "    >>> SchemaVar(\"x\", smt.IntSort()).schema_evidence\n",
    "    _SchemaVarEvidence(v=x!...)\n",
    "    \"\"\"\n",
    "    v = smt.FreshConst(sort, prefix=prefix)\n",
    "    v.schema_evidence = _SchemaVarEvidence(\n",
    "        v\n",
    "    )  # Is cyclic reference a garbage collection problem?\n",
    "    return v\n",
    "\n",
    "\n",
    "def generalize(vs: list[smt.ExprRef], pf: Proof) -> Proof:\n",
    "    \"\"\"\n",
    "    Generalize a theorem with respect to a list of schema variables.\n",
    "    This introduces a universal quantifier for schema variables.\n",
    "\n",
    "    >>> x = SchemaVar(\"x\", smt.IntSort())\n",
    "    >>> y = SchemaVar(\"y\", smt.IntSort())\n",
    "    >>> generalize([x, y], prove(x == x))\n",
    "    |= ForAll([x!..., y!...], x!... == x!...)\n",
    "    \"\"\"\n",
    "    assert all(is_schema_var(v) for v in vs)\n",
    "    assert isinstance(pf, Proof)\n",
    "    return axiom(smt.ForAll(vs, pf.thm), by=[\"generalize\", vs, pf])\n",
    "\n",
    "```\n",
    "\n",
    "The `herb` rule was quite painful to use. I think this new rule is fairly straightforward and much easier. It should make just about everything work better as it's usage propagates though Knuckledragger, because now I can more easily explicitly instantiate quantifiers inside of my tactics instead of leaving it up to z3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6dd9a2",
   "metadata": {},
   "source": [
    "# Telescopes vs Sequents\n",
    "\n",
    "There is something at odds here.\n",
    "\n",
    "In a telescope, new variables come into context one by one and the type can only refer to previous variables. It corresponds to a formula of the form `forall x, T[x] => forall y, T1(x)[y] => ,,,`  with universal and implies alternating\n",
    "\n",
    "A sequent is kind of similar `vs; hyps |- conc` with a context of variables and a context of hypotheses. The ordering of the hypotheses and variables is not linked. The hypotheses can refer to any variables. It corresponds to formulas of the form `forall x y... , And(P(x,y,...), Q(x,y,...), ...) => Conc(x,y,z)`. THis form is actually nicer to deal with in knuckledragger. I want to let z3 handle modus ponens, but deal with quantifiers manually, so it makes sense to have them all out front where I can get at them. Also Z3 supports multi-arity quantifiers and functions intrinsically, whereas most pencil and paper dependent type theories of telescopes use currying for multi argument object. I have `QForAll` combinators in Knuckeldragger for the \"sequent\" form.\n",
    "\n",
    "On the other hand, the telescoping form is kind of neat and more familiar maybe to someone looking for DTT analogs.\n",
    "\n",
    "I think I'm splitting the difference a little bit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152019d9",
   "metadata": {},
   "source": [
    "# Bits and Bobbles\n",
    "\n",
    "It's a work in progress. I am not fully satisfied by my solutions but I think it is kind of neat even where it's at.\n",
    "\n",
    "Cody's Boole work had a refinement typing system from the get go. I maybe was trying to avoid it merely on that principle.\n",
    "\n",
    "Algebraic datatypes I don't have licked. A topic for another day. I think I need to register a refinement of the type of the recognizers and constructors. Implicit parameters is kind of a problem here.\n",
    "\n",
    "Systems have the ability to make implicit arguments. I'm having a hard time seeing how to do this here in an elegant way.\n",
    "\n",
    "I have been trying to cut along the pre-existing grain of SMTLIB. I'm very much constrained in a self imposed and defined sense of elegance.\n",
    "\n",
    "FOLP https://isabelle.in.tum.de/library/FOL/FOLP/index.html I think is interesting as adding proof objects to first order logic.\n",
    "\n",
    "Telescopes are more fundamental to dependent types than the dependent types themselves. Telescopes are a notion of a dependent context.\n",
    "\n",
    "I'm no longer sold on the self evident necessity or desirability of dependent types. They are fun, just like many topics in logic and programming are fun, and that is good enough reason to play with them. I wonder what the most prominent forms of logic will look like in 100 years? The calculus of constructions may be a bygone fad, but we'll still have C.\n",
    "\n",
    "I'm not 100% sure the distinction between refinement typing, liquid typing https://goto.ucsd.edu/~rjhala/liquid/liquid_types.pdf , and predicate subtyping https://www.csl.sri.com/papers/tse98/tse98.pdf . I think liquid proposes to have better inference?\n",
    "\n",
    "Emphasizing `define-fun` and `define-fun-rec` makes SMTLIB look like a first order functional programming language https://semantic-domain.blogspot.com/2020/02/thought-experiment-introductory.html , a target that is not considered often enough, blowing right past to lambdas. Lambdas are the ultimate pain in the ass.\n",
    "\n",
    "There's a class of systems which offer a logic and programming language deeply integrated with SMT solvers.\n",
    "\n",
    "I would love if smtlib had built in Nats even though it's only an implicit constraint away from Ints. https://theory.stanford.edu/~nikolaj/z3navigate.html Talk about reduction of refinements types in z3 here. relax and restrict combinators. \n",
    "\n",
    "Something interesting\n",
    "\n",
    "https://arxiv.org/abs/2010.07763 Refinement Types: A Tutorial\n",
    "\n",
    "\n",
    "I've been interested in seeing how close I can get to mimicking interesting other logical systems in basically SMTLIB using a bit of trickery and squinting. For example, here I tried to do some temporal and separation logic https://www.philipzucker.com/shallow_logic_knuckle/\n",
    "\n",
    "A related system is [F*](https://fstar-lang.org/) , which is a fresh language designed for SMT discharged dependent types from the outset. \n",
    "\n",
    "Models involving collections of terms feel circularly motivated (is circulairty bad? Can motivation, like [sets](https://plato.stanford.edu/entries/nonwellfounded-set-theory/), be non-well founded?)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7396561",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Automata hashing\n",
    "Telescopes\n",
    "Schema Vars\n",
    "Automated Assembly 3\n",
    "Quickcheck Types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9de6eb",
   "metadata": {},
   "source": [
    "## Older Notes\n",
    "I've played around with different styles, like explicitly tagging terms with a attribute `ctx` to carry their intended context of usage. I'm not so sure this is a good idea.\n",
    "\n",
    "We can also make an explicit new form of `Proof` called `TProof` which carries the approriate new judgement. Also not convinced this is a good idea. It felt good, but also was just bloating.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8838f0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "760090df",
   "metadata": {},
   "source": [
    "https://lean-lang.org/functional_programming_in_lean/Programming-with-Dependent-Types/The-Universe-Design-Pattern/#Functional-Programming-in-Lean--Programming-with-Dependent-Types--The-Universe-Design-Pattern\n",
    "finite universes\n",
    "\n",
    "\n",
    "Indicdes vs parameters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a7f146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.all import *\n",
    "import kdrag.datatype as dt\n",
    "n = smt.Int(\"n\")\n",
    "Vec = dt.InductiveRel(\"Vec\", n)\n",
    "Vec.declare(\"Nil\",  pred = n == 0)\n",
    "Vec.declare(\"Cons\", (\"tl\", Vec), pred = lambda x: x.rel(n - 1))\n",
    "Vec.create()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc57c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pi(tele0 : Telescope, B : Family) -> SubSort: # Multiarity Pi\n",
    "    tele = normalize(tele0)\n",
    "    vs = [v for v, _ in tele]\n",
    "    TB = B(*vs)  # B is a family of sorts\n",
    "    sorts = [v.sort() for (v, _) in tele]\n",
    "    fsort = smt.ArraySort(*sorts, sort_domain(TB))\n",
    "    f = smt.FreshConst(fsort, prefix=\"f\")\n",
    "    return smt.Lambda([f], smt.TForAll(tele0, TB[f(*vs)]))\n",
    "\n",
    "ann(smt.Lambda([x], x), Pi([(x, Nat)]), Nat)\n",
    "\n",
    "def Sigma(): ...\n",
    "    # Not good tupling in smtlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093d5ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TProof(NamedTuple):\n",
    "    tele: _Tele\n",
    "    conc: smt.BoolRef\n",
    "    pf: kd.Proof\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.tele} |= {self.conc}\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_proof(cls, pf: kd.Proof) -> \"TProof\":\n",
    "        \"\"\"\n",
    "        Create a TProof from a kd.Proof.\n",
    "\n",
    "        >>> x, y = smt.Ints(\"x y\")\n",
    "        >>> pf = kd.prove(smt.ForAll([x], x + 1 > x))\n",
    "        >>> TProof.from_proof(pf)\n",
    "        [] |= ForAll(x, x + 1 > x)\n",
    "        \"\"\"\n",
    "        assert isinstance(pf, kd.Proof)\n",
    "        return TProof([], pf.thm, pf)\n",
    "\n",
    "    def __call__(self, *args): ...\n",
    "\n",
    "\n",
    "class TGoal(NamedTuple):\n",
    "    tele: _Tele\n",
    "    conc: smt.BoolRef\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.tele} ?|= {self.conc}\"\n",
    "\n",
    "\n",
    "class Lemma: ...\n",
    "\n",
    "\n",
    "class Calc:\n",
    "    tele: _Tele\n",
    "    start: smt.ExprRef\n",
    "    t: smt.ExprRef\n",
    "    pf: kd.Proof\n",
    "\n",
    "    def __init__(self, ctx: Telescope, start: smt.ExprRef):\n",
    "        self.tele = normalize(ctx)\n",
    "        self.start = start\n",
    "        self.pf = TProof(self.tele, start, kd.Proof(start))\n",
    "\n",
    "# but I want to allow dependencies in the signautre. Kind of the point\n",
    "def FunctionAxiom(name, *args: SubSort) -> smt.FuncDeclRef:\n",
    "    \"\"\"\n",
    "    Declare a function symbol to have a given signature axiomatically.\n",
    "\n",
    "    >>> n = smt.Int(\"n\")\n",
    "    >>> Nat = smt.Lambda([n], n >= 0)\n",
    "    >>> FunctionAxiom(\"inc\", Nat, Nat).pre_post\n",
    "    |= ForAll(c!..., Implies(c!... >= 0, Lambda(n, n >= 0)[inc(c!...)]))\n",
    "    \"\"\"\n",
    "    sorts = [subsort_domain(T) for T in args]\n",
    "    f = smt.Function(name, *sorts)\n",
    "    tele: Telescope = [\n",
    "        (smt.FreshConst(sort), T) for sort, T in zip(sorts[:-1], args[:-1])\n",
    "    ]\n",
    "    T = args[-1]\n",
    "    vs = [v for v, _ in tele]\n",
    "    P = kd.axiom(TForAll(tele, T[f(*vs)]), [\"user_sig\"])\n",
    "    f.pre_post = P\n",
    "    if f in _tsig:\n",
    "        print(\"Warning: Redefining function\", f)\n",
    "    _tsig[f] = P\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20049ceb",
   "metadata": {},
   "source": [
    "Maybe all open_binder should use SchmeaVar\n",
    "\n",
    "wf attached to variables instead. Interesting.\n",
    "\n",
    "(v, P) vs v.P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1573dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TSchemaVar(name, sort : smt.SortRef) -> smt.ExprRef:\n",
    "    \"\"\"\n",
    "    Create a schematic variable with the given name and sort.\n",
    "    \"\"\"\n",
    "    v = smt.FreshConst(sort, prefix=name)\n",
    "    return SchemaVarEvidence(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcbf302",
   "metadata": {},
   "source": [
    "Sequent style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70643188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.all import *\n",
    "def seq_view(pf : kd.Proof) -> tuple[list[smt.BoolRef], smt.BoolRef]:\n",
    "    \"\"\"\n",
    "    View a proof as a sequence of hypotheses and a conclusion.\n",
    "    Implies(smt.And(hyps), conc)\n",
    "\n",
    "    \"\"\"\n",
    "    assert isinstance(pf, kd.Proof)\n",
    "    thm = pf.thm\n",
    "    assert smt.is_implies(thm)\n",
    "    hyps, conc = thm.children()\n",
    "    assert smt.is_and(hyps)\n",
    "    return hyps.children(), conc\n",
    "\n",
    "def normalize_hyps(hyps : list[smt.BoolRef]) -> list[smt.BoolRef]:\n",
    "    \"\"\"\n",
    "    Normalize a list of hypotheses by removing duplicates and sorting them.\n",
    "    \"\"\"\n",
    "    return sorted(set(hyps), key=lambda t: t.get_id())\n",
    "\n",
    "def seq_normalize(pf : kd.Proof) -> kd.Proof:\n",
    "    \"\"\"\n",
    "    Normalize a theorem of the form \n",
    "    \"\"\"\n",
    "    hyps, conc = seq_view(pf)\n",
    "    thm = smt.Implies(smt.And(normalize_hyps(hyps.children())), conc)\n",
    "    if proof_mode:\n",
    "        return kd.axiom(smt.Implies(smt.And(normalize_hyps(hyps), conc), by=[\"seq_normalize\", pf]))\n",
    "    else:\n",
    "        return kd.prove(thm, by=[pf])\n",
    "\n",
    "a,b,c = smt.Bools(\"a b c\")\n",
    "p = kd.prove(smt.Implies(smt.And(b, a, a, c), a))\n",
    "seq_normalize(p)\n",
    "\n",
    "def weakenL(pf : kd.Proof, hyps1 : list[smt.BoolRef]) -> kd.Proof:\n",
    "    \"\"\"\n",
    "    Weaken a proof by adding additional hypotheses.\n",
    "    \"\"\"\n",
    "    hyps, conc = seq_view(pf)\n",
    "    return kd.axiom(smt.Implies(normalize_hyps(hyps + hyps1), conc), by=[\"weaken\", pf, *hyps])\n",
    "\n",
    "\n",
    "def forallI(pf : kd.Proof, vs : list[smt.ExprRef]) -> kd.Proof:\n",
    "    \"\"\"\n",
    "    Introduce universal quantifiers for the given variables.\n",
    "    \"\"\"\n",
    "    hyps, conc = seq_view(pf)\n",
    "    kd.utils.free_in(hyps, vs)\n",
    "    return kd.axiom(smt.Implies(hyps, generalize(conc, vs)), by=[\"forallI\", pf, *vs])\n",
    "\n",
    "\n",
    "def forallE(f : kd.Proof, x : kd.Proof):\n",
    "    \"\"\"\n",
    "    Eliminate a universal quantifier by instantiating it with a proof.\n",
    "    \"\"\"\n",
    "    hyps, conc = seq_view(f)\n",
    "    hyps1, conc1 = seq_view(x)\n",
    "    return kd.axiom(smt.Implies(smt.And(normalize_hyps((hyps - conc1) + hyps1)), conc), by=[\"forallE\", f, x])\n",
    "\n",
    "    \n",
    "\n",
    "def impliesI(pf : kd.Proof, hyp : smt.BoolRef) -> kd.Proof:\n",
    "    \"\"\"\n",
    "    Introduce an implication with the given hypotheses.\n",
    "    \"\"\"\n",
    "    hyps, conc = seq_view(pf)\n",
    "    assert hyp in hyps\n",
    "    return kd.axiom(smt.Implies(smt.And(hyps - hyp), smt.Implies(hyp, conc), by=[\"impliesI\", pf, hyp]))\n",
    "#return kd.axiom(smt.Implies(smt.And(normalize_hyps(hyps + hyps1)), conc), by=[\"impliesI\", pf, *hyps1])\n",
    "\n",
    "def piI(pf : kd.Proof, vs : list[smt.ExprRef]) -> kd.Proof:\n",
    "    \"\"\"\n",
    "    Introduce a pi quantifier for the given variables.\n",
    "    \"\"\"\n",
    "    hyps, conc = seq_view(pf)\n",
    "    kd.utils.free_in(hyps, vs)\n",
    "    return kd.axiom(smt.Implies(hyps, smt.Pi(vs, conc)), by=[\"piI\", pf, *vs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a875b47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.all import *\n",
    "\n",
    "n = smt.Int(\"n\")\n",
    "x = smt.Real(\"x\")\n",
    "RVec = kd.InductiveRel(\"RVec\", n)\n",
    "RVec.declare(\"Nil\", pred=n == 0)\n",
    "RVec.declare(\"Cons\", (\"hd\", smt.RealSort()), (\"tl\", RVec), pred=lambda hd, tl: tl.rel(n - 1))\n",
    "RVec = RVec.create()\n",
    "v = smt.Const(\"v\", RVec)\n",
    "# We want to turn off Call overloading on type\n",
    "smt.DatatypeSortRef.__call__ = lambda self, n: smt.Lambda([v], v.rel(n))\n",
    "smt.DatatypeSortRef.__getitem__ = lambda self, n: smt.Lambda([v], v.rel(n))\n",
    "kd.simp(RVec(2)[v])\n",
    "(v, RVec[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ad9221",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8660c6",
   "metadata": {},
   "source": [
    "Right I can register things for constructors and deconstructors.\n",
    "Then I learn stuff going into branches\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Vec\n",
    "\n",
    "Maybe an accessor that is only well formed under the right cirumstrances\n",
    "\n",
    "\n",
    "Hmm. It just reveal the definition of \n",
    "\n",
    "But the recorgnizer doesn't have access to the current context (?)\n",
    "\n",
    "I could just reveal the definition for ForAll() on the indices. Hmm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98436640",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m = kd.tactics.SchemaVars(\"n m\", smt.IntSort())\n",
    "x = smt.Real(\"x\")\n",
    "RVec = kd.Inductive(\"RVec\")\n",
    "RVec.declare(\"Nil\")\n",
    "RVec.declare(\"Cons\", (\"hd\", smt.RealSort()), (\"tl\", RVec))\n",
    "RVec = RVec.create()\n",
    "\n",
    "v = smt.FreshConst(RVec, prefix=\"v\")\n",
    "RVecP = smt.Function(\"RVecP\", smt.IntSort(), smt.ArraySort(RVec, smt.BoolSort()))\n",
    "RVecP = kd.define(\"RVecP\", [n], smt.Lambda([v], kd.cond(\n",
    "    (v.is_Nil,  n == 0),\n",
    "    (v.is_Cons, RVecP(n-1)[v.tl])\n",
    ")))\n",
    "\n",
    "b = smt.Bool(\"b\")\n",
    "prove_sig(RVec.is_Cons, [(v, RVecP(n))], smt.Lambda([b], smt.Implies(b, RVecP(n-1)[v.tl])), by=[RVecP.defn(n)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558f0c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.contrib.telescope import *\n",
    "from kdrag.all import *\n",
    "import kdrag\n",
    "def register_inductive(ctx : Telescope, dt : smt.DatatypeSortRef):\n",
    "    x = kd.kernel.SchemaVar(\"x\", dt) #smt.FreshConst(dt, prefix=\"x\")\n",
    "    tele = normalize(ctx)\n",
    "    vs = [v for v, _ in tele]\n",
    "    T = smt.Lambda([x], dt.rel(x, *vs))\n",
    "    b = smt.Bool(\"b\")\n",
    "    for i in range(dt.num_constructors()):\n",
    "        recog = dt.recognizer(i)\n",
    "        #constr = dt.constructor(n)\n",
    "        #accs = [dt.accessort(i,j) for j in constr.arity()]\n",
    "        pf = dt.rel.defn(x, *vs)\n",
    "        rhs = pf.thm.arg(1)\n",
    "        prove_sig(recog, [(x, T)], smt.Lambda([b], rhs), by=pf) \n",
    "n, m = kd.tactics.SchemaVars(\"n m\", smt.IntSort())\n",
    "x = smt.Real(\"x\")\n",
    "RVec = kd.InductiveRel(\"RVec\", n)\n",
    "RVec.declare(\"Nil\", pred=n == 0)\n",
    "RVec.declare(\"Cons\", (\"hd\", smt.RealSort()), (\"tl\", RVec), pred=lambda hd, tl: tl.rel(n - 1))\n",
    "RVec = RVec.create()\n",
    "RVec.rel.defn  \n",
    "\n",
    "register_inductive([n], RVec)\n",
    "kdrag.contrib.telescope._tsig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61315f8c",
   "metadata": {},
   "source": [
    "Ok, so we can replace implicits with Metaprogramming. Which is what it is.\n",
    "If we can statically determine what it should be, just write that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d004ab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "old_call = smt.FuncDeclRef.__call__\n",
    "def call_and_propagate(self, *args):\n",
    "    t = old_call(self, *args)\n",
    "    t.ctx = frozenset.union(*[a.ctx for a in args])\n",
    "    return t\n",
    "FuncDeclRef.__call__ = call_and_propagate\n",
    "\n",
    "# Get a context of only the variabnle appearing in t\n",
    "def ctx_of(bigctx, t):\n",
    "    todo = [t]\n",
    "    ctx = {}\n",
    "    seen = set()\n",
    "    while todo:\n",
    "        t = todo.pop()\n",
    "        if t in seen:\n",
    "            continue\n",
    "        if t in bigctx:\n",
    "            todo.extend(bigctx[t])\n",
    "            ctx[t] = bigctx[t]\n",
    "            seen.add(t)\n",
    "\n",
    "def synth(ctx, t):\n",
    "    if t in ctx:\n",
    "        return kd.prove(smt.Implies(ctx[t], ctx[t]))\n",
    "    \n",
    "\n",
    "def check(ctx, t, subset):\n",
    "    if t in ctx:\n",
    "        return kd.prove(smt.Implies(ctx[t], subset[y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebb6258",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Section():\n",
    "    ctx : _Tele\n",
    "    terms : \n",
    "\n",
    "    def SchemaVar(self, name, sort : )\n",
    "\n",
    "def ann(x, T):\n",
    "    # identity function showing intended subset. A projection function.\n",
    "    ann = kd.define(\"ann\", [x], smt.If(T[x], x, smt.FreshConst(x.sort(), prefix=\"ann_undefined\")))\n",
    "    return ann(x, T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ff1de3",
   "metadata": {},
   "source": [
    "def forallI(v, pf : kd.Proof) -> kd.Proof:\n",
    "    \"\"\"\n",
    "    Introduce a universal quantifier for the given variable.\n",
    "    \"\"\"\n",
    "    hyps, conc = seq_view(pf)\n",
    "    #assert v.prop in hyps\n",
    "    hyps = hyps - v.prop # we get to delete property from hypotheses\n",
    "    assert kd.kernel.is_schema_var(v)\n",
    "    assert kd.utils.free_in(hyps, v), \"Variable must not be free in the hypotheses\"\n",
    "    return kd.axiom(smt.Implies(smt.And(hyps), smt.ForAll([v], smt.Implies(v.prop, conc))), by=[\"forallI\", pf, v, v.prop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6008c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1df61b87",
   "metadata": {},
   "source": [
    "the two style of tagging info to variables.\n",
    "\n",
    "open_binder now tags the property on the varible instead of returning telescope tuple.\n",
    "\n",
    "type _Tele = list[smt.ExprRef]\n",
    "prop = smt.True\n",
    "\n",
    "The prop tag is not part of the trust.\n",
    "It is just hidden instructions.\n",
    "\n",
    "\n",
    "Styles:\n",
    "\n",
    "1. TProof(tele, conc, pf)\n",
    "2. TProof(hyps, conc)  and a to_proof axiom schema\n",
    "3. TProof(tele, conc, reasons)\n",
    "4. |= Implies(hyps, conc)  have to pack and unpack.\n",
    "\n",
    "contexts as ordered lists vs sets. Sets has some convevnient properties for mergability. Not requiring exactly the same stuff. They only need to \n",
    "\n",
    "1. Tagging. t.ctx  t.P\n",
    "2. Tupling  (t, P)\n",
    "3. Subclassing  \n",
    "4. Wrapping\n",
    "5. Registries\n",
    "\n",
    "\n",
    "\n",
    "SchemaVars have prop _assumptions_\n",
    "Terms have prop  _assertions_ which can be contextual (TProof)\n",
    "\n",
    "man I have completely lost it\n",
    "\n",
    "t.refine\n",
    "t.wf\n",
    "\n",
    "What is the most natural multi-arity form?\n",
    "forall x y z, And(p(x), q(y), r(z)) => yada\n",
    "forall x y z, And(p(x), q(x,y), r(x,y,z)) => yada . THis should be telescoped\n",
    "forall x y z, And(p(x,y,z), q(x,y,z), r(x,y,z)) => yada\n",
    "forall x y z, P(x,y,z) => yada\n",
    "\n",
    "If you want \n",
    "\n",
    "\n",
    "synth. if subterms all have prop, we can synth\n",
    "\n",
    "ctx synth is easy. just collect constraints from pieces\n",
    "\n",
    "t.ctx\n",
    "t.prop\n",
    "\n",
    "A third jduegment min_ctx\n",
    "\n",
    "v |- v minctx\n",
    "union G1 G2 G3  |- f(t1,t2,t3)   minctx \n",
    "\n",
    "synth can use minctx. synth can turn into minctx\n",
    "\n",
    "\n",
    "def synth(t):\n",
    "   saynth is done during term construction\n",
    "\n",
    "def check(t, P):\n",
    "    if hasattr(\"prop\", t):\n",
    "        kd.prove(t.ctx, smt.Implies(t.Prop, P))\n",
    "    t.ctx, P[t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dacca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Hom = DeclareFunction(\"Hom\", [a, b])\n",
    "#Hom = smt.Function(\"Hom\", Ob, Ob)\n",
    "DeclareFunction(\"id\", [a], Hom(a, a))\n",
    "DeclareFunction(\"comp\", [a, b, Hom(a, b), Hom(b, c)], Hom(a, c))\n",
    "DeclareFunction(\"comp\", [(f, Hom(a, b)), (g, Hom(b, c))], Hom(a, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e38f3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def assume(x, T):\n",
    "\n",
    "\n",
    "ann(ann(x,T1), T2) == ann(x, T1 && T2)\n",
    "T1 <= T2, T1[x] ==> ann(x,T1) == ann(x,T2) == x\n",
    "T1 <= T2, ann(ann(x, T1), T2) == ann(x, T1)\n",
    "\n",
    "#using refinement egraph alongside Coward's assume nodes\n",
    "\n",
    "\n",
    "def TLambda(ctx: Telescope, body: smt.ExprRef) -> smt.ExprRef:\n",
    "    return smt.Lambda([v for v, _ in ctx], smt.If(smt.And([P[v] for v,P in ctx]), ann(body,T), smt.FreshConst(body.sort(), prefix=\"lambda_undefined\")))\n",
    "\n",
    "\n",
    "#x.ann(T)\n",
    "\n",
    "# In has_type tactic, take has_type as recusrive subcalls \n",
    "\n",
    "def has_type():\n",
    "\n",
    "    ...\n",
    "    if name == \"ann\": # Ann are shifts from check and synth?\n",
    "        by.append(has_type(ctx, args[0], args[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6899a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "_axiom = True\n",
    "@dataclass(frozen=True)\n",
    "class TProof(kd.kernel.Judgement):\n",
    "    hyps : frozenset[smt.BoolRef]\n",
    "    conc : smt.BoolRef\n",
    "    reasons : list\n",
    "\n",
    "    def to_proof(self) -> kd.Proof:\n",
    "        \"\"\"\n",
    "        Convert this TProof to a kd.Proof.\n",
    "        \"\"\"\n",
    "        thm = smt.Implies(smt.And(self.hyps), self.conc)\n",
    "        return kd.axiom(thm, by=[\"TProof\", self])\n",
    "    \n",
    "    @classmethod\n",
    "    def from_proof(cls, pf : kd.Proof) -> 'TProof':\n",
    "        \"\"\"\n",
    "        Create a TProof from a kd.Proof.\n",
    "        \"\"\"\n",
    "        hyps, conc = seq_view(pf)\n",
    "        return cls(frozenset(hyps), conc, [\"from_proof\", pf])\n",
    "    \n",
    "    @classmethod\n",
    "    def ax(cls, P : smt.BoolRef) -> 'TProof':\n",
    "        \"\"\"\n",
    "        Create a TProof from a single proposition.\n",
    "        \"\"\"\n",
    "        assert isinstance(P, smt.BoolRef), \"P must be a boolean expression\"\n",
    "        return cls.from_proof(kd.prove(smt.Implies(smt.And(P), P)))\n",
    "        return cls(frozenset(P), P, [\"ax\", P])\n",
    "\n",
    "def prove(hyps : list[smt.BoolRef], conc : smt.BoolRef, by=None) -> TProof:\n",
    "    \"\"\"\n",
    "    Prove a theorem with the given hypotheses and conclusion.\n",
    "    \"\"\"\n",
    "    if by is None:\n",
    "        by = []\n",
    "    pf = kd.prove(smt.Implies(smt.And(hyps), conc), by=by)\n",
    "    return TProof.from_proof(pf)\n",
    "\n",
    "def forallE(pf : TProof,  x : TProof):\n",
    "    # Do I refuie f to have empty context, equal contexts?\n",
    "\n",
    "p = smt.Bool(\"p\")\n",
    "TProof.ax(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cebae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TSchemaVar(name : str, subtype : smt.ArrayRef = None):\n",
    "    sort = subtype.domain()\n",
    "    assert subtype.range() == smt.BoolSort(), \"Subtype must be an array of booleans\"\n",
    "    v = SchemaVar(name, sort)\n",
    "    v.prop = TProof.ax(subtype[v])  # P |= P\n",
    "    #v.wf # kind of\n",
    "    return v\n",
    "\n",
    "def Refine(v : smt.ExprRef, prop : smt.BoolRef) -> smt.ExprRef:\n",
    "    assert kd.kernel.is_schema_var(v), \"v must be a schema variable\"\n",
    "    v.prop = TProof.ax(prop)\n",
    "    return v\n",
    "\n",
    "def HasProp(ctx : list[smt.BoolRef], t : smt.ExprRef, prop : smt.BoolRef, by=[]) -> smt.ExprRef:\n",
    "    \"\"\"\n",
    "    Check if a term has a property.\n",
    "    \"\"\"\n",
    "    t.prop = prove(ctx, prop, by=by)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75967ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forallI(pf : TProof, v : smt.ExprRef) -> kd.TProof:\n",
    "    \"\"\"\n",
    "    Introduce a universal quantifier for the given variable.\n",
    "    \"\"\"\n",
    "    assert kd.kernel.is_schema_var(v), \"Variable must be a schema variable\"\n",
    "    hyps = kd.hyps.remove(v.prop)\n",
    "    assert all(kd.utils.free_in(hyp, v) for hyp in hyps), \"Variable must not be free in the hypotheses\"\n",
    "    return TProof(hyps, smt.ForAll([v], smt.Implies(v.prop, pf.conc)), [\"forallI\", pf, v, v.prop])\n",
    "\n",
    "def forallE(f : TProof, t : smt.ExprRef) -> kd.TProof:\n",
    "    assert isinstance(f, TProof), \"f must be a TProof\"\n",
    "    assert isinstance(t.prop, TProof), \"x must be an ExprRef\"\n",
    "    f.hyps - t.has_prop\n",
    "\n",
    "\n",
    "def TLambda(vs : list[smt.ExprRef], body : smt.ExprRef) -> smt.ExprRef:\n",
    "    t = smt.Lambda(vs, body)\n",
    "    t.pre = [v.prop for v in vs]\n",
    "\n",
    "def apply(f : smt.ExprRef, *args : list[smt.ExprRef], by=[]) -> smt.ExprRef:\n",
    "    \"\"\"\n",
    "    Apply a function to the given arguments.\n",
    "    \"\"\"\n",
    "    for pre, arg in zip(f.pre, args):\n",
    "        prove(pre, )\n",
    "        return f(*args)\n",
    "\n",
    "def prove(ctx, prop, by=[]):\n",
    "    return TProof.from_proof(kd.prove(smt.Implies(smt.And(ctx), prop), by=[p.to_proof() if isinstance(p, TProof) else p for p in by]))\n",
    "\n",
    "def has_type(ctx, t, T, by=[]):\n",
    "    t.has_prop = kd.prove(smt.Implies(smt.And(ctx), T[t]), by=by)\n",
    "    t.has_prop.append(kd.prove(smt.Implies(smt.And(ctx), smt.ForAll([t], T(t))), by=by)) # multiple props. But then which ones...\n",
    "\n",
    "def refine(ctx, t, prop, by=[]):\n",
    "    t.has_prop = kd.prove(smt.Implies(smt.And(ctx), prop), by=by)\n",
    "\n",
    "ProofS = smt.DeclareSort(\"ProofS\")\n",
    "# This is just a dummy thing to tag stuff onto\n",
    "ProofS = smt.Datatype(\"Proof\")\n",
    "Proof.declare(\"MakeItSo\")\n",
    "Proof = Proof.create()\n",
    "\n",
    "\n",
    "sort, subset = InductiveRel()\n",
    "# subset is a funcdecl that returns a Set of sort.\n",
    "# The _last_ argument should be \n",
    "\n",
    "Even = dt.InductiveRel(\"Even\", n)\n",
    "Even.declare(\"Zero\", pred=lambda n: n == 0)\n",
    "\n",
    "p = smt.Const(\"p\", sort)\n",
    "TForAll([n, (p, Even(n)), ]) ===>  ForAll(n, ForAll(p, Even(n)[p], ...))\n",
    "            (p, Even.rel(n))\n",
    "\n",
    "Even.rel(n)[p]\n",
    "\n",
    "class TProof():\n",
    "    vs : smt.ExprRef\n",
    "    ctx : frozendict[int, smt.BoolRef] # all hypotheses are assoicated with some hypothesis.\n",
    "    conc : smt.BoolRef\n",
    "\n",
    "# Why does ordering even hurt us?\n",
    "class TProof():\n",
    "    tele : list[tuple[smt.ExprRef, smt.BoolRef]]\n",
    "    conc : smt.BoolRef\n",
    "\n",
    "\n",
    "class RefinedDecl(FuncDeclRef):\n",
    "    #pre : list[SubSet]\n",
    "    #post : SubSet\n",
    "    pf : kd.TProof # |= forall arg0, T0[arg0], forall arg1, T1[arg1], ..., Tn[argn] => post(arg0, arg1, ..., argn)\n",
    "    # forall a0 a1 a2, Implies(And(T0(a0), T1(a1), T2(a2)), post(T[f(a0,a1,a2)])))\n",
    "    # The \"Seqeunt\" form is more natural since funcdecl are multiarity\n",
    "    def __call__(self, *args):\n",
    "        t = super().__call__(self, *args)\n",
    "        t.pf = self.pf(*args)\n",
    "        return t\n",
    "\n",
    "class RefinedLambda(QuantiferRef):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2cc5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "EqInt = dt.InductiveRel(\"EqInt\", n)\n",
    "EqInt.declare(\"Refl\", (\"m\", smt.IntSort()), pred = lambda m: m == n)\n",
    "EqInt = EqInt.create()\n",
    "m = smt.Int(\"m\")\n",
    "p = smt.Const(\"p\", EqInt)\n",
    "EqIntSet = kd.define(\"EqIntSet\", [n,m], smt.Lambda([p], smt.And(p.m == m, p.rel(n))))\n",
    "# TEqInt\n",
    "#[(p, EqIntSet(m,n))]\n",
    "# so maybe I should rearrange how InductiveRel works? It should also define a predicate SetSort on the spine objects. The opposite currying of rel.\n",
    "# it's impossible to use wf to auto infer a parameter version\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d4880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kd.NewType(\"Vec\", smt.SeqSort(smt.IntSort()), pred=lambda v: smt.Length(v) == n)\n",
    "# allow params?\n",
    "kd.NewType1(\"Vec\", , params=[n], pred=lambda x:  )\n",
    "\n",
    "kd.SubSet(\"Vec\", [n], smt.SeqSort(smt.IntSort()), pred=lambda v: smt.Length(v) == n)\n",
    "\n",
    "smt.SortRef.__truediv__ = lambda x,y: SubSet()\n",
    "SeqSort(smt.IntSort()) // smt.Lambda([n], smt.Length(n) == n)\n",
    "\n",
    "## some kind of anonymous subset type\n",
    "# use \"refine\" rather tha \"wf\"\n",
    "x.refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd20777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_type(ctx, x, T): ...\n",
    "    return TForAll(ctx, T[x])\n",
    "def eq_type(ctx, T1, T): ...\n",
    "    return TForAll(ctx, smt.And(T[x], T[y], x == y))\n",
    "def def_eq(ctx, x, y, T): ...\n",
    "\n",
    "\n",
    "\n",
    "type SetSort = ArraySortRef\n",
    "type Family = Callable[[smt.ExprRef], SetSort]\n",
    "def Pi(A : SetSort, B : Family):\n",
    "    x = smt.FreshConst(A.domain(), prefix=\"x\")\n",
    "    f = smt.FreshConst(smt.ArraySort(A.domain(), B(x).domain()), prefix=\"f\")\n",
    "    return Lambda([f], kd.TForAll([(x, A)], B(x)[f(x)]))\n",
    "\n",
    "\n",
    "\n",
    "# def Sigma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b542bc6",
   "metadata": {},
   "source": [
    "For any logic with an interpretation into Proof, we can do the same.\n",
    "Separation logic (Iris?)\n",
    "\n",
    "\n",
    "https://rocq-prover.org/doc/v8.12/refman/language/extensions/match.html#matching-dependent\n",
    "https://lean-lang.org/doc/reference/latest/Terms/Pattern-Matching/\n",
    "\n",
    "explicit motive annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99c0f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_tbinder(e : smt.QuantifierRef):\n",
    "    tele = []\n",
    "    while isinstance(e, smt.QuantifierRef):\n",
    "        vs, body = kd.open_binder(e)\n",
    "        assert len(vs) == 1\n",
    "        v = vs[0]\n",
    "        assert smt.is_implies(body)\n",
    "        e = body.arg(1)\n",
    "        tele.append((v, body.arg(0)))\n",
    "        # predicate form as primary or not.\n",
    "        # It feels like Lambdaifying it is just doing more work\n",
    "        #tele.append((v, smt.Lambda([v], body.arg(0))))\n",
    "    return tele, e\n",
    "\n",
    "def open_qbinder(e : smt.QuantifierRef):\n",
    "    assert isinstance(e, smt.QuantifierRef)\n",
    "    vs, body = kd.open_binder(e)\n",
    "    assert smt.is_implies(body)\n",
    "    return vs, body.arg(0), body.arg(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a857e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TGoal():\n",
    "    ctx : Tele\n",
    "    t : \n",
    "    T : SetSortRef\n",
    "\n",
    "class TProof(): # TAnswer? \n",
    "    ctx : Tele\n",
    "    t : smt.ExprRef\n",
    "    T : SetSortRef\n",
    "    pf : kd.Proof\n",
    "\n",
    "class TLemma():\n",
    "    def __init__(self, thm):\n",
    "        self.thm = thm\n",
    "        self.lemmas = []\n",
    "\n",
    "# recursors / induction principles for InductiveRel\n",
    "\n",
    "# rec_define\n",
    "def rec(x, T, f):\n",
    "    S = x.sort()\n",
    "    assert isinstance(S, smt.DatatypeSortRef)\n",
    "    FreshFunction()\n",
    "    for const in S:\n",
    "\n",
    "from kdrag.all import *\n",
    "type Telescope = list[tuple[smt.ExprRef, smt.BoolRef] | tuple[smt.ExprRef, smt.ArrayRef] | smt.ExprRef]\n",
    "def TForAll(xs : Telescope, P : smt.BoolRef) -> smt.BoolRef:\n",
    "    \"\"\"\n",
    "    Dependent forall quantifier for a telescope of variables.\n",
    "    \"\"\"\n",
    "    for v in reversed(xs):\n",
    "        if isinstance(v, tuple):\n",
    "            (v, T) = v\n",
    "            if T.sort() == smt.BoolSort():\n",
    "                P = kd.QForAll([v], T, P)\n",
    "            elif isinstance(T, smt.ArrayRef) or (isinstance(T, smt.QuantifierRef) and T.is_lambda()):\n",
    "                P = kd.QForAll([v], T(v), P)\n",
    "            else:\n",
    "                raise TypeError(f\"Unsupported type for quantifier: {T}\")\n",
    "        else:\n",
    "            P = kd.QForAll([v], P)\n",
    "    return P\n",
    "x, y, z = smt.Reals(\"x y z\")\n",
    "kd.prove(TForAll([(x, x > 0), (y, y > x)], y > -1))\n",
    "Pos = smt.Lambda([x], x > 0)\n",
    "def GT(x):\n",
    "    return smt.Lambda([y], y > x)\n",
    "kd.prove(TForAll([(x, Pos), (y, GT(x))], y > -1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def tinduct(x, P):\n",
    "\n",
    "# what does a tmatch look like\n",
    "def tmatch(x, cases, typ=None, params=None, motive=None):\n",
    "    # typ is assumption about x\n",
    "    # params are ?\n",
    "    # motive is predicate about output?\n",
    "def qmatch(x, )\n",
    "\n",
    "def tpattern_match(t, pat, cond):\n",
    "\n",
    "\n",
    "def tcond(): #? Does this make sense?\n",
    "\n",
    "\n",
    "# isDefEq\n",
    "def tunify(tele1, tele2): ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fa1699",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prop = kd.Enum(\"Prop\", [\"tt\"])\n",
    "# it shouldn't be prop. It's a proof object.\n",
    "Proof = smt.DeclareSort(\"Proof\")\n",
    "refl = smt.Const(\"refl\", Proof)\n",
    "reflInt = smt.Function(\"reflInt\", smt.IntSort(), Proof)\n",
    "p = smt.Const(\"p\", Prop)\n",
    "\n",
    "[(p, x == y)] #==> forall p: x == y\n",
    "def Eq(x,y):\n",
    "    \"\"\"\n",
    "    Equality as a dependent type.\n",
    "    \"\"\"\n",
    "    return smt.Lambda([p], x == y)\n",
    "def Squash(b):\n",
    "    p = smt.FreshConst(Prop)\n",
    "    return smt.Lambda([p], b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d38f483",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = smt.IntSort()\n",
    "Nat = smt.Lambda([n], n >= 0)\n",
    "Zero = smt.Lambda([n], n == 0)\n",
    "Pos = smt.Lambda([n], n > 0)\n",
    "Neg = smt.Lambda([n], n < 0)\n",
    "Even = smt.Lambda([n], n % 2 == 0)\n",
    "Odd = smt.Lambda([n], n % 2 == 1)\n",
    "\n",
    "incr = kd.define(\"incr\", [n], n + 1)\n",
    "kd.pdefine(\"incr\", [(n, Nat)], Nat, n + 1)\n",
    "kd.pdefine(\"incr\", [(n, Nat)], smt.Lambda([m], m > n), n + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192f8c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b537025",
   "metadata": {},
   "source": [
    "https://www.philipzucker.com/notes/Languages/ocaml/#universal-types\n",
    "\n",
    "https://okmij.org/ftp/ML/trep.ml\n",
    "\n",
    "Boxing and unboxing.\n",
    "My notes on \"Any\"  in knuckledragger\n",
    "\n",
    "Hmm. Maybe I could do a single RecFunction for my universe levels. Then I do get to bake it in to z3.\n",
    "Or for open recursion?\n",
    "\n",
    "I do have existentials (?) Oh myyyyyy\n",
    "\n",
    "Box = kd.Record(\"Box\", (typ : 'a Code, val : TypeVar(\"a\")))\n",
    "Hmm. Yeah, I kind of need GADTs to use the tag trick.\n",
    "\n",
    "\n",
    "\n",
    "def Get\n",
    "\n",
    "\n",
    "https://dl.acm.org/doi/10.1145/3649836 Persimmon: Nested Family Polymorphism with Extensible Variant Types. Poster at NEPLS\n",
    "\n",
    "\n",
    "\n",
    "GADTs.\n",
    "\n",
    "PInductive()\n",
    "  pred=\n",
    "  pred=\n",
    "\n",
    "InductiveRel\n",
    "wf\n",
    "Why did I call it rel and not use the wf system?\n",
    "That's weird.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52ef921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kdrag.theories.seq as seq\n",
    "\n",
    "def Vec(n, S):\n",
    "    T = seq.Seq(S)\n",
    "    x = smt.FreshConst(T)\n",
    "    return smt.Lambda([x], smt.Length(x) == n)\n",
    "\n",
    "def IVec(n):\n",
    "    return Vec(n, smt.IntSort())\n",
    "n = smt.Int(\"n\")\n",
    "Nat = smt.Lambda([n], n >= 0)\n",
    "x,y = smt.Consts(\"x y\", seq.Seq(smt.IntSort()))\n",
    "tdefine(\"add\", [(n, Nat), (x, IVec(n)), (y, IVec(n))],\n",
    "smt.cond(\n",
    "    (n == 0, Nil),\n",
    "    default=Cons(x.head + y.head, add(n - 1, x.tail, y.tail) , \n",
    "    ), IVec(n)\n",
    ")\n",
    "\n",
    "#( add(n - 1, x.tail, y.tail) ,  Nat ))\n",
    "\n",
    "TForAll([(n, Nat), (x, IVec(n)), (y, IVec(n))],   ? )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b860f87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extensible sort of Codes\n",
    "# Universes are an open type. Their codes are open\n",
    "# This is exactly what the extensible tricks in ocaml are for. Keys. 'a tag\n",
    "\n",
    "TypeCode = smt.DeclareSort(\"TypeCode\")\n",
    "# Code = smt.IntSort()\n",
    "# El = OpenFunction()\n",
    "\n",
    "\n",
    "def El(code):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080ac728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naaaaaah, doesn't really make sense.\n",
    "def ann(x, T):\n",
    "    undef = FreshConst(x.sort())\n",
    "    smt.If(T(x), x, undef)\n",
    "\n",
    "def Epsilon(T):\n",
    "    FreshConst()\n",
    "    smt.If(smt.Exists([y], T(y)) T(x), x, undef)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbcaa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pi(A,B): ...\n",
    "def Pi(xA, B):\n",
    "    (x,A) = xA\n",
    "    #B(x, f(x)))) vs B(x)(f(x)) vs B(f(x))\n",
    "    # Following prior conventions, B should just be a function expression that already contains x\n",
    "    # B has to be a predicate. it can't contain it's variable.\n",
    "    f = smt.FreshConst(smt.ArraySort(x.sort(), B(x).domain()))\n",
    "    return smt.Lambda([f], TForAll([(x,A)], B(f(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5fd3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type Type = smt.ArraySortRef | smt.QuantifierRef | smt.BoolRef\n",
    "\n",
    "# domain cannot be inferred\n",
    "def domain(A : TYPE):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f92e73",
   "metadata": {},
   "source": [
    "Could record known substype and register different coercions\n",
    "\n",
    "\n",
    "SHould All of these optionally take a Tuple?\n",
    "\n",
    "def TForAll(vs, P):\n",
    "    if isiinstance(P, tuple):\n",
    "        P = P[1](P(0))\n",
    "\n",
    "def tdefine(name, args, body):\n",
    "    if isinstance(body, tuple):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b11812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtype_dom(A):\n",
    "    if isinstance(A, smt.QuantifierRef):\n",
    "        return A.sort()\n",
    "\n",
    "def is_subtype(A,B, by=[]):\n",
    "    #x =\n",
    "    return smt.Prove(A <= B, by=by)  #smt.IsSubSet()\n",
    "    #return kd.prove(kd.TForAll([(x,A)], B(x)), by=by)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0337dc6",
   "metadata": {},
   "source": [
    "types are a syntactic discipline to enforce levels of abstraction\n",
    "\n",
    "Type systems as tactic.\n",
    "\n",
    "Homotopy type and transport and stuff probably says how to manually translate isomorphic based proofs. Which is what Talia was getting at?\n",
    "\n",
    "\n",
    "Definitional equality checks use simp as subtactic.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b258527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def TExists(xs : Tele, P : smt.BoolRef) -> smt.BoolRef:\n",
    "    for v in reversed(xs):\n",
    "        if isinstance(v, tuple):\n",
    "            (v, T) = v\n",
    "            if T.sort() == smt.BoolSort():\n",
    "                P = kd.QExists([v], T, P)\n",
    "            elif isinstance(T, smt.QuantifierRef) and T.is_lambda():\n",
    "                P = kd.QExists([v], T(v), P)\n",
    "            elif isinstance(T, smt.ArraySortRef):\n",
    "                P = kd.QExists([v], T(v), P)\n",
    "            else:\n",
    "                raise TypeError(f\"Unsupported type for quantifier: {T}\")\n",
    "        else:\n",
    "            P = kd.QExists([v], P)\n",
    "    return P\n",
    "\n",
    "# TLambda\n",
    "# TExists\n",
    "\n",
    "\n",
    "\n",
    "def pdefine(name, args, out, body, by=[]):\n",
    "    f = kd.define(name, args, smt.If(cond, body, undef))\n",
    "    kd.prove(smt.TForAll(args, out(f(*args))))\n",
    "    substypes[f] = SubTypeDefn(f, args, out, )\n",
    "\n",
    "def subtype_tac(tele, P):\n",
    "    # sweep though expression\n",
    "    # prove TForAll(tele, P) via subtype abstractions.\n",
    "    # Don't fail, output needed subproofs instead. Or raise with them?\n",
    "\n",
    "subtypes = {}\n",
    "\n",
    "# Gamma, x : T, Delta |- x : T\n",
    "def refl_tele(tele, n : int) -> kd.Proof:\n",
    "    (x,T) = tele[n]\n",
    "    return kd.prove(smt.TForAll(tele, T(x)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def synth(tele, t) -> tuple[Subsort, kd.Proof]:\n",
    "    \"\"\"\n",
    "    Synthesize the type of an expression in a telescope.\n",
    "    Returns a tuple of the type and a proof that the expression has that type.\n",
    "    \"\"\"\n",
    "    if n := tele_vars(tele).find(t):\n",
    "        return tele[n][1], refl_tele(tele, n)\n",
    "    elif smt.is_app(t):\n",
    "        decl, children = t.decl(), t.children()\n",
    "        if t in subtypes:\n",
    "            subtype_defn = subtypes[t]\n",
    "            subproofs = [check(c, v) for c, v in zip(children, subtype_defn.tele)]\n",
    "            kd.prove(smt.TForAll(subtype_defn.tele, subtype_defn.out(t(*t.children()))), by=subproofs + [subtype_defn.subtype_lemma])\n",
    "            return subtype_defn.out, \n",
    "def check(tele, t, T) -> kd.Proof:\n",
    "\n",
    "\n",
    "def ann(t,T):\n",
    "    # refine\n",
    "    # annotation is semantically an identity function. Or a refining function.\n",
    "    x = FreshConst(t.sort())\n",
    "    return kd.tdefine(\"ann\", [(x,T)], T, x)\n",
    "\n",
    "def ann(t, T):\n",
    "    return has_type(?, t, T)\n",
    "\n",
    "def restrict(f, T):\n",
    "    # Can sensible annotate a term. If \n",
    "    xs = [smt.FreshConst(args) for arg in f.args]\n",
    "    undef = smt.FreshFunction(*[x.sort() for x in xs], f.sort())\n",
    "    return smt.Lambda([x], smt.If(T(f(*xs)), f(*xs), undef(*xs)))  # restrict f to the type T\n",
    "\n",
    "def restrict(f, T, by=[]):\n",
    "    if f in subtypes:\n",
    "    # make new anonymous definition?\n",
    "        return kd.tdefine(freshname, args, smt.And(T, Tf), f(), by=[f.subtype_lemma] + by)\n",
    "    else:\n",
    "        return kd.tdefine(freshname, args, T, f(args), by=by)\n",
    "\n",
    "# i could tag metadata to kd.Proof objects. tele, vs. Or it could go in the reasons field... yikes.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def has_type(tele : Telescope, t : smt.ExprRef, T : smt.BoolRef, by=[], **kwargs):\n",
    "    if n := tele_vars(tele).find(t):\n",
    "        return refl_tele(tele, n)\n",
    "    elif smt.is_app(t):\n",
    "        decl, children = t.decl(), t.children()\n",
    "        if decl in subtypes:\n",
    "            subtype_defn = subtypes[decl]\n",
    "            has_typ()\n",
    "\n",
    "\n",
    "# Another case wherwe maybe my core Proof thing holding a context would be useful.\n",
    "def has_type(tele : Telescope, t : smt.ExprRef, T : SubSort, by=[], **kwargs):\n",
    "    # Tactic to prove TForAll(tele, T[t])\n",
    "    # search through collecting up substypes.\n",
    "\n",
    "    lemmas = [] # lemmas starts with tele somehow?\n",
    "    todo = [t]\n",
    "    # The let z3 handle it version.\n",
    "    # The telescope character makes it annoying\n",
    "\n",
    "    # get topological order of children and go bottom up?\n",
    "    # compose ctx -> P ,  tele -> P1 moves\n",
    "    # cut move   ctx -> P   ctx -> (P -> P1)  --->  ctx -> P1 \n",
    "    # I need hilbert style combinators\n",
    "\n",
    "    # Use BMC or horn solvers?\n",
    "    # use consider axiom?\n",
    "    while todo:\n",
    "        t = todo.pop()\n",
    "        if n := tele_vars(tele).find(t):\n",
    "            lemmas.append(refl_tele(tele, n))\n",
    "\n",
    "            #kd.prove(TForAll(tele, T(t)))\n",
    "\n",
    "        if smt.is_app(t):\n",
    "            decl, children = t.decl(), t.children()\n",
    "            if decl in subtypes:\n",
    "                subtype_defn = subtypes[decl]\n",
    "                l = subtype_defn.subtype_lemma\n",
    "                if len(children) > 0 and isinstance(l, smt.QuantifierRef) and l.is_forall():\n",
    "                    l = l(children[0]) # One layer at least is easy\n",
    "                lemmas.append(l)\n",
    "                todo.extend(children)\n",
    "        \"\"\"\n",
    "        if smt.is_app(t):\n",
    "            decl,children = t.decl(), t.children()\n",
    "            if decl in subtypes:\n",
    "                subtype_defn = subtypes[decl]\n",
    "                l = subtype_defn.subtype_lemma\n",
    "                while smt.is_implies(l) or smt.is_forall(l):\n",
    "                    if isinstance(l, smt.QuantifierRef) and l.is_forall():\n",
    "                        c = children.pop()\n",
    "                        l = l(c) # instantiate quantifier.\n",
    "                    elif smt.is_implies(l):\n",
    "                        goal = l.arg(0)\n",
    "                        lemmas.append(kd.prove(goal, by=lemmas))\n",
    "                        l = l.arg(1)\n",
    "                for c in children:\n",
    "                    kd.prove( )\n",
    "                    l = l[c]\n",
    "        \"\"\"\n",
    "    return kd.prove(smt.TForAll(tele, T(t)), by=by + lemmas, **kwargs) # unfold=1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99894cda",
   "metadata": {},
   "source": [
    "idea: just using qforall would make the quantifer easier to instnatiate. Otherwise we need a \n",
    "A => forall x, B    ---> A => B[t/x] rule\n",
    "\n",
    "iterate uncurry and \n",
    "A => forall x (B[x] => C)  ---> A => (B[t] => C) ---> and(A,B) => C\n",
    "\n",
    "comp(acc, instan2(pf.arg(1), t)\n",
    "\n",
    "\n",
    "\n",
    "Not all things of shape forall xs, A => B\n",
    "can be easily turned into forall x0 A0 => forall x1 A1 => ,, (?)\n",
    "Well. In some null sense forall x0 True, forall x1 True, ... forall xn A\n",
    "\n",
    "\n",
    "Oh but I have that with compose instan2\n",
    "    .  forall x phi(x) => phi(t)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "QForAll([x], Nat(x), P) is fine.\n",
    "But still would want to register.\n",
    "\n",
    "Quantifiers are evil and implications are just whatever for smt. So it's not symmettric in that sense\n",
    "\n",
    "\n",
    "What if cbs just get fired at the end and they delete non useful stuff.\n",
    "\n",
    "What if GoalCtx was kept in sequent `forall xs, And(hyps) => P` normal form \n",
    "\n",
    "Interesting... Use lemmas as a second stack. Does this work? It is lensy right? This is the trail.\n",
    "\n",
    "Is there a way to do an earlier call to cbs?\n",
    "\n",
    "maybe lemmas and cbstack\n",
    "\n",
    "## Lemma callbacks\n",
    "lemma : id -> [callback]\n",
    "def add_lemma(p):\n",
    "    pid = p.thm.get_id()\n",
    "    cbs = lemma.get(p.thm.get_id())\n",
    "    if isinstance(cbs, list):\n",
    "        lemmas[pid] = p\n",
    "        for cb in cbs:\n",
    "            cb()\n",
    "    elif isinstance(cbs, kd.Proof):\n",
    "        pass\n",
    "    else:\n",
    "        raise UnExpcted\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lookup proofs by get_id\n",
    "Could also close branches by lookup up to see if already proven.\n",
    "That's kind of interesting.\n",
    "\n",
    "\n",
    "\n",
    "What if I put the callbacks on the goals stack. So then I call them as soon as the subgoals are done\n",
    "Goals might be an iniaprrporatye name at this point.\n",
    "\n",
    "goals.append(newgoal)\n",
    "goals.append(cb)\n",
    "\n",
    "t = self.subst[v]\n",
    "        kd.kernel.abstract()\n",
    "\n",
    "    goals.append(body)\n",
    "    goals.append(cb)\n",
    "\n",
    "\n",
    "\n",
    "class Lemma2\n",
    "    def intros():\n",
    "    def intro()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "Lemmas()\n",
    "    self.lemmas = {}\n",
    "    cbs: list[Callable[[], None]]\n",
    "\n",
    "    def fixes(self):\n",
    "        vs, ab = kd.kernel.herb(self.goals)\n",
    "        def cb():\n",
    "            a = lemmas[ab.thm.arg(0).get_id()]\n",
    "            #a = lemmas.pop()\n",
    "            #if p.thm.arg(0)\n",
    "            pb = modus(ab, a)\n",
    "            lemmas[pb.thm.get_id()] = pb\n",
    "            lemmas.append(modus(a, ab))\n",
    "        cbs.append(cb)\n",
    "        cbs.append(lambda: self.lemmas.find(pf, t.arg(0)))\n",
    "    def \n",
    "\n",
    "    def qed(self):\n",
    "        for cb in reversed(cb):\n",
    "            cb()\n",
    "        return lemma.find(pf, self.topgoal)\n",
    "```\n",
    "also might help with eexists\n",
    "subst[v] = whatever\n",
    "And then cb can look for it\n",
    "\n",
    "def eexists():\n",
    "    vs, body = open_binder(goal)\n",
    "    for v in vs:\n",
    "        self.subst[v] = None\n",
    "    def cb():\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598071a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "from kdrag.all import *\n",
    "from kdrag.notation import Telescope\n",
    "\n",
    "type QCtx = tuple[list[smt.ExprRef], list[smt.BoolRef]]\n",
    "type Telescope1 = list[tuple[smt.ExprRef, smt.QuantifierRef | smt.ArrayRef]]\n",
    "type Telescope2 = \n",
    "\n",
    "\n",
    "@dataclass\n",
    "class NormTele():\n",
    "    vs : list[smt.ExprRef]\n",
    "    pred : list[smt.ArrayRef | smt.QuantifierRef] # normalized into predicate form or normalize into Bool form?\n",
    "    @classmethod\n",
    "    def from_tele(cls, tele : Telescope) -> 'NormTele':\n",
    "        vs = []\n",
    "        pred = []\n",
    "        for v in tele:\n",
    "            if isinstance(v, tuple):\n",
    "                (v, T) = v\n",
    "                vs.append(v)\n",
    "                if T.sort() == smt.BoolSort():\n",
    "                    pred.append(smt.Lambda([v], T))\n",
    "                elif isinstance(T, smt.ArrayRef) or (isinstance(T, smt.QuantifierRef) and T.is_lambda()):\n",
    "                    pred.append(T)\n",
    "                else:\n",
    "                    raise TypeError(f\"Unsupported type for quantifier: {T}\")\n",
    "            else:\n",
    "                vs.append(v)\n",
    "                pred.append(smt.Lambda([v], smt.BoolVal(True)))\n",
    "        return cls(vs, pred)\n",
    "    def precond(self):\n",
    "        return smt.And(T(v) for v,T in zip(self.vs, self.preds))\n",
    "    def eval(self, P):\n",
    "        return smt.QForAll(self.vs, self.precond(), P)\n",
    "\n",
    "#def tele_apply(pf : kd.Proof, *args) -> kd.Proof:\n",
    "n,m,k = smt.Ints(\"n m k\")\n",
    "Nat = smt.Lambda([n], n >= 0)\n",
    "NormTele.from_tele([(n, Nat), (m, m > 0), k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d76e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06ec7bf4",
   "metadata": {},
   "source": [
    "## Telescoped axioms\n",
    "\n",
    "telescope normal form for Proofs forall x, p -> forall y, q -> ...\n",
    "\n",
    "\n",
    "Qnormal form forall xs, ctx => A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c92766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.all import *\n",
    "from kdrag.notation import Telescope, SubSort, TForAll, TExists\n",
    "from typing import Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class SubTypeDefn():\n",
    "    decl : smt.FuncDeclRef\n",
    "    ctx : list[tuple[smt.ExprRef, smt.QuantifierRef | smt.ArrayRef]]\n",
    "    T : Optional[smt.BoolRef]\n",
    "    ax : kd.Proof # forall xs, tele(xs), out(f(xs))\n",
    "\n",
    "def tele_vars(tele : Telescope) -> list[smt.ExprRef]:\n",
    "    \"\"\"\n",
    "    Extract the variable names from a telescope.\n",
    "    \"\"\"\n",
    "    return [v if isinstance(v, smt.ExprRef) else v[0] for v in tele]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def norm_tele(tele : Telescope) -> Telescope:\n",
    "    acc = []\n",
    "    for v in tele:\n",
    "        if isinstance(v, tuple):\n",
    "            (var, T) = v\n",
    "            if isinstance(T, smt.ArrayRef) or (isinstance(T, smt.QuantifierRef) and T.is_lambda()):\n",
    "                acc.append((var, T))\n",
    "            elif T.sort() == smt.BoolSort():\n",
    "                acc.append((var, smt.Lambda([var], T)))\n",
    "            else:\n",
    "                raise TypeError(f\"Unsupported type for quantifier: {T}\")\n",
    "        else:\n",
    "            acc.append((v, smt.Lambda([v], True)))\n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "def tele_cond(tele : Telescope) -> Optional[smt.BoolRef]:\n",
    "    \"\"\"\n",
    "    Extract the condition from a telescope.\n",
    "    \"\"\"\n",
    "    acc = []\n",
    "    for v in tele:\n",
    "        if isinstance(v, tuple):\n",
    "            (v, T) = v\n",
    "            if T.sort() == smt.BoolSort():\n",
    "                acc.append(T)\n",
    "            elif isinstance(T, smt.ArrayRef) or (isinstance(T, smt.QuantifierRef) and T.is_lambda()):\n",
    "                acc.append(T(v))\n",
    "            else:\n",
    "                raise TypeError(f\"Unsupported type for quantifier: {T}\")\n",
    "    if len(acc) == 0:\n",
    "        return None\n",
    "    elif len(acc) == 1:\n",
    "        return acc[0]\n",
    "    else:\n",
    "        return smt.And(acc)\n",
    "\n",
    "subtypes = {}\n",
    "\n",
    "# allow synthesis of output Sort?\n",
    "def tdefine(name, args : Telescope, T : SubSort, body, by=[]):\n",
    "    \"\"\"\n",
    "    Define a subtype with a name.\n",
    "    \"\"\"\n",
    "    tvars = tele_vars(args)\n",
    "    body_lemma = kd.prove(TForAll(args, T(body)), by=by)\n",
    "    undef = smt.FreshFunction(*[v.sort() for v in tvars], body.sort())\n",
    "    cond = tele_cond(args)\n",
    "    f = kd.define(name, tvars, smt.If(cond, body, undef(*tvars)))\n",
    "    f.tele = norm_tele(args)\n",
    "    f.subtype = T\n",
    "    f.subtype_lemma = kd.prove(TForAll(args, T(f(*tvars))), by=[body_lemma, f.defn]) # I could do this more directly. It follows from a single unfold.\n",
    "    subtypes[f] = SubTypeDefn(f, args, T, f.subtype_lemma)\n",
    "    return f\n",
    "\n",
    "n = smt.Int(\"n\")\n",
    "Nat = smt.Lambda([n], n >= 0)\n",
    "incr = tdefine(\"incr\", [(n, Nat)], Nat, n + 1)\n",
    "incr.subtype_lemma\n",
    "incr.subtype\n",
    "incr.tele\n",
    "\n",
    "def lookup(ctx : Telescope, v : smt.ExprRef) -> Optional[tuple[smt.ExprRef, smt.BoolRef]]:\n",
    "    for v in ctx:\n",
    "        if isinstance(v, tuple):\n",
    "            (var, T) = v\n",
    "            if var.eq(v):\n",
    "                return (var, T)\n",
    "        elif v.eq(v):\n",
    "            return \n",
    "\n",
    "def check(ctx : Telescope, t : smt.ExprRef, T : SubSort) -> kd.Proof:\n",
    "    S,pf = synth(ctx, t)\n",
    "    if S.eq(T):\n",
    "        return pf\n",
    "    else:\n",
    "        #kd.prove(smt.SubSet(S, T), by=[pf])\n",
    "        return kd.prove(TForAll(ctx, T(t)), by=[pf])  # unfold=1\n",
    "\n",
    "\n",
    "def synth(ctx : Telescope, t : smt.ExprRef) -> tuple[SubSort, kd.Proof]:\n",
    "    \"\"\"\n",
    "    Check that an expression has a type in a telescope.\n",
    "    \"\"\"\n",
    "    ctx = norm_tele(ctx)\n",
    "    for (var, T) in ctx:\n",
    "        if var.eq(t):\n",
    "            return T, kd.prove(TForAll(ctx, T(var)))\n",
    "    if smt.is_app(t):\n",
    "        decl, children = t.decl(), t.children()\n",
    "        if decl in subtypes:\n",
    "            subtype_defn = subtypes[decl]\n",
    "            T = subtype_defn.T\n",
    "            subproofs = [check(ctx, c, T1) for c, (v, T1) in zip(children, subtype_defn.ctx)]\n",
    "            return T, kd.prove(TForAll(subtype_defn.ctx, T(decl(*children))), by=subproofs + [subtype_defn.ax])\n",
    "    else:\n",
    "        raise TypeError(f\"Could not synthesize type for {t} in {tele}\")\n",
    "\n",
    "synth([(n, Nat)], incr(incr(n) + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eda6afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunSpec():\n",
    "    decl : smt.FuncDeclRef\n",
    "    #args : list[smt.ExprRef]\n",
    "    #precond : smt.BoolRef\n",
    "    #postcond : smt.BoolRef\n",
    "    #bod\n",
    "    thm : kd.Proof\n",
    "\n",
    "fun_specs = {}\n",
    "\n",
    "def qdefine(name, args, body, pre=None, post=None): # could make pre and post keyword args\n",
    "    undef = smt.FreshFunction(*[v.sort() for v in args], body.sort())\n",
    "    f = kd.define(name,   ,smt.If(precond, body, undef(*args)))\n",
    "    kd.prove(smt.QForAll(args, precond, postcond), by=[body.defn] + \n",
    "\n",
    "def FunctionAxiom(name, *sorts, pre=None, post=None, by=[]): # Method ?\n",
    "    f = smt.Function(name, *sorts)\n",
    "    f.wf = kd.axiom(smt.QForAll(args, precond, postcond), by=[body.defn] + by)\n",
    "    fun_specs[f] = FunSpec(f, f.wf)\n",
    "\n",
    "Ob = smt.DeclareSort(\"Ob\")\n",
    "Arr = smt.DeclareSort(\"Arr\")\n",
    "Hom = smt.Function(\"Hom\", Ob, Ob, smt.SetSort(Arr))\n",
    "id_ = Function(\"id\", Ob, Arr)\n",
    "id_.wf = kd.axiom(kd.QForAll([a],Hom(a,a)(id_(a))))\n",
    "fun_specs[id_] = FunSpec(id_, id_.wf)\n",
    "\n",
    "\n",
    "comp = Function(\"comp\", Arr, Arr, Arr, Arr)\n",
    "comp.wf = kd.axiom(kd.QForAll([a,b,c,f,g], smt.Implies(smt.And(Hom(a,b)(f), Hom(b,c)(g)), Hom(a,c)(comp(f,g)))))\n",
    "fun_specs[comp] = FunSpec(comp, comp.wf)\n",
    "\n",
    "def lemmas(t):\n",
    "    todo = [t]\n",
    "\n",
    "def well_formed(vs, pre, t): # \"synth\"\n",
    "    if t.decl() in fun_specs:\n",
    "        spec = fun_specs[t.decl()]\n",
    "        return kd.prove(smt.QForAll(vs, pre, spec.thm), by=[t] + lemmas(t))\n",
    "    else:\n",
    "        return kd.prove(smt.QForAll(vs, pre, smt.BoolVal(True)))\n",
    "\n",
    "def qprove(vs, pre, P, by=[]): # \"check\" ?\n",
    "    vs1, P1 = kd.kernel.herb(smt.QForAll(vs, pre, P))\n",
    "    typ_lemmas\n",
    "\n",
    "def qeq(vs, pre, t1, t2):\n",
    "    lemmas = well_formed(vs, pre, t1)\n",
    "    lemmas = well_formed(vs, pre, t2)\n",
    "\n",
    "\n",
    "def wf_lemmas(t): #empty context\n",
    "    res = []\n",
    "    todo = [t]\n",
    "    while todo:\n",
    "        t = todo.pop()\n",
    "        decl,children = t.decl(), t.children()\n",
    "        if decl in fun_specs:\n",
    "            spec = fun_specs[decl]\n",
    "            res.append(spec.thm(*children))\n",
    "            for c in children:\n",
    "                res.extend(wf_lemmas(c))\n",
    "    return res\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f97f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.all import *\n",
    "from kdrag.notation import Telescope, SubSort, TForAll, TExists\n",
    "from typing import Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "type QCtx = tuple[list[smt.ExprRef], list[smt.BoolRef]]\n",
    "@dataclass\n",
    "class SubTypeDefn():\n",
    "    decl : smt.FuncDeclRef\n",
    "    ctx : QCtx\n",
    "    T : smt.QuantifierRef | smt.ArrayRef  # | smt.FuncDeclRef ?\n",
    "    ax : kd.Proof # forall xs, precond, prop\n",
    "\n",
    "\n",
    "def tele_to_qctx(tele : Telescope) -> QCtx:\n",
    "    \"\"\"\n",
    "    Extract the condition from a telescope.\n",
    "    \"\"\"\n",
    "    vs = []\n",
    "    pred = []\n",
    "    for v in tele:\n",
    "        if isinstance(v, tuple):\n",
    "            (v, T) = v\n",
    "            vs.append(v)\n",
    "            if T.sort() == smt.BoolSort():\n",
    "                pred.append(T)\n",
    "            elif isinstance(T, smt.ArrayRef) or (isinstance(T, smt.QuantifierRef) and T.is_lambda()):\n",
    "                pred.append(T(v))\n",
    "            else:\n",
    "                raise TypeError(f\"Unsupported type for quantifier: {T}\")\n",
    "        elif smt.is_const(v):\n",
    "            vs.append(v)\n",
    "            pred.append(smt.BoolVal(True))\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type for quantifier: {v}\")\n",
    "    return (vs, pred)\n",
    "\n",
    "subtypes = {}\n",
    "\n",
    "# allow synthesis of output Sort?\n",
    "def tdefine(name, args : Telescope, T : SubSort, body, by=[]):\n",
    "    \"\"\"\n",
    "    Define a subtype with a name.\n",
    "    \"\"\"\n",
    "    vs,pred = tele_to_qctx(args)\n",
    "    body_lemma = kd.prove(kd.QForAll(vs, *pred, T(body)), by=by)\n",
    "    undef = smt.FreshFunction(*[v.sort() for v in vs], body.sort())\n",
    "    f = kd.define(name, vs, smt.If(smt.And(pred), body, undef(*vs)))\n",
    "    f.qctx = (vs, pred)\n",
    "    f.subtype = T\n",
    "    f.subtype_lemma = kd.prove(kd.QForAll(vs, *pred, T(f(*vs))), by=[body_lemma, f.defn]) # I could do this more directly. It follows from a single unfold.\n",
    "    subtypes[f] = SubTypeDefn(f, (vs,pred), T, f.subtype_lemma)\n",
    "    return f\n",
    "\n",
    "n = smt.Int(\"n\")\n",
    "Nat = smt.Lambda([n], n >= 0)\n",
    "incr = tdefine(\"incr\", [(n, Nat)], Nat, n + 1)\n",
    "incr.subtype_lemma\n",
    "#incr.subtype\n",
    "#incr.qctx\n",
    "\n",
    "\n",
    "def has_type(ctx : Telescope, t : smt.ExprRef, T : SubSort, by=[], **kwargs):\n",
    "    vs,pred = tele_to_qctx(ctx)\n",
    "    def doit(vs1):\n",
    "        todo = [smt.substitute(t, zip(vs1))]\n",
    "        lemmas = []\n",
    "        while todo:\n",
    "            if smt.is_app(t):\n",
    "                decl, children = t.decl(), t.children()\n",
    "                if decl in subtypes:\n",
    "                    subtype_defn = subtypes[decl]\n",
    "                    lemmas.append(subtype_defn.ax(*children))\n",
    "                    todo.extend(children)\n",
    "        return lemmas\n",
    "    return kd.prove(kd.QForAll(vs, pred, T(t)), by=by, instans=doit  ,**kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5170bd",
   "metadata": {},
   "source": [
    "## qforall axioms\n",
    "```\n",
    "procedure test(x: Seq, y: Seq) returns (res: Seq)\n",
    "requires NonEmpty(x) /\\ NonEmpty(y);\n",
    "ensures NonEmpty(res) {\n",
    "  res := Append(x,y);\n",
    "}\n",
    "```\n",
    "\n",
    "Boogie has intrinsic requires ensures stuff. Hmm.\n",
    "\n",
    "\n",
    "\n",
    "Actually, should QForAll always / sometimes traverse the P term and get the well formedness conditions too?\n",
    "QForAll([xs], precond, P)\n",
    "\n",
    "TForAll([xs], T, P) #?\n",
    "TForAll([xs], t, T) #?  HasType(xs, t, T)\n",
    "WellFormed(ctx, pre, t)\n",
    "\n",
    "\n",
    "That one partial function approach from nipkow reference suggested doing it at `==`\n",
    "\n",
    "I feel like there is an assertion mode and checkingt mode? In one or the other\n",
    "\n",
    "return tuple, vs return Anded Version inside quantifier.\n",
    "def QForAll():\n",
    "    objligations = wf(P)\n",
    "    if len(obligations) == 0:\n",
    "        return QForAll0\n",
    "    return QForAll0([], cond, P) , QForAll([], cond, obl)\n",
    "    vs return QForAll([], cond, And(P, oblig))\n",
    "    vs return QForAll([], And(cond, oblig), P)\n",
    "\n",
    "Quotients. Subsets ofg powerset stable wrt eq relation.\n",
    "Set(IntSort()) |  lam A, forall x y, A[x], eq(x,y) => A[y]\n",
    "def Quot(eq):\n",
    "    T = eq.domain(0)\n",
    "    S = SetSort(T)\n",
    "    A = FreshConst(S)\n",
    "    return smt.Lambda([A], QForAll([x,y], A[x], eq(x,y), A[y]))\n",
    "Not higher order though.\n",
    "def Quot(T : SubSet, eq):\n",
    "    S = SetSort(T.domain())\n",
    "    return smt.Lambda([A], QForAll([x,y], T[x], T[y], eq(x,y), A[x], A[y])\n",
    "Hmm.\n",
    "\n",
    "\n",
    "\n",
    "It is natural if I have QLambda and QForAll and QExists to also have qdefine.\n",
    "\n",
    "Could match for QLambda . maybe associate the undefined false branch with the lambda.\n",
    "\n",
    "if t == Lambda(, If(cond, , undef)):\n",
    "    \n",
    "```\n",
    "# Just as a saniuty check\n",
    "def QLambda(vs, *args, post=None)\n",
    "    l = \n",
    "    if post \n",
    "    l.pf = kd.prove(QForAll( vs, cond, post())\n",
    "```\n",
    "\n",
    "This starts to feel more like Dafny.\n",
    "\n",
    "If proof fails, explanation method could try to traverse don and see which preconditions fail.\n",
    "\n",
    "From the subset typing persepctive. Dependent types are a methodology for deraling with partiality.\n",
    "\n",
    "But so is precondition postcondition style reasoning.\n",
    "\n",
    "What would be the analog of Q reasoning for other models of DTT?\n",
    "Setoid Specs? Maybe a hoare logic style relational thing.\n",
    "forall x0 y0, eq(x0,y0), => eq(f(x0),f(y0))\n",
    "To always show representation independence\n",
    "\n",
    "n = smt.Int(\"n\")\n",
    "[(n, Mod3)]\n",
    "Obviously I can't have n == n % 3, because n is interpreted.\n",
    "\n",
    "Or to show High Low security noninterference security properties\n",
    "idefine([(n, High), (m, Low)], body,  Low)\n",
    "Hmm.\n",
    "\n",
    "or parametricity\n",
    "DeclareSort(\"T\")\n",
    "TypeVar(\"T\") ??? Uhh.\n",
    "[(n, T), (m, S)]\n",
    "\n",
    "\n",
    "The curried vs multiairty is a good analogy.\n",
    "MultiArity Q form is like taking in a refinement tuple (x,y,z) : R(x,y,z)\n",
    "\n",
    "\n",
    "QInductive is InductiveRel?\n",
    "\n",
    "\n",
    "def QInductive():\n",
    "    def create():\n",
    "        dt = old_create()\n",
    "        for i in d.num_constructors()\n",
    "        fun_specs[d.constructor(i), kd.smt.QForAll(  )]\n",
    "Q is sequent style basically.\n",
    "\n",
    "\n",
    "class Sequent():\n",
    "    vs : frozenset[smt.ExprRef]\n",
    "    hyps : frozenset[smt.BoolRef]\n",
    "    concs : frozenset[smt.BoolRef]\n",
    "    \n",
    "\n",
    "https://fstar-lang.org/tutorial/proof-oriented-programming-in-fstar.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c06b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DepType(name, params, indices : list[smt.SortRef]): ...  # inductive name p[0] p[1] ... : ind[0] -> ind[1] -> Type\n",
    "# first n positions have to match the index sorts. Can be constants to give implicit n == 3 constraint.\n",
    "\n",
    "def TSchemaVar(name : str, subtype : smt.ArrayRef):\n",
    "    sort = subtype.domain()\n",
    "    assert subtype.range() == smt.BoolSort(), \"Subtype must be an array of booleans\"\n",
    "    v = SchemaVar(name, sort)\n",
    "    v.prop = subtype(v)\n",
    "    #v.wf # kind of\n",
    "    return v\n",
    "\n",
    "def Refine(x : smt.ExprRef, prop : smt.BoolRef) -> smt.ExprRef:\n",
    "    x.prop = prop\n",
    "    return x\n",
    "\n",
    "def TForAll():\n",
    "    if hasattr(\"typ\", v):\n",
    "        p = v.typ\n",
    "\n",
    "def tgeneralize(p : )\n",
    "\n",
    "def open_binder(t : smt.QuantifierRef):\n",
    "    \"\"\"\n",
    "    open binder tagging both variable and body with the context.\n",
    "    We need the body tagged because to do recursive binder opening.\n",
    "    \"\"\"\n",
    "    ctx = t.ctx\n",
    "    [v], body = utils.open_binder(t)\n",
    "    prop = body.args(0)\n",
    "    ctx = ctx + [prop]\n",
    "    v.ctx = ctx\n",
    "    body = body.args(1)\n",
    "    body.ctx = ctx\n",
    "    return v, body"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "philzook58.github.io",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
