{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "399541f1",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Brute Egraph Modulo Theories 2: Extraction, Proofs, and Context\"\n",
    "date: 2025-05-26\n",
    "---\n",
    "\n",
    "\n",
    "It's interesting, while I was writing https://www.philipzucker.com/brute_eggmt/ I was hating the post, but immediately after dumping it out I began to appreciate that I had achieved something quite useful.\n",
    "\n",
    "The single biggest mundane insight I've had with knuckledragger https://github.com/philzook58/knuckledragger  is that centralizing over the z3 ast is a really good idea (or at least an idea very much to my taste). At a certain point I was centralizing my egraphs modulo theories stuff in its own repo https://github.com/philzook58/eggmt . I was going to build out a clone of the z3 data structures and maybe I still might have to. Z3's ast is not extensible. However, the style I made in my recent post uses the z3 interned ids with python dictionaries to other bits. This is straightforward and extensible enough to probably work, using z3 as my common blackboard.\n",
    "\n",
    "By the time I implement the e-graph and e-matching, I rarely (never?) get to the point where I implement extraction or proof production. Here we go.\n",
    "\n",
    "The code for the post is here https://github.com/philzook58/knuckledragger/blob/0419f27bbc6cecbd5d1156a568cebd329dd5cbb0/kdrag/solvers/egraph.py#L1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da78ac7c",
   "metadata": {},
   "source": [
    "## Rewrites / Simplify\n",
    "Another nice thing this style of egraph gets you is the ability to do regular rewrites / reuse existing rewirting mechanisms that work over terms. Z3 has a built in simplifier. I can use it by traversing the term bank. This is a relative of the \"extract and simplfy\" technique of Koehler et al.\n",
    "\n",
    "```python\n",
    "    def simplify_terms(self):\n",
    "        \"\"\"\n",
    "        Use built in simplifier to simplify all terms in the egraph.\n",
    "        Similar to \"extract and simplify\".\n",
    "\n",
    "        >>> E = EGraph()\n",
    "        >>> x,y,z = smt.Ints('x y z')\n",
    "        >>> E.add_term(4 + x + y + 7)\n",
    "        >>> E.add_term(8 + x + y + 3)\n",
    "        >>> E.simplify_terms()\n",
    "        >>> assert E.find(8 + x + y + 3) == E.find(4 + x + y + 7)\n",
    "        \"\"\"\n",
    "        todo = []\n",
    "        for t in self.terms.values():\n",
    "            t1 = smt.simplify(t)\n",
    "            if not t1.eq(t):\n",
    "                todo.append((t, t1))\n",
    "        for t, t1 in todo:\n",
    "            self.add_term(t1)\n",
    "            self._union(t, t1)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae3004f",
   "metadata": {},
   "source": [
    "## Extraction\n",
    "\n",
    "Extraction is kind of the spice that has made egraphs interesting to a larger number of users, because it is the thing that changes it from a theorem proving method `Term -> Term -> Bool` to a simplification method `Term -> Term`.\n",
    "\n",
    "The basic bottom up dynamic programming approach is to traverse all your enodes and add together the sum of the cost of your children with the cost of the enode funcdecl itself. Once this converges, you can extract out the term by following the best choice on downwards.\n",
    "\n",
    "I implemented this as a total brute force loop.\n",
    "\n",
    "```python\n",
    "class EGraph():\n",
    "...\n",
    "    def extract(self, t0: smt.ExprRef, cost_fun=(lambda _: 1)):\n",
    "        \"\"\"\n",
    "        Extract a term from the egraph.\n",
    "\n",
    "        >>> E = EGraph()\n",
    "        >>> x,y,z = smt.Ints('x y z')\n",
    "        >>> E.add_term(x + y)\n",
    "        >>> E.rebuild()\n",
    "        >>> E.extract(x + y)\n",
    "        x + y\n",
    "        >>> _ = E.union(x + y, y)\n",
    "        >>> E.rebuild()\n",
    "        >>> E.extract(x + y)\n",
    "        y\n",
    "        \"\"\"\n",
    "        inf = float(\"inf\")\n",
    "        best_cost = defaultdict(lambda: inf)\n",
    "        best = {}\n",
    "        while True:\n",
    "            done = True\n",
    "            # Terms are taking the place of enodes.\n",
    "            for t in self.terms.values():\n",
    "                eid = self.find(t)\n",
    "                cost = cost_fun(t) + sum(\n",
    "                    [best_cost[self.find(c)] for c in t.children()]\n",
    "                )  # cost_fun(t.decl()) ?\n",
    "                if cost < best_cost[eid]:\n",
    "                    best_cost[eid] = cost\n",
    "                    best[eid] = t\n",
    "                    done = False\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # @functools.cache\n",
    "        def build_best(t):\n",
    "            t1 = best[self.find(t)]\n",
    "            return t1.decl()(*[build_best(c) for c in t1.children()])\n",
    "\n",
    "        return build_best(t0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb3a559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EGraph(roots=defaultdict(<class 'set'>, {Int: {1929, 324, 41}}), terms={265: (a*2)/2, 149: a*2, 324: a, 41: 2, 1929: 2*a}, uf={265: 324, 149: 1929}, solver=[], reasons={})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.solvers.egraph import EGraph\n",
    "from kdrag.all import *\n",
    "a = smt.Int(\"a\") \n",
    "# kd.prove((a * 2)/ 2 == a)\n",
    "E = EGraph()\n",
    "t = (a * 2) / 2\n",
    "E.add_term(t)\n",
    "E.simplify_terms()\n",
    "print(E.extract(t))\n",
    "E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c2fd7f",
   "metadata": {},
   "source": [
    "## Proofs\n",
    "\n",
    "I have the opinion that what you mean by proof may mean different things. https://www.philipzucker.com/proof_objects/ Proofs objects can exist on a spectrum of \"things to be filled in\".\n",
    "\n",
    "A canonical example in my mind is that the proof object of the connectivity of two vertices in a graph is that path between them. This is quite literally the thing that a proof producing union find provides https://www.cs.upc.edu/~roberto/papers/rta05.pdf\n",
    "\n",
    "One of the use cases of union finds is for fast connectivity querying in a graph (connectivity is an equivalence relation). It is used in Kruskal's algorithm to find a minimum weight spanning tree https://en.wikipedia.org/wiki/Kruskal%27s_algorithm .  It works by sorting the edges, and the adding them in order one by one into the union find. If one joins two previous unjoined components, it is part of the spanning tree. This spanning tree is the thing the proof producing union find holds.\n",
    "In equality saturation, you kind of want a least length proof, which means the least number of rule applications. This is basically what you get since you learn the rule applications in order.\n",
    "\n",
    "As part of a general principle that `traces = proof`, a workable proof producing union find is to just log any union that was novel in a big list. You can then later post postprocess this spanning tree to find the appropriate path for two nodes of interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d5b8b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 2, 2: 3}\n",
      "[(1, 2, 'for fun'), (1, 3, 'by fiat')]\n"
     ]
    }
   ],
   "source": [
    "uf = {}\n",
    "def find(x):\n",
    "    while x in uf:\n",
    "        x = uf[x]\n",
    "    return x\n",
    "    \n",
    "log = []\n",
    "def union(x,y, reason=None):\n",
    "    x1,y1 = find(x), find(y)\n",
    "    if x1 != y1:\n",
    "        uf[x1] = y1\n",
    "        log.append((x,y,reason))\n",
    "\n",
    "union(1,2, \"for fun\")\n",
    "union(1,3, \"by fiat\")\n",
    "union(2,3, \"because I said so\") # not logged because already connected\n",
    "union(3,1, \"to connect them\")\n",
    "print(uf)\n",
    "print(log)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f02cec",
   "metadata": {},
   "source": [
    "When you add rules and congruence closure into the mix, the `reason` field becomes more important because vertices aren't atomic entities anymore.\n",
    "\n",
    "You may need to recursively understand the rewriting path that connects children of your term or know what made the rule you used fireable.\n",
    "\n",
    "In my z3 based egraph, I have taken the principle to lean on z3 as much as possible. Z3 already has a proof producing union find.\n",
    "Z3 has proof terms, but also it has the notion of unsat cores, which are a fairly minimal number of asserted facts necessary to make a qeury unsatisfable. Using these, I can get a proof skeleton. Every node in the proof skeleton follows from it's children via fairly straightforward quantifier free reasoning. The rules are dealt with externally and are logged with the rule that fired, the instantiation of the firing\n",
    "\n",
    "\n",
    "```python\n",
    "class EGraph:\n",
    "...\n",
    "    reasons: dict[int, object]\n",
    "...\n",
    "    def union(self, t1: smt.ExprRef, t2: smt.ExprRef, reason=None) -> bool:\n",
    "        \"\"\"\n",
    "        Assert equal two terms in the EGraph.\n",
    "        Note that this does not add the terms to the EGraph.\n",
    "\n",
    "        >>> x,y,z = smt.Ints('x y z')\n",
    "        >>> E = EGraph()\n",
    "        >>> _ = E.union(x, y)\n",
    "        >>> assert E.find(x) == E.find(y)\n",
    "        \"\"\"\n",
    "        if self._union(t1, t2):\n",
    "            if self.proof:\n",
    "                p = smt.FreshConst(smt.BoolSort())\n",
    "                self.reasons[p.get_id()] = (t1, t2, reason)\n",
    "                self.solver.assert_and_track(t1 == t2, p)\n",
    "            else:\n",
    "                self.solver.add(t1 == t2)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def get_proof(self, t1: smt.ExprRef, t2: smt.ExprRef) -> list[object]:\n",
    "        \"\"\"\n",
    "        Get the proof of why t1 == t2 in the egraph.\n",
    "        The reasons returns may require recursive calls of get_proof.\n",
    "\n",
    "\n",
    "        >>> E = EGraph(proof=True)\n",
    "        >>> x,y,z = smt.Ints('x y z')\n",
    "        >>> E.add_term(x + y)\n",
    "        >>> _ = E.union(x + y, y, reason=\"because I said so\")\n",
    "        >>> _ = E.union(x + y, x, reason=\"because I said so too\")\n",
    "        >>> _ = E.union(x + y, z, reason=\"because I said so three\")\n",
    "        >>> E.get_proof(x, y)\n",
    "        [(x + y, y, 'because I said so'), (x + y, x, 'because I said so too')]\n",
    "\n",
    "        \"\"\"\n",
    "        self.solver.push()\n",
    "        self.solver.add(t1 != t2)\n",
    "        res = self.solver.check()\n",
    "        assert res == smt.unsat\n",
    "        cores = self.solver.unsat_core()\n",
    "        self.solver.pop()\n",
    "        return [self.reasons[p.get_id()] for p in cores]\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Hmm. Does this actually work? I could get non well founded proof trees when we recurse through the rules (?). If I keep my assertions minimal this shouldn't be the case? Hmm.\n",
    "\n",
    "You may be unsatisfied that these aren't fully explicit rewrite proofs. Well,\n",
    "- with theory reasoning, unless the theory is an equational theory, what can you expect?\n",
    "- I have taken you pretty close to constructing a rewrite looking proof yourself. You don't trust z3? It's probably your verifier anyway. Can recheck these proofs out in an independent SMT solver, and ITP tactics can probably handle this quantifier free reasoning without too much pain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51519198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(f(x), x, None), (f(x), x + y + z, None)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = EGraph(proof=True)\n",
    "x,y,z = smt.Ints(\"x y z\")\n",
    "f = smt.Function(\"f\", smt.IntSort(), smt.IntSort())\n",
    "t1 = f(f(f(x)))\n",
    "E.add_term(t1)\n",
    "E.union(f(x), x)\n",
    "E.union(y, z)\n",
    "E.union(f(x), x + y + z, )\n",
    "E.get_proof(y + z, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0208466",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "Z3 is intrinsically a more contextual engine than an egg-like implementation. We can assert equalities under assumptions using `z3.Implies`.\n",
    "\n",
    "One way to turn the Z3 EMT into a contextual egraph is to just carry a list of contexts of interests. The idea of contexts is that sometimes you want to rewrite under If-then-elses in a way that only works under the assumptions you gain for being in that branch. For example `If(x > 0, abs(x), 0) == If(x > 0, x, 0)`. See also datapath aware https://arxiv.org/pdf/2303.01839 and colored egraphs https://arxiv.org/abs/2305.19203\n",
    "\n",
    "The contexts can be cleaned up for equivalence and subsumption during the rebuilding phase via seeing if `solver.add(smt.Not(smt.Implies(ctx1,ctx2)))` comes back unsat. The union find can be used for context equivalences, but a separate transitive structure is probably wise for subsumption. I don't know how to make something all that better than brute force for maintaining an online transitive relation like subsumption. Surprisingly, I didn't really need to retain the subsumption list. In ematching under context, I only return if there is a context that implies the discovered context in `in_ctxs`. What this means is that if I have `And(p,q)` in my contexts, the `in_ctxs` filter will pass the context `p`. In bottom up ematching, the implementation changes very little for ematching under context. It is interesting that adding contexts does not combinatorially explode bottom up ematching. The loop size remains largely dependent on the number of variables in your pattern whereas top down matching probably requires a scan over contexts.\n",
    "\n",
    "One probably does not want to let contexts explode.\n",
    "\n",
    "I think I need to modify extract to also build for each context of interest and pull from these tables when you go under an `If` or lazy `And` `Or`. Another reason to maybe do extraction top down.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fc968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdrag.all import *\n",
    "def subsumes(ctx1, ctx2): # __le__ for contexts\n",
    "    s = smt.Solver()\n",
    "    s.add(smt.Not(smt.Implies(ctx1, ctx2)))\n",
    "    return s.check() == smt.unsat\n",
    "\n",
    "p,q,r,s = smt.Bools(\"p q r s\")\n",
    "assert subsumes(p, p)\n",
    "assert not subsumes(p, q)\n",
    "assert subsumes(smt.And(p, q), p) # p is stronger assumption than p and q\n",
    "assert not subsumes(p, smt.And(p, q))\n",
    "assert not subsumes(smt.And(p, q, s), smt.And(p, q, r)) # incomparable contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae56ed72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "If(x &gt; 0, x, 7 + x)"
      ],
      "text/plain": [
       "If(x > 0, x, 7 + x)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kdrag.all import *\n",
    "from kdrag.solvers.egraph import EGraph\n",
    "from dataclasses import dataclass\n",
    "import itertools\n",
    "@dataclass\n",
    "class CtxEGraph(EGraph):\n",
    "    ctxs : set[int]\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ctxs = set()\n",
    "    def add_ctx(self, ctx : smt.BoolRef):\n",
    "        assert isinstance(ctx, smt.BoolRef), \"Context must be a BoolRef\"\n",
    "        self.ctxs.add(ctx.get_id())\n",
    "        self.add_term(ctx)\n",
    "    def ctx_union(self, ctx : smt.BoolRef, t1 : smt.ExprRef, t2 : smt.ExprRef):\n",
    "        with self.solver:\n",
    "            self.solver.add(smt.Not(ctx))\n",
    "            res = self.solver.check()\n",
    "        if res == smt.unsat:\n",
    "            return self.union(t1, t2)\n",
    "        else:\n",
    "            with self.solver:\n",
    "                self.solver.add(smt.Not(smt.Implies(ctx, t1 == t2)))\n",
    "                res = self.solver.check()\n",
    "            if res == smt.unsat:\n",
    "                return False\n",
    "            else:\n",
    "                ctx = self.terms[self.find(ctx)]\n",
    "                self.solver.add(smt.Implies(ctx, t1 == t2))\n",
    "                return True\n",
    "    def subsumes(self, ctx1 : smt.BoolRef, ctx2 : smt.BoolRef):\n",
    "        with self.solver:\n",
    "            self.solver.add(smt.Not(smt.Implies(ctx1, ctx2)))\n",
    "            return self.solver.check() == smt.unsat\n",
    "    def in_ctxs(self, ctx: smt.BoolRef) -> bool:\n",
    "        with self.solver:\n",
    "            self.solver.add(smt.Not(smt.Or(smt.Implies(self.terms[ctxid], ctx) for ctxid in self.ctxs)))\n",
    "            return self.solver.check() == smt.unsat\n",
    "    def ematch_ctx(\n",
    "        self, vs: list[smt.ExprRef], ctxpat : smt.BoolRef, pat: smt.ExprRef\n",
    "    ) -> list[list[smt.ExprRef]]:\n",
    "        res = []\n",
    "        for eids in itertools.product(*[self.roots[v.sort()] for v in vs]):\n",
    "            ts = [self.terms[eid] for eid in eids]\n",
    "            lhs = smt.substitute(pat, *zip(vs, ts))\n",
    "            ctx = smt.substitute(ctxpat, *zip(vs, ts))\n",
    "            if self.in_ctxs(ctx) and self.in_terms(lhs):\n",
    "                res.append(ts)\n",
    "        return res\n",
    "    def rebuild(self):\n",
    "        super().rebuild()\n",
    "        self.ctxs = {self._find(ctxid) for ctxid in self.ctxs}\n",
    "\n",
    "\n",
    "E = CtxEGraph()\n",
    "x,y,z = smt.Reals(\"x y z\")\n",
    "t = smt.If(x > 0, smt.Sqrt(x**2), 3 + x + 4)\n",
    "E.add_term(t)\n",
    "E.simplify_terms()\n",
    "p,q,r = smt.Bools(\"p q r\")\n",
    "\n",
    "for ctx,_,_ in E.ematch([p,y,z], smt.If(p, y, z)):\n",
    "    E.add_ctx(ctx)\n",
    "E.rebuild()\n",
    "\n",
    "for c,q in E.ematch_ctx([ctx, y], ctx, smt.Sqrt(y**2)):\n",
    "    E.ctx_union(c, smt.Sqrt(q**2), q)\n",
    "E.rebuild()\n",
    "# Ugh, extract has to be context aware.\n",
    "# I'm cheating here.\n",
    "E.extract(t)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5e8358",
   "metadata": {},
   "source": [
    "# Bits and Bobbles\n",
    "\n",
    "Next time: Lambdas. Z3 does kind of sort of support lambdas. Slotted egraphs I think can be emulated by going to an eta-maximal form. Z3 simplify alread evals lambdas. Nice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342391cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#smt.BitVec(\"a\", 64)\n",
    "#kd.prove((a * 2) / 2 ==  (a << 1) / 2)\n",
    "#kd.prove(smt.Implies(smt.And(a < 2**100, a > 0), (a * 2) / 2 ==  a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57301d4",
   "metadata": {},
   "source": [
    "## Contextual union find\n",
    "\n",
    "A persistent union find vs a colored.\n",
    "Colored mantains many and the other unions finds inherit from their parent union finds. The persistent union find lives in many worlds.\n",
    "\n",
    "In a contextual union find , the \"color\" keys themselves are union finds. You make make a union find into a key by fully canonizing/compressing it and then use the usual techniques to turn maps/dictionaries into keys. Patricia trie or sorted assoc list.\n",
    "\n",
    "This inheritance structure is interesting.\n",
    "\n",
    "\n",
    "```python\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class UF():\n",
    "    uf : list[int] = field(default_factory=list)\n",
    "    def makeset(self):\n",
    "        eid = len(self.uf)\n",
    "        self.uf.append(eid)\n",
    "        return eid\n",
    "    def find(self, x):\n",
    "        while self.uf[x] != x:\n",
    "            x = self.uf[x]\n",
    "        return x\n",
    "    def union(self, x, y):\n",
    "        x,y = self.find(x), self.find(y)\n",
    "        if x != y:\n",
    "            self.uf[x] = y\n",
    "        return y\n",
    "    def rebuild(self):\n",
    "        for i in range(len(self.uf)):\n",
    "            self.uf[i] = self.find(i)\n",
    "\n",
    "uf = UF()\n",
    "for i in range(10):\n",
    "    uf.makeset()\n",
    "uf.union(0, 1)\n",
    "uf.union(1, 2)\n",
    "uf.rebuild()\n",
    "uf\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    UF(uf=[2, 2, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "\n",
    "\n",
    "A persistent union find retains all old versions of the union find\n",
    "\n",
    "a colored / linked / refiniing / hiearchical union find has multiple refining union finds hanging around. Unions higher in the herarchy are inherited by ufs lower in the hierarchy. \n",
    "\n",
    "A contextual union find is like this with the added feature that the ufs are identified with contexts. When contexts become equivalent, the appropriate unuion finds should become equivalent. When a context is subsumed,it should inherit the equality infromation of the subsumee. \n",
    "\n",
    "Subsumption is a better mechanism than lattices for contexts. While there is a lattice, it's a weird one. Subsumption is more of a direct translation\n",
    "\n",
    "\n",
    "Equating two nodes in a colored union find makes a new node? Multiparent. Maybe you have to ping pong until convergence. I think the contracting nature of the maps means this'll work. You only have to ping pong up to common ancestor.\n",
    "Equating two color nodes goes into a meta-union find or color nodes? You need to ping pong through the entire tree, or normalize everything in the root node.\n",
    "a meta meta union find?\n",
    "Really you can assert node1 <= node2.\n",
    "\n",
    "class DiffUF():\n",
    "    ufs: list[UF]\n",
    "    self.duf\n",
    "\n",
    "class DiffUF():\n",
    "    parent | self.uf, self.duf  # either points to equivalent parent UF or actually has the data and pointer to inehritance uf.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "class DiffUF():\n",
    "    def __init__(self, uf : UF):\n",
    "        self.uf = uf\n",
    "        self.duf = {}\n",
    "    def makeset(self):\n",
    "        return self.uf.makeset()\n",
    "    def find(self, x):\n",
    "        x = self.uf.find(x)\n",
    "        while x in self.duf:\n",
    "            x = self.duf[x]\n",
    "        return x\n",
    "    def union(self, x, y):\n",
    "        x,y = self.find(x), self.find(y)\n",
    "        if x != y:\n",
    "            self.duf[x] = y\n",
    "        return y\n",
    "    def __hash__(self):\n",
    "        return hash(tuple(sorted(self.duf.items())))\n",
    "    def __le__(self, other):\n",
    "        if len(self.duf) > len(other.duf): # fast check\n",
    "            return False\n",
    "        return all(other.find(k) == other.find(v) for k,v in self.duf.items())\n",
    "    def __eq__(self, other):\n",
    "        return len(self.duf) == len(other.duf) and self <= other # ? Right?\n",
    "    def __or__(self, other): # over same base\n",
    "        \"\"\"\n",
    "        Union find join. Finest partition greater than both.\n",
    "        \"\"\"\n",
    "        assert id(self.uf) == id(other.uf)\n",
    "        new = DiffUF(self.uf)\n",
    "        new.duf = self.duf.copy() # or pick biggest one\n",
    "        for k,v in other.duf.items():\n",
    "            new.union(k,v)\n",
    "        return new\n",
    "    def __and__(self, other): # over same base\n",
    "        \"\"\"union find meet. Coarsest partition less than both.\"\"\"\n",
    "        assert id(self.uf) == id(other.uf)\n",
    "        new = DiffUF(self.uf)\n",
    "        for k,v in self.duf.items():\n",
    "            if other.find(k) == other.find(v):\n",
    "                new.union(k,v)\n",
    "        return new\n",
    "    def rebuild(self): # canon\n",
    "        old_duf = {}\n",
    "        self.duf = {}\n",
    "        self.uf.rebuild()\n",
    "        for k,v in old_duf.items():\n",
    "            self.union(k,v)\n",
    "    \n",
    "    \n",
    "```\n",
    "\n",
    "https://usr.lmf.cnrs.fr/~jcf/publis/puf-wml07.pdf  A Persistent Union-Find Data Structure\n",
    "\n",
    "Proof producing \n",
    "\n",
    "1. Tie braking\n",
    "2. Path compress or no\n",
    "3. edge storage, attributed storage\n",
    "4. Pointers, array, or dict\n",
    "5. Lazy vs eager\n",
    "\n",
    "A purely function union find using purely functional distionaries\n",
    "\n",
    "\n",
    "Union finds solve connectivity in graphs. Proof producing UF stores a spanning tree also so that it can return a path when you ask for it.\n",
    "\n",
    "\n",
    "Layered union finds are like layered theories\n",
    "`M1 |= M2 |= M3 |= M4 ...`\n",
    "\n",
    "\n",
    "A canonizer uf would want to update all the children to be updated too.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class EagerUF():\n",
    "    uf : list[int] = field(default_factory=list)\n",
    "    def makeset(self):\n",
    "        eid = len(self.uf)\n",
    "        self.uf.append(eid)\n",
    "        return eid\n",
    "    def find(self, x):\n",
    "        return self.uf[x]\n",
    "    def union(self, x, y):\n",
    "        x,y = self.find(x), self.find(y)\n",
    "        if x != y:\n",
    "            self.uf[x] = y\n",
    "            self.rebuild()\n",
    "        return y\n",
    "    def rebuild(self):\n",
    "        for i in range(len(self.uf)):\n",
    "            self.uf[i] = self.find(i)\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "class FrozenDict()\n",
    "```\n",
    "\n",
    "You don't _have_ to structurally canonicalize to implement a correct hash.\n",
    "But you kind of might as well\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "@dataclass(frozen=True)\n",
    "class CanonUF():\n",
    "    uf : tuple[int,...]\n",
    "    @classmethod\n",
    "    def create(cls):\n",
    "        return CanonUF(())\n",
    "    def makeset(self):\n",
    "        eid = len(self.uf)\n",
    "        self.uf.append(eid)\n",
    "        return CanonUF(self.uf + (eid,))\n",
    "    def find(self, x):\n",
    "        return self.uf[x]\n",
    "    def union(self, x, y):\n",
    "        x,y = self.find(x), self.find(y)\n",
    "        if x != y:\n",
    "            self.uf[x] = y\n",
    "            self.rebuild() # rebuild immeidately\n",
    "        return y\n",
    "    def __hash__(self):\n",
    "        return hash(self.uf)\n",
    "    def __eq__(self, other):\n",
    "    def rebuild(self):\n",
    "        for i in range(len(self.uf)):\n",
    "            self.uf[i] = self.find(i)\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "class ContextUF():\n",
    "    base : UF\n",
    "    ctxs : dict[CanonUF, DiffUF] #  ctx |- res \n",
    "    def __init__(self):\n",
    "        self.base = UF()\n",
    "        self.ctxs = {}\n",
    "    def rebuild(self):\n",
    "        newctx = {}\n",
    "        for ctx, uf in self.ctxs.items():\n",
    "            ctx1 = ctx.rebuild()\n",
    "            for ctx1, uf1 in self.ctxs.items():\n",
    "                if ctx <= ctx1:\n",
    "                    uf1.merge(uf)\n",
    "            newctx[ctx.rebuild()] = uf.rebuild()\n",
    "        self.base.rebuild()\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "### Persistent\n",
    "https://github.com/MagicStack/immutables\n",
    "https://github.com/tobgu/pyrsistent\n",
    "https://discuss.python.org/t/pep-603-adding-a-frozenmap-type-to-collections/2318/219\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "! python3 -m pip install immutables\n",
    "```\n",
    "\n",
    "    Collecting immutables\n",
    "      Downloading immutables-0.21-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
    "    Downloading immutables-0.21-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (104 kB)\n",
    "    Installing collected packages: immutables\n",
    "    Successfully installed immutables-0.21\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "```\n",
    "\n",
    "### Bits and Bobbles\n",
    "\n",
    "I called it base. Are fibers leaking into my thinking?\n",
    " \n",
    "I have meet and join of uf. A heyting algerba if I can define an A => B? Probably the finest partition that when merged with A gives B or is less than B? C /\\ A  <= B\n",
    "\n",
    "def diff(self, other):\n",
    "\n",
    "![](https://en.wikipedia.org/wiki/File:Set_partitions_4;_Hasse;_circles.svg) partition refinement https://en.wikipedia.org/wiki/Partition_of_a_set\n",
    "\n",
    "### old \n",
    "```python\n",
    "\n",
    "```\n",
    "\n",
    "Simple union find\n",
    "\n",
    "compressing\n",
    "\n",
    "colored union finds - use min to ping pong. label the union find. DAG hierarchy is fine.\n",
    "\n",
    "union finds as converging functions\n",
    "\n",
    "proof pdoucting union find\n",
    "\n",
    "\n",
    "using dictionary vs using ids\n",
    "vs using pointers\n",
    "\n",
    "The z3 egraph and doubly linked lists. If we want to retain _down_ pointers it is abboying because there mightb e multiple children to one parent. But you can insert yourself into a doubly linked list via the dasncing link technique.\n",
    "Hmm. Maybe this is why z3 does it this way. For fast backtracking https://z3prover.github.io/papers/z3internals.html#sec-equality-and-uninterpreted-functions\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "from dataclasses import dataclass\n",
    "class UF():\n",
    "    uf : list[int]\n",
    "    def find(self, x):\n",
    "        while x != self.uf[x]:\n",
    "            x = self.uf[x]\n",
    "        return self.uf[x]\n",
    "    def makeset(self):\n",
    "        self.uf.append(len(self.uf))\n",
    "        return len(self.uf) - 1\n",
    "    def union(self, x, y):\n",
    "        self.uf[self.find(x)] = self.find(y)\n",
    "        return self.find(y)\n",
    "\n",
    "uf = UF()\n",
    "a, b, c = uf.makeset()\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "    ---------------------------------------------------------------------------\n",
    "\n",
    "    AttributeError                            Traceback (most recent call last)\n",
    "\n",
    "    Cell In[1], line 16\n",
    "         13         return self.find(y)\n",
    "         15 uf = UF()\n",
    "    ---> 16 uf.ma\n",
    "\n",
    "\n",
    "    AttributeError: 'UF' object has no attribute 'ma'\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class Cell():\n",
    "    name: str\n",
    "    id: int\n",
    "    parent: 'Cell'\n",
    "    def __init__(self, name=\"_\"):\n",
    "        self.parent = self\n",
    "        self.id = id(self)\n",
    "        self.name = name\n",
    "    def find(self):\n",
    "        x = self\n",
    "        while x.parent is not x:\n",
    "            x = x.parent\n",
    "        return x\n",
    "    def union(self,y):\n",
    "        self.find().parent = y.find()\n",
    "        return y.find()\n",
    "    \n",
    "x = Cell(\"x\")\n",
    "y = Cell(\"y\")\n",
    "z = Cell(\"z\")\n",
    "print(x.parent)\n",
    "x.union(y)\n",
    "y.union(z)\n",
    "print(x.find() == z.find())\n",
    "print(x)\n",
    "print(z)\n",
    "```\n",
    "\n",
    "    Cell(name='x', id=136449433498864, parent=...)\n",
    "    True\n",
    "    Cell(name='x', id=136449433498864, parent=Cell(name='y', id=136449433498432, parent=Cell(name='z', id=136449433492432, parent=...)))\n",
    "    Cell(name='z', id=136449433492432, parent=...)\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "reasons = []\n",
    "trace = []\n",
    "def union_reason(x, y, reason):\n",
    "    reasons[find(x)] = (x, y, reason)\n",
    "    trace.append((x, y, reason)) # this is sufficient. we don't need to store find(x) and find(y)\n",
    "    uf[find(x)] = find(y)\n",
    "    return find(y)\n",
    "\n",
    "def explain(x,y):\n",
    "    \n",
    "```\n",
    "\n",
    "Visualizing as a graph.\n",
    "The union find is part of kruskal's algorithm\n",
    "https://en.wikipedia.org/wiki/Kruskal%27s_algorithm\n",
    "\n",
    "So for example if you had a bunch of equalities and you know how painful each one was to get, you could devise a minimum spanning tree for that.\n",
    "\n",
    "Term rewriting as a graph.\n",
    "\n",
    "Secret congruence edges\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "import networkx as nx\n",
    "\n",
    "# random graph with multiple components\n",
    "G = nx.Graph()\n",
    "#G.add_nodes_from(range(10))\n",
    "\n",
    "\n",
    "\n",
    "# color the edges in the union find\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "# vectorized normalization.\n",
    "# For egraph purposes, not being fully normalized isn't really a problem.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "uf = np.arange(10)\n",
    "uf[8] = 0\n",
    "uf[0] = 4\n",
    "\n",
    "def normstep(uf):\n",
    "    return uf[uf] \n",
    "\n",
    "normstep(uf)\n",
    "\n",
    "def step2(uf):\n",
    "    return uf[uf[uf]]\n",
    "step2(uf)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    array([4, 1, 2, 3, 4, 5, 6, 7, 4, 9])\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
