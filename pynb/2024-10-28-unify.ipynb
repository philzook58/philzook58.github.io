{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Don't Implement Unification by Recursion\n",
    "date: 2024-10-28\n",
    "---\n",
    "\n",
    "[Unification](https://en.wikipedia.org/wiki/Unification_(computer_science)) is formal methods speak for solving equations.\n",
    "\n",
    "The most common form of unification discussed is first order syntactic unification. When it succeeds, it solves a pile of equations no matter what the actual functions represent.\n",
    "\n",
    "`foo(bar(?X)) = foo(?Y)` has a solution `?Y = bar(?X)`. Or `cos(sin(?X) = cos(?Y)` has a solution `?Y = sin(?X)`. From the perspective of first order unification, it doesn't matter what `cos` and `sin` mean. \n",
    "\n",
    "Actually implementing unification, similar to most other algorithms that manipulate variables, is kind of the bane of my existence. I avoid it at extreme cost.\n",
    "\n",
    "It is somewhat surprising that unification is cleaner and easier to implement in an loopy imperative mutational style than in a recursive functional pure style. Typically theorem proving / mathematical algorithms are much cleaner in the second style in my subjective opinion. Unification has too much spooky action at a distance, a threaded state, and can usefully use access to the stack in the form a todo queue to canonize it or reorder it.\n",
    "\n",
    "A recursion form can be convenient if you need to rebuild a term after you're done. In the manual todo list form, you'll need to store a zipper of some kind to replicate that. Unification typically only returns a substitution and not the original inputs terms specialized to the substitution (although this would be useful for critical pairs, narrowing etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern Matching\n",
    "\n",
    "Unification can be seen as two sided pattern matching. Pattern matching (like python's new match-case construct) takes in some tree and allows you to match it against patterns. Patterns maybe contain variables, and when the pattern matches, that branch of the pattern has the variables bound. Unification allows you to match patterns against patterns. One low level implementation, the variables are refcells. Unification works via pointer manipulation, pointing the refcell to a piece of a tree or another refcell.\n",
    "\n",
    "Pattern matching is much easier to implement. Let's take a look to make a point about recursive vs iterative implementations.\n",
    "\n",
    "Like many algorithms, there is a recursive and iterative version. The iterative version more or less reifies the call stack of the recursive version into a normal data structure, keeping around a queue of thins to do.\n",
    "\n",
    "You can also choose whether to manipulate the substitution you're building purely functionally or mutationally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to work over the z3py ast, because it's useful for knuckledragger and it avoids defining some arbitrary ast.\n",
    "from z3 import *\n",
    "def pmatch(pat, t):\n",
    "    subst = {}\n",
    "    def worker(pat, t):\n",
    "        if is_var(pat):\n",
    "            if pat in subst:\n",
    "                return subst[pat].eq(t)\n",
    "            else:\n",
    "                subst[pat] = t\n",
    "                return True\n",
    "        if is_app(pat):\n",
    "            if is_app(t) and pat.decl() == t.decl():\n",
    "                return all(worker(pat.arg(i), t.arg(i)) for i in range(pat.num_args()))\n",
    "            return False\n",
    "    if worker(pat, t):\n",
    "        return subst\n",
    "\n",
    "# I'm sort of abusing z3's Var here. It's meant for de bruijn vars\n",
    "x,y,z = Var(0,IntSort()), Var(1,IntSort()), Var(2,IntSort())\n",
    "assert pmatch(IntVal(3), IntVal(3)) == {}\n",
    "assert pmatch(IntVal(3), IntVal(4)) == None\n",
    "assert pmatch(x, IntVal(3)) == {x : IntVal(3)}\n",
    "assert pmatch(x + x, IntVal(3) + IntVal(4)) == None\n",
    "assert pmatch(x + x, IntVal(3) + IntVal(3)) == {x : IntVal(3)}\n",
    "assert pmatch(x + y, IntVal(3) + IntVal(4)) == {x : IntVal(3), y : IntVal(4)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can also write this in a loopy todo list form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from z3 import *\n",
    "def pmatch_loop(pat, t):\n",
    "    subst = {}\n",
    "    todo = [(pat, t)]\n",
    "    while todo:\n",
    "        pat, t = todo.pop()\n",
    "        if is_var(pat):\n",
    "            if pat in subst:\n",
    "                if not subst[pat].eq(t):\n",
    "                    return None\n",
    "            else:\n",
    "                subst[pat] = t\n",
    "        elif is_app(pat):\n",
    "            if not is_app(t) or pat.decl() != t.decl():\n",
    "                return None\n",
    "            todo.extend(zip(pat.children(), t.children())) \n",
    "    return subst\n",
    "\n",
    "assert pmatch_loop(IntVal(3), IntVal(3)) == {}\n",
    "assert pmatch_loop(IntVal(3), IntVal(4)) == None\n",
    "assert pmatch_loop(x, IntVal(3)) == {x : IntVal(3)}\n",
    "assert pmatch_loop(x + x, IntVal(3) + IntVal(4)) == None\n",
    "assert pmatch_loop(x + x, IntVal(3) + IntVal(3)) == {x : IntVal(3)}\n",
    "assert pmatch_loop(x + y, IntVal(3) + IntVal(4)) == {x : IntVal(3), y : IntVal(4)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Rules to the Loop\n",
    "Unification can be presented as an inference system. \n",
    "\n",
    "Inference rules as compared to pseudocode are nice sometimes. They make things feel mathier. They can make it clear that there is choice available on how to proceed. If you know prolog, rules are cool in that you can write them down as prolog clauses.\n",
    "\n",
    "The huge downsides of inference rules is that they are a barrier to entry, and the leap from rules to any sort of implementable algorithm can be very non trivial.\n",
    "\n",
    "If I write unification with a LIFO queue, FIFO queue or some other ordering, it doesn't matter much. And this can matter in more complex unification domains  (E-unification and higher order unification) where you can get locally stumped on how to proceed, so it can be fruitful to pick off of you todo list the easiest to solve equation.\n",
    "\n",
    "![](/assets/traat/unify_rules.png)\n",
    "\n",
    "\n",
    "`delete` remove a trivial equation, `decompose` matches heads and then zips together their children, `orient` puts variables in the lhs, `eliminate` takes an equation in solved for and substitues the solution everywhere.\n",
    "\n",
    "A `todo` queue is basically our multiset `S` and we choose a particular order to process the equations.\n",
    "We end up with something like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def occurs(x, t):\n",
    "    if is_var(t):\n",
    "        return x.eq(t)\n",
    "    if is_app(t):\n",
    "        return any(occurs(x, t.arg(i)) for i in range(t.num_args()))\n",
    "    return False\n",
    "\n",
    "def unify(p1,p2):\n",
    "    subst = {}\n",
    "    todo = [(p1,p2)]\n",
    "    while todo:\n",
    "        p1,p2 = todo.pop() # we could pop _any_ of the todos, not just the top.\n",
    "        if p1.eq(p2): # delete\n",
    "            continue\n",
    "        elif is_var(p1): # elim\n",
    "            if occurs(p1, p2):\n",
    "                return None\n",
    "            todo = [(substitute(t1,(p1,p2)), substitute(t2,(p1,p2))) for (t1,t2) in todo]\n",
    "            subst = {k : substitute(v, (p1,p2)) for k,v in subst.items()}\n",
    "            subst[p1] = p2\n",
    "        elif is_var(p2): # orient\n",
    "            todo.append((p2,p1))\n",
    "        elif is_app(p1): # decompose\n",
    "            if not is_app(p2) or p1.decl() != p2.decl():\n",
    "                return None\n",
    "            todo.extend(zip(p1.children(), p2.children())) \n",
    "        else:\n",
    "            raise Exception(\"unexpected case\", p1, p2)\n",
    "    return subst\n",
    "\n",
    "x,y,z = Var(0,IntSort()), Var(1,IntSort()), Var(2,IntSort())\n",
    "assert unify(IntVal(3), IntVal(3)) == {}\n",
    "assert unify(IntVal(3), IntVal(4)) == None\n",
    "assert unify(x, IntVal(3)) == {x : IntVal(3)}\n",
    "assert unify(x, y) == {x : y}\n",
    "assert unify(x + x, y + y) == {x : y}\n",
    "assert unify(x + x, y + z) == {x : y, z : y}\n",
    "assert unify(x + y, y + z) == {x : z, y : z}\n",
    "assert unify(y + z, x + y) == {y : x, z : x}\n",
    "# non terminating if no occurs check\n",
    "assert unify((x + x) + x, x + (x + x)) == None\n",
    "assert unify(1 + x, x) == None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eager vs Lazy Substitution\n",
    "\n",
    "You can wait to remove the solved for variables from your `todo` expressions. There is a lot of wasteful passes doing nothing in the eager method where I immediately eliminate `x` everywhere as soon as it is solved.\n",
    "\n",
    "The lazy method also becomes basically required if you write in a recursive functional style since you do not have access to the `todo` queue that is on your call stack. \n",
    "\n",
    "The lazy method is a bit more confusing IMO.\n",
    "\n",
    "There is also a choice about whether to canonize your substitutions as you use them. The is the analog of path compression in a union find. You can also choose to keep your substitutions in a triangular form where you substitution mapping is never normalized, but then you need to apply it recursively until a fixed point. This style is made popular by [minikanren](http://minikanren.org/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_lazy(p1,p2):\n",
    "    subst = {}\n",
    "    todo = [(p1,p2)]\n",
    "    def lookup_var(v):\n",
    "        while v in subst:\n",
    "            v = subst[v]\n",
    "        return v\n",
    "    def lookup_term(t):\n",
    "        if is_var(t):\n",
    "            t = lookup_var(t)\n",
    "        if is_var(t):\n",
    "            return t\n",
    "        if is_app(t):\n",
    "            return t.decl()(*[lookup_term(c) for c in t.children()])\n",
    "    while todo:\n",
    "        p1,p2 = todo.pop()\n",
    "        p1,p2 = lookup_term(p1), lookup_term(p2)\n",
    "        if p1.eq(p2):\n",
    "            continue\n",
    "        elif is_var(p1): # elim\n",
    "            if occurs(p1, p2):\n",
    "                return None\n",
    "            subst[p1] = p2\n",
    "        elif is_var(p2): # orient\n",
    "            todo.append((p2,p1))\n",
    "        elif is_app(p1): # decompose\n",
    "            if not is_app(p2) or p1.decl() != p2.decl():\n",
    "                return None\n",
    "            todo.extend(zip(p1.children(), p2.children())) \n",
    "        else:\n",
    "            raise Exception(\"unexpected case\", p1, p2)\n",
    "    return subst\n",
    "\n",
    "x,y,z = Var(0,IntSort()), Var(1,IntSort()), Var(2,IntSort())\n",
    "assert unify_lazy(IntVal(3), IntVal(3)) == {}\n",
    "assert unify_lazy(IntVal(3), IntVal(4)) == None\n",
    "assert unify_lazy(x, IntVal(3)) == {x : IntVal(3)}\n",
    "assert unify_lazy(x, y) == {x : y}\n",
    "assert unify_lazy(x + x, y + y) == {x : y}\n",
    "assert unify_lazy(x + x, y + z) == {x : z, z : y}\n",
    "assert unify_lazy(x + y, y + z) == {x : z, y : z}\n",
    "assert unify_lazy(y + z, x + y) == {z : y, y : x}\n",
    "assert unify_lazy(y + z, x - y) == None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Form\n",
    "\n",
    "Finally here is the recursive form. All the looking up and the laziness is what makes it confusing to me.\n",
    "This is basically the lazy iterative form turned back into recursion.\n",
    "\n",
    "Note that we have kind of removed the ability to inspect which equation in our todo to process next. We are forced to pick some order and then maybe retrieve that ordering by some wacky continuation thing or returning frozen constraints or something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_rec1(p1,p2, subst):\n",
    "    def lookup_var(v):\n",
    "        while v in subst:\n",
    "            v = subst[v]\n",
    "        return v\n",
    "    def lookup_term(t):\n",
    "        if is_var(t):\n",
    "            t = lookup_var(t)\n",
    "        if is_var(t):\n",
    "            return t\n",
    "        if is_app(t):\n",
    "            return t.decl()(*[lookup_term(c) for c in t.children()])\n",
    "    p1,p2 = lookup_term(p1), lookup_term(p2)\n",
    "    if p1.eq(p2):\n",
    "        return subst\n",
    "    elif is_var(p1): # elim\n",
    "        if occurs(p1, p2):\n",
    "            return None\n",
    "        return {**subst, p1 : p2}\n",
    "    elif is_var(p2): # orient\n",
    "        return unify_rec1(p2,p1, subst)\n",
    "    elif is_app(p1): # decompose\n",
    "        if not is_app(p2) or p1.decl() != p2.decl():\n",
    "            return None\n",
    "        for c in zip(p1.children(), p2.children()):\n",
    "            subst = unify_rec1(c[0], c[1], subst)\n",
    "            if subst is None:\n",
    "                return None\n",
    "    else:\n",
    "        raise Exception(\"unexpected case\", p1, p2)\n",
    "    return subst\n",
    "def unify_rec(p1,p2):\n",
    "    return unify_rec1(p1,p2,{})\n",
    "\n",
    "x,y,z = Var(0,IntSort()), Var(1,IntSort()), Var(2,IntSort())\n",
    "assert unify_rec(IntVal(3), IntVal(3)) == {}\n",
    "assert unify_rec(IntVal(3), IntVal(4)) == None\n",
    "assert unify_rec(x, IntVal(3)) == {x : IntVal(3)}\n",
    "assert unify_rec(x, y) == {x : y}\n",
    "assert unify_rec(x + x, y + y) == {x : y}\n",
    "assert unify_rec(x + x, y + z) == {x : y, y : z}\n",
    "assert unify_rec(x + y, y + z) == {x : y, y : z}\n",
    "assert unify_rec(y + z, x + y) == {y : x, z : x}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bits and Bobbles\n",
    "Some unification implementations to compare. I've copied some of the relevant bits out far below\n",
    "\n",
    "- minikanren , microkanren, faster-minikanren\n",
    "- harrison https://www.cl.cam.ac.uk/~jrh13/atp/index.html\n",
    "- traat https://www21.in.tum.de/~nipkow/TRaAT/ but it also has pascal\n",
    "- pyres https://github.com/eprover/PyRes/blob/master/unification.py\n",
    "- prover9 - https://github.com/ai4reason/Prover9/blob/cdca95a51d3c3459b8fd2ebbb5ac1504be2172e3/ladr/unify.c#L345\n",
    "- unification fd https://hackage.haskell.org/package/unification-fd\n",
    "- cody's\n",
    "- ocaml-alg https://github.com/smimram/ocaml-alg/blob/3905b52a90bc6ac7c91054e1f961b8685b77a30a/src/term.ml#L375\n",
    "- Graham's \n",
    "- eprover https://github.com/eprover/eprover/blob/ab3ea0835b13553d3872b858e93739c2b1aeb0e6/TERMS/cte_match_mgu_1-1.c#L463\n",
    "- vampire https://github.com/vprover/vampire/blob/6b4efd08c39a0fdc5b28f266dc6b639e807903d7/Kernel/RobSubstitution.cpp#L266\n",
    "- https://eli.thegreenplace.net/2018/unification/\n",
    "\n",
    "\n",
    "# Union Find\n",
    "\n",
    "The pure var to var part of `subst` is being used as a union find\n",
    "\n",
    "THis is  the find operation\n",
    "\n",
    "```\n",
    "    def lookup_var(v):\n",
    "        while v in subst:\n",
    "            v = subst[v]\n",
    "        return v\n",
    "```\n",
    "\n",
    "Union finds can be implemented in different styles. An arena style or a refcell/pointer style.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Occurs Check\n",
    "\n",
    "https://en.wikipedia.org/wiki/Occurs_check\n",
    "\n",
    "I'm not sure where the idea that the occurs check is the \"correct\" thing to do and that we only avoid it as a near sighted optimization.\n",
    "\n",
    "It is an interesting perspective and it is true for things like lists.\n",
    "\n",
    "There is a related thing to the occurs check, which is correct scoping of forall and exists variables. Curiously, you can make the occurs check deal with this by making all the existential variables in scope parameters to a fresh forall variable in a goal. This is disccussed in the addendum here https://www.philipzucker.com/harrop-checkpoint/ and the Otten provers https://jens-otten.de/tutorial_cade19/ . The occurs check will then detect an ill scoping. https://dl.acm.org/doi/pdf/10.1145/66068.66075 \n",
    "\n",
    "But for many other function symbols in the theorem proving context, it is perfectly natural to have a loopy equation. `pow(?X, 2) = ?X` has the solution of `1`. It is not an inconsistent thing to ask for. Nor is it an inconsistent universal thing to assert. It is saying multiplication is absorptive, like in boolean algebra.\n",
    "\n",
    "Also, if we are \"scientists\" about it, we can take observation it is simpler to just not write the occurs check as evidence that unification is kind of naturally coinductive / loopy / observational / non-well-founded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Egraph / Flat Style\n",
    "An interesting style for doing unification is to maintain two mappings.\n",
    "\n",
    "`var -> option obs` and a `var -> var` union find\n",
    "\n",
    "I discussed this more here. https://www.philipzucker.com/coegraph/\n",
    "\n",
    "You can process the equations quite lazily. The thing is very uniform. Also you can do bisimulation reduction and \"hashcons\" equivalent rational terms. The observation table is exactly what you need to do the automata minimization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other\n",
    "\n",
    "\n",
    "\n",
    "## Rules\n",
    "There are a couple different ways to interpret inference rules into code.\n",
    "\n",
    "We may have one function that has ~one case per inference rule\n",
    "Or we may write a function per inference rule\n",
    "The inference rules may recuyrsively call other inference rules.\n",
    "\n",
    "We may choose which pieces are inputs and outputs of the rule\n",
    "\n",
    "1. Bottom comes in, top comes out\n",
    "2. top comes in, bottoms come out\n",
    "3. some combo of top and bottom come out\n",
    "\n",
    "```python\n",
    "def delete(S):\n",
    "    t,t1 = S.pop()\n",
    "    assert t.eq(t1)\n",
    "    return S\n",
    "\n",
    "def decompose(S):\n",
    "    t,t1 = S.pop()\n",
    "    assert is_app(t) and is_app(t1) and t.decl() == t1.decl()\n",
    "    S.extend(zip(t.children(), t1.children()))\n",
    "    return S\n",
    "\n",
    "def orient(S):\n",
    "    t,x = S.pop()\n",
    "    assert is_var(x) and not is_var(t)\n",
    "    S.append((x, t))\n",
    "\n",
    "def elim(S):\n",
    "    x,t = S.pop()\n",
    "    S = [    ]\n",
    "    return S\n",
    "\n",
    "# S is a multiset\n",
    "def permute(S, perm):\n",
    "    return [S[perm[i]] for i in range(len(S))]\n",
    "```\n",
    "## other\n",
    "\n",
    "I am distrubed by the number of times I've already written posts about unification, and yet don't feel that much wiser\n",
    "\n",
    "I have no memory of this one https://www.philipzucker.com/unification-in-julia/\n",
    "\n",
    "https://www.philipzucker.com/resolution1/ This was pretty recent. I wrote the same style unification here that I learned from PyRes.\n",
    "\n",
    "In unification, we talk about \"unification variables\". \"unification variables\"  can really refer to things that are very very different.\n",
    "\n",
    "In theorem proving, there is both forward inference, deriving new theorems from axioms, or backward inference, breaking down goals into easier goals.\n",
    "\n",
    "Goals and axioms/theorems are very different. Goals are things we want to show are true. Axioms are things we assert true. Unification variables in goals are implicitly existentially quantifier. Unification variables in axioms are implicitly universally quantified.\n",
    "\n",
    "In prolog, the variables you enter at the prompt are existentially quantified. The variables in the rules and the answers are universally quantified. Running the prolog program converts these existentially quantified questions into universally quantified answers.\n",
    "\n",
    "\n",
    "## variable freshening and context.\n",
    "- Sometimes you want to unify two things where the variables are disjoint even if variable names are shared. This is for example the case when unifying two literals from different clauses, or a prolog goal against a prolog rule head. Just because I wrote `foo(Y,X) :- bar(X).` under the query `?- foo(X, Y)` should not imply `X = Y`. Implicitly there is a binding at the head of the rule `forall x y, foo(y,x) :- bar(x).`. \n",
    "- Sometimes you want to unify two things where the variables can overlap. This is what happens when you apply the factoring rule inside a single clause.\n",
    "\n",
    "You can freshen all the variables to turn a routine for the second case into the first. Freshening may be a reason to inlcude an integer id in your variable datatype. Still this is pretty clunky and ugly.\n",
    "\n",
    "Another option is to pass in two extra ctx parameters to unify and every variable is understood with respect to them. Then the second case comes from the first if the two ctx are aliased.\n",
    "\n",
    "\n",
    "Python is a very imperative language. It doesn't have good easy access immutable data structures. Basically making a whole new copy of lists or dicts is the only good option. This also informs what is the easiest style to write.\n",
    "\n",
    "Substitution mapping considered as rewrite rules.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Unification_(computer_science)\n",
    "\n",
    "\n",
    "\n",
    "http://www.cs.man.ac.uk/~hoderk/ubench/unification_full.pdf Comparing Unification Algorithms in First-Order\n",
    "Theorem Proving\n",
    "\n",
    "https://users.soe.ucsc.edu/~lkuper/papers/walk.pdf Efficient representations for triangular substitutions: A comparison in miniKanren\n",
    "\n",
    "\n",
    "https://www.proquest.com/openview/f8298f16044b130532ceca70ed4d60c2/1?pq-origsite=gscholar&cbl=2026366&diss=y Automated Theorem Proving in Higher-Order Logic - Bhayat thesis\n",
    "\n",
    "do on z3\n",
    "\n",
    "https://www.philipzucker.com/resolution1/\n",
    "\n",
    "\n",
    "E-unificationun\n",
    "https://web.archive.org/web/20200211213303id_/https://publikationen.sulb.uni-saarland.de/bitstream/20.500.11880/25047/1/RR_92_01.pdf\n",
    "\n",
    "HO-unification as a alngague. When you have full HO unfication, do you need prolog search anymore? You already have so much nontdeterminis\n",
    "\n",
    "\n",
    "uniification  as observation\n",
    "unification as fixed point - When written as an inference system this espcailly makes sense.\n",
    "\n",
    "\n",
    "Lazy vs eager substitution in unification\n",
    "\n",
    "Tringular = Lazy\n",
    "\n",
    "Eager vs lazy normalization of union find.\n",
    "\n",
    "Recursive vs loop.\n",
    "We have access to the \"todo\" equations in loop form in the form of some kind of stack.\n",
    "\n",
    "\n",
    "Inference rule form.\n",
    "I kind of feel like completion you're moving from E to S, building a valid substitution. E;S. \n",
    "Inference rule form is closer to loop form. You have access to all of E.\n",
    "Typical loop form just pops, but you could use a loop to find the next one to deal with.\n",
    "\n",
    "\n",
    "\n",
    "Logical Form.\n",
    "Exists([x,y,z], T) == Exist([x,y,z], T)\n",
    "Exists([], T1 = T2)\n",
    "ForAll([], ) # rigid.\n",
    "\n",
    "occursw check vs scope escape. That prolog trick\n",
    "Just having Exists and ForAll might give you a variation of miller. Ignore lambda?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclass import dataclass\n",
    "@dataclass\n",
    "class Var():\n",
    "    x : ExprRef\n",
    "    ctx : Context\n",
    "    def collect_a(self):\n",
    "        res = []\n",
    "        x = self \n",
    "        while x != None:\n",
    "            if isinstance(x, AVar):\n",
    "                res.append(x)\n",
    "            x = x.ctx\n",
    "        return res\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "class EVar(Var):\n",
    "    x : ExprRef\n",
    "    ctx : Context\n",
    "class AVar(Var):\n",
    "\n",
    "\n",
    "def unify(avars, edecls, p1,p2):\n",
    "    edecls = []\n",
    "\n",
    "    def freshe():\n",
    "        edecl = Function(\"e_\", [x.sort() for x in avars])\n",
    "        te = edecl(*avars)\n",
    "        substitute_vars(t, te)\n",
    "\n",
    "\n",
    "def unify(p1,p2 vctx):\n",
    "    subst = {}\n",
    "    ectx = {}\n",
    "    todo = [([], p1,p2)]\n",
    "    while todo:\n",
    "        ctx,p1,p2 = todo.pop()\n",
    "        if p1.eq(p2):\n",
    "            continue\n",
    "        if is_quantifier(p1):\n",
    "            body, vs = open_binder(p1)\n",
    "            if p1.is_exists():\n",
    "                for v in vs:\n",
    "                    ectx[v] = ctx\n",
    "                todo.append((ctx, body, p2))\n",
    "            elif p1.is_forall():\n",
    "                todo.append((ctx + vs, body, p2))\n",
    "            elif p1.is_lambda():\n",
    "                todo.append((ctx + vs, body, p2))\n",
    "        elif is_var(p1):\n",
    "            todo = [(substitute(t1,(p1,p2)), substitute(t2,(p1,p2))) for (t1,t2) in todo]\n",
    "            subst = {k : substitute(v, (p1,p2)) for k,v in subst.items()}\n",
    "            subst[p1] = p2\n",
    "        elif is_var(p2):\n",
    "            todo.append((ctx,p2,p1))\n",
    "        elif is_app(p1):\n",
    "            if not is_app(p2) or p1.decl() != p2.decl():\n",
    "                return None\n",
    "            todo.extend(zip(p1.children(), p2.children())) \n",
    "        else:\n",
    "            raise Exception(\"unexpected case\", p1, p2)\n",
    "    return subst\n",
    "\n",
    "def unify(p1,p2, vctx):\n",
    "    subst = {}\n",
    "    todo = [(p1,p2)]\n",
    "    while todo:\n",
    "        p1,p2 = todo.pop()\n",
    "        if p1.eq(p2):\n",
    "            continue\n",
    "        elif is_var(p1):\n",
    "            if # do \"occurs\"\n",
    "                in vctx[p1] # narrow the contx  of any var in rhs.\n",
    "            todo = [(substitute(t1,(p1,p2)), substitute(t\n",
    "                                                        \n",
    "def unify_miller(p1,p2, vs):\n",
    "    if p1.decl() in vs: # is_var\n",
    "        \n",
    "        #substitute(   p1.children(),  \n",
    "        # abstract out children\n",
    "        subst[p1.decl()] = Lambda(freshes, substitute(p1, zip(p1.children(), freshes)))\n",
    "        t = Lambda(freshes, substitute(p1, zip(p1.children(), freshes)))\n",
    "        check_no_escape(t)\n",
    "        todo = [  , substitute(p1)]\n",
    "        subst[p1.decl()] = t\n",
    "    todo = []\n",
    "    noescape = []\n",
    "    if is_quantifier(p1)\n",
    "        if is_quantifier(p2) and p1.num_vars() == p2.num_vars() and # sorts:\n",
    "            body, vs = open_binder(p1)\n",
    "            noescape += vs\n",
    "            body2 = instantiate(p2, vs)\n",
    "            todo.append((body,body2))\n",
    "\n",
    "\n",
    "Exisst x, p(x) = exists y, p(y) # I guess we could allow this? Kind of odd\n",
    "ex(lam x, p(x))\n",
    "all(lam x, p(x)) # all is basically treated as a lambda.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-------------------------\n",
    "{ex x  f = ex y g} ==> \n",
    "\n",
    "-----------------\n",
    "{all x, f = all x, g} ==> \n",
    "\n",
    "---------------\n",
    "{lam x. f = lam x. g} ==>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z3 Unify\n",
    "\n",
    "\n",
    "Unification is useful for question asking (exists)\n",
    "and for inferring new facts\n",
    "\n",
    "questions ~ goals ~ queries ~ BoolRef ~ typed at prolog repl ~ prolog call\n",
    "answers ~ solutions ~ Proof ~ returned to prolog repl ~ prolog return\n",
    "\n",
    "questions can be forall or exists\n",
    "answers can also be forall or exists\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_generalized(t):\n",
    "    \"\"\"\n",
    "    Miller nadathur book\n",
    "    alternatig quatifiers then conjuction of equations\n",
    "    Q Q Q Q Q (t1 =t2 /\\ t3 = t4 /\\ t5 = t6 /\\ t7 = t8 /\\ t9 = t10)\n",
    "\n",
    "    \"\"\"\n",
    "    vars = []\n",
    "    while is_quantifier(t)\n",
    "        vars.append(t.vars)\n",
    "        t = body()\n",
    "    todo = [t]\n",
    "    eqs = []\n",
    "    while todo:\n",
    "        t = todo.pop()\n",
    "        if is_eq(t):\n",
    "            eqs.append(t)\n",
    "        elif is_conj(t):\n",
    "            todo.extend(t.children())\n",
    "        else:\n",
    "            raise ValueError(\"not a conjunction of equations\")\n",
    "    subst = {}\n",
    "    for eq in eqs:\n",
    "        if eq.lhs in subst:\n",
    "            if subst[eq.lhs] != eq.rhs:\n",
    "                raise ValueError(\"inconsistent equations\")\n",
    "            # scope check\n",
    "        else:\n",
    "            subst[eq.lhs] = eq.rhs\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_prove(t : z3.BoolRef):\n",
    "    \"\"\"\n",
    "    request an exists formula\n",
    "    return a forall _Proof_.\n",
    "    \"\"\"\n",
    "    if is_quantifier(t):\n",
    "        assert t.is_exists():\n",
    "    \n",
    "\n",
    "def unify_resolve(q : kd.Proof, t : kd.Proof):\n",
    "    # Take two forall proofs q and t, and return a proof of the resolution of q and t\n",
    "    # forall forall -> forall\n",
    "def unify_apply(t : BoolRef, t : kd.Proof):\n",
    "    # exist goal + forall proof -> (exist goal', Proof of exists goal' -> exists goal)\n",
    "    # can just use matching?\n",
    "    # forall goal + forall proof -> (forall goal', Proof of forall (goal' -> goal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from z3 import *\n",
    "\n",
    "def subterms(t):\n",
    "    ts = set(t)\n",
    "    for c in t.children():\n",
    "        ts |= subterms(c)\n",
    "    return ts\n",
    "\n",
    "def unify(t1 : ExprRef, t2 : ExprRef, subst, vs):\n",
    "    if t1.eq(t2):\n",
    "        return\n",
    "    if t2 in vs:\n",
    "        t2, t1 = t1, t2\n",
    "    if t1 in vs:\n",
    "        if t1 in subst:\n",
    "            unify(subst[t1], t2, subst, vs)\n",
    "        else:\n",
    "            if t1 in subterms(t2): # occurs\n",
    "                raise Exception(\"Unification failed\")\n",
    "            subst = {i : substitute(k, t1, t2) for i,k in subst.items()} # eager subst. Oh but I can't normalize all my terms too\n",
    "            subst[t1] = t2\n",
    "    else:\n",
    "        if t1.decl() == t2.decl():\n",
    "            for  c1,c2 in zip(t1.children(), t2.children()):\n",
    "                unify(c1, c2, subst, vs)\n",
    "        else:\n",
    "            raise Exception(\"Unification failed\")\n",
    "    else:\n",
    "        raise Exception(\"Unification failed\")\n",
    "    \n",
    "\n",
    "unify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Var(0, StringSort()))\n",
    "x = Int('x')\n",
    "is_app(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Var(0): x*6, Var(1): y, Var(2): x}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from z3 import *\n",
    "def z3_match(t : ExprRef, pat : ExprRef) -> dict[z3.ExprRef, z3.ExprRef]:\n",
    "    \"\"\"\n",
    "    Pattern match t against pat. Variables are constructed as `z3.Var(i, sort)`.\n",
    "    Returns substitution dict if match succeeds.\n",
    "    Returns None if match fails.\n",
    "    Outer quantifier (Exists, ForAll, Lambda) in pat is ignored.\n",
    "    \"\"\"\n",
    "    if z3.is_quantifier(pat):\n",
    "        pat = pat.body()\n",
    "    subst = {}\n",
    "    todo = [(t,pat)]\n",
    "    while len(todo) > 0:\n",
    "        t,pat  = todo.pop()\n",
    "        if t.eq(pat):\n",
    "            continue\n",
    "        if z3.is_var(pat):\n",
    "            if pat in subst:\n",
    "                if not subst[pat].eq(t):\n",
    "                    return None\n",
    "            else:\n",
    "                subst[pat] = t\n",
    "        elif z3.is_app(t) and z3.is_app(pat):\n",
    "            if pat.decl() == t.decl():\n",
    "                todo.extend(zip(t.children(), pat.children()))\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            raise Exception(\"Unexpected subterm or subpattern\", t, pat)\n",
    "    return subst\n",
    "# not worth doing\n",
    "def match_quant(t,p):\n",
    "    if is_quantifier(p):\n",
    "        return z3_match(t,p.body())\n",
    "    else:\n",
    "        raise Exception(\"Not a quantifier\")\n",
    "R = RealSort()\n",
    "x,y,z = Reals('x y z')\n",
    "z3_match(x, Var(0, R))\n",
    "pmatch(x + y, Var(0, R) + Var(1, R))\n",
    "pmatch(x + y, Var(0, R) + Var(1, R) + Var(2, R))\n",
    "pmatch(x + y + x, Var(0, R) + Var(1, R) + Var(0, R))\n",
    "pmatch(x + y + x*6, Var(0, R) + Var(1, R) + Var(2, R))\n",
    "\n",
    "match_quant(x + y + x*6 == 0, ForAll([x,y,z], x + y + z == 0))\n",
    "\n",
    "# If I wanted deeper matching into binders, then what?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E-unify Egraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E-unification Egraph Style\n",
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "@dataclass\n",
    "class Unify():\n",
    "    uf: list[int]\n",
    "    obs: dict[int, tuple[Any, tuple[int]]]\n",
    "    def __init__(self):\n",
    "        self.uf = []\n",
    "        self.obs = {}\n",
    "    def make_var(self):\n",
    "        v = len(self.uf)\n",
    "        self.uf.append(v)\n",
    "        return v\n",
    "    def add_term(self, t):\n",
    "        # try to check for rationality?\n",
    "        if isinstance(t, int):\n",
    "            return t\n",
    "        head, *args = t\n",
    "        args = tuple(self.add_term(arg) for arg in args)\n",
    "        # we're not interning at all here, which is fine but inefficient.\n",
    "        x = self.make_var() \n",
    "        self.observe(x, (head, args))\n",
    "        return x\n",
    "    def find(self, x):\n",
    "        while self.uf[x] != x:\n",
    "            x = self.uf[x]\n",
    "        return x\n",
    "    def union(self, x, y):\n",
    "        x = self.find(x)\n",
    "        y = self.find(y)\n",
    "        self.uf[x] = y\n",
    "        return y\n",
    "    def merge_obs(self, obs, obs1): # unify_flat\n",
    "        head, args = obs\n",
    "        head1, args1 = obs1\n",
    "        if head != head1:\n",
    "            raise Exception(\"head mismatch\")\n",
    "        if len(args) != len(args1):\n",
    "            raise Exception(\"arity mismatch\")\n",
    "        for a,a1 in zip(args, args1):\n",
    "            self.union(a,a1)\n",
    "    def observe(self, x, obs):\n",
    "        x = self.find(x)\n",
    "        o = self.obs.get(x)\n",
    "        if o != None:\n",
    "            self.merge_obs(o, obs)\n",
    "        self.obs[x] = obs\n",
    "    def extract(self,x):\n",
    "        # assuming a well founded term. Could extract the rational term?\n",
    "        x = self.find(x)\n",
    "        f = self.obs.get(x)\n",
    "        if f == None:\n",
    "            return x\n",
    "        else:\n",
    "            head, args = f\n",
    "            return (head, *[self.extract(a) for a in args])\n",
    "    def rebuild(self):\n",
    "        while True:\n",
    "            newobs = {}\n",
    "            # \"unobserved\" vars aren't be merged. unobserved is actually Maximally observed, i.e. has identity.\n",
    "            for x,obs in self.obs.items():\n",
    "                x1 = self.find(x)\n",
    "                obs1 = self.obs.get(x1)\n",
    "                if obs1 != None:\n",
    "                    self.merge_obs(obs, obs1)\n",
    "                (head, args) = obs\n",
    "                newobs[x1] = (head, tuple(map(self.find, args)))\n",
    "            if self.obs == newobs:\n",
    "                break\n",
    "            self.obs = newobs\n",
    "\n",
    "U = Unify()\n",
    "x = U.make_var()\n",
    "y = U.make_var()\n",
    "z = U.make_var()\n",
    "print(U)\n",
    "#U.union(x,y)\n",
    "a_x = U.add_term((\"a\", (\"b\", z)))\n",
    "b_y = U.add_term((\"a\", y))\n",
    "U.union(a_x, b_y)\n",
    "print(U)\n",
    "U.rebuild()\n",
    "print(U)\n",
    "U.extract(a_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Unification algorithms\n",
    "## PyRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/eprover/PyRes/blob/master/unification.py\n",
    "def occursCheck(x, t):\n",
    "   \"\"\"\n",
    "   Perform an occurs-check, i.e. determine if the variable x occurs in\n",
    "   the term t. If that is the case (and t != x), the two can never be\n",
    "   unified.\n",
    "   \"\"\"\n",
    "   if termIsCompound(t):\n",
    "        for i in t[1:]:\n",
    "            if occursCheck(x, i):\n",
    "                return True\n",
    "        return False\n",
    "   else:\n",
    "       return x == t\n",
    "\n",
    "\n",
    "def mguTermList(l1, l2, subst):\n",
    "    \"\"\"\n",
    "    Unify all terms in l1 with the corresponding terms in l2 with a\n",
    "    common substitution variable \"subst\". We don't use explicit\n",
    "    equations or pairs of terms here - if l1 is [s1, s2, s3] and l2 is\n",
    "    [t1, t2, t3], this represents the set of equations {s1=t1, s2=t2,\n",
    "    s3=t3}. This makes several operations easier to implement.\n",
    "    \"\"\"\n",
    "    assert len(l1)==len(l2)\n",
    "    while(len(l1)!=0):\n",
    "       # Pop the first term pair to unify off the lists (pop removes\n",
    "       # and returns the denoted elements)\n",
    "       t1 = l1.pop(0)\n",
    "       t2 = l2.pop(0)\n",
    "       if termIsVar(t1):\n",
    "          if t1==t2:\n",
    "             # This implements the \"Solved\" rule.\n",
    "             # We could always test this upfront, but that would\n",
    "             # require an expensive check every time.\n",
    "             # We descend recursively anyway, so we only check this on\n",
    "             # the terminal case.\n",
    "             continue\n",
    "          if occursCheck(t1, t2):\n",
    "             return None\n",
    "          # Here is the core of the \"Bind\" rule\n",
    "          # We now create a new substitution that binds t2 to t1, and\n",
    "          # apply it to the remaining unification problem. We know\n",
    "          # that every variable will only ever be bound once, because\n",
    "          # we eliminate all occurances of it in this step - remember\n",
    "          # that by the failed occurs-check, t2 cannot contain t1.\n",
    "          new_binding = Substitution([(t1, t2)])\n",
    "          l1 = [new_binding(t) for t in l1]\n",
    "          l2 = [new_binding(t) for t in l2]\n",
    "          subst.composeBinding((t1, t2))\n",
    "       elif termIsVar(t2):\n",
    "          # Symmetric case\n",
    "          # We know that t1!=t2, so we can drop this check\n",
    "          if occursCheck(t2, t1):\n",
    "             return None\n",
    "          new_binding = Substitution([(t2, t1)])\n",
    "          l1 = [new_binding(t) for t in l1]\n",
    "          l2 = [new_binding(t) for t in l2]\n",
    "          subst.composeBinding((t2, t1))\n",
    "       else:\n",
    "          assert termIsCompound(t1) and termIsCompound(t2)\n",
    "          # Try to apply \"Decompose\"\n",
    "          # For f(s1, ..., sn) = g(t1, ..., tn), first f and g have to\n",
    "          # be equal...\n",
    "          if terms.termFunc(t1) != terms.termFunc(t2):\n",
    "             # Nope, \"Structural fail\":\n",
    "             return None\n",
    "          # But if the symbols are equal, here is the decomposition:\n",
    "          # We need to ensure that for all i si=ti get\n",
    "          # added to the list of equations to be solved.\n",
    "          l1.extend(termArgs(t1))\n",
    "          l2.extend(termArgs(t2))\n",
    "    return subst\n",
    "\n",
    "\n",
    "def mgu(t1, t2):\n",
    "    \"\"\"\n",
    "    Try to unify t1 and t2, return substitution on success, or None on failure.\n",
    "    \"\"\"\n",
    "    res =  mguTermList([t1], [t2], Substitution())\n",
    "    res2 = \"False\"\n",
    "    if res:\n",
    "       res2 = \"True\"\n",
    "    # print(\"% :\", term2String(t1), \" : \", term2String(t2), \" => \", res2);\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minikanren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%file /tmp/minikanren_unif.scm\n",
    ";; http://webyrd.net/scheme-2013/papers/HemannMuKanren2013.pdf\n",
    ";; https://github.com/jasonhemann/microKanren/blob/master/microKanren.scm\n",
    "\n",
    "; Jason Hemann and Dan Friedman\n",
    ";; microKanren, final implementation from paper\n",
    "\n",
    "(define (var c) (vector c))\n",
    "(define (var? x) (vector? x))\n",
    "(define (var=? x1 x2) (= (vector-ref x1 0) (vector-ref x2 0)))\n",
    "\n",
    "(define (walk u s)\n",
    "  (let ((pr (and (var? u) (assp (lambda (v) (var=? u v)) s))))\n",
    "    (if pr (walk (cdr pr) s) u)))\n",
    "\n",
    "(define (ext-s x v s) `((,x . ,v) . ,s))\n",
    "\n",
    "(define (== u v)\n",
    "  (lambda (s/c)\n",
    "    (let ((s (unify u v (car s/c))))\n",
    "      (if s (unit `(,s . ,(cdr s/c))) mzero))))\n",
    "\n",
    "(define (unit s/c) (cons s/c mzero))\n",
    "(define mzero '())\n",
    "\n",
    "(define (unify u v s)\n",
    "  (let ((u (walk u s)) (v (walk v s)))\n",
    "    (cond\n",
    "      ((and (var? u) (var? v) (var=? u v)) s)\n",
    "      ((var? u) (ext-s u v s))\n",
    "      ((var? v) (ext-s v u s))\n",
    "      ((and (pair? u) (pair? v))\n",
    "       (let ((s (unify (car u) (car v) s)))\n",
    "         (and s (unify (cdr u) (cdr v) s))))\n",
    "      (else (and (eqv? u v) s)))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harrison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/harrison.ml\n",
    "(* ========================================================================= *)\n",
    "(* Unification for first order terms.                                        *)\n",
    "(*                 https://www.cl.cam.ac.uk/~jrh13/atp/OCaml/unif.ml                                                           *)\n",
    "(* Copyright (c) 2003-2007, John Harrison. (See \"LICENSE.txt\" for details.)  *)\n",
    "(* ========================================================================= *)\n",
    "\n",
    "let rec istriv env x t =\n",
    "  match t with\n",
    "    Var y -> y = x or defined env y & istriv env x (apply env y)\n",
    "  | Fn(f,args) -> exists (istriv env x) args & failwith \"cyclic\";;\n",
    "\n",
    "(* ------------------------------------------------------------------------- *)\n",
    "(* Main unification procedure                                                *)\n",
    "(* ------------------------------------------------------------------------- *)\n",
    "\n",
    "let rec unify env eqs =\n",
    "  match eqs with\n",
    "    [] -> env\n",
    "  | (Fn(f,fargs),Fn(g,gargs))::oth ->\n",
    "        if f = g & length fargs = length gargs\n",
    "        then unify env (zip fargs gargs @ oth)\n",
    "        else failwith \"impossible unification\"\n",
    "  | (Var x,t)::oth | (t,Var x)::oth ->\n",
    "        if defined env x then unify env ((apply env x,t)::oth)\n",
    "        else unify (if istriv env x t then env else (x|->t) env) oth;;\n",
    "\n",
    "(* ------------------------------------------------------------------------- *)\n",
    "(* Solve to obtain a single instantiation.                                   *)\n",
    "(* ------------------------------------------------------------------------- *)\n",
    "\n",
    "let rec solve env =\n",
    "  let env' = mapf (tsubst env) env in\n",
    "  if env' = env then env else solve env';;\n",
    "\n",
    "(* ------------------------------------------------------------------------- *)\n",
    "(* Unification reaching a final solved form (often this isn't needed).       *)\n",
    "(* ------------------------------------------------------------------------- *)\n",
    "\n",
    "let fullunify eqs = solve (unify undefined eqs);;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prover9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/prover9.c\n",
    "BOOL unify(Term t1, Context c1,\n",
    "           Term t2, Context c2, Trail *trp)\n",
    "{\n",
    "  Trail tpos, tp, t3;\n",
    "  int vn1, vn2;\n",
    "\n",
    "  DEREFERENCE(t1, c1)  /* dereference macro */\n",
    "\n",
    "  DEREFERENCE(t2, c2)  /* dereference macro */\n",
    "\n",
    "  /* Now, neither t1 nor t2 is a bound variable. */\n",
    "\n",
    "  if (VARIABLE(t1)) {\n",
    "    vn1 = VARNUM(t1);\n",
    "    if (VARIABLE(t2)) {\n",
    "      /* both t1 and t2 are variables */\n",
    "      if (vn1 == VARNUM(t2) && c1 == c2)\n",
    "        return TRUE;  /* identical */\n",
    "      else {\n",
    "        BIND_TR(vn1, c1, t2, c2, trp)\n",
    "        return TRUE;\n",
    "      }\n",
    "    }\n",
    "    else {\n",
    "      /* t1 variable, t2 not variable */\n",
    "      if (occur_check(vn1, c1, t2, c2)) {\n",
    "        BIND_TR(vn1, c1, t2, c2, trp)\n",
    "        return TRUE;\n",
    "      }\n",
    "      else\n",
    "        return FALSE;  /* failed occur_check */\n",
    "    }\n",
    "  }\n",
    "\n",
    "  else if (VARIABLE(t2)) {\n",
    "    /* t2 variable, t1 not variable */\n",
    "    vn2 = VARNUM(t2);\n",
    "    if (occur_check(vn2, c2, t1, c1)) {\n",
    "      BIND_TR(vn2, c2, t1, c1, trp)\n",
    "      return TRUE;\n",
    "    }\n",
    "    else\n",
    "      return FALSE;  /* failed occur_check */\n",
    "  }\n",
    "    \n",
    "  else if (SYMNUM(t1) != SYMNUM(t2))\n",
    "    return FALSE;  /* fail because of symbol clash */\n",
    "\n",
    "  else if (ARITY(t1) == 0)\n",
    "    return TRUE;\n",
    "\n",
    "  else {  /* both complex with same symbol */\n",
    "    int i, arity;\n",
    "\n",
    "    tpos = *trp;  /* save trail position in case of failure */\n",
    "        \n",
    "    i = 0; arity = ARITY(t1);\n",
    "    while (i < arity && unify(ARG(t1,i), c1, ARG(t2,i), c2, trp))\n",
    "      i++;\n",
    "\n",
    "    if (i == arity)\n",
    "      return TRUE;\n",
    "    else {  /* restore trail and fail */\n",
    "      tp = *trp;\n",
    "      while (tp != tpos) {\n",
    "        tp->context->terms[tp->varnum] = NULL;\n",
    "        tp->context->contexts[tp->varnum] = NULL;\n",
    "        t3 = tp;\n",
    "        tp = tp->next;\n",
    "        free_trail(t3);\n",
    "      }\n",
    "      *trp = tpos;\n",
    "      return FALSE;\n",
    "    }\n",
    "  }\n",
    "}  /* unify */"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ocaml alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/ocaml_alg.ml\n",
    "(* https://github.com/smimram/ocaml-alg/blob/main/src/term.ml#L375 *)\n",
    "(** Most general unifier. *)\n",
    "let unify t1 t2 =\n",
    "  (* Printf.printf \"UNIFY %s WITH %s\\n%!\" (to_string t1) (to_string t2); *)\n",
    "  let rec aux q s =\n",
    "    match q with\n",
    "    | [] -> s\n",
    "    | p::q ->\n",
    "       match p with\n",
    "       | Var x, t ->\n",
    "          if occurs x t then raise Not_unifiable;\n",
    "          let s' = Subst.simple x t in\n",
    "          let f = Subst.app s' in\n",
    "          let q = List.map (fun (t1,t2) -> f t1, f t2) q in\n",
    "          let s = Subst.compose s s' in\n",
    "          aux q (Subst.add s x t)\n",
    "       | t, Var x -> aux ((Var x,t)::q) s\n",
    "       | App (f1,a1), App (f2,a2) ->\n",
    "          if not (Op.eq f1 f2) then raise Not_unifiable;\n",
    "          let q = (List.map2 pair a1 a2) @ q in\n",
    "          aux q s\n",
    "  in\n",
    "  let s = aux [t1,t2] Subst.empty in\n",
    "  assert (eq (Subst.app s t1) (Subst.app s t2));\n",
    "  s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/traat.ml\n",
    "(*** https://www21.in.tum.de/~nipkow/TRaAT/programs/trs.ML The basics of term rewriting: terms, unification, matching, normalization\n",
    "\n",
    "ML Programs from Chapter 4 of\n",
    "\n",
    "  Term Rewriting and All That\n",
    "  by Franz Baader and Tobias Nipkow,\n",
    "  (Cambridge University Press, 1998)\n",
    "\n",
    "Copyright (C) 1998 by Cambridge University Press.\n",
    "Permission to use without fee is granted provided that this copyright\n",
    "notice is included in any copy.\n",
    "***)\n",
    "\n",
    "type vname = string * int;\n",
    "\n",
    "datatype term = V of vname | T of string * term list;\n",
    "\n",
    "(* indom: vname -> subst -> bool *)\n",
    "fun indom x s = exists (fn (y,_) => x = y) s;\n",
    "\n",
    "(* app: subst -> vname -> term *)\n",
    "fun app ((y,t)::s) x  =  if x=y then t else app s x;\n",
    "\n",
    "(* lift: subst -> term -> term *)\n",
    "fun lift s (V x)    = if indom x s then app s x else V x\n",
    "  | lift s (T(f,ts)) = T(f, map (lift s) ts);\n",
    "\n",
    "(* occurs: vname -> term -> bool *)\n",
    "fun occurs x (V y)    = x=y\n",
    "  | occurs x (T(_,ts)) = exists (occurs x) ts;\n",
    "\n",
    "exception UNIFY;\n",
    "\n",
    "(* solve: (term * term)list * subst -> subst *)\n",
    "fun solve([], s) = s\n",
    "  | solve((V x, t) :: S, s) =\n",
    "      if V x = t then solve(S,s) else elim(x,t,S,s)\n",
    "  | solve((t, V x) :: S, s) = elim(x,t,S,s)\n",
    "  | solve((T(f,ts),T(g,us)) :: S, s) =\n",
    "      if f = g then solve(zip(ts,us) @ S, s) else raise UNIFY\n",
    "\n",
    "(* elim: vname * term * (term * term) list * subst -> subst *)\n",
    "and elim(x,t,S,s) =\n",
    "      if occurs x t then raise UNIFY\n",
    "      else let val xt = lift [(x,t)]\n",
    "           in solve(map (fn (t1,t2) => (xt t1, xt t2)) S,\n",
    "                    (x,t) :: (map (fn (y,u) => (y, xt u)) s))\n",
    "           end;\n",
    "\n",
    "(* unify: term * term -> subst *)\n",
    "fun unify(t1,t2) = solve([(t1,t2)], []);\n",
    "\n",
    "(* matchs: (term * term) list * subst -> subst *)\n",
    "fun matchs([], s) = s\n",
    "  | matchs((V x, t) :: S, s) =\n",
    "      if indom x s then if app s x = t then matchs(S,s) else raise UNIFY\n",
    "      else matchs(S,(x,t)::s)\n",
    "  | matchs((t, V x) :: S, s) = raise UNIFY\n",
    "  | matchs((T(f,ts),T(g,us)) :: S, s) =\n",
    "      if f = g then matchs(zip(ts,us) @ S, s) else raise UNIFY;\n",
    "\n",
    "(* match: term * term -> subst *)\n",
    "fun match(pat,obj) = matchs([(pat,obj)],[]);\n",
    "\n",
    "exception NORM;\n",
    "\n",
    "(* rewrite: (term * term) list -> term -> term *)\n",
    "fun rewrite [] t = raise NORM\n",
    "  | rewrite ((l,r)::R) t = lift(match(l,t)) r\n",
    "                          handle UNIFY => rewrite R t;\n",
    "\n",
    "(* norm: (term * term) list -> term -> term *)\n",
    "fun norm R (V x) = V x\n",
    "  | norm R (T(f,ts)) =\n",
    "      let val u = T(f, map (norm R) ts)\n",
    "      in (norm R (rewrite R u))  handle NORM => u  end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alpha prolog or lambda prolog as a librtary would be good.\n",
    "alpha leantap\n",
    "(an interpreter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import janus_swi as janus\n",
    "\n",
    "# leantap with higher order unify?\n",
    "# trs with higher order unify?\n",
    "\n",
    "janus.consult(\"hounify\", \"\"\"\n",
    "\n",
    "ho_unify(bvar()).\n",
    "ho_unify(app(F1,X1), app(F2,X2)) :- ho_unify(F1,F2, Sig), ho_unify(X1,X2,Sig).\n",
    "ho_unify(lam(X1,B1), lam(X2,B2), Sig) :- gensym(S), V =.. [S|Sig], X1 = V, X2 = V, ho_unify(B1,B2,Sig).\n",
    "\n",
    "              \n",
    "% noiminal_unify(T1, T2 ,  Perm)\n",
    "nominal(atom(A), atom(B), Perm1, Perm2) :- member(A-B, Perm1), Perm1 = Perm2.\n",
    "nominal(atom(A), atom(B), Perm1, Perm2) :- +/ member(A-Y, Perm1), +/ member(Z-B, Perm1), Perm2 = [A-B|Perm1].\n",
    "nominal(app(F,Args), app(F1,Args2), Perm1, Perm2) :- nominal(F,F1)\n",
    "nominal\n",
    "\n",
    "% maybe a dcg of the permutation? We are threading a state.\n",
    "nominal(atom(A), atom(B)) --> \n",
    "\n",
    "% https://stackoverflow.com/questions/64638801/the-unification-algorithm-in-prolog#:~:text=unify(A%2CB)%3A%2D%20atomic,B)%2CA%3DB.        \n",
    "              unify(A,B):-\n",
    "   atomic(A),atomic(B),A=B.\n",
    "unify(A,B):-\n",
    "   var(A),A=B.            % without occurs check\n",
    "unify(A,B):-\n",
    "   nonvar(A),var(B),A=B.  % without occurs check\n",
    "unify(A,B):-\n",
    "   compound(A),compound(B),\n",
    "   A=..[F|ArgsA],B=..[F|ArgsB],\n",
    "   unify_args(ArgsA,ArgsB).\n",
    "   \n",
    "unify_args([A|TA],[B|TB]):-\n",
    "   unify(A,B),\n",
    "   unify_args(TA,TB).\n",
    "unify_args([],[]).\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bottom up ho unify is simpler. Dowek. Maybe anmm inverse method/magic set is in order.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
