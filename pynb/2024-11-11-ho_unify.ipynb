{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Higher Order Pattern Unification on the Z3py AST\n",
    "date: 2024-11-11\n",
    "---\n",
    "\n",
    "[Unification](https://en.wikipedia.org/wiki/Unification_(computer_science)) is the logic-y word for equation solving. It is finding terms to fill in the holes of an implicitly existential quantified goal equation formulas like `3*X + 4*Y = 7` or `foo(X) = foo(bar(Y))`.\n",
    "\n",
    "In first order syntactic unification, we can kind of follow our nose going down the term. I discussed this more previously https://www.philipzucker.com/unify/\n",
    "\n",
    "We can also bolt in various [extra features](https://en.wikipedia.org/wiki/Unification_(computer_science)#E-unification) into our equation solver, for example intrinsic understanding of linear algebra, booleans, or algebraic properties like associativity or commutativity.\n",
    "\n",
    "One pile of features you can toss on unification are related to having other notions of variable besides unification holes in the terms. Examples of where you might want this include\n",
    "\n",
    "- Integral expressions $\\int dx e^{-x^2}$ have dummy variables\n",
    "- Sums $\\sum_i a_i$ have dummy indices\n",
    "- lambdas $\\lambda x. (x x)$, have bound variables\n",
    "- $min_x f(x)$\n",
    "- indexful [tensor](https://en.wikipedia.org/wiki/Tensor) expressions $T_{ijk}\\epsilon_{ij}$\n",
    "- confusingly modelling logic itself, with quantifiers $\\forall x. P(x)$ and $\\exists x. P(x)$\n",
    "\n",
    "Vaguely this set of features is called [higher order unification](https://en.wikipedia.org/wiki/Unification_(computer_science)#Higher-order_unification) because the people who work on it mostly have in mind a lambda calculus.\n",
    "\n",
    "There is some useful distinction to be made though. The point of the lambda calculus is substitution $(\\lambda x. foo(x,x))10 \\rightarrow foo(10,10)$, aka [beta reduction](https://en.wikipedia.org/wiki/Lambda_calculus#%CE%B2-reduction). This is a useful feature, but it possibly is too much to ask for. It turns out that full lambda unification is undecidable, meaning you can encode very difficult problems into it.\n",
    "\n",
    "A separate thing to ask for is to deal with dummy variables properly aka well-scoped alpha equivalence. For example, syntactically unifying $\\int dx e^{-x^2} = \\int dy e^{-y^2}$ shouldn't fail.\n",
    "\n",
    "There are two related approaches here\n",
    "\n",
    "- Nominal unification\n",
    "- Higher order pattern unification aka Miller pattern unification\n",
    "\n",
    "Pattern unification I think is actually fairly simple. It is almost the obvious thing to do (in hindsight of course) if you want to extend first order unification but keep things well scoped.\n",
    "\n",
    "Try it out on colab: https://colab.research.google.com/github/philzook58/philzook58.github.io/blob/master/pynb/2024-11-11-ho_unify.ipynb \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern Matching\n",
    "\n",
    "Before discussing unification, you should always try pattern matching first. It's way simpler, probably faster and more useful.\n",
    "\n",
    "Pattern matching is like one-way unification, or unification is like 2-way pattern matching.\n",
    "\n",
    "First off, let us note that the following problem cannot be solved\n",
    "\n",
    "$\\exists T. (\\lambda x. f(x,x) = \\lambda x. T)$\n",
    "\n",
    "What the heck am I talking about? OBVIOUSLY, $T = f(x,x)$, right? No, because T is bound outside of the lambda that binds $x$.\n",
    "This statement gets more confusing when you leave the $\\exists$ implicit and write $\\lambda x. f(x,x) ?= \\lambda x. T$.\n",
    "\n",
    "\n",
    "Okay, well how about\n",
    "\n",
    "$\\exists T. (\\lambda x. f(x,x) = \\lambda x. T(x))$\n",
    "\n",
    "Yes, this is perfectly solvable as $T = \\lambda y. f(y,y)$.\n",
    "\n",
    "What about this?\n",
    "$\\exists T. (\\lambda x. f(42,42) = \\lambda x. T(42))$\n",
    "\n",
    "Well, actually this has a couple solutions. $T = \\lambda y. f(42,42)$ or $T = \\lambda y. f(y,y)$ or $T = \\lambda y. f(42,y)$ or $T = \\lambda y. f(y,42)$.\n",
    "\n",
    "Pattern unification is a subset of higher order unification that forbids combos that have multiple possible solutions. Unification variables may only be applied to unique rigid bound variables.\n",
    "\n",
    "Really, the combination `T(x)` should be thought of as a single entity rather than a unification variable applied to a bound variable. I tend to not even think of pattern unification as lesser higher order unification at all. It's a different thing.\n",
    "\n",
    "Sometimes types can tell a whole story. Ivan once said something like, \"show me the types, and I don't need to see your implementation\". The ocaml datatype of a regular first order term with variables would be \n",
    "\n",
    "```ocaml\n",
    "type uvar = string\n",
    "type term_fo =\n",
    "    | UVar of uvar\n",
    "    | Const of string * term_fo list\n",
    "```\n",
    "\n",
    "The ocaml datatype for higher order pattern terms would be\n",
    "\n",
    "```ocaml\n",
    "type bvar = int\n",
    "type term_pat = \n",
    "    | UVar of uvar * bvar list (* When we hit the unification var, we know exactly what to do. *)\n",
    "    | Binder of term_pat (* binder represented as de Bruijn *)\n",
    "    | BVar of int\n",
    "    | Const of string * term_pat list\n",
    "```\n",
    "\n",
    "And NOT like this (which would be a reasonable term type for full higher order unification)\n",
    "\n",
    "```ocaml\n",
    "type uvar = string\n",
    "type bvar = int\n",
    "type term_ho = \n",
    "    | UVar of uvar\n",
    "    | Lam of term_ho\n",
    "    | BVar of int\n",
    "    | App of term_ho * term_ho (* app is playing two purposes here. *)\n",
    "    | Const of string\n",
    "```\n",
    "\n",
    "We can see that kind of we've inlined the app node and that the HO pattern `term` is a closer relative of the first order `term` than the full higher order `term_ho`. \n",
    "\n",
    "We make a distinction between the binders of our `term` type and different kind of binders or application of the domain we are modelling inside our terms.\n",
    "Regular application of a modelled lambda calculus could be represented as a constant `Const(\"app\", [f; x])`.\n",
    "\n",
    "\n",
    "# Ok Let's do it on Z3's AST\n",
    "\n",
    "I've complained before that python doesn't have a nice lambda manipulation library. That is not true. z3 is that library.\n",
    "\n",
    "We still need some preliminaries dealing with lambda term.\n",
    "\n",
    "Z3 AST's are sadly not alpha equivalent. This is not that surprising, making alpha equiv fast is hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install z3-solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from z3 import *\n",
    "x,y = Reals(\"x y\")\n",
    "Lambda([x], x).eq(Lambda([y], y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [locally nameless approach](https://chargueraud.org/research/2009/ln/main.pdf) to binders, you represent bound variables using de bruijn indices and free variables as fresh constants (or alternatively de bruijn levels). The lesson is that whenever you need to traverse a term under a binder, you should open the binder by replacing it's variables with fresh constants. If you maintain this discipline, everything just kind of works. I don't think I really know a deep reason why this is the right thing to do, but let's take it on faith.\n",
    "\n",
    "Z3 thank god already deals with the de bruijn indices. That would be a blog post on it's own. It also offers convenient FreshConst functions.\n",
    "\n",
    "A simple `open_binder` function gives us the body of a quantifier and a list of the new free variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VList = list[z3.ExprRef]\n",
    "def open_binder(lam: z3.QuantifierRef) -> tuple[VList, z3.ExprRef]:\n",
    "    vs = [\n",
    "        z3.FreshConst(lam.var_sort(i), prefix=lam.var_name(i))\n",
    "        for i in range(lam.num_vars())\n",
    "    ]\n",
    "    return vs, z3.substitute_vars(lam.body(), *reversed(vs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha equivalence is kind of the obvious traversal zipping together the two terms. The interesting bit maybe is when you hit a quantifier. You open one and then instantiate the other with the same free variables. Alternatively, you could open both and maintain a map saying which free vars correspond to which."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quant_kind_eq(t1, t2):\n",
    "    \"\"\"Check both quantifiers are of the same kind\"\"\"\n",
    "    return t1.is_forall() == t2.is_forall() and t1.is_exists() == t2.is_exists() and t1.is_lambda() == t2.is_lambda()\n",
    "\n",
    "def alpha_eq(t1, t2):\n",
    "    if t1.eq(t2): # fast path\n",
    "        return True\n",
    "    elif is_quantifier(t1) and is_quantifier(t2):\n",
    "        if quant_kind_eq(t1,t2) and t1.num_vars() == t2.num_vars() and [t1.var_sort(i) == t2.var_sort(i) for i in range(t1.num_vars())]: \n",
    "            vs, body1 = open_binder(t1)\n",
    "            body2 = substitute_vars(t2.body(), *reversed(vs))\n",
    "            return alpha_eq(body1, body2)\n",
    "        else:\n",
    "            return False\n",
    "    elif is_app(t1) and is_app(t2):\n",
    "        if t1.decl() == t2.decl():\n",
    "            return all(alpha_eq(t1.arg(i), t2.arg(i)) for i in range(t1.num_args()))\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        raise Exception(f\"Unexpected terms in alpha_eq\", t1, t2)\n",
    "    # could instead maybe use a solver check or simplify tactic on Goal(t1 == t2)\n",
    "    \n",
    "assert alpha_eq(Lambda([x], x), Lambda([y], y))\n",
    "assert not alpha_eq(ForAll([x], x == x), Exists([y], y == y))\n",
    "t = Lambda([x,y], x + y)\n",
    "vs, body = open_binder(t)\n",
    "assert alpha_eq(t, Lambda(vs, body))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok now onto pattern matching. [Previously](https://www.philipzucker.com/unify/), I showed how to write first order pattern matching.\n",
    "\n",
    "The pattern matching variables are the constants in the list `vs`.\n",
    "\n",
    "You can write it in different style. Here I use a todo queue and loop. If you hit a variable in the, look it up in the `subst` if its there, or add it to the `subst`. Otherwise, make sure the heads match and then match all the children of the pattern and term zipped together.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from z3 import *\n",
    "\n",
    "\n",
    "def pmatch_fo(vs : VList, pat, t):\n",
    "    if pat.sort() != t.sort():\n",
    "        raise Exception(\"Sort mismatch\", pat, t)\n",
    "    subst = {}\n",
    "    todo = [(pat, t)]\n",
    "    def is_var(x):\n",
    "        return any(x.eq(v) for v in vs)\n",
    "    while todo:\n",
    "        pat, t = todo.pop()\n",
    "        if is_var(pat): # regular pattern\n",
    "            if pat in subst:\n",
    "                if not subst[pat].eq(t):\n",
    "                    return None\n",
    "            else: \n",
    "                subst[pat] = t\n",
    "        elif is_app(pat):\n",
    "            if not is_app(t) or pat.decl() != t.decl():\n",
    "                return None\n",
    "            todo.extend(zip(pat.children(), t.children())) \n",
    "        else:\n",
    "            raise Exception(\"Unexpected pattern\", t, pat)\n",
    "    return subst\n",
    "\n",
    "x,y,z = Ints(\"x y z\")\n",
    "\n",
    "assert pmatch_fo([x], x, IntVal(4)) == {x: IntVal(4)}\n",
    "assert pmatch_fo([x], IntVal(3), IntVal(3)) == {}\n",
    "assert pmatch_fo([x], IntVal(3), IntVal(4)) == None\n",
    "assert pmatch_fo([x], x, IntVal(3)) == {x : IntVal(3)}\n",
    "assert pmatch_fo([x], x + x, IntVal(3) + IntVal(4)) == None\n",
    "assert pmatch_fo([x], x + x, IntVal(3) + IntVal(3)) == {x : IntVal(3)}\n",
    "assert pmatch_fo([y], x + x, IntVal(3) + IntVal(3)) == None\n",
    "assert pmatch_fo([x,y], x + y, IntVal(3) + IntVal(4)) == {x : IntVal(3), y : IntVal(4)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The higher order pattern match adds a couple cases.\n",
    "\n",
    "When we open binders, we note that these should not escape into pattern variables by storing them in `noescape`.\n",
    "\n",
    "When we finally resolve a variable, we check that the thing it matched is free of the noescape variables. This is similar to an occurs check in some respects.\n",
    "\n",
    "When we hit a pattern of `F[x1,x2,x3] = t`, we process it into `F = Lambda([x1,x2,x3], t)` and continue. That is basically the magic of the miller pattern and the way you can smuggle terms containing bound vars out. You build a lambda abstraction to ferry them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from z3 import *\n",
    "\n",
    "\n",
    "def pmatch(vs, pat, t):\n",
    "    if pat.sort() != t.sort():\n",
    "        raise Exception(\"Sort mismatch\", pat, t)\n",
    "    subst = {}\n",
    "    todo = [(pat, t)]\n",
    "    no_escape = []\n",
    "    def is_var(x):\n",
    "        return any(x.eq(v) for v in vs)\n",
    "    def check_escape(x):\n",
    "        if any(x.eq(v) for v in no_escape):\n",
    "            return False\n",
    "        else:\n",
    "            return all(check_escape(c) for c in x.children())\n",
    "    while todo:\n",
    "        pat, t = todo.pop()\n",
    "        if is_var(pat): # regular pattern\n",
    "            if pat in subst:\n",
    "                if not alpha_eq(subst[pat], t):\n",
    "                    return None\n",
    "            else: \n",
    "                if check_escape(t): # check_escape is relative of occurs_check\n",
    "                    subst[pat] = t\n",
    "                else:\n",
    "                    return None\n",
    "        elif is_select(pat) and is_var(pat.arg(0)): #  higher order pattern. \"select\" is smt speak for apply.\n",
    "                F = pat.arg(0)\n",
    "                allowedvars = pat.children()[1:]\n",
    "                if any(v not in no_escape for v in allowedvars):\n",
    "                    raise Exception(\"Improper higher order pattern\", pat) # we could relax this to do syntactic unification here.\n",
    "                t1 = Lambda(allowedvars, t) # abstract out the allowed vars\n",
    "                todo.append((F, t1))\n",
    "        #elif pat.eq(t): early stopping. Not allowed if t contains a pattern variable.\n",
    "        #if part.sort() != t.sort(): return None. another fast break \n",
    "        elif is_quantifier(pat):\n",
    "            if not is_quantifier(t) or not quant_kind_eq(t,pat) or t.num_vars() != pat.num_vars():\n",
    "                return None\n",
    "            vs1, patbody = open_binder(pat)\n",
    "            no_escape.extend(vs1)\n",
    "            tbody = substitute_vars(t.body(), *reversed(vs1))\n",
    "            todo.append((patbody, tbody))\n",
    "        elif is_app(pat):\n",
    "            if not is_app(t) or pat.decl() != t.decl():\n",
    "                return None\n",
    "            todo.extend(zip(pat.children(), t.children())) \n",
    "        else:\n",
    "            raise Exception(\"Unexpected pattern\", t, pat)\n",
    "    return subst\n",
    "\n",
    "x,y,z = Ints(\"x y z\")\n",
    "F,G = Consts(\"F G\", ArraySort(IntSort(), IntSort()))\n",
    "assert pmatch([x], x, IntVal(4)) == {x: IntVal(4)}\n",
    "assert pmatch([x], IntVal(3), IntVal(3)) == {}\n",
    "assert pmatch([x], IntVal(3), IntVal(4)) == None\n",
    "assert pmatch([x], x, IntVal(3)) == {x : IntVal(3)}\n",
    "assert pmatch([x], x + x, IntVal(3) + IntVal(4)) == None\n",
    "assert pmatch([x], x + x, IntVal(3) + IntVal(3)) == {x : IntVal(3)}\n",
    "assert pmatch([y], x + x, IntVal(3) + IntVal(3)) == None\n",
    "assert pmatch([x,y], x + y, IntVal(3) + IntVal(4)) == {x : IntVal(3), y : IntVal(4)}\n",
    "\n",
    "# alpha equiv terms should pmatch\n",
    "assert pmatch([], Lambda([x], x == x), Lambda([y], y == y)) == {}\n",
    "t = Lambda([x,y], x + y)\n",
    "vs, body = open_binder(t)\n",
    "assert pmatch([], t, Lambda(vs, body)) == {}\n",
    "\n",
    "assert alpha_eq(pmatch([F], Lambda([x], F[x]), Lambda([x], x + 3))[F],\n",
    "                Lambda([x], x + 3))\n",
    "assert alpha_eq(pmatch([F], Lambda([x], F[x]), Lambda([y], y + 3))[F], \n",
    "                Lambda([z], z + 3))\n",
    "assert alpha_eq(pmatch([F], Lambda([x], F[x]), Lambda([x], G[x]))[F], \n",
    "                Lambda([x], G[x]))\n",
    "\n",
    "# Failing examples\n",
    "# should we allow this? \n",
    "# pmatch([F], F[3], G[3]). Seems obvious what the answer should be {F:G}, but we're opening up a can of worms\n",
    "assert pmatch([F], Lambda([x,y], F[x]), Lambda([x,y], G[y])) == None\n",
    "assert pmatch([F], Lambda([x,y], F), Lambda([x,y], Lambda([z], x + 3))) == None\n",
    "\n",
    "# This is the sort of thing you have to do if you want to apply an induction principle about (forall P) to a goal.\n",
    "P = Const(\"P\", ArraySort(IntSort(), BoolSort()))\n",
    "assert alpha_eq(pmatch([P], ForAll([x], P[x]), ForAll([y], Or(y == 0, y > 0)))[P], \n",
    "                Lambda([z], Or(z == 0, z > 0)))\n",
    "\n",
    "assert pmatch([F,G], Lambda([x,y],F[y] + F[y]), Lambda([x,y], x + y)) == None\n",
    "assert pmatch([F,G], Lambda([x,y],F[y] + F[x]), Lambda([x,y], x + y)) == None\n",
    "assert alpha_eq(pmatch([F,G], Lambda([x,y],F[x] + F[y]), Lambda([x,y], x + y))[F],\n",
    "                Lambda([x], x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unification\n",
    "Most of the difficulties that occur with unification are basically already dealt with in first order unification.\n",
    "\n",
    "I mentioned in my [previous post](https://www.philipzucker.com/unify/) that the eager substitution loopy form of unification is the most clear to my eye. Eager substitution can only be easily written if you write unification as a todo queue, where you have access to your \"stack\" to perform the appropriate substitutions immediately everywhere.\n",
    "\n",
    "With higher order unification, everything is even more confusing, so I'm going to stick to that style.\n",
    "\n",
    "This is the basic first order unify routine. UIn this form, it isn't _that_ different from the pattern match code. The main difference is substituting away the unification variables in the `todo` and `subst` when we find them. Even in the first order form, we have a check to see if our solution is ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify(vs, p1, p2):\n",
    "    subst = {}\n",
    "    todo = [(p1,p2)]\n",
    "    def is_var(x):\n",
    "        return any(x.eq(v) for v in vs)\n",
    "    def occurs(x, t):\n",
    "        if is_var(t):\n",
    "            return x.eq(t)\n",
    "        if is_app(t):\n",
    "            return any(occurs(x, t.arg(i)) for i in range(t.num_args()))\n",
    "        return False\n",
    "    while todo:\n",
    "        p1,p2 = todo.pop()\n",
    "        if p1.eq(p2): # delete\n",
    "            continue\n",
    "        elif is_var(p1): # elim\n",
    "            if occurs(p1, p2):\n",
    "                return None\n",
    "            todo = [(substitute(t1,(p1,p2)), substitute(t2,(p1,p2))) for (t1,t2) in todo]\n",
    "            subst = {k : substitute(v, (p1,p2)) for k,v in subst.items()}\n",
    "            subst[p1] = p2\n",
    "        elif is_var(p2): # orient\n",
    "            todo.append((p2,p1))\n",
    "        elif is_app(p1): # decompose\n",
    "            if not is_app(p2) or p1.decl() != p2.decl():\n",
    "                return None\n",
    "            todo.extend(zip(p1.children(), p2.children())) \n",
    "        else:\n",
    "            raise Exception(\"unexpected case\", p1, p2)\n",
    "    return subst\n",
    "\n",
    "vs = Ints(\"x y z\")\n",
    "x,y,z = vs\n",
    "assert unify(vs,IntVal(3), IntVal(3)) == {}\n",
    "assert unify(vs,IntVal(3), IntVal(4)) == None\n",
    "assert unify(vs,x, IntVal(3)) == {x : IntVal(3)}\n",
    "assert unify(vs, x, y) == {x : y}\n",
    "assert unify(vs, x + x, y + y) == {x : y}\n",
    "assert unify(vs, x + x, y + z) == {x : y, z : y}\n",
    "assert unify(vs,x + y, y + z) == {x : z, y : z}\n",
    "assert unify(vs,y + z, x + y) == {y : x, z : x}\n",
    "assert unify(vs, (x + x) + x, x + (x + x)) == None\n",
    "assert unify(vs, 1 + x, x) == None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another piece of infrastructure we need is $\\beta_0$ normalization. $beta_0$ normalization _only_ performs substitution on rigid bound variables. It is the part of $\\beta$ normalization we can deal with elegantly, but it's enough to get us a lot of distance.\n",
    "\n",
    "Basically, traverse the term and use z3 to do the substitutions.\n",
    "\n",
    "When we substitute in a pattern variable during unification, we may create $\\beta_0$ redexes. That's why we might want this. Maybe it's overkill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "&lambda;x!34 : 3 + x!34"
      ],
      "text/plain": [
       "Lambda(x!34, 3 + x!34)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from z3 import *\n",
    "def beta0_norm(ctx,t):\n",
    "    # reduce any lambdas applied to rigid variables\n",
    "    if is_select(t) and is_quantifier(t.arg(0)): # (\\x y z. body)[p1,p2,p3]\n",
    "        params = t.children()[1:]\n",
    "        if all(any(v.eq(v1) for v1 in ctx) for v in params):\n",
    "            return beta0_norm(ctx, substitute_vars(t.arg(0).body(), *reversed(params)))\n",
    "        else:\n",
    "            return t.decl()(*[beta0_norm(ctx, x) for x in t.children()])\n",
    "    elif is_quantifier(t):\n",
    "        vs, body = open_binder(t)\n",
    "        binder = Lambda if t.is_lambda() else Exists if t.is_exists() else ForAll\n",
    "        return binder(*vs, beta0_norm(ctx + vs, body))\n",
    "    elif is_app(t):\n",
    "        return t.decl()(*[beta0_norm(ctx, x) for x in t.children()])\n",
    "    else:\n",
    "        raise Exception(\"Unexpected term in beta0_norm\", t)\n",
    "\n",
    "def substitute_beta0(ctx,t,*subs):\n",
    "    t = substitute(t, *subs)\n",
    "    return beta0_norm(ctx, t)\n",
    "\n",
    "x,y,z = Ints(\"x y z\")\n",
    "F,G = Consts(\"F G\", ArraySort(IntSort(), IntSort()))\n",
    "beta0_norm([], Lambda([x], Lambda([y], 3 + y)[x]))\n",
    "beta0_norm([], Lambda([x], Lambda([y], 3 + y)[4]))\n",
    "substitute_beta0([], Lambda([x], F[x]), (F, Lambda([y], 3 + y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unification looks very much like first order unification with the new quantifier and application dealing code spliced in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify(vs, p1, p2):\n",
    "    subst = {}\n",
    "    todo = [(p1,p2)]\n",
    "    no_escape = []\n",
    "    def is_var(x):\n",
    "        return any(x.eq(v) for v in vs)\n",
    "    def occurs(x, t):\n",
    "        if x.eq(t):\n",
    "            return True\n",
    "        elif any(x.eq(v) for v in no_escape):\n",
    "            return True\n",
    "        elif is_app(t):\n",
    "            return any(occurs(x, t.arg(i)) for i in range(t.num_args()))\n",
    "        return False\n",
    "    while todo:\n",
    "        # it can be instructive to print(todo) here\n",
    "        p1,p2 = todo.pop()\n",
    "        if p1.eq(p2): # delete\n",
    "            continue\n",
    "        elif is_var(p1): # elim\n",
    "            if occurs(p1, p2):\n",
    "                return None\n",
    "            # use substitute_beta_0 instead of substitute\n",
    "            todo = [(substitute_beta0(no_escape, t1,(p1,p2)), substitute_beta0(no_escape, t2,(p1,p2))) for (t1,t2) in todo]\n",
    "            subst = {k : substitute_beta0(no_escape, v, (p1,p2)) for k,v in subst.items()}\n",
    "            subst[p1] = p2\n",
    "        elif is_select(p1) and is_var(p1.arg(0)): # higher order abstract. Unmodified from pattern matching basically\n",
    "            allowedvars = p1.children()[1:]\n",
    "            if any(v not in no_escape for v in allowedvars):\n",
    "                raise Exception(\"Improper higher order pattern\", p1, p2) # we could relax this to do syntactic unification here.\n",
    "            p2 = Lambda(allowedvars, p2) # abstract out the allowed vars\n",
    "            todo.append((p1.arg(0), p2))\n",
    "        elif is_quantifier(p1): # also unchanged from pattern match\n",
    "            if not is_quantifier(p2) or not quant_kind_eq(p1,p2) or p1.num_vars() != p2.num_vars():\n",
    "                return None\n",
    "            vs1, body1 = open_binder(p1)\n",
    "            no_escape.extend(vs1)\n",
    "            body2 = beta0_norm(no_escape,substitute_vars(p2.body(), *reversed(vs1)))\n",
    "            todo.append((body1, body2))\n",
    "        elif is_var(p2) or is_select(p2) and is_var(p2.arg(0)): # orient\n",
    "            todo.append((p2,p1))\n",
    "        elif is_app(p1): # decompose\n",
    "            if not is_app(p2) or p1.decl() != p2.decl():\n",
    "                return None\n",
    "            todo.extend(zip(p1.children(), p2.children())) \n",
    "        else:\n",
    "            raise Exception(\"unexpected case\", p1, p2)\n",
    "    return subst\n",
    "\n",
    "vs = Ints(\"x y z\")\n",
    "x,y,z = vs\n",
    "\n",
    "assert unify(vs,IntVal(3), IntVal(3)) == {}\n",
    "assert unify(vs,IntVal(3), IntVal(4)) == None\n",
    "assert unify(vs,x, IntVal(3)) == {x : IntVal(3)}\n",
    "assert unify(vs, x, y) == {x : y}\n",
    "assert unify(vs, x + x, y + y) == {x : y}\n",
    "assert unify(vs, x + x, y + z) == {x : y, z : y}\n",
    "assert unify(vs,x + y, y + z) == {x : z, y : z}\n",
    "assert unify(vs,y + z, x + y) == {y : x, z : x}\n",
    "assert unify(vs, (x + x) + x, x + (x + x)) == None\n",
    "assert unify(vs, 1 + x, x) == None\n",
    "\n",
    "assert alpha_eq(unify([F,G], Lambda([x], F[x]), Lambda([y], G[y]))[F],\n",
    "                Lambda([x], G[x]))\n",
    "assert unify([F,G], Lambda([x,y],F[y] + F[y]), Lambda([x,y], x + y)) == None\n",
    "assert unify([F,G], Lambda([x,y],F[y] + F[x]), Lambda([x,y], x + y)) == None\n",
    "\n",
    "\n",
    "\n",
    "assert alpha_eq(pmatch([F,G], Lambda([x,y],F[x] + F[y]), Lambda([x,y], x + y))[F],\n",
    "                Lambda([x], x))\n",
    "assert alpha_eq(unify([F,G], Lambda([x,y],F[x] + F[y]), Lambda([x,y], G[x] + G[y]))[F],\n",
    "                Lambda([x], G[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bits and Bobbles\n",
    "\n",
    "Thanks to Cody and Graham for useful discussions.\n",
    "\n",
    "Useful for induction principles. I want an apply tactic in knuckledragger.\n",
    "\n",
    "Implementing a lambda prolog. Next time!\n",
    "\n",
    "Slotted egraphs are quite similar in flavor to miller patterns. Sort of turn your term into eta maximal form, which ferries all variables down through explicit lambdas  .\n",
    "\n",
    "I'll note that supporting multi-arity lambdas is a useful feature that is perhaps under represented in toy lambda calculi. Implementations definitely want to treat fully applied functions in a manner different from repeated curried application (push-enter https://www.cs.tufts.edu/comp/150FP/archive/simon-peyton-jones/eval-apply-jfp.pdf , Leroy's ZINC machine ). But also it lets you avoid the need for full beta reduction for some purposes. True lambda is the ulimate unneccessarily powerful and expensive thing. Ask for less. Use less. `let` also rules independent of lambda. Implementing `let` via lambda is insane.\n",
    "\n",
    "Abstract binding trees. If our programming languages offered nice support for binders, it'd be good. PFPL by Bob Harper. https://semantic-domain.blogspot.com/2015/03/abstract-binding-trees.html\n",
    "\n",
    "HOAS. Sometimes hoas is just using your host language lambdas for your DSL. In most languages, you can only apply these lambdas, not introspect them. You can introspect by reifying into a first order syntax, but now you're doing all the work yourself.\n",
    "\n",
    "Some languages (lambda prolog) have a built in notion of lambdas that you can break down. It's nice.\n",
    "\n",
    "Most proof assitants basically have higher order unification in them. It's how their type checkers work / infer. It's how dependent pattern matching infers. The core of isabelle (Pure) is basically bolting seuqents together with higher order unification.\n",
    "\n",
    "- https://stackoverflow.com/questions/1936432/higher-order-unification \n",
    "- https://github.com/jozefg/higher-order-unification/blob/master/explanation.md https://github.com/jozefg/higher-order-unification  jozefg\n",
    " exmaplanation. Haskell.\n",
    "- http://conal.net/papers/elliott90.pdf conal elliott's thesis\n",
    "- http://www.lsv.fr/~dowek/Publi/unification.ps dowek chapter \n",
    "- https://www21.in.tum.de/~nipkow/pubs/lics93.html Functional Unification of Higher-Order Patterns - Tobias Nipkow\n",
    "- https://dl.acm.org/doi/10.1145/1637837.1637839  Automatically computing functional instantiations - Moore\n",
    "- https://inria.hal.science/hal-04716439v1/file/INRIA1977_275_pdf_impression.pdf - Proving and applying program transformations\n",
    "expressed with second-order patterns - Gerard Huet, Bernard Lang\n",
    "- https://www.sciencedirect.com/science/article/pii/S0747717189800239 Higher-order unification revisited: Complete sets of transformations - snyder gallier\n",
    "- Miller and nadathur - programming with higher order logic. https://www.lix.polytechnique.fr/Labo/Dale.Miller/lProlog/examples/code.html . https://repository.upenn.edu/cgi/viewcontent.cgi?article=1470&context=cis_reports Unification Under a Mixed Prefix - miller\n",
    "- ELPI lambda prolog \n",
    "- https://arxiv.org/pdf/2011.09507 EFFICIENT FULL HIGHER-ORDER UNIFICATION - PETAR VUKMIROVIC, ALEXANDER BENTKAMP, AND VISA NUMMELIN\n",
    "-  https://www.youtube.com/watch?v=oUX-iyvH-DA minikarnen lambdrakanren http://minikanren.org/workshop/2021/minikanren-2021-final8.pdf\n",
    "-  https://www.cs.cmu.edu/~fp/papers/optunif03.pdf Optimizing Higher-Order Pattern Unification - Brigitte Pientka and Frank Pfenning?\n",
    "-  Kovacs is wizard\n",
    "-  https://homepages.inf.ed.ac.uk/jcheney/publications/cheney05unif.pdf Relating Nominal and Higher-Order Pattern\n",
    "Unification - cheney\n",
    "- https://www.cs.cas.cz/unif-2022/Presentations/presentation_1.pdf Higher-Order Unification with\n",
    "Definition by Cases \"“Unification in Lambda-Calculi with if-then-else”\n",
    "Beeson\"\n",
    "- Zipperposition, Eprover-ho, LEO-III are ATPS with HO unify in them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python and Lambdas\n",
    "Python does let us check for equality on lambdas. It is object equality.\n",
    "We can also pattern match on them. The only pattern that'll match is a default catch all.\n",
    "\n",
    "Does this chill your blood? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "match (lambda x: x + 3):\n",
    "    case f:\n",
    "        print(f(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lambda x: x) == (lambda y: y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lambda x: x) == (lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = lambda x: x\n",
    "f == f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are used to lambda being a pretty opaque thing, but it doesn't have to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (864088669.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[13], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    lambda\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z3 zipper list[FuncDeclRef, largs, rargs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual beta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def substitute_beta0(t,t1,t2):\n",
    "    if t.eq(t1):\n",
    "        return t2\n",
    "    elif is_select(t) and t.arg(0).eq(t1):\n",
    "        return substitute_vars(t2.body(), *reversed(t.children()[1:]))\n",
    "    elif is_quantifier(t):\n",
    "        vs, body = open_binder(t)\n",
    "        binder = Lambda if t.is_lambda() else Exists if t.is_exists() else ForAll\n",
    "        return binder(vs, substitute_beta_0(body, t1, t2))\n",
    "    elif is_app(t):\n",
    "        return t.decl()(*[substitute_beta_0(t.arg(i), t1, t2) for i in range(t.num_args())])\n",
    "    else:\n",
    "        raise Exception(\"Unexpected term in subst_beta_0\", t)\n",
    "#substitute_beta0(Lambda([x], F[x]), F, Lambda([y], 3 + y))\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We can store the avars e can hold\n",
    "Or we could have the things it is forbidden to hold?\n",
    "Or we could skolmize and make E a higher order variable\n",
    "\n",
    "\n",
    "This is not going to be the most elegant because I wish I had a Var constructor to my term type. And it should take arguments.\n",
    "\n",
    "```ocaml\n",
    "type term =\n",
    "   | App of decl * term list\n",
    "   | Var of decl * term list (* var list *)\n",
    "   | BVar of int\n",
    "   | FVar of ident\n",
    "   \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from z3 import *\n",
    "\n",
    "def prefix(goal):\n",
    "    \"\"\"\n",
    "    Strip off quantifier prefix.\n",
    "    \"\"\"\n",
    "    ectx = {}\n",
    "    avars = []\n",
    "    while is_quantifier(goal):\n",
    "        body,vs = open_binder(goal)\n",
    "        if goal.is_forall():\n",
    "            avars.extend(vs)\n",
    "        elif goal.is_exists():\n",
    "            for v in vs:\n",
    "                avs = avars.copy()\n",
    "                ectx[v] = avs\n",
    "        goal = body\n",
    "    return goal,ectx,avars\n",
    "            \n",
    "def gen_unify(goal):\n",
    "    goal, ectx, avars = prefix(goal)\n",
    "    assert goal.decl().name() == \"=\"\n",
    "    lhs,rhs = goal.children()\n",
    "    return unify(lhs,rhs,ectx,avars)\n",
    "\n",
    "\n",
    "def abstract(t, ts):\n",
    "    []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def occurs(naughties, t):\n",
    "    if t in naughties:\n",
    "        return True\n",
    "    if is_app(t):\n",
    "        return any(occurs(naughty, c) for c in t.children())\n",
    "    return False\n",
    "\n",
    "def unify(p1,p2,ectx,avars):\n",
    "    subst = {}\n",
    "    todo = [(p1,p2)]\n",
    "    while todo:\n",
    "        p1,p2 = todo.pop() # we could pop _any_ of the todos, not just the top.\n",
    "        if p1.eq(p2): # delete\n",
    "            continue\n",
    "        if p1 in ectx: # regular is_var\n",
    "        elif is_app(p1) and p1.decl().name() == \"Select\" and p1.get_arg(0) in ectx: # higher order match\n",
    "            if occurs(avars - ectx[p1] + [p1], p2):\n",
    "                return None\n",
    "            todo = [(substitute(t1,(p1,p2)), substitute(t2,(p1,p2))) for (t1,t2) in todo]\n",
    "            subst = {k : substitute(v, (p1,p2)) for k,v in subst.items()}\n",
    "            subst[p1] = p2\n",
    "        elif is_app(p2) and p2.decl() in vs: # orient\n",
    "            todo.append((p2,p1))\n",
    "        if is_quantifier(p1):\n",
    "            if p1.is_lambda() and is_quantifier(p2) and p1.is_quantifier():\n",
    "                b1,vs = open_binder(p1)\n",
    "                b2 = substitute_vars(p2.body(), vs) # instantiate\n",
    "                avars.extend(vs) # These variable shall not escape\n",
    "                todo.append((b1,b2))\n",
    "        elif is_app(p1): # decompose\n",
    "            if not is_app(p2) or p1.decl() != p2.decl():\n",
    "                return None\n",
    "            todo.extend(zip(p1.children(), p2.children())) \n",
    "        else:\n",
    "            raise Exception(\"unexpected case\", p1, p2)\n",
    "    return subst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[f, x, x]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from z3 import *\n",
    "f = Const(\"f\", ArraySort(IntSort(), IntSort(), IntSort()))\n",
    "x = Int(\"x\")\n",
    "f[x, x].children()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "Z3Exception",
     "evalue": "b'parser error'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZ3Exception\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m x,y,z \u001b[38;5;241m=\u001b[39m vs\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m unify(IntVal(\u001b[38;5;241m3\u001b[39m), IntVal(\u001b[38;5;241m3\u001b[39m), vs) \u001b[38;5;241m==\u001b[39m {}\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[43munify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIntVal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIntVal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m unify(x, IntVal(\u001b[38;5;241m3\u001b[39m), vs) \u001b[38;5;241m==\u001b[39m {x : IntVal(\u001b[38;5;241m3\u001b[39m)}\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m unify(x, y, vs) \u001b[38;5;241m==\u001b[39m {x : y}\n",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m, in \u001b[0;36munify\u001b[0;34m(p1, p2, vs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p1\u001b[38;5;241m.\u001b[39meq(p2): \u001b[38;5;66;03m# delete\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_app(p1) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mp1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvs\u001b[49m: \u001b[38;5;66;03m# elim\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m occurs(p1, p2):\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/z3/z3.py:1033\u001b[0m, in \u001b[0;36mExprRef.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m other \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1033\u001b[0m a, b \u001b[38;5;241m=\u001b[39m \u001b[43m_coerce_exprs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BoolRef(Z3_mk_eq(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx_ref(), a\u001b[38;5;241m.\u001b[39mas_ast(), b\u001b[38;5;241m.\u001b[39mas_ast()), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/z3/z3.py:1237\u001b[0m, in \u001b[0;36m_coerce_exprs\u001b[0;34m(a, b, ctx)\u001b[0m\n\u001b[1;32m   1235\u001b[0m s \u001b[38;5;241m=\u001b[39m _coerce_expr_merge(s, b)\n\u001b[1;32m   1236\u001b[0m a \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mcast(a)\n\u001b[0;32m-> 1237\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (a, b)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/z3/z3.py:2406\u001b[0m, in \u001b[0;36mArithSortRef.cast\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m   2404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2405\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_int():\n\u001b[0;32m-> 2406\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIntVal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2407\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_real():\n\u001b[1;32m   2408\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m RealVal(val, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/z3/z3.py:3243\u001b[0m, in \u001b[0;36mIntVal\u001b[0;34m(val, ctx)\u001b[0m\n\u001b[1;32m   3235\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a Z3 integer value. If `ctx=None`, then the global context is used.\u001b[39;00m\n\u001b[1;32m   3236\u001b[0m \n\u001b[1;32m   3237\u001b[0m \u001b[38;5;124;03m>>> IntVal(1)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3240\u001b[0m \u001b[38;5;124;03m100\u001b[39;00m\n\u001b[1;32m   3241\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3242\u001b[0m ctx \u001b[38;5;241m=\u001b[39m _get_ctx(ctx)\n\u001b[0;32m-> 3243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m IntNumRef(\u001b[43mZ3_mk_numeral\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_to_int_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIntSort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mast\u001b[49m\u001b[43m)\u001b[49m, ctx)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/z3/z3core.py:2378\u001b[0m, in \u001b[0;36mZ3_mk_numeral\u001b[0;34m(a0, a1, a2, _elems)\u001b[0m\n\u001b[1;32m   2376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mZ3_mk_numeral\u001b[39m(a0, a1, a2, _elems\u001b[38;5;241m=\u001b[39mElementaries(_lib\u001b[38;5;241m.\u001b[39mZ3_mk_numeral)):\n\u001b[1;32m   2377\u001b[0m   r \u001b[38;5;241m=\u001b[39m _elems\u001b[38;5;241m.\u001b[39mf(a0, _str_to_bytes(a1), a2)\n\u001b[0;32m-> 2378\u001b[0m   \u001b[43m_elems\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2379\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/z3/z3core.py:1566\u001b[0m, in \u001b[0;36mElementaries.Check\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m   1564\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_error_code(ctx)\n\u001b[1;32m   1565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mOK:\n\u001b[0;32m-> 1566\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mException(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_error_message(ctx, err))\n",
      "\u001b[0;31mZ3Exception\u001b[0m: b'parser error'"
     ]
    }
   ],
   "source": [
    "from z3 import *\n",
    "def occurs(x, t):\n",
    "    if x.eq(t):\n",
    "        return True\n",
    "    if is_app(t):\n",
    "        return any(occurs(x, t.arg(i)) for i in range(t.num_args()))\n",
    "    return False\n",
    "\n",
    "def unify(p1,p2, vs):\n",
    "    subst = {}\n",
    "    todo = [(p1,p2)]\n",
    "    while todo:\n",
    "        p1,p2 = todo.pop() # we could pop _any_ of the todos, not just the top.\n",
    "        if p1.eq(p2): # delete\n",
    "            continue\n",
    "        elif is_app(p1) and p1.decl() in vs: # elim\n",
    "            if occurs(p1, p2):\n",
    "                return None\n",
    "            todo = [(substitute(t1,(p1,p2)), substitute(t2,(p1,p2))) for (t1,t2) in todo]\n",
    "            subst = {k : substitute(v, (p1,p2)) for k,v in subst.items()}\n",
    "            subst[p1] = p2\n",
    "        elif is_app(p2) and p2.decl() in vs: # orient\n",
    "            todo.append((p2,p1))\n",
    "        elif is_app(p1): # decompose\n",
    "            if not is_app(p2) or p1.decl() != p2.decl():\n",
    "                return None\n",
    "            todo.extend(zip(p1.children(), p2.children())) \n",
    "        else:\n",
    "            raise Exception(\"unexpected case\", p1, p2)\n",
    "    return subst\n",
    "\n",
    "vs = Ints(\"x y z\")\n",
    "x,y,z = vs\n",
    "assert unify(IntVal(3), IntVal(3), vs) == {}\n",
    "assert unify(IntVal(3), IntVal(4), vs) == None\n",
    "assert unify(x, IntVal(3), vs) == {x : IntVal(3)}\n",
    "assert unify(x, y, vs) == {x : y}\n",
    "assert unify(x + x, y + y, vs) == {x : y}\n",
    "assert unify(x + x, y + z, vs) == {x : y, z : y}\n",
    "assert unify(x + y, y + z, vs) == {x : z, y : z}\n",
    "assert unify(y + z, x + y, vs) == {y : x, z : x}\n",
    "# non terminating if no occurs check\n",
    "assert unify((x + x) + x, x + (x + x), vs) == None\n",
    "assert unify(1 + x, x, vs) == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclass import dataclass\n",
    "@dataclass\n",
    "class Var():\n",
    "    x : ExprRef\n",
    "    ctx : Context\n",
    "    def collect_a(self):\n",
    "        res = []\n",
    "        x = self \n",
    "        while x != None:\n",
    "            if isinstance(x, AVar):\n",
    "                res.append(x)\n",
    "            x = x.ctx\n",
    "        return res\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "class EVar(Var):\n",
    "    x : ExprRef\n",
    "    ctx : Context\n",
    "class AVar(Var):\n",
    "\n",
    "\n",
    "def unify(avars, edecls, p1,p2):\n",
    "    edecls = []\n",
    "\n",
    "    def freshe():\n",
    "        edecl = Function(\"e_\", [x.sort() for x in avars])\n",
    "        te = edecl(*avars)\n",
    "        substitute_vars(t, te)\n",
    "\n",
    "\n",
    "def unify(p1,p2 vctx):\n",
    "    subst = {}\n",
    "    ectx = {}\n",
    "    todo = [([], p1,p2)]\n",
    "    while todo:\n",
    "        ctx,p1,p2 = todo.pop()\n",
    "        if p1.eq(p2):\n",
    "            continue\n",
    "        if is_quantifier(p1):\n",
    "            body, vs = open_binder(p1)\n",
    "            if p1.is_exists():\n",
    "                for v in vs:\n",
    "                    ectx[v] = ctx\n",
    "                todo.append((ctx, body, p2))\n",
    "            elif p1.is_forall():\n",
    "                todo.append((ctx + vs, body, p2))\n",
    "            elif p1.is_lambda():\n",
    "                todo.append((ctx + vs, body, p2))\n",
    "        elif is_var(p1):\n",
    "            todo = [(substitute(t1,(p1,p2)), substitute(t2,(p1,p2))) for (t1,t2) in todo]\n",
    "            subst = {k : substitute(v, (p1,p2)) for k,v in subst.items()}\n",
    "            subst[p1] = p2\n",
    "        elif is_var(p2):\n",
    "            todo.append((ctx,p2,p1))\n",
    "        elif is_app(p1):\n",
    "            if not is_app(p2) or p1.decl() != p2.decl():\n",
    "                return None\n",
    "            todo.extend(zip(p1.children(), p2.children())) \n",
    "        else:\n",
    "            raise Exception(\"unexpected case\", p1, p2)\n",
    "    return subst\n",
    "\n",
    "def unify(p1,p2, vctx):\n",
    "    subst = {}\n",
    "    todo = [(p1,p2)]\n",
    "    while todo:\n",
    "        p1,p2 = todo.pop()\n",
    "        if p1.eq(p2):\n",
    "            continue\n",
    "        elif is_var(p1):\n",
    "            if # do \"occurs\"\n",
    "                in vctx[p1] # narrow the contx  of any var in rhs.\n",
    "            todo = [(substitute(t1,(p1,p2)), substitute(t\n",
    "                                                        \n",
    "def unify_miller(p1,p2, vs):\n",
    "    if p1.decl() in vs: # is_var\n",
    "        \n",
    "        #substitute(   p1.children(),  \n",
    "        # abstract out children\n",
    "        subst[p1.decl()] = Lambda(freshes, substitute(p1, zip(p1.children(), freshes)))\n",
    "        t = Lambda(freshes, substitute(p1, zip(p1.children(), freshes)))\n",
    "        check_no_escape(t)\n",
    "        todo = [  , substitute(p1)]\n",
    "        subst[p1.decl()] = t\n",
    "    todo = []\n",
    "    noescape = []\n",
    "    if is_quantifier(p1)\n",
    "        if is_quantifier(p2) and p1.num_vars() == p2.num_vars() and # sorts:\n",
    "            body, vs = open_binder(p1)\n",
    "            noescape += vs\n",
    "            body2 = instantiate(p2, vs)\n",
    "            todo.append((body,body2))\n",
    "\n",
    "\n",
    "Exisst x, p(x) = exists y, p(y) # I guess we could allow this? Kind of odd\n",
    "ex(lam x, p(x))\n",
    "all(lam x, p(x)) # all is basically treated as a lambda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmatch(t : z3.ExprRef, vs : list[z3.ExprRef], pat : z3.ExprRef) -> z3.ExprRef:\n",
    "    if len(vs) == 0:\n",
    "        return t\n",
    "    else:\n",
    "        return z3.simplify(z3.substitute(t, list(zip(vs, [z3.FreshReal('v') for _ in vs]))))\n",
    "\n",
    "def pmatch(vs, pat, t):\n",
    "    subst = {}\n",
    "    def worker(pat, t):\n",
    "        if any(pat.eq(v) for v in vs):\n",
    "            if pat in subst:\n",
    "                return subst[pat].eq(t)\n",
    "            else:\n",
    "                subst[pat] = t\n",
    "                return True\n",
    "        if is_app(pat):\n",
    "            if is_app(t) and pat.decl() == t.decl():\n",
    "                return all(worker(pat.arg(i), t.arg(i)) for i in range(pat.num_args()))\n",
    "            return False\n",
    "    if worker(pat, t):\n",
    "        return subst"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
