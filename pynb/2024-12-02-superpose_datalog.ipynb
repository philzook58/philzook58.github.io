{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Superposition as a Super Datalog\n",
    "date: 2024-12-02\n",
    "---\n",
    "\n",
    "[Resolution](https://en.wikipedia.org/wiki/Resolution_(logic)) is an old technique in automated reasoning. [Datalog](https://en.wikipedia.org/wiki/Datalog) is a family of languages capable of expressing recursive database queries. The ancestry of datalog can be traced back to resolution and it is interesting and fruitful to examine the capabilities of modern resolution style provers in light of the use cases and operational interpretability of datalog.\n",
    "\n",
    "Datalog is quite simple. You have a starting set of facts in relations for example the edges in a graph. These can be stored as a relational table.\n",
    "\n",
    "```prolog\n",
    "edge(1,2).\n",
    "edge(2,3).\n",
    "```\n",
    "\n",
    "Then you have rules that iteratively derive new facts from the currently existing facts. The is done by making a database query out of the body of the rule, and inserting the head with the found values.\n",
    "\n",
    "```prolog\n",
    "path(X,Y) :- edge(X,Y).  % if there is an edge, there is a path\n",
    "path(X,Y) :- edge(X,Z), path(Z,Y). % You can paste an edge on the end of a path to get a new path.\n",
    "```\n",
    "\n",
    "A good datalog is [souffle](https://souffle-lang.github.io/simple). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/path.dl\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/path.dl\n",
    ".decl edge(x:number, y:number)\n",
    "edge(1,2).\n",
    "edge(2,3).\n",
    "\n",
    ".decl path(x:number, y:number)\n",
    ".output path(IO=stdout)\n",
    "path(X,Y) :- edge(X,Y).\n",
    "path(X,Y) :- edge(X,Z), path(Z,Y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "path\n",
      "===============\n",
      "1\t2\n",
      "1\t3\n",
      "2\t3\n",
      "===============\n"
     ]
    }
   ],
   "source": [
    "! souffle /tmp/path.dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also express basically the same thing to a first order theorem prover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/path.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/path.p\n",
    "\n",
    "cnf(edgeab, axiom, edge(a,b)).\n",
    "cnf(edgebc, axiom, edge(b,c)).\n",
    "cnf(edge_is_path , axiom, path(X,Y) | ~edge(X,Y)).\n",
    "cnf(path_trans, axiom, path(X,Z) | ~edge(X,Y) | ~path(Y,Z)).\n",
    "\n",
    "% alternative fof syntax for rules. There are more https://www.tptp.org/\n",
    "%fof(edge_is_path , axiom, ![X,Y] : (edge(X,Y) => path(X,Y))).\n",
    "%fof(path_transm, axiom, ![X,Y,Z] : ((path(X,Z) & edge(X,Y)) => path(Y,Z)))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the first two assertions establish the base edge facts and the the last two establish rules. To translate the logic programming rules to a first order ATP clause, we take the classical correspondence that implication `a -> b` is equivalent to `~a | b`. Hence for example  `path(X,Z) :- edge(X,Y), path(Y,Z).` becomes `path(X,Z) | ~edge(X,Y) | ~path(Y,Z)`. We can kind of think of negation `~` as a marker stating this literal goes in the body of the rule. There is an alternate prolog universe in which this was standard notation.\n",
    "\n",
    "Two premier resolution style theorems provers are [Vampire](https://vprover.github.io/usage.html) and [eprover](https://github.com/eprover/eprover). They are usually top in class in the [CADE ATP competition](https://tptp.org/CASC/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Running in auto input_syntax mode. Trying TPTP\n",
      "% SZS status Satisfiable for path\n",
      "% # SZS output start Saturation.\n",
      "cnf(u13,axiom,\n",
      "    ~edge(b,X0) | path(X0,c)).\n",
      "\n",
      "cnf(u12,axiom,\n",
      "    ~edge(a,X0) | path(X0,b)).\n",
      "\n",
      "cnf(u15,axiom,\n",
      "    path(c,c)).\n",
      "\n",
      "cnf(u17,axiom,\n",
      "    ~edge(c,X0) | path(X0,c)).\n",
      "\n",
      "cnf(u19,axiom,\n",
      "    ~edge(c,X0) | path(X0,b)).\n",
      "\n",
      "cnf(u14,axiom,\n",
      "    path(b,b)).\n",
      "\n",
      "cnf(u16,axiom,\n",
      "    ~edge(b,X0) | path(X0,b)).\n",
      "\n",
      "cnf(u9,axiom,\n",
      "    ~path(X0,X2) | ~edge(X0,X1) | path(X1,X2)).\n",
      "\n",
      "cnf(u18,axiom,\n",
      "    path(c,b)).\n",
      "\n",
      "cnf(u8,axiom,\n",
      "    ~edge(X0,X1) | path(X0,X1)).\n",
      "\n",
      "cnf(u1,axiom,\n",
      "    edge(a,b)).\n",
      "\n",
      "cnf(u11,axiom,\n",
      "    path(b,c)).\n",
      "\n",
      "cnf(u10,axiom,\n",
      "    path(a,b)).\n",
      "\n",
      "cnf(u2,axiom,\n",
      "    edge(b,c)).\n",
      "\n",
      "% # SZS output end Saturation.\n",
      "% ------------------------------\n",
      "% Version: Vampire 4.9 (commit 5ad494e78 on 2024-06-14 14:05:27 +0100)\n",
      "% Linked with Z3 4.12.3.0 79bbbf76d0c123481c8ca05cd3a98939270074d3 z3-4.8.4-7980-g79bbbf76d\n",
      "% Termination reason: Satisfiable\n",
      "\n",
      "% Memory used [KB]: 429\n",
      "% Time elapsed: 0.0000 s\n",
      "perf_event_open failed (instruction limiting will be disabled): Permission denied\n",
      "(If you are seeing 'Permission denied' ask your admin to run 'sudo sysctl -w kernel.perf_event_paranoid=-1' for you.)\n",
      "% ------------------------------\n",
      "% ------------------------------\n"
     ]
    }
   ],
   "source": [
    "! vampire /tmp/path.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh wow, sweet. That was easy. Blog post over.\n",
    "\n",
    "No, sorry.\n",
    "\n",
    "Really rule of thumb is that you should never be running either vampire or eprover without a `--mode` or `--auto` flag. The default modes are enormously slower.\n",
    "\n",
    "In `casc_sat` mode we get piles of difficult to interpret garbage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Running in auto input_syntax mode. Trying TPTP\n",
      "% WARNING: time unlimited strategy and instruction limiting not in place - attempting to translate instructions to time\n",
      "% fmb+10_1:1_sil=256000:i=98885:tgt=full:fmbsr=1.3:fmbss=10_0 on path for (495ds/98885Mi)\n",
      "Detected minimum model sizes of [1]\n",
      "Detected maximum model sizes of [3]\n",
      "TRYING [10]\n",
      "Finite Model Found!\n",
      "% SZS status Satisfiable for path\n",
      "perf_event_open failed (instruction limiting will be disabled): Permission denied\n",
      "(If you are seeing 'Permission denied' ask your admin to run 'sudo sysctl -w kernel.perf_event_paranoid=-1' for you.)\n",
      "% Solution written to \"/tmp/vampire-proof-3398902\"\n",
      "% SZS output start FiniteModel for path\n",
      "tff('declare_$i1',type,a:$i).\n",
      "tff('declare_$i2',type,b:$i).\n",
      "tff('declare_$i3',type,'fmb_$i_3':$i).\n",
      "tff('declare_$i4',type,a:$i).\n",
      "tff('declare_$i5',type,a:$i).\n",
      "tff('declare_$i6',type,a:$i).\n",
      "tff('declare_$i7',type,b:$i).\n",
      "tff('declare_$i8',type,a:$i).\n",
      "tff('declare_$i9',type,a:$i).\n",
      "tff('declare_$i10',type,'fmb_$i_10':$i).\n",
      "tff('finite_domain_$i',axiom,\n",
      "      ! [X:$i] : (\n",
      "         X = a | X = b | X = 'fmb_$i_3' | X = a | X = a | \n",
      "         X = a | X = b | X = a | X = a | X = 'fmb_$i_10'\n",
      "      ) ).\n",
      "\n",
      "tff('distinct_domain_$i',axiom,\n",
      "         a != b & a != 'fmb_$i_3' & a != a & a != a & a != a & \n",
      "         a != b & a != a & a != a & a != 'fmb_$i_10' & b != 'fmb_$i_3' & \n",
      "         b != a & b != a & b != a & b != b & b != a & \n",
      "         b != a & b != 'fmb_$i_10' & 'fmb_$i_3' != a & 'fmb_$i_3' != a & 'fmb_$i_3' != a & \n",
      "         'fmb_$i_3' != b & 'fmb_$i_3' != a & 'fmb_$i_3' != a & 'fmb_$i_3' != 'fmb_$i_10' & a != a & \n",
      "         a != a & a != b & a != a & a != a & a != 'fmb_$i_10' & \n",
      "         a != a & a != b & a != a & a != a & a != 'fmb_$i_10' & \n",
      "         a != b & a != a & a != a & a != 'fmb_$i_10' & b != a & \n",
      "         b != a & b != 'fmb_$i_10' & a != a & a != 'fmb_$i_10' & a != 'fmb_$i_10'\n",
      ").\n",
      "\n",
      "tff(declare_c,type,c:$i).\n",
      "tff(c_definition,axiom,c = a).\n",
      "tff(declare_edge,type,edge: ($i * $i) > $o).\n",
      "tff(predicate_edge,axiom,\n",
      "           edge(a,a)\n",
      "         & edge(a,b)\n",
      "         & ~edge(a,'fmb_$i_3')\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,b) undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,'fmb_$i_10') undefined in model\n",
      "         & edge(b,a)\n",
      "         & edge(b,b)\n",
      "         & ~edge(b,'fmb_$i_3')\n",
      "%         edge(b,a) undefined in model\n",
      "%         edge(b,a) undefined in model\n",
      "%         edge(b,a) undefined in model\n",
      "%         edge(b,b) undefined in model\n",
      "%         edge(b,a) undefined in model\n",
      "%         edge(b,a) undefined in model\n",
      "%         edge(b,'fmb_$i_10') undefined in model\n",
      "         & ~edge('fmb_$i_3',a)\n",
      "         & ~edge('fmb_$i_3',b)\n",
      "         & ~edge('fmb_$i_3','fmb_$i_3')\n",
      "%         edge('fmb_$i_3',a) undefined in model\n",
      "%         edge('fmb_$i_3',a) undefined in model\n",
      "%         edge('fmb_$i_3',a) undefined in model\n",
      "%         edge('fmb_$i_3',b) undefined in model\n",
      "%         edge('fmb_$i_3',a) undefined in model\n",
      "%         edge('fmb_$i_3',a) undefined in model\n",
      "%         edge('fmb_$i_3','fmb_$i_10') undefined in model\n",
      "         & ~edge(a,a)\n",
      "         & ~edge(a,b)\n",
      "         & ~edge(a,'fmb_$i_3')\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,b) undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,'fmb_$i_10') undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,b) undefined in model\n",
      "%         edge(a,'fmb_$i_3') undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,b) undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,'fmb_$i_10') undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,b) undefined in model\n",
      "%         edge(a,'fmb_$i_3') undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,b) undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,'fmb_$i_10') undefined in model\n",
      "%         edge(b,a) undefined in model\n",
      "%         edge(b,b) undefined in model\n",
      "%         edge(b,'fmb_$i_3') undefined in model\n",
      "%         edge(b,a) undefined in model\n",
      "%         edge(b,a) undefined in model\n",
      "%         edge(b,a) undefined in model\n",
      "%         edge(b,b) undefined in model\n",
      "%         edge(b,a) undefined in model\n",
      "%         edge(b,a) undefined in model\n",
      "%         edge(b,'fmb_$i_10') undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,b) undefined in model\n",
      "%         edge(a,'fmb_$i_3') undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,b) undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,'fmb_$i_10') undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,b) undefined in model\n",
      "%         edge(a,'fmb_$i_3') undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,b) undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,a) undefined in model\n",
      "%         edge(a,'fmb_$i_10') undefined in model\n",
      "%         edge('fmb_$i_10',a) undefined in model\n",
      "%         edge('fmb_$i_10',b) undefined in model\n",
      "%         edge('fmb_$i_10','fmb_$i_3') undefined in model\n",
      "%         edge('fmb_$i_10',a) undefined in model\n",
      "%         edge('fmb_$i_10',a) undefined in model\n",
      "%         edge('fmb_$i_10',a) undefined in model\n",
      "%         edge('fmb_$i_10',b) undefined in model\n",
      "%         edge('fmb_$i_10',a) undefined in model\n",
      "%         edge('fmb_$i_10',a) undefined in model\n",
      "%         edge('fmb_$i_10','fmb_$i_10') undefined in model\n",
      "\n",
      ").\n",
      "\n",
      "tff(declare_path,type,path: ($i * $i) > $o).\n",
      "tff(predicate_path,axiom,\n",
      "           path(a,a)\n",
      "         & path(a,b)\n",
      "         & path(a,'fmb_$i_3')\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,b) undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,'fmb_$i_10') undefined in model\n",
      "         & path(b,a)\n",
      "         & path(b,b)\n",
      "         & path(b,'fmb_$i_3')\n",
      "%         path(b,a) undefined in model\n",
      "%         path(b,a) undefined in model\n",
      "%         path(b,a) undefined in model\n",
      "%         path(b,b) undefined in model\n",
      "%         path(b,a) undefined in model\n",
      "%         path(b,a) undefined in model\n",
      "%         path(b,'fmb_$i_10') undefined in model\n",
      "         & path('fmb_$i_3',a)\n",
      "         & path('fmb_$i_3',b)\n",
      "         & path('fmb_$i_3','fmb_$i_3')\n",
      "%         path('fmb_$i_3',a) undefined in model\n",
      "%         path('fmb_$i_3',a) undefined in model\n",
      "%         path('fmb_$i_3',a) undefined in model\n",
      "%         path('fmb_$i_3',b) undefined in model\n",
      "%         path('fmb_$i_3',a) undefined in model\n",
      "%         path('fmb_$i_3',a) undefined in model\n",
      "%         path('fmb_$i_3','fmb_$i_10') undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,b) undefined in model\n",
      "%         path(a,'fmb_$i_3') undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,b) undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,'fmb_$i_10') undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,b) undefined in model\n",
      "%         path(a,'fmb_$i_3') undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,b) undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,'fmb_$i_10') undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,b) undefined in model\n",
      "%         path(a,'fmb_$i_3') undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,b) undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,'fmb_$i_10') undefined in model\n",
      "%         path(b,a) undefined in model\n",
      "%         path(b,b) undefined in model\n",
      "%         path(b,'fmb_$i_3') undefined in model\n",
      "%         path(b,a) undefined in model\n",
      "%         path(b,a) undefined in model\n",
      "%         path(b,a) undefined in model\n",
      "%         path(b,b) undefined in model\n",
      "%         path(b,a) undefined in model\n",
      "%         path(b,a) undefined in model\n",
      "%         path(b,'fmb_$i_10') undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,b) undefined in model\n",
      "%         path(a,'fmb_$i_3') undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,b) undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,'fmb_$i_10') undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,b) undefined in model\n",
      "%         path(a,'fmb_$i_3') undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,b) undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,a) undefined in model\n",
      "%         path(a,'fmb_$i_10') undefined in model\n",
      "%         path('fmb_$i_10',a) undefined in model\n",
      "%         path('fmb_$i_10',b) undefined in model\n",
      "%         path('fmb_$i_10','fmb_$i_3') undefined in model\n",
      "%         path('fmb_$i_10',a) undefined in model\n",
      "%         path('fmb_$i_10',a) undefined in model\n",
      "%         path('fmb_$i_10',a) undefined in model\n",
      "%         path('fmb_$i_10',b) undefined in model\n",
      "%         path('fmb_$i_10',a) undefined in model\n",
      "%         path('fmb_$i_10',a) undefined in model\n",
      "%         path('fmb_$i_10','fmb_$i_10') undefined in model\n",
      "\n",
      ").\n",
      "\n",
      "% SZS output end FiniteModel for path\n",
      "% ------------------------------\n",
      "% Version: Vampire 4.9 (commit 5ad494e78 on 2024-06-14 14:05:27 +0100)\n",
      "% Linked with Z3 4.12.3.0 79bbbf76d0c123481c8ca05cd3a98939270074d3 z3-4.8.4-7980-g79bbbf76d\n",
      "% Termination reason: Satisfiable\n",
      "\n",
      "% Memory used [KB]: 682\n",
      "% Time elapsed: 0.001 s\n",
      "% ------------------------------\n",
      "% ------------------------------\n",
      "% Success in time 0.005 s\n"
     ]
    }
   ],
   "source": [
    "! vampire --mode casc_sat /tmp/path.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eprover in it's default mode does not terminate/saturate on this problem. We can kind of see the problem that it is resolving rules against rules, building larger and larger transitivity clauses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Initializing proof state\n",
      "# Scanning for AC axioms\n",
      "#\n",
      "#cnf(i_0_3, plain, (edge(a,b))).\n",
      "#\n",
      "#cnf(i_0_4, plain, (edge(b,c))).\n",
      "#\n",
      "#cnf(i_0_5, plain, (path(X1,X2)|~edge(X1,X2))).\n",
      "#\n",
      "#cnf(i_0_6, plain, (path(X3,X2)|~path(X1,X2)|~edge(X1,X3))).\n",
      "#\n",
      "#cnf(i_0_8, plain, (path(X1,X2)|~edge(X3,X1)|~edge(X3,X2))).\n",
      "#\n",
      "#cnf(i_0_7, plain, (path(X1,X2)|~path(X4,X2)|~edge(X3,X1)|~edge(X4,X3))).\n",
      "#\n",
      "#cnf(i_0_9, plain, (path(X1,X2)|~edge(X3,X1)|~edge(X4,X3)|~edge(X4,X2))).\n",
      "##\n",
      "#cnf(i_0_10, plain, (path(X1,X2)|~path(X4,X2)|~edge(X3,X1)|~edge(X5,X3)|~edge(X4,X5))).\n",
      "\n",
      "# Failure: User resource limit exceeded!\n",
      "# SZS status ResourceOut\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --total-clause-set-limit=15 /tmp/path.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we can get it to terminate with a reasonable database if we start tweaking the options controlling it's execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Initializing proof state\n",
      "# Scanning for AC axioms\n",
      "#\n",
      "#cnf(i_0_3, plain, (edge(a,b))).\n",
      "#\n",
      "#cnf(i_0_4, plain, (edge(b,c))).\n",
      "#\n",
      "#cnf(i_0_5, plain, (path(X1,X2)|~edge(X1,X2))).\n",
      "#\n",
      "#cnf(i_0_7, plain, (path(b,c))).\n",
      "#\n",
      "#cnf(i_0_8, plain, (path(a,b))).\n",
      "#\n",
      "#cnf(i_0_6, plain, (path(X3,X2)|~path(X1,X2)|~edge(X1,X3))).\n",
      "#\n",
      "#cnf(i_0_9, plain, (path(X1,c)|~edge(b,X1))).\n",
      "#\n",
      "#cnf(i_0_11, plain, (path(c,c))).\n",
      "#\n",
      "#cnf(i_0_10, plain, (path(X1,b)|~edge(a,X1))).\n",
      "#\n",
      "#cnf(i_0_13, plain, (path(b,b))).\n",
      "#\n",
      "#cnf(i_0_12, plain, (path(X1,c)|~edge(c,X1))).\n",
      "#\n",
      "#cnf(i_0_14, plain, (path(X1,b)|~edge(b,X1))).\n",
      "#\n",
      "#cnf(i_0_15, plain, (path(c,b))).\n",
      "#\n",
      "#cnf(i_0_16, plain, (path(X1,b)|~edge(c,X1))).\n",
      "\n",
      "# No proof found!\n",
      "# SZS status Satisfiable\n",
      "# Processed positive unit clauses:\n",
      "cnf(i_0_3, plain, (edge(a,b))).\n",
      "cnf(i_0_4, plain, (edge(b,c))).\n",
      "cnf(i_0_7, plain, (path(b,c))).\n",
      "cnf(i_0_8, plain, (path(a,b))).\n",
      "cnf(i_0_11, plain, (path(c,c))).\n",
      "cnf(i_0_13, plain, (path(b,b))).\n",
      "cnf(i_0_15, plain, (path(c,b))).\n",
      "\n",
      "# Processed negative unit clauses:\n",
      "\n",
      "# Processed non-unit clauses:\n",
      "cnf(i_0_5, plain, (path(X1,X2)|~edge(X1,X2))).\n",
      "cnf(i_0_6, plain, (path(X1,X2)|~path(X3,X2)|~edge(X3,X1))).\n",
      "cnf(i_0_9, plain, (path(X1,c)|~edge(b,X1))).\n",
      "cnf(i_0_10, plain, (path(X1,b)|~edge(a,X1))).\n",
      "cnf(i_0_12, plain, (path(X1,c)|~edge(c,X1))).\n",
      "cnf(i_0_14, plain, (path(X1,b)|~edge(b,X1))).\n",
      "cnf(i_0_16, plain, (path(X1,b)|~edge(c,X1))).\n",
      "\n",
      "# Unprocessed positive unit clauses:\n",
      "\n",
      "# Unprocessed negative unit clauses:\n",
      "\n",
      "# Unprocessed non-unit clauses:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --print-saturated --literal-selection-strategy=\"SelectNegativeLiterals\" /tmp/path.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So these provers in their rawest black box form can't really be used as datalogs, but if we peer under the covers a bit at the operational mechanisms, we can do it.\n",
    "\n",
    "Even more so than that, in terms of pure raw mechanism these systems subsume things like equality saturation and knuth bendix completion. The difficulty id controlling them well enough to get the thing we want out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordered Resolution and Selection\n",
    "\n",
    "The naive form of ground binary resolution looks like this. Regardless of whether A is true or false, we know one at least one of the clauses C and D is true.\n",
    "\n",
    "```\n",
    "C \\/ A    ~A \\/ D\n",
    "-----------------\n",
    "     C \\/ D  \n",
    "```\n",
    "\n",
    "Our nontermination with eprover is because yea, this would just keep growing because the rule `path(X,Z) | ~edge(X,Y) | ~path(Y,Z)` could resolve against itself forever.\n",
    "\n",
    "[Ordered resolution](https://lawrencecpaulson.github.io/papers/bachmair-hbar-resolution.pdf) is a paradigm for restricting the resolution process while maintaining completeness. It only requires certain resolutions to go through that fit the conditions of a term ordering and literal selection function.\n",
    "\n",
    "An idea that is both simple and complex is that of [Term Orderings](https://www.cs.unm.edu/~mccune/prover9/manual/2009-11A/term-order.html). Sometimes, it makes sense to have an ordering on terms (simpler, smaller, faster, more expanded/foiled, defined earlier are all possible natural partial orders on terms). Having this play nice with unification variables/substitution and/or theories and/or alpha renaming and/or [lambda computation](https://arxiv.org/abs/1506.03943) is quite a bit trickier (rewrite and simplification orderings). \n",
    "\n",
    "Ordered resolution uses a term ordering sort of as a recipe on how to orient a `|` clause into a directed `:-` rule. If the largest literal is positive (\"productive clauses\"), it picked as the head. Other positive literals become negations in the body of the rule. If the largest literal is negative, then the entire clause is a constraint (Kind of a rule with head false `:- a, b, c.` You see these sorts of things in answer set programming, or you could see it if you are trying to refutation prove using datalog `false() :- a(),b(),c().`).\n",
    "\n",
    "At the same time, this ordering puts an ordering on the possible [Herbrand models](https://en.wikipedia.org/wiki/Herbrand_structure) (Herbrand models are sets of ground terms) of the theory, and it becomes possible to speak of a minimal model as we do in the context of datalog. A big distinction between SAT solvers and ATPs and Datalog/Answer Set Programming is a notion of [\"justification\"](https://www.philipzucker.com/minikanren_inside_z3/). Datalog only derives facts that are forced to be true. SAT solvers seemingly give you a random model if there is one. Datalog gives you a particular \"best\" model. There is a sense in which SAT solvers are also giving you a minimal model. It is minimal with respect to the current internal backtracking trail of the solvers, so a perspective on SAT is that it is building both a model and \"good\" literal ordering, or pivoting its literal ordering on the fly.\n",
    "\n",
    "From the perspective of refutation proving, when one wants to show there can't be a satisfying model, it is sufficient to show there can't be a minimal model.\n",
    "\n",
    "This is reminiscent of the notion of [symmetry breaking](https://en.wikipedia.org/wiki/Symmetry-breaking_constraints) in optimization that if there is some symmetry in your model (all reds can be swapped with blues in a graph coloring for example or permutations of vehicles in a routing problem), that it is useful to put an an extra ordering constraint to reduce the search space (prefer reds).\n",
    "\n",
    "A term ordering naturally extends to an ordering on clauses.\n",
    "\n",
    "During the datalog like process to produce a minimal model, if we hit a failing constraint, then there should have been an ordered resolution step possible to make a rule in an earlier \"strata\" that would have avoided the constraint failure. Carefully describing this idea is the proof of completeness of ordered resolution.\n",
    "\n",
    "The literal selection function is basically an arbitrary function from clauses to literals. It is surprising to find that much flexibility.\n",
    "\n",
    "Frankly, it's all a little confusing. `--literal-selection-strategy=\"SelectNegativeLiterals\"` is sufficient to make our particular example saturate. Other possible options also work.\n",
    "\n",
    "See slide 13 https://www.tcs.ifi.lmu.de/lehre/ws-2024-25/atp/slides07-more-resolution.pdf\n",
    "\n",
    "![](/assets/ordered_resolve.png)\n",
    "\n",
    "\n",
    "\n",
    "The key thing that is making our example terminate is probably \"Nothing is Selected in D \\/ B\". The \"rule\" clauses have negative literlas in them, so they will have something selected by the SelectNegativeLiterals strategy. The facts are a single positive unit literal, so will never have anything selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Datalog and Beyond\n",
    "These superposition systems however go far beyond datalog. It is under the capabilities of their calculus to be (with the appropriate clause prioerity, selection functions, and literal orderings)\n",
    "\n",
    "- Knuth Bendix completion\n",
    "- Prolog\n",
    "- Egraphs\n",
    "- Equality Saturation\n",
    "- Hypothetical Datalog https://www.philipzucker.com/contextual-datalog/\n",
    "- Contextual Egraphs https://github.com/eytans/easter-egg https://arxiv.org/abs/2305.19203\n",
    "- Lambda egraphs via the new HO extensions to eprover\n",
    "\n",
    "## Call Graphs as Ordering in Prolog and Datalog\n",
    "\n",
    "Prolog and Datalog have a couple different notions of ordering in them.\n",
    "\n",
    "- In prolog, the predicates in the body are ordered and the order that the rules appear also matters. More than that we kind of think of prolog as sort of a chain of function calls. The rules with a particular head define that predicate, and the body of the rule are the functions they rely on. The rules are an almost direct representation of the call graph https://en.wikipedia.org/wiki/Call_graph of the program (the graph of which functions call which functions). Recursive calls show up as self edges in the call graph, or mutually recursive definitions show up as connected components.\n",
    "- In datalog, there is a derived notion of strata. Strata are again the connected components of the dependency graph of predicates. They are useful to note as an optimization, but crucially semantically important to note for one proper notion of negation\n",
    "\n",
    "Prolog like goals are encoded as negated literals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given Clause and Semi Naive Evaluation\n",
    "Most if not all resolution style saturating theorem provers are organized around a given clause loops.\n",
    "\n",
    "A pile of processed and unprocessed clauses are maintained. A clause in selected out of the unprocessed (the given clause) and all inference against the processed clauses are done. The results are thrown into the unprocessed.\n",
    "\n",
    "This is similar to the seminaive distinction of delta (unprocessed) and old (processed) relations. The given clause procedure makes sure there is always one new thing in every attempt at inference because otherwise you are just redundantly rediscovering inferences.\n",
    "\n",
    "Both Datalog and resolution can be executed in the naive style where you do a full inference sweep of the entire database every time.\n",
    "\n",
    "The clause selection heuristics pick which clause to pick to be the given clause. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering\n",
    "\n",
    "Question answering mode in ATPs gives you prolog like capabilities to return a substitution that makes the goal true.\n",
    " \n",
    " For example, consider this definition of an `add` predicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/add.pl\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/add.pl\n",
    "add(0,X,X).\n",
    "add(s(X),Y,s(Z)) :- add(X,Y,Z)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0,s(s(0))]\n",
      "[s(0),s(0)]\n",
      "[s(s(0)),0]\n",
      "\u001b[1;31mERROR: -g add(X,Y,s(s(0))),writeln([X,Y]),fail: false\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!swipl -s /tmp/add.pl -g \"add(X,Y,s(s(0))),writeln([X,Y]),fail\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equivalent in TPTP would be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/prolog.p\n",
    "cnf(add_succ, axiom, add(s(X),Y,s(Z)) | ~add(X, Y, Z)).\n",
    "cnf(add_z, axiom, add(z, Y, Y)).\n",
    "fof(add_g, conjecture, ?[X,Y]: add(X,Y,s(s(z))))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Initializing proof state\n",
      "# Scanning for AC axioms\n",
      "#\n",
      "#cnf(i_0_4, plain, (add(z,X1,X1))).\n",
      "#\n",
      "#cnf(i_0_3, plain, (add(s(X1),X2,s(X3))|~add(X1,X2,X3))).\n",
      "#\n",
      "#cnf(i_0_5, negated_conjecture, ($answer(esk1_2(X1,X2))|~add(X1,X2,s(s(z))))).\n",
      "## SZS status Theorem\n",
      "# SZS answers Tuple [[z, s(s(z))]|_]\n",
      "\n",
      "#cnf(i_0_6, negated_conjecture, ($answer(esk1_2(z,s(s(z)))))).\n",
      "#\n",
      "#cnf(i_0_7, negated_conjecture, ($answer(esk1_2(s(X1),X2))|~add(X1,X2,s(z)))).\n",
      "## SZS answers Tuple [[s(z), s(z)]|_]\n",
      "\n",
      "#cnf(i_0_8, negated_conjecture, ($answer(esk1_2(s(z),s(z))))).\n",
      "#\n",
      "#cnf(i_0_9, negated_conjecture, ($answer(esk1_2(s(s(X1)),X2))|~add(X1,X2,z))).\n",
      "## SZS answers Tuple [[s(s(z)), z]|_]\n",
      "\n",
      "# Proof found!\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --answers=3 --conjectures-are-questions /tmp/prolog.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Running in auto input_syntax mode. Trying TPTP\n",
      "% Refutation found. Thanks to Tanya!\n",
      "% SZS status Theorem for prolog\n",
      "% SZS answers Tuple [[z,s(s(z))]|_] for prolog\n",
      "% SZS output start Proof for prolog\n",
      "2. add(z,X1,X1) [input]\n",
      "3. ? [X0,X1] : add(X0,X1,s(s(z))) [input]\n",
      "4. ~? [X0,X1] : add(X0,X1,s(s(z))) [negated conjecture 3]\n",
      "5. ~? [X0,X1] : (add(X0,X1,s(s(z))) & ans0(X0,X1)) [answer literal 4]\n",
      "6. ! [X0,X1] : (~add(X0,X1,s(s(z))) | ~ans0(X0,X1)) [ennf transformation 5]\n",
      "7. ~add(X0,X1,s(s(z))) | ~ans0(X0,X1) [cnf transformation 6]\n",
      "8. ~ans0(z,s(s(z))) [resolution 7,2]\n",
      "9. ans0(X0,X1) [answer literal]\n",
      "10. $false [unit resulting resolution 9,8]\n",
      "% SZS output end Proof for prolog\n",
      "% ------------------------------\n",
      "% Version: Vampire 4.9 (commit 5ad494e78 on 2024-06-14 14:05:27 +0100)\n",
      "% Linked with Z3 4.12.3.0 79bbbf76d0c123481c8ca05cd3a98939270074d3 z3-4.8.4-7980-g79bbbf76d\n",
      "% Termination reason: Refutation\n",
      "\n",
      "% Memory used [KB]: 415\n",
      "% Time elapsed: 0.0000 s\n",
      "perf_event_open failed (instruction limiting will be disabled): Permission denied\n",
      "(If you are seeing 'Permission denied' ask your admin to run 'sudo sysctl -w kernel.perf_event_paranoid=-1' for you.)\n",
      "% ------------------------------\n",
      "% ------------------------------\n"
     ]
    }
   ],
   "source": [
    "! vampire --question_answering answer_literal --avatar off /tmp/prolog.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equational Reasoning\n",
    "\n",
    "## Union Find\n",
    "\n",
    "In a my egraphs 2024 talk https://www.philipzucker.com/egraph2024_talk_done/ , I showed how to use Twee to get a union find. This is the same idea using eprover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/uf.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/uf.p\n",
    "\n",
    "cnf(ax1, axiom, a = b).\n",
    "cnf(ax2, axiom, b = c).\n",
    "cnf(ax2, axiom, c = b).\n",
    "cnf(ax2, axiom, b = z).\n",
    "cnf(ax2, axiom, z = c).\n",
    "cnf(ax3, axiom, d = e)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Initializing proof state\n",
      "# Scanning for AC axioms\n",
      "#\n",
      "#cnf(i_0_7, plain, (b=a)).\n",
      "#\n",
      "#cnf(i_0_8, plain, (c=a)).\n",
      "##\n",
      "#cnf(i_0_10, plain, (z=a)).\n",
      "##\n",
      "#cnf(i_0_12, plain, (d=e)).\n",
      "\n",
      "# No proof found!\n",
      "# SZS status Satisfiable\n",
      "# Processed positive unit clauses:\n",
      "cnf(i_0_7, plain, (b=a)).\n",
      "cnf(i_0_8, plain, (c=a)).\n",
      "cnf(i_0_10, plain, (z=a)).\n",
      "cnf(i_0_12, plain, (d=e)).\n",
      "\n",
      "# Processed negative unit clauses:\n",
      "\n",
      "# Processed non-unit clauses:\n",
      "\n",
      "# Unprocessed positive unit clauses:\n",
      "\n",
      "# Unprocessed negative unit clauses:\n",
      "\n",
      "# Unprocessed non-unit clauses:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --print-saturated /tmp/uf.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Egraph\n",
    "\n",
    "I also mentioned in the talk how you can use knuth bendix completion to build an egraph out of ground equations, represent by its ground ocmpleted rewrite system\n",
    "\n",
    "![](https://www.philipzucker.com/assets/egraph2024/egraph2.svg)\n",
    "![](https://www.philipzucker.com/assets/egraph2024/egraphs_1.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/groundshift.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/groundshift.p\n",
    "fof(shift, axiom, mul(a,two) = shift(a, one)).\n",
    "fof(assoc, axiom, div(mul(a,two),two) = mul(a,div(two,two))).\n",
    "fof(cancel, axiom, div(two,two) = one).\n",
    "fof(unit_mul, axiom, mul(a,one) = a). \n",
    "fof(cancel, axiom, myterm = div(mul(a,two), two)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting user weights\n",
      "# Initializing proof state\n",
      "# Scanning for AC axioms\n",
      "#\n",
      "#cnf(i_0_4, plain, (mul(a,one)=a)).\n",
      "#\n",
      "#cnf(i_0_3, plain, (div(two,two)=one)).\n",
      "#\n",
      "#cnf(i_0_5, plain, (myterm=div(mul(a,two),two))).\n",
      "#\n",
      "#cnf(i_0_1, plain, (shift(a,one)=mul(a,two))).\n",
      "#\n",
      "#cnf(i_0_2, plain, (div(mul(a,two),two)=a)).\n",
      "#\n",
      "#cnf(i_0_5, plain, (myterm=a)).\n",
      "\n",
      "# No proof found!\n",
      "# SZS status Satisfiable\n",
      "# Processed positive unit clauses:\n",
      "cnf(i_0_4, plain, (mul(a,one)=a)).\n",
      "cnf(i_0_3, plain, (div(two,two)=one)).\n",
      "cnf(i_0_1, plain, (shift(a,one)=mul(a,two))).\n",
      "cnf(i_0_2, plain, (div(mul(a,two),two)=a)).\n",
      "cnf(i_0_5, plain, (myterm=a)).\n",
      "\n",
      "# Processed negative unit clauses:\n",
      "\n",
      "# Processed non-unit clauses:\n",
      "\n",
      "# Unprocessed positive unit clauses:\n",
      "\n",
      "# Unprocessed negative unit clauses:\n",
      "\n",
      "# Unprocessed non-unit clauses:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --print-saturated --order-weights=\"myterm:100\"  /tmp/groundshift.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knuth Bendix Completion\n",
    "Knuth Bendix completion is a way to possibly turn a system of equations into a conlfuent terminating rewrite system. One example where t5his is possible is the free group. The default ordering of E is Knuth Bendix Ordering.\n",
    "\n",
    "https://www.metalevel.at/trs/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/grp.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/grp.p\n",
    "cnf(ax1, axiom, mul(X,mul(Y,Z)) = mul(mul(X,Y),Z)).\n",
    "cnf(ax2, axiom, mul(e,X) = X).\n",
    "cnf(ax3, axiom, mul(inv(X), X) = e)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Initializing proof state\n",
      "# Scanning for AC axioms\n",
      "# mul is associative\n",
      "#\n",
      "#cnf(i_0_5, plain, (mul(e,X1)=X1)).\n",
      "#\n",
      "#cnf(i_0_6, plain, (mul(inv(X1),X1)=e)).\n",
      "#\n",
      "#cnf(i_0_4, plain, (mul(mul(X1,X2),X3)=mul(X1,mul(X2,X3)))).\n",
      "#\n",
      "#cnf(i_0_8, plain, (mul(inv(X1),mul(X1,X2))=X2)).\n",
      "#\n",
      "#cnf(i_0_13, plain, (mul(inv(e),X1)=X1)).\n",
      "#\n",
      "#cnf(i_0_12, plain, (mul(inv(inv(X1)),e)=X1)).\n",
      "#\n",
      "#cnf(i_0_16, plain, (mul(inv(inv(e)),X1)=X1)).\n",
      "#\n",
      "#cnf(i_0_23, plain, (inv(e)=e)).\n",
      "#\n",
      "#cnf(i_0_11, plain, (mul(inv(inv(X1)),X2)=mul(X1,X2))).\n",
      "#\n",
      "#cnf(i_0_12, plain, (mul(X1,e)=X1)).\n",
      "#\n",
      "#cnf(i_0_33, plain, (inv(inv(X1))=X1)).\n",
      "#\n",
      "#cnf(i_0_38, plain, (mul(X1,inv(X1))=e)).\n",
      "#\n",
      "#cnf(i_0_39, plain, (mul(X1,mul(inv(X1),X2))=X2)).\n",
      "##\n",
      "#cnf(i_0_42, plain, (mul(X1,mul(X2,inv(mul(X1,X2))))=e)).\n",
      "#\n",
      "#cnf(i_0_61, plain, (mul(X2,inv(mul(X1,X2)))=inv(X1))).\n",
      "#\n",
      "#cnf(i_0_78, plain, (mul(inv(mul(X1,X2)),X1)=inv(X2))).\n",
      "#\n",
      "#cnf(i_0_77, plain, (inv(mul(X2,X1))=mul(inv(X1),inv(X2)))).\n",
      "##\n",
      "# No proof found!\n",
      "# SZS status Satisfiable\n",
      "# Processed positive unit clauses:\n",
      "cnf(i_0_5, plain, (mul(e,X1)=X1)).\n",
      "cnf(i_0_6, plain, (mul(inv(X1),X1)=e)).\n",
      "cnf(i_0_4, plain, (mul(mul(X1,X2),X3)=mul(X1,mul(X2,X3)))).\n",
      "cnf(i_0_8, plain, (mul(inv(X1),mul(X1,X2))=X2)).\n",
      "cnf(i_0_23, plain, (inv(e)=e)).\n",
      "cnf(i_0_12, plain, (mul(X1,e)=X1)).\n",
      "cnf(i_0_33, plain, (inv(inv(X1))=X1)).\n",
      "cnf(i_0_38, plain, (mul(X1,inv(X1))=e)).\n",
      "cnf(i_0_39, plain, (mul(X1,mul(inv(X1),X2))=X2)).\n",
      "cnf(i_0_77, plain, (inv(mul(X1,X2))=mul(inv(X2),inv(X1)))).\n",
      "\n",
      "# Processed negative unit clauses:\n",
      "\n",
      "# Processed non-unit clauses:\n",
      "\n",
      "# Unprocessed positive unit clauses:\n",
      "\n",
      "# Unprocessed negative unit clauses:\n",
      "\n",
      "# Unprocessed non-unit clauses:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!eprover-ho --print-saturated /tmp/grp.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Egglog\n",
    "\n",
    "The essence of [egglog](https://github.com/egraphs-good/egglog) in the same way the essence of datalog is the transitivity query is the connected component compression query.\n",
    "\n",
    "Here the compressed database holds a union find (The `=` facts, which are oriented according to the default term ordering). Notice that `path(b,b)` is deduped with respect to `path(d,d)` because they are expressing the same information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/path.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/path.p\n",
    "\n",
    "cnf(edgeab, axiom, edge(a,b)).\n",
    "cnf(edgebc, axiom, edge(b,c)).\n",
    "cnf(edgecd, axiom, edge(c,b)).\n",
    "cnf(edgedc, axiom, edge(d,c)).\n",
    "cnf(edgecd, axiom, edge(c,d)).\n",
    "\n",
    "cnf(edge_is_path , axiom, path(X,Y) | ~edge(X,Y)).\n",
    "cnf(path_trans, axiom, path(X,Z) | ~edge(X,Y) | ~path(Y,Z)).\n",
    "cnf(path_eq, axiom, X = Y | ~path(X,Y) | ~path(Y,X)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Initializing proof state\n",
      "# Scanning for AC axioms\n",
      "#\n",
      "#cnf(i_0_9, plain, (edge(a,b))).\n",
      "#\n",
      "#cnf(i_0_10, plain, (edge(b,c))).\n",
      "#\n",
      "#cnf(i_0_11, plain, (edge(c,b))).\n",
      "#\n",
      "#cnf(i_0_13, plain, (edge(c,d))).\n",
      "#\n",
      "#cnf(i_0_12, plain, (edge(d,c))).\n",
      "#\n",
      "#cnf(i_0_14, plain, (path(X1,X2)|~edge(X1,X2))).\n",
      "#\n",
      "#cnf(i_0_17, plain, (path(d,c))).\n",
      "#\n",
      "#cnf(i_0_18, plain, (path(c,d))).\n",
      "#\n",
      "#cnf(i_0_19, plain, (path(c,b))).\n",
      "#\n",
      "#cnf(i_0_20, plain, (path(b,c))).\n",
      "#\n",
      "#cnf(i_0_21, plain, (path(a,b))).\n",
      "#\n",
      "#cnf(i_0_16, plain, (X1=X2|~path(X2,X1)|~path(X1,X2))).\n",
      "#\n",
      "#cnf(i_0_22, plain, (d=c)).\n",
      "#\n",
      "#cnf(i_0_23, plain, (c=b)).\n",
      "#\n",
      "#cnf(i_0_22, plain, (d=b)).\n",
      "#\n",
      "#cnf(i_0_18, plain, (path(b,b))).\n",
      "##\n",
      "#cnf(i_0_12, plain, (edge(b,b))).\n",
      "######\n",
      "#cnf(i_0_15, plain, (path(X1,X2)|~path(X3,X2)|~edge(X1,X3))).\n",
      "##\n",
      "#cnf(i_0_28, plain, (path(X1,b)|~edge(X1,a))).\n",
      "\n",
      "# No proof found!\n",
      "# SZS status Satisfiable\n",
      "# Processed positive unit clauses:\n",
      "cnf(i_0_9, plain, (edge(a,b))).\n",
      "cnf(i_0_21, plain, (path(a,b))).\n",
      "cnf(i_0_23, plain, (c=b)).\n",
      "cnf(i_0_22, plain, (d=b)).\n",
      "cnf(i_0_18, plain, (path(b,b))).\n",
      "cnf(i_0_12, plain, (edge(b,b))).\n",
      "\n",
      "# Processed negative unit clauses:\n",
      "\n",
      "# Processed non-unit clauses:\n",
      "cnf(i_0_14, plain, (path(X1,X2)|~edge(X1,X2))).\n",
      "cnf(i_0_16, plain, (X1=X2|~path(X2,X1)|~path(X1,X2))).\n",
      "cnf(i_0_15, plain, (path(X1,X2)|~path(X3,X2)|~edge(X1,X3))).\n",
      "cnf(i_0_28, plain, (path(X1,b)|~edge(X1,a))).\n",
      "\n",
      "# Unprocessed positive unit clauses:\n",
      "\n",
      "# Unprocessed negative unit clauses:\n",
      "\n",
      "# Unprocessed non-unit clauses:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --print-saturated --literal-selection-strategy=\"SelectNegativeLiterals\" /tmp/path.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/eq.egg\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/eq.egg\n",
    "(datatype node (a) (b) (c) (d))\n",
    "(relation edge (node node))\n",
    "(relation path (node node))\n",
    "(edge (a) (b))\n",
    "(edge (b) (c))\n",
    "(edge (c) (d))\n",
    "(edge (d) (c))\n",
    "(edge (c) (b))\n",
    "\n",
    "(rule ((edge x y)) ((path x y)))\n",
    "(rule ((edge x y) (path y z)) ((path x z)))\n",
    "(rule ((path x y) (path y x)) ((union x y)))\n",
    "\n",
    "(run 10)\n",
    "(print-function path 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[38;5;8m[\u001b[0m\u001b[0m\u001b[32mINFO \u001b[0m\u001b[0m\u001b[38;5;8m]\u001b[0m Declared sort node.\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m\u001b[0m\u001b[32mINFO \u001b[0m\u001b[0m\u001b[38;5;8m]\u001b[0m Declared function a.\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m\u001b[0m\u001b[32mINFO \u001b[0m\u001b[0m\u001b[38;5;8m]\u001b[0m Declared function b.\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m\u001b[0m\u001b[32mINFO \u001b[0m\u001b[0m\u001b[38;5;8m]\u001b[0m Declared function c.\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m\u001b[0m\u001b[32mINFO \u001b[0m\u001b[0m\u001b[38;5;8m]\u001b[0m Declared function d.\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m\u001b[0m\u001b[32mINFO \u001b[0m\u001b[0m\u001b[38;5;8m]\u001b[0m Declared function edge.\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m\u001b[0m\u001b[32mINFO \u001b[0m\u001b[0m\u001b[38;5;8m]\u001b[0m Declared function path.\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m\u001b[0m\u001b[32mINFO \u001b[0m\u001b[0m\u001b[38;5;8m]\u001b[0m Declared rule (rule ((edge x y))\n",
      "          ((path x y))\n",
      "             ).\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m\u001b[0m\u001b[32mINFO \u001b[0m\u001b[0m\u001b[38;5;8m]\u001b[0m Declared rule (rule ((edge x y)\n",
      "           (path y z))\n",
      "          ((path x z))\n",
      "             ).\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m\u001b[0m\u001b[32mINFO \u001b[0m\u001b[0m\u001b[38;5;8m]\u001b[0m Declared rule (rule ((path x y)\n",
      "           (path y x))\n",
      "          ((union x y))\n",
      "             ).\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m\u001b[0m\u001b[32mINFO \u001b[0m\u001b[0m\u001b[38;5;8m]\u001b[0m Ran schedule (repeat 10 (run)).\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m\u001b[0m\u001b[32mINFO \u001b[0m\u001b[0m\u001b[38;5;8m]\u001b[0m Report: Rule (rule ((edge x y)        (path y z))       ((path x z))          ): search 0.000s, apply 0.000s, num matches 9\n",
      "    Rule (rule ((edge x y))       ((path x y))          ): search 0.000s, apply 0.000s, num matches 7\n",
      "    Rule (rule ((path x y)        (path y x))       ((union x y))          ): search 0.000s, apply 0.000s, num matches 5\n",
      "    Ruleset : search 0.000s, apply 0.000s, rebuild 0.000s\n",
      "    \n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m\u001b[0m\u001b[32mINFO \u001b[0m\u001b[0m\u001b[38;5;8m]\u001b[0m Printing up to 100 tuples of table path: \n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m\u001b[0m\u001b[32mINFO \u001b[0m\u001b[0m\u001b[38;5;8m]\u001b[0m    (path (b) (b))\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m\u001b[0m\u001b[32mINFO \u001b[0m\u001b[0m\u001b[38;5;8m]\u001b[0m    (path (a) (b))\n",
      "(\n",
      "   (path (b) (b))\n",
      "   (path (a) (b))\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!egglog /tmp/eq.egg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bits and Bobbles 2\n",
    "Altogether I find vampire more confusing to control when being used off label. I can kind of more or less interpret the various command line options to eprover in terms of the underlying calculus. Eprover also ships with a latex manual https://github.com/eprover/eprover/blob/master/DOC/eprover.tex which clarifies at least some things. Combining this + experimentation + Blanchette slides + Bachmair Ganzinger handbook of automated reasoning article is the only thing I've got.\n",
    "\n",
    "I'm intrigued at the idea of using eprover as an operational mechanism rather than a solver for first order logic. A surface language which exposes more things like selection and clause ordering would be nice. I want a happy controllable predictable medium between datalog, prolog, and atp.\n",
    "\n",
    "Prover9 exposes knobs and operational view is more emphasized\n",
    "\n",
    "Are the orderings in datalog/prolog more like clause orderings, literal orderings, or selection. Or is this all not that related?\n",
    "Goal clause prioritization \"PreferGoals\" `PreferGroundGoals` `\n",
    "\n",
    "Hypthoetical datalog\n",
    "`a -| b :- c.` The partially applied transitive rule is kind of a new hypthetical rule. If all variables are grounded in c, this is a what I have called hypothetical datalog. \n",
    "\n",
    "\n",
    "I'm not entirely clear that selection is persay the thing that makes eprover terminate. The option may be kicking on a subsumption mechanism, which is what is really making it saturate?\n",
    "\n",
    "The only difference under --print-strategy is \n",
    "\n",
    "```\n",
    "NoSelection: Perform ordinary superposition without selection.\n",
    "\n",
    "SelectNegativeLiterals: Select all negative literals. For Horn clauses, this\n",
    "implements the maximal literal positive unit strategy [Der91] previously\n",
    "realized separately in E.\n",
    "```\n",
    "\n",
    "https://domino.mpi-inf.mpg.de/internet/reports.nsf/c125634c000710cec125613300585c64/19a118dff60c0790c12572ff002b586a/$FILE/MPI-I-2007-RG1-001.pdf \n",
    "Superposition for Finite Domains (Plain Text\n",
    "Version) Thomas Hillenbrand Christoph Weidenbach\n",
    "\n",
    "\n",
    "|  | Propositions | Equations |\n",
    "|---|------|------------|\n",
    "| Brute Search | Resolution     |   Paramodulation         |\n",
    "| Ordered Search | Ordered Resolution | Superposition |\n",
    "| ? | Knuth Bendix Completion |\n",
    "| Ground | Ground Ordered Resolution | EGraph |\n",
    "| Goal Driven, Imperative, stacky | Prolog | Functional Logic Programming |\n",
    "|Bottom Up Ground | Datalog | Egglog |\n",
    "| Unoriented | Clause `|` | Eq `=` |\n",
    "| Oriented   | rule `:-` | Rewrite `->` |\n",
    "\n",
    "\n",
    "The features that make these provers powerful refutation provers make them harder to interpret when using them for other purposes like saturation.\n",
    "\n",
    "Vampire has a ton of bells and whistles and it is harder for me to figure out how to control them.\n",
    "E exposes more options that make sense to me and has a smaller core calculus.\n",
    "\n",
    "Both have mechanisms that defer to smt/sat solvers to try to use their strengths (see AVATAR and splitting). When this occurs, I am more confused on how to interpret the model they've found.\n",
    "\n",
    "We are running our theorem proving somewhat unusually in that we are really seeking a notion of saturated database/clause set and not trying to show unsat / refutation proof.\n",
    "\n",
    "At this point, I think I prefer the `cnf` notation better than the `fof` notation. The precendence of `fof` is so unintuitive to me (and I suspect ) that I end up putting.\n",
    "\n",
    "Unlike in prolog `|` has no intrinsic ordering. In datalog, the ordering of `,` commonly does not have operational meaning either.\n",
    "\n",
    "The transitivity closure query is a little tired, but it really is the essence of datalog.\n",
    "\n",
    "One aspect of datalog I find compelling is that it mirrors my simplistic image of what logic even is. Logic is axioms in some language and inference rules that take in theorems and produce new theorems. The set of all provable states is the closure of the axioms under the rules.\n",
    "\n",
    "\n",
    "\n",
    "Resolution theorem proving is a little more involved. It is \n",
    "You have clauses and you you can make an inference by smushing them together.\n",
    "\n",
    "This is a method for classical first order logic because you can use skolemization to put the system into prenex normal form, where all the existential quantifiers are pushed outside the forall quantifiers via skolemization.  https://en.wikipedia.org/wiki/Skolem_normal_form\n",
    "\n",
    "\n",
    "Clauses `a | c | ~d`\n",
    "\n",
    "Resolution allows matching of rules against rules instead of only rule against facts.\n",
    "\n",
    "https://dl.acm.org/doi/10.1145/321250.321253 A Machine-Oriented Logic Based on the Resolution Principle - Robinson 1965\n",
    "\n",
    "\n",
    "https://en.wikipedia.org/wiki/Herbrand_structure\n",
    "https://en.wikipedia.org/wiki/Herbrand%27s_theorem\n",
    "\n",
    "```\n",
    " D \\/ B      C \\/ ~A\n",
    "-------------------\n",
    "   sigma[D \\/ C]\n",
    "\n",
    "```\n",
    "- $\\sigma = mgu(A,B)$\n",
    "- ...\n",
    "- Nothing is selected in `D \\/ B`\n",
    "- `~A` is selected or ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<clingo.control.Control at 0x7bed3d33eef0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import clingo\n",
    "prog = \"\"\"\n",
    "edge(1,2;3,4).\n",
    "path(X,Y) :- edge(X,Y).\n",
    "\"\"\"\n",
    "ctl = clingo.Control()\n",
    "ctl.add(prog)\n",
    "ctl.ground([(\"base\",[])])\n",
    "ctl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/path.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/path.p\n",
    "edge(1,2; 2,3; 3,4).\n",
    "path(X,Y) :- edge(X,Y).\n",
    "path(X,Z) :- edge(X,Y), path(Y,Z)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge(1,2).\n",
      "edge(2,3).\n",
      "edge(3,4).\n",
      "path(1,2).\n",
      "path(2,3).\n",
      "path(3,4).\n",
      "path(2,4).\n",
      "path(1,3).\n",
      "path(1,4).\n"
     ]
    }
   ],
   "source": [
    "! python3 -m clingo --text /tmp/path.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "other datalogs to checkout\n",
    "\n",
    "https://inst.eecs.berkeley.edu/~cs294-260/sp24/2024-02-05-datalog\n",
    "- https://s-arash.github.io/ascent/\n",
    "- slog\n",
    "- gpu datalog\n",
    "- logica\n",
    "- dusa\n",
    "\n",
    "- https://www.philipzucker.com/notes/Logic/answer-set-programming/\n",
    "- https://www.philipzucker.com/notes/Languages/datalog/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Superposition\n",
    "\n",
    "atomic ground superposition - a contextual union find\n",
    "ground superposition\n",
    "\n",
    "colored egraphs\n",
    "\n",
    "brainiac\n",
    "\n",
    "cruanes slides https://simon.cedeela.fr/assets/jetbrains_2021.pdf\n",
    "\n",
    "blanchette slides https://www.tcs.ifi.lmu.de/lehre/ws-2024-25/atp/slides12-superposition.pdf\n",
    "\n",
    "model is ground rewrite rules = egraph?\n",
    "\n",
    "\n",
    "weidenbach draft?\n",
    "SCL simple clause\n",
    "cdcl and superposition\n",
    "\n",
    "The layering of ordering resolution (set knuth bendix) + equations (term knuth bendix) reminds me of my idea of egraph modulo theory / theory union finds as layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Horn\n",
    "class Clause():\n",
    "    hyps : list[tuple[int,int]] # negative literals\n",
    "    conc : tuple[int,int]\n",
    "\n",
    "\n",
    "\n",
    "def superpose(c1 : Clause, c2 : Clause):\n",
    "    if c1.conc[0] == c2.conc[0]:\n",
    "        x,y = c1.conc[1], c2.conc[1]\n",
    "        if x < y:\n",
    "            x,y = y,x\n",
    "        return Clause(sorted(set(c1.hyps + c2.hyps)), (x,y))\n",
    "\n",
    "def neg_superpose(c1 : Clause, c2 : Clause):\n",
    "\n",
    "def equality_res():\n",
    "    # delete all hyps of the form x=x\n",
    "\n",
    "def factor():\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordered Ground Resolution\n",
    "### Model Building and Completeness\n",
    "Model Existence.\n",
    "\n",
    "We want to pick a particular herbrand model. There are many. Pick an ordering.\n",
    "\n",
    "Minimal herbrand makes sense in the context of datalog / horn clauses...\n",
    "\n",
    "refutation Completeness proofs in general involve building models from saturated clauses (?) Robinson https://web.stanford.edu/class/linguist289/robinson65.pdf\n",
    "\n",
    "In egraphs, we rag on completeness as silly. How silly is it?\n",
    "\n",
    "### Knuth Bendix Analogy\n",
    "Ordered Resolution completes a set of clauses into rules.\n",
    "The rules can convert a ground database into a normal implied form. (The intensional to extensional database. The base facts to the ).\n",
    "\n",
    "Consistency checks `:- a,b,c.` may mean that it is insistent to add certain base facts.\n",
    "\n",
    "\n",
    "\n",
    "Alternative usage.\n",
    "\n",
    "set rewriting = datalog\n",
    "ordered resolution = knuth bendix for set rewriting\n",
    "rewriting (ground) herbrand models.\n",
    "\n",
    "Take a set of extra ground facts and close them out to minimal model that contains them, or possibly say they are inconstiant.\n",
    "\n",
    "certain ground facts are equivalent under the axioms. ordered resolution builds the decision procedure.\n",
    "\n",
    "strata ordering\n",
    "accumulating semantics. obviously confluent if no negation.\n",
    "{a, c} not b --> {d}\n",
    "\n",
    "Convert clauses into datalog rules\n",
    "\n",
    "datalog rules are like rewrite rules. They are oriented clauses.\n",
    "You can run a base set of facts into a caonnical model.\n",
    "Confluence.\n",
    "\n",
    "\n",
    "dually, resolution/superposition is perhaps a generalized e-unification. Negated `p(A) != p(B)` can factor into stuff.\n",
    "maybe splitting makes this correspondance better?\n",
    "\n",
    "https://www.philipzucker.com/string_knuth/\n",
    "\n",
    "\n",
    "body of rules and db are made of the same thing (?) This was part of the SQL = homomorphisms post. That the query and db are surprisingly symmetrical.\n",
    "\n",
    "| Prop  |  Eq |\n",
    "|---|---|\n",
    "| Unoriented | Clause    | Equation |\n",
    "| Oriented   | Rule `:-` | Rewrite |\n",
    "| |   Ordered Resolution | KB |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subseq(body,  db):\n",
    "    pass\n",
    "\n",
    "def replace(db, body, head):\n",
    "    \"\"\"replace in quotes since monotonic\"\"\"\n",
    "    pass\n",
    "\n",
    "def rewrite(db, rules):\n",
    "    # aka saturate\n",
    "\n",
    "def overlaps(body1, body2):\n",
    "\n",
    "def deduce():\n",
    "    \"\"\"find all critical pairs\"\"\"\n",
    "    pass\n",
    "\n",
    "def KB(clauses): # clauses ~ E\n",
    "    done = False\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAT solving comparison\n",
    "sat solvers do not take it an a priori literal ordering. They discover a useful one via heuristics and pivoting.\n",
    "\n",
    "\n",
    "\n",
    "https://types.pl/@sandmouth/113528558531822923\n",
    "\"\"\"\n",
    "there’s a fascinating viewpoint I’ve only become aware of in the last week that sat solvers in a sense do output a minimal model, they just don’t accept a definition of minimality in the form of a literal ordering nor do they output the ordering they discovered (which exists in the form of their internal decision and propagation trail). Ordered resolution by constrast https://lawrencecpaulson.github.io/papers/bachmair-hbar-resolution.pdf takes in an a priori definition of which literals you prefer to be true/false, which in turn tells you how to orient clauses into rules. The maximum positive literal of the clause is the head and any other positive literals become negations in the rule body. It’s a really interesting knob to travel between prolog and datalog and in between. It’s kind of like user defined datalog strata or something. I think this stuff is under explained nor properly translated to a logic programming viewpoint (at least in any reference I’ve read so far)\n",
    "\"\"\"\n",
    "\n",
    "ASP maybe is like SAT except the rule orientations are chosen.\n",
    "What is conflict vs producing is preordianned by user.\n",
    "\n",
    "### Splitting\n",
    "Add an extra dimension to the reolsution style search. Instead of being purely sturating, we can fork our clause databases making a guess as to which part of the clause is true.\n",
    "\n",
    "A clause can always be split by introducing a fresh symbol `q` that hodls the shared variables. If no shared varaibles, then q is propsitional and amenable to SAT solving / branching more easily. `q` can also be kind of seen as a propsotional clause abstraction / cegar. SAT modulo Resolution.\n",
    "`a(X,Y) | b(Y,W)` ->  `q(Y) | a(X,Y)`  `~q(Y) | b(Y,W)` \n",
    "\n",
    "\n",
    "Grounding. You can randomly (?) pick any instantiaions of clauses and then toss into SMT/SAT solver. If that grounding is unsat, cool.\n",
    "\n",
    "AVATAR\n",
    "\n",
    "https://www.cl.cam.ac.uk/~lp15/papers/Arith/case-splitting.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Logic Programming\n",
    "The combination of the ordering and selection feels like a knob to tweak between prolog and datalog and other things. It would be nice to have a crisper picture of this.\n",
    "\n",
    "- hyperresolution\n",
    "- locking resolution https://www.doc.ic.ac.uk/%7Ekb/MACTHINGS/SLIDES/2013Notes/7LControl4up13.pdf boyer 1973 https://www.cs.utexas.edu/~boyer/boyer-dissertation.pdf\n",
    "- unit resulting resolution\n",
    "\n",
    "ordered resolution as a logic programming language\n",
    "\n",
    "\n",
    "negative literals are goals. The Factoring rule is prolog style unification.\n",
    "\n",
    "\n",
    "```python\n",
    "# idea. preprocessor to convert to clauses + ordering + selection function.\n",
    "# Or write own ordered resolution\n",
    "\n",
    "import lark\n",
    "grammar = \"\"\"\n",
    "rule: head \":-\" selected \"|\" unselected.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "Marking particular predicates as selected or unselected.\n",
    "```\n",
    ":- constraint foo/2.  % means it isn't selected?\n",
    "```\n",
    "\n",
    "Or make it work like LPO. \n",
    "```\n",
    "decl foo : bar. % means it is a constructor and therefore at the bottom precedence.\n",
    "```\n",
    "\n",
    "Interactively saturate with every new definition? That would be a termination check (?)\n",
    "It's kind of like elf or the termination arugments given to dafny / coq / lean etc.\n",
    "\n",
    "\n",
    "`head  -| ctx  :- body.` hypothetical datalog. Maybe a notation for\n",
    "`maxposliteral |  selected   | other`  CHR kind of has a multipart thing. I think in principle its just multiset rewrite rules. Its a conveience to not depelte and reinsert.\n",
    "It is then the theorem provers job to discharge a term ordering that makes the max pos literal, selected literals work.\n",
    "selected literals can emulate hyperresolution.\n",
    "\n",
    "prolog vs E https://wwwlehre.dhbw-stuttgart.de/~sschulz/E/FAQ.html\n",
    "\n",
    "https://web4.ensiie.fr/~guillaume.burel/download/LFAT.pdf focusing and atp. Focusing is a mechanism for describing the imperative nature of prolog or how the sequent claculus is like an imperative machine. https://drops.dagstuhl.de/storage/00lipics/lipics-vol117-mfcs2018/LIPIcs.MFCS.2018.9/LIPIcs.MFCS.2018.9.pdf\n",
    "\n",
    "\n",
    "Termination checking of logic programs.\n",
    "https://www.sciencedirect.com/science/article/pii/0743106692900455  Proving termination properties of prolog programs: A semantic approach\n",
    "https://www.metalevel.at/prolog/termination \n",
    "https://www.cs.unipr.it/cTI/  cTI: A Termination Inference Engine\n",
    "https://github.com/atp-lptp/automated-theorem-proving-for-prolog-verification\n",
    "\n",
    "elf had termination checking. But like simple syntactic.\n",
    "\n",
    "IC3 and CHC.\n",
    "IC3 vs saturation?\n",
    "#### programming resolution\n",
    "look at datalog program\n",
    "\n",
    "continuation passing as an evaluation order forciong mechanism\n",
    "https://www.swi-prolog.org/pldoc/man?section=delcont deliimited continuations?\n",
    "\n",
    "```\n",
    "call(edge(X,Y)) | ~edge(X,Y).\n",
    "\n",
    "```\n",
    "\n",
    "Consider more metagames I tried to play in egglog or datalog. They should be more doable.\n",
    "\n",
    "first class clauses\n",
    "\n",
    "`clause( poses, negs )`.\n",
    "\n",
    "`assert`\n",
    "\n",
    "It would be kind of cool to have computational proedciates. writeln\n",
    "What was the deal with e-lop?\n",
    "\n",
    "dcgs? Proof recording.\n",
    "```\n",
    "cnf(ax1, axiom, prove( A > B, Pf-Tl, Pf)).\n",
    "```\n",
    "\n",
    "This idea of staging resolution is like staging prolog.\n",
    "Prolog macros? Kind of ugly as hell.\n",
    "modules? Lambda prolog modules?\n",
    "\n",
    "twelf\n",
    "\n",
    "\n",
    "### Ordering\n",
    "\n",
    "Ordering = datalog strata presciprtion\n",
    "\n",
    "Using other term orderings -> datalog termination proofs\n",
    "Or datalog consistency? Having negation but showing you won't derive then underive something.\n",
    "\"dynamic\" stratification\n",
    "This doesn't have a unique minimal model\n",
    "```\n",
    "b :- not a.\n",
    "a :- not b.\n",
    "```\n",
    "\n",
    "This does. Stratification can't cover it though. So how to prove? Term ordering maybe.\n",
    "```\n",
    "b(n) :- not a(n).\n",
    "a(n + 1) :- not b(n), n < 10.\n",
    "```\n",
    "d(1, N)\n",
    "d(2, N) etc\n",
    "\n",
    "There is some kind of redundancy symmettry in brute resolution and people have been fighting it from the beginning basically. Rewynolds, slagle, kowalski\n",
    "\n",
    "https://www.cs.upc.edu/~%7B%7Dalbert/cpo.zip https://arxiv.org/abs/1506.03943 computbility path ordering. compare types first\n",
    "LPO RPO\n",
    "KBO\n",
    "\n",
    "\n",
    "### Selection Functions\n",
    "\n",
    "SL SLD resolution. They use the term selection function.\n",
    "https://www.sciencedirect.com/science/article/abs/pii/0004370271900129 Linear resolution with selection function kowalski kuehner\n",
    "https://en.wikipedia.org/wiki/SLD_resolution SLD resolution is so named S is for selection\n",
    "\n",
    "\n",
    "Selection functions. \n",
    "p :- not p, not q, z | a,b,c.\n",
    "Some kind of CLP like syntax. \n",
    "Maximalnegative/minimal does perhaps seem the most prolog like.  \n",
    "\n",
    "Selection is like a goal ordering. a prolog rule p :- q,r,s. tries to deal with q, r, s in syntactic order. q would be selected.\n",
    "But if prolog had more delcarative semantics, there might be some way for the system to pick from q,r,s as the next direction work on.\n",
    "\n",
    "\n",
    "### Saturation and Proof by Consistency\n",
    "inductionless induction\n",
    "\n",
    "\n",
    "If we have a termination criteria / strata criteria for our prolog / datalog program, can we convert that to selection functions and a term ordering.\n",
    "\n",
    "The prcendence gnerating routines of E seem like a nice way to fill in gaps. Syntax for constraints that put precedence or weight constraints.\n",
    "\n",
    "Inductionless induction could be used to prove negations at lower levels?\n",
    "The similaity of using induction to prove consistent (has model) is mentioned in paramodulation chapter of handbook\n",
    "\n",
    "\n",
    "Could I use this to do progress and preservation proofs?\n",
    "boolexpr progress proof?\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "Termination of lambda calculus requires the typing relation. Step-indexing. Logical relations.\n",
    "\n",
    "### Sequents\n",
    "Resolution doesn't seem to really be about classical first order logic.\n",
    "neg and positive literals can be interpreted as parts of sequent. Resolution is cut.\n",
    "Bachmair and ganzinger vaguely allude to macro proof steps\n",
    "\n",
    "\n",
    "### Chaining\n",
    "\n",
    "\"bi-rweriting a term rewriting techniqyue for monotonic order relaTIONS\" levy and agusty https://www.iiia.csic.es/~levy/papers/RTA93.pdf\n",
    "https://pdf.sciencedirectassets.com/272990/1-s2.0-S1571066100X00631/1-s2.0-S1571066104002968/main.pdf Knuth-Bendix Completion for Non-Symmetric\n",
    "Transitive Relations struith\n",
    "https://opus.bibliothek.uni-augsburg.de/opus4/frontdoor/index/index/year/2006/docId/229 Termination of ground non-symmetric Knuth-Bendix completion\n",
    "\n",
    "chaining slagle 72\n",
    "infinitary depth first search... ?\n",
    "two rewrite relations. < + termorder and < + opptermorder\n",
    "\n",
    "ordered chaining for total orderings https://link.springer.com/chapter/10.1007/3-540-58156-1_32\n",
    "\n",
    "Rewrite Techniques for Transitive Relations\n",
    "\n",
    "\n",
    "\n",
    "## Misc\n",
    "\n",
    "\n",
    "\n",
    "https://people.mpi-inf.mpg.de/~mfleury/paper/Weidenback_Book_CDCL.pdf\n",
    "Weidenbach chapter 2 draft\n",
    "\n",
    "https://core.ac.uk/download/303691264.pdf  Formalizing the metatheory of logical calculi and automatic provers in Isabelle/HOL\n",
    "(invited talk)\n",
    "Blanchette, Jasmin Christian\n",
    "\n",
    "https://www.tcs.ifi.lmu.de/lehre/ws-2024-25/atp/paper.pdf  Automated Theorem Proving∗ Dr. Uwe Waldmann\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Types are dsichagred differently. see weidnebach chapter.\n",
    "Type check ~ static. \n",
    "A stratification of inference.\n",
    "Stratification either comes from orderings, or explicit quasiquote thingy. Like z3py meta. Like two level type kovacs. like metaocaml. like HOL quote carette and farmer https://arxiv.org/abs/1802.00405\n",
    "One could implement a quote mechanism inside of an ATP. Kind of an interesting idea.\n",
    "\n",
    "\n",
    "\n",
    "Saturated clauses -> minimal model (according to that ordering)\n",
    "Alterantive - push pop search in order of ordering to SAT solver.\n",
    "Can cut out branches that are unsat.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Bachmair and ganzinger in handbook\n",
    "https://www.isa-afp.org/entries/Functional_Ordered_Resolution_Prover.html\n",
    "\n",
    "hypothetical datalog?\n",
    " |- \n",
    "Ground database\n",
    "\n",
    "\n",
    "minimal proofs\n",
    "\n",
    "\n",
    "https://rg1-teaching.mpi-inf.mpg.de/autrea-ws21/notes-3d.pdf ordered resolution with selection waldemann.\n",
    "\n",
    "https://www.tcs.ifi.lmu.de/lehre/ws-2024-25/atp_de.html\n",
    "https://www.tcs.ifi.lmu.de/lehre/ws-2024-25/atp/slides05-resolution.pdf\n",
    "ordering stratifies clause set by their maximal atom\n",
    "\n",
    "polynomial unification. Restrict unfication to do small terms first\n",
    "(guassian pivoting?)\n",
    "\n",
    "\n",
    "https://dl.acm.org/doi/pdf/10.1145/321420.321428 slagle 1967\n",
    "\n",
    "Building a model from a saturation.\n",
    "\n",
    "switching from ground to nonground makes > become !<=\n",
    "\n",
    "sequent calculus and resolution. Cut or macro rules?\n",
    "The multiset chjaracter of alsues makes permutation symettry\n",
    "\n",
    "\n",
    "stratified resolution\n",
    "\n",
    "\n",
    "2-sat ~ congruence closure?\n",
    "\n",
    "`a | b` orients to `a :- b`\n",
    "\n",
    "a | b | c. is a 3 way symmettric thing.\n",
    "\n",
    "Multiequations a = b = c ? Could that be cogent?\n",
    "a = b = c as a triangle. higher dimesional rewriting. ab -> c oriented.\n",
    "Hmm. kind of jives with the equations = paths stuff.\n",
    "unification sometimes uses the term.\n",
    "a = b | c = d\n",
    "\n",
    "Bachmair\n",
    "Ganzigner\n",
    "Niewenhuis https://www.cs.upc.edu/~roberto/\n",
    "Rubio https://www.cs.upc.edu/~albert/ https://link.springer.com/chapter/10.1007/978-3-642-31585-5_21 nominal completion\n",
    "waldemann https://dblp.org/pid/w/UweWaldmann.html\n",
    "weidenbach\n",
    "stickel\n",
    "wayne snyder\n",
    "hillenbrand\n",
    "kuehner\n",
    "kowalski\n",
    "slagle\n",
    "veroff\n",
    "wos\n",
    "suda\n",
    "loveland\n",
    "blanchette\n",
    "bledsoe\n",
    "gallier\n",
    "baader\n",
    "nipkow\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "https://resources.mpi-inf.mpg.de/SATURATE/Saturate.html\n",
    "https://resources.mpi-inf.mpg.de/SATURATE/doc/Saturate/node11.html\n",
    "transitive relations have special inference rule. chaining. paramdodulation is an instance...\n",
    "\n",
    "Loveland book\n",
    "\n",
    "https://link.springer.com/article/10.1007/BF01190829 1994 ganziner bachmair waldeman\n",
    "\n",
    "whoa. this is insane https://people.mpi-inf.mpg.de/alumni/ag2/2011/hg/index/index7.html\n",
    "I need to read like ganzinger's entire work\n",
    "especially part 2.\n",
    "\n",
    "mcallester. steensgard analysis\n",
    "\n",
    "https://www3.risc.jku.at/conferences/rta2008/slides/Slides_Hillenbrand.pdf hillenbrand waldmeisetrt. in mathematica?\n",
    "\n",
    "lock resolution\n",
    "\"the inverse method can also be encoded\"\n",
    "\n",
    "Bachmair and Ganzinger\n",
    "\"non-clausal reoslution and superposition wioth seelction and redunancy criteri\"\n",
    "\"perfoect model semantics for logic programs with equality\"\n",
    "\"rewirte based equational theorem proving with selection and simplification\"\n",
    "\"rewrite techniques with transitive relations\"\n",
    "\"ordered chaining for total orderings\"\n",
    "\n",
    "\n",
    "\n",
    "https://www.sciencedirect.com/science/article/pii/S0890540106000617?via%3Dihub  Modular proof systems for partial functions with Evans equality. Total and partial functions\n",
    "Kuper  https://www.sciencedirect.com/science/article/pii/S0890540183710631  An Axiomatic Theory for Partial Functions\n",
    "https://www21.in.tum.de/students/set_theory_partial_functions/index.html Formalising Set Theory Based on Partial Functions\n",
    "https://page.mi.fu-berlin.de/cbenzmueller/papers/C57.pdf  Automating Free Logic in Isabelle/HOL\n",
    "\n",
    "Man a return to form of category theory blog post 0. Flat is good anyway.\n",
    "Avoiding junk elements is good.\n",
    "Fun,El,El choiuce is like SEAR\n",
    "Fun,Fun,Fun choice is like ETCS\n",
    "\n",
    "subsets are partial functions to bool.\n",
    "f(x) undef means x isn't in domain.\n",
    "f(x) = false means not in subset\n",
    "f(x) = true means in subset\n",
    "\n",
    "\n",
    "```\n",
    "DeclareSort(\"Fun\")\n",
    "# apply as ternary\n",
    "apply = Function(\"apply\", Fun, El, El, BoolSort()) # Fun Fun Fun?\n",
    "undef = define(\"undef\", [f,x], Not(Exists([y], apply(f,x,y))))\n",
    "# f.x ~ y   notation for apply(f,x,y) is nice. Hard to see how to do this in python. Could make parser. Or overload __eq__ to check for a call. Hmmmm.\n",
    "\n",
    "\"\"\" put partial application at metalevel.\"\"\"\n",
    "\n",
    "class PApply():\n",
    "    f : Fun\n",
    "    x : PApply | Fun # enable recursive expressions.\n",
    "    def __eq__(self, y):\n",
    "        if isinstance(y, ExprRef):\n",
    "            return apply(self.f, self.x, y)\n",
    "    def __call__(self, y):\n",
    "        return PApply(self, y)\n",
    "    def defined(self):\n",
    "        return Exists([y], self == y)\n",
    "\n",
    "def apply_eq(fx,y):\n",
    "    if is_app(fx) and  fx.decl() == apply:\n",
    "        return return fx[2] == y\n",
    "    else:\n",
    "    return apply(fx[0],fx[1],y)\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "https://github.com/NikolajBjorner/ShonanArtOfSAT/blob/main/AkihisaYamada-slides.pdf \n",
    "satisfiability modulo rewriting\n",
    "WP\n",
    "CPO\n",
    "HORPO\n",
    "\n",
    "\n",
    "\n",
    "books \n",
    "troesltra\n",
    "pohlers proof thoery\n",
    "takeuti\n",
    "zach proof theory\n",
    "handbook of proof theory\n",
    "girard\n",
    "\n",
    "kleene metamartrhemtics\n",
    "computability theory by \n",
    "\n",
    "\n",
    "theory resolution stickel 1985\n",
    "\n",
    "vampire for QBF?\n",
    "```\n",
    "cnf( v(B) | v(c) )\n",
    "v(skolem(A))\n",
    "```\n",
    "\n",
    "vampire for modal / intuitonsitc? Judicious choice of ordering /precdence to help?\n",
    "https://ieeexplore.ieee.org/document/848641 Chaining techniques for automated theorem proving in many-valued logics\n",
    "\n",
    "\n",
    "nonclausal resolution\n",
    "https://www.sciencedirect.com/science/article/pii/S0890540105000258 Superposition with equivalence reasoning and delayed clause normal form transformation\n",
    "\n",
    "### Saturate\n",
    "https://resources.mpi-inf.mpg.de/SATURATE/Saturate.html\n",
    "INteresting system. Interesting example files.\n",
    "I doubt I can get this running\n",
    "\n",
    "Saturation of first-order (constrained) clauses with the Saturate system https://dl.acm.org/doi/10.5555/647193.720661\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clauses as sorted list\n",
    "# use integer ids. negative for negative literals if we want those to come first?\n",
    "atoms = []\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## python\n",
    "We pick the (name, neg) encoding because in python \n",
    "{A,A} is neg lit\n",
    "{A} is pos lit\n",
    "\n",
    "is the same ordering as\n",
    "\n",
    "(A, True) is neg lit\n",
    "(A, False) is pos lit\n",
    "\n",
    "\n",
    "Lesser things are \"simpler\" in some sense. \"Smaller\". We try to eliminate to lesser things.\n",
    "\n",
    "Given saturated clause set, contruct model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('0b', False), ('0a', False)],\n",
       " [('1a', False), ('0b', False)],\n",
       " [('1a', False), ('0b', True)],\n",
       " [('1b', False), ('1b', False), ('0b', True), ('0b', True)],\n",
       " [('2a', False), ('1b', False), ('0b', True)],\n",
       " [('2a', True), ('1b', False), ('0b', True)],\n",
       " [('2b', False), ('1b', True)]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def c(*ls): return sorted(ls,reverse=True, key=lambda x: (x[0], x[1]))\n",
    "def l(atom, neg=False): return (atom,neg)\n",
    "def cset(*cs): return sorted(cs)\n",
    "def maxlit(c): return c[0]\n",
    "def maxatom(c): return c[0][0]\n",
    "\n",
    "b0,a0,b1,a1,b2,a2 = map(lambda x: l(x), \"0b 0a 1b 1a 2b 2a\".split())\n",
    "nb0, na0, nb1, na1, nb2, na2 = map(lambda x: l(x, neg=True),  \"0b 0a 1b 1a 2b 2a\".split())\n",
    "\n",
    "N = cset(\n",
    "    c(b0, a1),\n",
    "    c(a0, b0),\n",
    "    c(nb0, a1),\n",
    "    c(nb0, b1, nb0, b1),\n",
    "    c(nb0, a2, b1),\n",
    "    c(nb0, na2, b1),\n",
    "    c(nb1, b2),\n",
    ")\n",
    "N\n",
    "#def Ic(n): return sum(epsC(n) for i in range(n))\n",
    "#def epsC(n): return {maximal(N[n])} if  else set()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set() [('0b', False), ('0a', False)] False\n",
      "{'0b'} [('1a', False), ('0b', False)] True\n",
      "{'0b'} [('1a', False), ('0b', True)] False\n",
      "{'1a', '0b'} [('1b', False), ('1b', False), ('0b', True), ('0b', True)] False\n",
      "{'1a', '0b', '1b'} [('2a', False), ('1b', False), ('0b', True)] True\n",
      "{'1a', '0b', '1b'} [('2a', True), ('1b', False), ('0b', True)] True\n",
      "{'1a', '0b', '1b'} [('2b', False), ('1b', True)] False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0b', '1a', '1b', '2b'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def interp(model, clause): \n",
    "    for atom, neg in clause:\n",
    "        if neg:\n",
    "            if atom not in model:\n",
    "                return True\n",
    "        else:\n",
    "            if atom in model:\n",
    "                return True\n",
    "    return False\n",
    "    #return any(atom not in model if neg else atom in model for (atom, neg) in model)\n",
    "Ic = set()\n",
    "for c in N:\n",
    "    print(Ic, c, interp(Ic, c))\n",
    "    if not interp(Ic, c):\n",
    "        atom,neg = maxlit(c)\n",
    "        if neg:\n",
    "            raise Exception(\"counterexample\", c, Ic)\n",
    "        Ic.add(atom)\n",
    "Ic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selection functions take in clause and select some subset of the negative literals.\n",
    "\n",
    "Negative and positive literals are not treated symmetrically by the model generation process.\n",
    "A little odd. I think we could have the model generation have everything true by default and derive not trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allsel(c): return [atom for (atom, neg) in c if neg]\n",
    "def nonesel(c): return []\n",
    "def maxsel(c): return max(allsel(c))\n",
    "def minsel(c): return min(allset(c))\n",
    "\n",
    "def ordered_resolve(pc,nc): # positive and negative clause\n",
    "    (a,neg) = maxlit(pc)\n",
    "    assert not neg\n",
    "    (b,neg) = maxlit(nc)\n",
    "    assert neg\n",
    "    assert a == b\n",
    "    return cset(pc[1:] + nc[1:])\n",
    "\n",
    "# https://www.tcs.ifi.lmu.de/lehre/ws-2024-25/atp/slides07-more-resolution.pdf\n",
    "def resolve_osel(pc,nc,sel):\n",
    "    assert len(sel(pc)) == 0\n",
    "    a,neg = maxlit(pc)\n",
    "    assert not neg\n",
    "    bs = sel(nc)\n",
    "    if len(bs) == 0:\n",
    "        b,neg = maxlit(nc)\n",
    "        assert neg\n",
    "        return cset(pc[1:] + nc[1:])\n",
    "    else:\n",
    "        for b in bs:\n",
    "            if b == a:\n",
    "                c = nc.copy().remove((b,True))\n",
    "                c.extend(pc[1:])\n",
    "                return cset(c)\n",
    "\n",
    "def factor(c,sel):\n",
    "    a,neg = maxlit(c)\n",
    "    assert c[1] == (a, neg)\n",
    "    assert len(sel(c) == 0)\n",
    "    return c[2:]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the any subsumption/redundant rules that work on ordered ground resolution?\n",
    "\n",
    "Connection to SAT search (counterexample clauses? unit propagate )\n",
    "Connection to sequents and other logics. Mega steps of inference\n",
    "\n",
    "abstract dpll\n",
    "https://gist.github.com/kmicinski/17dffc8b2cbbd4f3264071e19ae75dfa See this paper: https://homepage.cs.uiowa.edu/~tinelli/papers/NieOT-JACM-06.pdf\n",
    "\n",
    "Otter vs discount loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def clausedict(cs):\n",
    "    pcs,ncs = defaultdict(list),defaultdict(list)\n",
    "    for c in cs:\n",
    "        a,neg = maxlit(c)\n",
    "        if neg:\n",
    "            ncs[a].append(c)\n",
    "        else:\n",
    "            pcs[a].append(c)\n",
    "    return pcs,ncs\n",
    "\n",
    "def saturate(N):\n",
    "    passive = N\n",
    "    active = []\n",
    "    while passive:\n",
    "        passive.pop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A term ordering gives a clause ordering.\n",
    "\n",
    "Producing clauses.\n",
    "A tern ordering turns a set of clauses into a model generating datalog / prolog program\n",
    "The produced maximal atom is the head of a clause. \n",
    "The strata are the levels.\n",
    "\n",
    "This is ASP like.\n",
    "\n",
    "blanchette had those slides about completeness discussing how models get built\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2sat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METIS\n",
    "https://www.gilith.com/metis/\n",
    "ordered paramodulation\n",
    "https://github.com/gilith/metis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eprover\n",
    "```\n",
    "  --expert-heuristic=<arg>\n",
    "    Select one of the clause selection heuristics. Currently at least\n",
    "    available: Auto, Weight, StandardWeight, RWeight, FIFO, LIFO, Uniq,\n",
    "    UseWatchlist. For a full list check HEURISTICS/che_proofcontrol.c. Auto\n",
    "    is recommended if you only want to find a proof. It is special in that it\n",
    "    will also set some additional options. To have optimal performance, you\n",
    "    also should specify -tAuto to select a good term ordering. LIFO is unfair\n",
    "    and will make the prover incomplete. Uniq is used internally and is not\n",
    "    very useful in most cases. You can define more heuristics using the\n",
    "    option -H (see below).\n",
    "\n",
    "      --split-clauses[=<arg>]\n",
    "    Determine which clauses should be subject to splitting. The argument is\n",
    "    the binary 'OR' of values for the desired classes:\n",
    "         1:  Horn clauses\n",
    "         2:  Non-Horn clauses\n",
    "         4:  Negative clauses\n",
    "         8:  Positive clauses\n",
    "        16:  Clauses with both positive and negative literals\n",
    "    Each set bit adds that class to the set of clauses which will be split.\n",
    "    The option without the optional argument is equivalent to\n",
    "    --split-clauses=7.\n",
    "\n",
    "  --split-method=<arg>\n",
    "    Determine how to treat ground literals in splitting. The argument is\n",
    "    either '0' to denote no splitting of ground literals (they are all\n",
    "    assigned to the first split clause produced), '1' to denote that all\n",
    "    ground literals should form a single new clause, or '2', in which case\n",
    "    ground literals are treated as usual and are all split off into\n",
    "    individual clauses.\n",
    "\n",
    "       -H <arg>\n",
    "  --define-heuristic=<arg>\n",
    "    Define a clause selection heuristic (see manual for details). Later\n",
    "    definitions override previous definitions.\n",
    "```\n",
    "\n",
    "Special clause type `watchlist`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Union find\n",
    "\n",
    "In a my egraphs 2024 talk https://www.philipzucker.com/egraph2024_talk_done/ , I showed how to use twee to get a union find. This is the same idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/uf.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/uf.p\n",
    "\n",
    "cnf(ax1, axiom, a = b).\n",
    "cnf(ax2, axiom, b = c).\n",
    "cnf(ax2, axiom, c = b).\n",
    "cnf(ax2, axiom, b = z).\n",
    "cnf(ax2, axiom, z = c).\n",
    "cnf(ax3, axiom, d = e).\n",
    "%cnf(ax4, axiom, d != a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Initializing proof state\n",
      "# Scanning for AC axioms\n",
      "#\n",
      "#cnf(i_0_7, plain, (b=a)).\n",
      "#\n",
      "#cnf(i_0_8, plain, (c=a)).\n",
      "##\n",
      "#cnf(i_0_10, plain, (z=a)).\n",
      "##\n",
      "#cnf(i_0_12, plain, (d=e)).\n",
      "\n",
      "# No proof found!\n",
      "# SZS status Satisfiable\n",
      "# Processed positive unit clauses:\n",
      "cnf(i_0_7, plain, (b=a)).\n",
      "cnf(i_0_8, plain, (c=a)).\n",
      "cnf(i_0_10, plain, (z=a)).\n",
      "cnf(i_0_12, plain, (d=e)).\n",
      "\n",
      "# Processed negative unit clauses:\n",
      "\n",
      "# Processed non-unit clauses:\n",
      "\n",
      "# Unprocessed positive unit clauses:\n",
      "\n",
      "# Unprocessed negative unit clauses:\n",
      "\n",
      "# Unprocessed non-unit clauses:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --print-saturated /tmp/uf.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--print-saturated=teigEIGaA --print-sat-info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eprover: Wrong argument to option -G (--order-precedence-generation). Possible values: none, unary_first, unary_freq, arity, invarity, const_max, const_min, freq, invfreq, invconjfreq, invfreqconjmax, invfreqconjmin, invfreqconstmin, invfreqhack, typefreq, invtypefreq, combfreq, invcombfreq, arrayopt, orient_axioms\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --order-precedence-generation=none"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\"invfreq: Sort symbols by frequency (frequently occurring symbols are smaller).\n",
    "In our experience, this is one of the best general-purpose precedence gen-\n",
    "eration schemes.\"\n",
    "\n",
    "\"The option --literal-comparison=<arg> allow the user to select alterna-\n",
    "tive literal comparison schemes. In particular, literals will be first compared by\n",
    "predicate symbol, and only then by full terms. This is a poor man’s version of\n",
    "transfinite KBO [LW07, KMV11], applied to literals only, but also extended to\n",
    "LPO.\"\n",
    "\n",
    "Ah, if I use `>` unquoted bash thinks its a file redirect\n",
    "\n",
    "\"There are two uses for a watchlist: To guide the proof search (using a heuris-\n",
    "tic that prefers clauses on the watchlist), or to find purely constructive proofs\n",
    "for clauses on the watchlist.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnf(ax1, axiom, (a=b), file('/tmp/uf.p', ax1)).\n",
      "cnf(ax2, axiom, (b=c), file('/tmp/uf.p', ax2)).\n",
      "cnf(ax2, axiom, (z=c), file('/tmp/uf.p', ax2)).\n",
      "cnf(ax3, axiom, (d=e), file('/tmp/uf.p', ax3)).\n",
      "# Initializing proof state\n",
      "# Scanning for AC axioms\n",
      "cnf(c_0_5, plain, (a=c),inference(rw, [status(thm)],[c_0_-9223372036854775799,c_0_-9223372036854775798])).\n",
      "cnf(c_0_6, plain, (b=z),inference(rw, [status(thm)],[c_0_-9223372036854775798,c_0_-9223372036854775797])).\n",
      "cnf(c_0_7, plain, (a=z),inference(rw, [status(thm)],[c_0_5,c_0_-9223372036854775797])).\n",
      "cnf(c_0_8, plain, (c=z), c_0_-9223372036854775797,['final']).\n",
      "cnf(c_0_9, plain, (d=e), c_0_-9223372036854775796,['final']).\n",
      "cnf(c_0_10, plain, (a=z), c_0_7,['final']).\n",
      "cnf(c_0_11, plain, (b=z), c_0_6,['final']).\n",
      "\n",
      "# No proof found!\n",
      "# SZS status Satisfiable\n",
      "# Processed positive unit clauses:\n",
      "cnf(c_0_8, plain, (c=z)).\n",
      "cnf(c_0_9, plain, (d=e)).\n",
      "cnf(c_0_10, plain, (a=z)).\n",
      "cnf(c_0_11, plain, (b=z)).\n",
      "\n",
      "# Processed negative unit clauses:\n",
      "\n",
      "# Processed non-unit clauses:\n",
      "\n",
      "# Unprocessed positive unit clauses:\n",
      "\n",
      "# Unprocessed negative unit clauses:\n",
      "\n",
      "# Unprocessed non-unit clauses:\n",
      "\n",
      "\n",
      "# Parsed axioms                        : 4\n",
      "# Removed by relevancy pruning/SinE    : 0\n",
      "# Initial clauses                      : 4\n",
      "# Removed in clause preprocessing      : 0\n",
      "# Initial clauses in saturation        : 4\n",
      "# Processed clauses                    : 6\n",
      "# ...of these trivial                  : 0\n",
      "# ...subsumed                          : 0\n",
      "# ...remaining for further processing  : 6\n",
      "# Other redundant clauses eliminated   : 0\n",
      "# Clauses deleted for lack of memory   : 0\n",
      "# Backward-subsumed                    : 0\n",
      "# Backward-rewritten                   : 2\n",
      "# Generated clauses                    : 0\n",
      "# ...of the previous two non-redundant : 2\n",
      "# ...aggressively subsumed             : 0\n",
      "# Contextual simplify-reflections      : 0\n",
      "# Paramodulations                      : 0\n",
      "# Factorizations                       : 0\n",
      "# NegExts                              : 0\n",
      "# Equation resolutions                 : 0\n",
      "# Disequality decompositions           : 0\n",
      "# Total rewrite steps                  : 3\n",
      "# ...of those cached                   : 1\n",
      "# Propositional unsat checks           : 0\n",
      "#    Propositional check models        : 0\n",
      "#    Propositional check unsatisfiable : 0\n",
      "#    Propositional clauses             : 0\n",
      "#    Propositional clauses after purity: 0\n",
      "#    Propositional unsat core size     : 0\n",
      "#    Propositional preprocessing time  : 0.000\n",
      "#    Propositional encoding time       : 0.000\n",
      "#    Propositional solver time         : 0.000\n",
      "#    Success case prop preproc time    : 0.000\n",
      "#    Success case prop encoding time   : 0.000\n",
      "#    Success case prop solver time     : 0.000\n",
      "# Current number of processed clauses  : 4\n",
      "#    Positive orientable unit clauses  : 4\n",
      "#    Positive unorientable unit clauses: 0\n",
      "#    Negative unit clauses             : 0\n",
      "#    Non-unit-clauses                  : 0\n",
      "# Current number of unprocessed clauses: 0\n",
      "# ...number of literals in the above   : 0\n",
      "# Current number of archived formulas  : 0\n",
      "# Current number of archived clauses   : 2\n",
      "# Clause-clause subsumption calls (NU) : 0\n",
      "# Rec. Clause-clause subsumption calls : 0\n",
      "# Non-unit clause-clause subsumptions  : 0\n",
      "# Unit Clause-clause subsumption calls : 0\n",
      "# Rewrite failures with RHS unbound    : 0\n",
      "# BW rewrite match attempts            : 2\n",
      "# BW rewrite match successes           : 2\n",
      "# Condensation attempts                : 0\n",
      "# Condensation successes               : 0\n",
      "# Termbank termtop insertions          : 32\n",
      "# Search garbage collected termcells   : 0\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --output-level=4  --print-saturated --term-ordering=KBO6 --precedence=\"a>b>c>d>e>z\" /tmp/uf.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnf(ax1, axiom, (a=b), file('/tmp/uf.p', ax1)).\n",
      "cnf(ax2, axiom, (b=c), file('/tmp/uf.p', ax2)).\n",
      "cnf(ax2, axiom, (z=c), file('/tmp/uf.p', ax2)).\n",
      "cnf(ax3, axiom, (d=e), file('/tmp/uf.p', ax3)).\n",
      "setting user weights\n",
      "# Initializing proof state\n",
      "# Scanning for AC axioms\n",
      "cnf(c_0_5, plain, (a=c),inference(rw, [status(thm)],[c_0_-9223372036854775799,c_0_-9223372036854775798])).\n",
      "cnf(c_0_6, plain, (b=z),inference(rw, [status(thm)],[c_0_-9223372036854775798,c_0_-9223372036854775797])).\n",
      "cnf(c_0_7, plain, (a=z),inference(rw, [status(thm)],[c_0_5,c_0_-9223372036854775797])).\n",
      "cnf(c_0_8, plain, (c=z), c_0_-9223372036854775797,['final']).\n",
      "cnf(c_0_9, plain, (d=e), c_0_-9223372036854775796,['final']).\n",
      "cnf(c_0_10, plain, (a=z), c_0_7,['final']).\n",
      "cnf(c_0_11, plain, (b=z), c_0_6,['final']).\n",
      "\n",
      "# No proof found!\n",
      "# SZS status Satisfiable\n",
      "# Processed positive unit clauses:\n",
      "cnf(c_0_8, plain, (c=z)).\n",
      "cnf(c_0_9, plain, (d=e)).\n",
      "cnf(c_0_10, plain, (a=z)).\n",
      "cnf(c_0_11, plain, (b=z)).\n",
      "\n",
      "# Processed negative unit clauses:\n",
      "\n",
      "# Processed non-unit clauses:\n",
      "\n",
      "# Unprocessed positive unit clauses:\n",
      "\n",
      "# Unprocessed negative unit clauses:\n",
      "\n",
      "# Unprocessed non-unit clauses:\n",
      "\n",
      "\n",
      "# Parsed axioms                        : 4\n",
      "# Removed by relevancy pruning/SinE    : 0\n",
      "# Initial clauses                      : 4\n",
      "# Removed in clause preprocessing      : 0\n",
      "# Initial clauses in saturation        : 4\n",
      "# Processed clauses                    : 6\n",
      "# ...of these trivial                  : 0\n",
      "# ...subsumed                          : 0\n",
      "# ...remaining for further processing  : 6\n",
      "# Other redundant clauses eliminated   : 0\n",
      "# Clauses deleted for lack of memory   : 0\n",
      "# Backward-subsumed                    : 0\n",
      "# Backward-rewritten                   : 2\n",
      "# Generated clauses                    : 0\n",
      "# ...of the previous two non-redundant : 2\n",
      "# ...aggressively subsumed             : 0\n",
      "# Contextual simplify-reflections      : 0\n",
      "# Paramodulations                      : 0\n",
      "# Factorizations                       : 0\n",
      "# NegExts                              : 0\n",
      "# Equation resolutions                 : 0\n",
      "# Disequality decompositions           : 0\n",
      "# Total rewrite steps                  : 3\n",
      "# ...of those cached                   : 1\n",
      "# Propositional unsat checks           : 0\n",
      "#    Propositional check models        : 0\n",
      "#    Propositional check unsatisfiable : 0\n",
      "#    Propositional clauses             : 0\n",
      "#    Propositional clauses after purity: 0\n",
      "#    Propositional unsat core size     : 0\n",
      "#    Propositional preprocessing time  : 0.000\n",
      "#    Propositional encoding time       : 0.000\n",
      "#    Propositional solver time         : 0.000\n",
      "#    Success case prop preproc time    : 0.000\n",
      "#    Success case prop encoding time   : 0.000\n",
      "#    Success case prop solver time     : 0.000\n",
      "# Current number of processed clauses  : 4\n",
      "#    Positive orientable unit clauses  : 4\n",
      "#    Positive unorientable unit clauses: 0\n",
      "#    Negative unit clauses             : 0\n",
      "#    Non-unit-clauses                  : 0\n",
      "# Current number of unprocessed clauses: 0\n",
      "# ...number of literals in the above   : 0\n",
      "# Current number of archived formulas  : 0\n",
      "# Current number of archived clauses   : 2\n",
      "# Clause-clause subsumption calls (NU) : 0\n",
      "# Rec. Clause-clause subsumption calls : 0\n",
      "# Non-unit clause-clause subsumptions  : 0\n",
      "# Unit Clause-clause subsumption calls : 0\n",
      "# Rewrite failures with RHS unbound    : 0\n",
      "# BW rewrite match attempts            : 2\n",
      "# BW rewrite match successes           : 2\n",
      "# Condensation attempts                : 0\n",
      "# Condensation successes               : 0\n",
      "# Termbank termtop insertions          : 32\n",
      "# Search garbage collected termcells   : 0\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --output-level=4  --print-saturated --term-ordering=KBO6 --order-weights=a:9,b:8,c:7,d:6,e:5,z:4 /tmp/uf.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## edge path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/path.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/path.p\n",
    "\n",
    "cnf(ax2, axiom, path(X,Y) | ~edge(X,Y)).\n",
    "cnf(ax1, axiom, path(X,Z) | ~edge(X,Y) | ~path(Y,Z)).\n",
    "cnf(ax1, axiom, edge(a,b)).\n",
    "cnf(ax2, axiom, edge(b,c)).\n",
    "cnf(ax3, axiom, edge(c,d)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NoSelection - doesm't terminate\n",
    "NoGeneration - not sure what this one is doing\n",
    "SelectNegativeLiterals\n",
    "SelectLargestNegLit\n",
    "--precedence=\"path>edge\" \n",
    "-term-ordering=LPO4\n",
    "\n",
    "--literal-selection-strategy=\"SelectSmallestNegLit\" \n",
    "\n",
    "--auto doesn't process the path\n",
    "No selection doesn't terminate.\n",
    "\n",
    "--print-strategy \n",
    "\n",
    "Oh yea. Those non ground are necessary if there is no multi-resolution rule.\n",
    "\n",
    "precedence does not seem to matter to final result\n",
    "\n",
    "--filter-saturated='u'\n",
    "--literal-selection-strategy=\"SelectSmallestNegLit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eprover: Wrong argument to option -W (--literal-selection-strategy). Possible values: NoSelection, NoGeneration, SelectNegativeLiterals, PSelectNegativeLiterals, SelectPureVarNegLiterals, PSelectPureVarNegLiterals, SelectLargestNegLit, PSelectLargestNegLit, SelectSmallestNegLit, PSelectSmallestNegLit, SelectLargestOrientable, PSelectLargestOrientable, MSelectLargestOrientable, SelectSmallestOrientable, PSelectSmallestOrientable, MSelectSmallestOrientable, SelectDiffNegLit, PSelectDiffNegLit, SelectGroundNegLit, PSelectGroundNegLit, SelectOptimalLit, PSelectOptimalLit, SelectMinOptimalLit, PSelectMinOptimalLit, SelectMinOptimalNoTypePred, PSelectMinOptimalNoTypePred, SelectMinOptimalNoXTypePred, PSelectMinOptimalNoXTypePred, SelectMinOptimalNoRXTypePred, PSelectMinOptimalNoRXTypePred, SelectCondOptimalLit, PSelectCondOptimalLit, SelectAllCondOptimalLit, PSelectAllCondOptimalLit, SelectOptimalRestrDepth2, PSelectOptimalRestrDepth2, SelectOptimalRestrPDepth2, PSelectOptimalRestrPDepth2, SelectOptimalRestrNDepth2, PSelectOptimalRestrNDepth2, SelectNonRROptimalLit, PSelectNonRROptimalLit, SelectNonStrongRROptimalLit, PSelectNonStrongRROptimalLit, SelectAntiRROptimalLit, PSelectAntiRROptimalLit, SelectNonAntiRROptimalLit, PSelectNonAntiRROptimalLit, SelectStrongRRNonRROptimalLit, PSelectStrongRRNonRROptimalLit, SelectUnlessUniqMax, PSelectUnlessUniqMax, SelectUnlessPosMax, PSelectUnlessPosMax, SelectUnlessUniqPosMax, PSelectUnlessUniqPosMax, SelectUnlessUniqMaxPos, PSelectUnlessUniqMaxPos, SelectComplex, PSelectComplex, SelectComplexExceptRRHorn, PSelectComplexExceptRRHorn, SelectLComplex, PSelectLComplex, SelectMaxLComplex, PSelectMaxLComplex, SelectMaxLComplexNoTypePred, PSelectMaxLComplexNoTypePred, SelectMaxLComplexNoXTypePred, PSelectMaxLComplexNoXTypePred, SelectComplexPreferNEQ, PSelectComplexPreferNEQ, SelectComplexPreferEQ, PSelectComplexPreferEQ, SelectComplexExceptUniqMaxHorn, PSelectComplexExceptUniqMaxHorn, MSelectComplexExceptUniqMaxHorn, SelectNewComplex, PSelectNewComplex, SelectNewComplexExceptUniqMaxHorn, PSelectNewComplexExceptUniqMaxHorn, SelectMinInfpos, PSelectMinInfpos, HSelectMinInfpos, GSelectMinInfpos, SelectMinInfposNoTypePred, PSelectMinInfposNoTypePred, SelectMin2Infpos, PSelectMin2Infpos, SelectComplexExceptUniqMaxPosHorn, PSelectComplexExceptUniqMaxPosHorn, SelectUnlessUniqMaxSmallestOrientable, PSelectUnlessUniqMaxSmallestOrientable, SelectDivLits, SelectDivPreferIntoLits, SelectMaxLComplexG, SelectMaxLComplexAvoidPosPred, SelectMaxLComplexAPPNTNp, SelectMaxLComplexAPPNoType, SelectMaxLComplexAvoidPosUPred, SelectComplexG, SelectComplexAHP, PSelectComplexAHP, SelectNewComplexAHP, PSelectNewComplexAHP, SelectComplexAHPExceptRRHorn, PSelectComplexAHPExceptRRHorn, SelectNewComplexAHPExceptRRHorn, PSelectNewComplexAHPExceptRRHorn, SelectNewComplexAHPExceptUniqMaxHorn, PSelectNewComplexAHPExceptUniqMaxHorn, SelectNewComplexAHPNS, SelectVGNonCR, SelectCQArEqLast, SelectCQArEqFirst, SelectCQIArEqLast, SelectCQIArEqFirst, SelectCQAr, SelectCQIAr, SelectCQArNpEqFirst, SelectCQIArNpEqFirst, SelectGrCQArEqFirst, SelectCQGrArEqFirst, SelectCQArNTEqFirst, SelectCQIArNTEqFirst, SelectCQArNTNpEqFirst, SelectCQIArNTNpEqFirst, SelectCQArNXTEqFirst, SelectCQIArNXTEqFirst, SelectCQArNTNp, SelectCQIArNTNp, SelectCQArNT, SelectCQIArNT, SelectCQArNp, SelectCQIArNp, SelectCQArNpEqFirstUnlessPDom, SelectCQArNTEqFirstUnlessPDom, SelectCQPrecW, SelectCQIPrecW, SelectCQPrecWNTNp, SelectCQIPrecWNTNp, SelectMaxLComplexAvoidAppVar, SelectMaxLComplexStronglyAvoidAppVar, SelectMaxLComplexPreferAppVar\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --literal-selection-strategy=none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnf(ax2, axiom, (path(X1,X2)|~edge(X1,X2)), file('/tmp/path.p', ax2)).\n",
      "cnf(ax1, axiom, (path(X1,X2)|~edge(X1,X3)|~path(X3,X2)), file('/tmp/path.p', ax1)).\n",
      "cnf(ax1, axiom, (edge(a,b)), file('/tmp/path.p', ax1)).\n",
      "cnf(ax2, axiom, (edge(b,c)), file('/tmp/path.p', ax2)).\n",
      "cnf(ax3, axiom, (edge(c,d)), file('/tmp/path.p', ax3)).\n",
      "cnf(c_0_6, plain, (path(X1,X2)|~edge(X1,X2)),inference(fof_simplification, [status(thm)],[c_0_1])).\n",
      "cnf(c_0_7, plain, (path(X1,X2)|~edge(X1,X3)|~path(X3,X2)),inference(fof_simplification, [status(thm)],[c_0_2])).\n",
      "# Initializing proof state\n",
      "cnf(c_0_8, plain, (edge(a,b)), c_0_-9223372036854775793,['eval']).\n",
      "cnf(c_0_9, plain, (edge(b,c)), c_0_-9223372036854775792,['eval']).\n",
      "cnf(c_0_10, plain, (edge(c,d)), c_0_-9223372036854775791,['eval']).\n",
      "cnf(c_0_11, plain, (path(X1,X2)|~edge(X1,X2)), c_0_-9223372036854775795,['eval']).\n",
      "cnf(c_0_12, plain, (path(X1,X2)|~path(X3,X2)|~edge(X1,X3)), c_0_-9223372036854775794,['eval']).\n",
      "# Scanning for AC axioms\n",
      "cnf(c_0_13, plain, (edge(a,b)), c_0_8,['new_given']).\n",
      "cnf(c_0_14, plain, (edge(b,c)), c_0_9,['new_given']).\n",
      "cnf(c_0_15, plain, (edge(c,d)), c_0_10,['new_given']).\n",
      "cnf(c_0_16, plain, (path(X1,X2)|~edge(X1,X2)), c_0_11,['new_given']).\n",
      "cnf(c_0_17, plain, (path(c,d)),inference(pm,[status(thm)],[c_0_16,c_0_15])).\n",
      "cnf(c_0_18, plain, (path(b,c)),inference(pm,[status(thm)],[c_0_16,c_0_14])).\n",
      "cnf(c_0_19, plain, (path(a,b)),inference(pm,[status(thm)],[c_0_16,c_0_13])).\n",
      "cnf(c_0_20, plain, (path(c,d)), c_0_17,['eval']).\n",
      "cnf(c_0_21, plain, (path(b,c)), c_0_18,['eval']).\n",
      "cnf(c_0_22, plain, (path(a,b)), c_0_19,['eval']).\n",
      "cnf(c_0_23, plain, (path(X1,X2)|~edge(X1,X3)|~path(X3,X2)), c_0_12,['new_given']).\n",
      "cnf(c_0_24, plain, (path(c,X1)|~path(d,X1)),inference(pm,[status(thm)],[c_0_23,c_0_15])).\n",
      "cnf(c_0_25, plain, (path(b,X1)|~path(c,X1)),inference(pm,[status(thm)],[c_0_23,c_0_14])).\n",
      "cnf(c_0_26, plain, (path(a,X1)|~path(b,X1)),inference(pm,[status(thm)],[c_0_23,c_0_13])).\n",
      "cnf(c_0_27, plain, (path(c,X1)|~path(d,X1)), c_0_24,['eval']).\n",
      "cnf(c_0_28, plain, (path(b,X1)|~path(c,X1)), c_0_25,['eval']).\n",
      "cnf(c_0_29, plain, (path(a,X1)|~path(b,X1)), c_0_26,['eval']).\n",
      "cnf(c_0_30, plain, (path(c,d)), c_0_20,['new_given']).\n",
      "cnf(c_0_31, plain, (path(b,c)), c_0_21,['new_given']).\n",
      "cnf(c_0_32, plain, (path(a,b)), c_0_22,['new_given']).\n",
      "cnf(c_0_33, plain, (path(c,X1)|~path(d,X1)), c_0_27,['new_given']).\n",
      "cnf(c_0_34, plain, (path(b,X1)|~path(c,X1)), c_0_28,['new_given']).\n",
      "cnf(c_0_35, plain, (path(b,d)),inference(pm,[status(thm)],[c_0_34,c_0_30])).\n",
      "cnf(c_0_36, plain, (path(b,d)), c_0_35,['eval']).\n",
      "cnf(c_0_37, plain, (path(a,X1)|~path(b,X1)), c_0_29,['new_given']).\n",
      "cnf(c_0_38, plain, (path(a,c)),inference(pm,[status(thm)],[c_0_37,c_0_31])).\n",
      "cnf(c_0_39, plain, (path(a,c)), c_0_38,['eval']).\n",
      "cnf(c_0_40, plain, (path(b,d)), c_0_36,['new_given']).\n",
      "cnf(c_0_41, plain, (path(a,d)),inference(pm,[status(thm)],[c_0_37,c_0_40])).\n",
      "cnf(c_0_42, plain, (path(a,d)), c_0_41,['eval']).\n",
      "cnf(c_0_43, plain, (path(a,c)), c_0_39,['new_given']).\n",
      "cnf(c_0_44, plain, (path(a,d)), c_0_42,['new_given']).\n",
      "cnf(c_0_45, plain, (edge(a,b)), c_0_13,['final']).\n",
      "cnf(c_0_46, plain, (edge(b,c)), c_0_14,['final']).\n",
      "cnf(c_0_47, plain, (edge(c,d)), c_0_15,['final']).\n",
      "cnf(c_0_48, plain, (path(c,d)), c_0_30,['final']).\n",
      "cnf(c_0_49, plain, (path(b,c)), c_0_31,['final']).\n",
      "cnf(c_0_50, plain, (path(a,b)), c_0_32,['final']).\n",
      "cnf(c_0_51, plain, (path(b,d)), c_0_40,['final']).\n",
      "cnf(c_0_52, plain, (path(a,c)), c_0_43,['final']).\n",
      "cnf(c_0_53, plain, (path(a,d)), c_0_44,['final']).\n",
      "cnf(c_0_54, plain, (path(X1,X2)|~edge(X1,X2)), c_0_16,['final']).\n",
      "cnf(c_0_55, plain, (path(X1,X2)|~edge(X1,X3)|~path(X3,X2)), c_0_23,['final']).\n",
      "cnf(c_0_56, plain, (path(c,X1)|~path(d,X1)), c_0_33,['final']).\n",
      "cnf(c_0_57, plain, (path(b,X1)|~path(c,X1)), c_0_34,['final']).\n",
      "cnf(c_0_58, plain, (path(a,X1)|~path(b,X1)), c_0_37,['final']).\n",
      "\n",
      "# No proof found!\n",
      "# SZS status Satisfiable\n",
      "# Processed positive unit clauses:\n",
      "cnf(c_0_45, plain, (edge(a,b))).\n",
      "cnf(c_0_46, plain, (edge(b,c))).\n",
      "cnf(c_0_47, plain, (edge(c,d))).\n",
      "cnf(c_0_48, plain, (path(c,d))).\n",
      "cnf(c_0_49, plain, (path(b,c))).\n",
      "cnf(c_0_50, plain, (path(a,b))).\n",
      "cnf(c_0_51, plain, (path(b,d))).\n",
      "cnf(c_0_52, plain, (path(a,c))).\n",
      "cnf(c_0_53, plain, (path(a,d))).\n",
      "\n",
      "# Processed negative unit clauses:\n",
      "\n",
      "# Processed non-unit clauses:\n",
      "cnf(c_0_54, plain, (path(X1,X2)|~edge(X1,X2))).\n",
      "cnf(c_0_55, plain, (path(X1,X2)|~edge(X1,X3)|~path(X3,X2))).\n",
      "cnf(c_0_56, plain, (path(c,X1)|~path(d,X1))).\n",
      "cnf(c_0_57, plain, (path(b,X1)|~path(c,X1))).\n",
      "cnf(c_0_58, plain, (path(a,X1)|~path(b,X1))).\n",
      "\n",
      "# Unprocessed positive unit clauses:\n",
      "\n",
      "# Unprocessed negative unit clauses:\n",
      "\n",
      "# Unprocessed non-unit clauses:\n",
      "\n",
      "\n",
      "# Parsed axioms                        : 5\n",
      "# Removed by relevancy pruning/SinE    : 0\n",
      "# Initial clauses                      : 5\n",
      "# Removed in clause preprocessing      : 0\n",
      "# Initial clauses in saturation        : 5\n",
      "# Processed clauses                    : 14\n",
      "# ...of these trivial                  : 0\n",
      "# ...subsumed                          : 0\n",
      "# ...remaining for further processing  : 14\n",
      "# Other redundant clauses eliminated   : 0\n",
      "# Clauses deleted for lack of memory   : 0\n",
      "# Backward-subsumed                    : 0\n",
      "# Backward-rewritten                   : 0\n",
      "# Generated clauses                    : 9\n",
      "# ...of the previous two non-redundant : 9\n",
      "# ...aggressively subsumed             : 0\n",
      "# Contextual simplify-reflections      : 0\n",
      "# Paramodulations                      : 9\n",
      "# Factorizations                       : 0\n",
      "# NegExts                              : 0\n",
      "# Equation resolutions                 : 0\n",
      "# Disequality decompositions           : 0\n",
      "# Total rewrite steps                  : 0\n",
      "# ...of those cached                   : 0\n",
      "# Propositional unsat checks           : 0\n",
      "#    Propositional check models        : 0\n",
      "#    Propositional check unsatisfiable : 0\n",
      "#    Propositional clauses             : 0\n",
      "#    Propositional clauses after purity: 0\n",
      "#    Propositional unsat core size     : 0\n",
      "#    Propositional preprocessing time  : 0.000\n",
      "#    Propositional encoding time       : 0.000\n",
      "#    Propositional solver time         : 0.000\n",
      "#    Success case prop preproc time    : 0.000\n",
      "#    Success case prop encoding time   : 0.000\n",
      "#    Success case prop solver time     : 0.000\n",
      "# Current number of processed clauses  : 14\n",
      "#    Positive orientable unit clauses  : 9\n",
      "#    Positive unorientable unit clauses: 0\n",
      "#    Negative unit clauses             : 0\n",
      "#    Non-unit-clauses                  : 5\n",
      "# Current number of unprocessed clauses: 0\n",
      "# ...number of literals in the above   : 0\n",
      "# Current number of archived formulas  : 0\n",
      "# Current number of archived clauses   : 0\n",
      "# Clause-clause subsumption calls (NU) : 1\n",
      "# Rec. Clause-clause subsumption calls : 1\n",
      "# Non-unit clause-clause subsumptions  : 0\n",
      "# Unit Clause-clause subsumption calls : 0\n",
      "# Rewrite failures with RHS unbound    : 0\n",
      "# BW rewrite match attempts            : 0\n",
      "# BW rewrite match successes           : 0\n",
      "# Condensation attempts                : 0\n",
      "# Condensation successes               : 0\n",
      "# Termbank termtop insertions          : 138\n",
      "# Search garbage collected termcells   : 9\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --print-saturated --output-level=10 --term-ordering=LPO4 --expert-heuristic=FIFO --literal-selection-strategy=\"SelectLargestNegLit\" --precedence=\"path>edge\"   /tmp/path.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knuth Bendix\n",
    "UEQ \n",
    "http://cl-informatik.uibk.ac.at/software/mkbtt/download.php 101 problems\n",
    "\n",
    "https://www.metalevel.at/trs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/grp.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/grp.p\n",
    "cnf(ax1, axiom, mul(X,mul(Y,Z)) = mul(mul(X,Y),Z)).\n",
    "cnf(ax2, axiom, mul(e,X) = X).\n",
    "cnf(ax3, axiom, mul(inv(X), X) = e).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! eprover-ho --print-saturated --output-level=10 --term-ordering=KBO6 --literal-selection-strategy=\"SelectLargestNegLit\"  /tmp/grp.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unification\n",
    "Raw usage. Equality resolution rule ought to put unifier into ans predicate.\n",
    "\n",
    "`er` is equality resolution. Interesting.\n",
    "I needed to give it a selection to make it do this\n",
    "\n",
    "Ah, side condition says u != v has to be eligibile for resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/unify.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/unify.p\n",
    "\n",
    "cnf(ax1, axiom, unifier(a(A),b(B)) | f(g(A)) != f(B)).\n",
    "%cnf(ax1, axiom, g(A) != B  | f(g(A)) != f(B)).\n",
    "% cnf(, ocnjecture, ?[A,B] : f(g(A)) = f(B)).  negate. ![A,B]: ~(f(g(A)) = f(B)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnf(ax1, axiom, (unifier(a(X1),b(X2))|f(g(X1))!=f(X2)), file('/tmp/unify.p', ax1)).\n",
      "cnf(c_0_2, plain, (unifier(a(X1),b(X2))|f(g(X1))!=f(X2)),inference(fof_simplification, [status(thm)],[c_0_1])).\n",
      "# Initializing proof state\n",
      "cnf(c_0_3, plain, (unifier(a(X1),b(X2))|f(g(X1))!=f(X2)), c_0_-9223372036854775804,['eval']).\n",
      "# Scanning for AC axioms\n",
      "cnf(c_0_4, plain, (unifier(a(X1),b(X2))|f(g(X1))!=f(X2)), c_0_3,['new_given']).\n",
      "cnf(c_0_5, plain, (unifier(a(X1),b(g(X1)))),inference(er,[status(thm)],[c_0_4])).\n",
      "cnf(c_0_6, plain, (unifier(a(X1),b(g(X1)))), c_0_5,['eval']).\n",
      "cnf(c_0_7, plain, (unifier(a(X1),b(g(X1)))), c_0_6,['new_given']).\n",
      "cnf(c_0_8, plain, (unifier(a(X1),b(g(X1)))), c_0_7,['final']).\n",
      "cnf(c_0_9, plain, (unifier(a(X1),b(X2))|f(g(X1))!=f(X2)), c_0_4,['final']).\n",
      "\n",
      "# No proof found!\n",
      "# SZS status Satisfiable\n",
      "# SZS output start Saturation\n",
      "cnf(ax1, axiom, (unifier(a(X1),b(X2))|f(g(X1))!=f(X2)), file('/tmp/unify.p', ax1)).\n",
      "cnf(c_0_1, plain, (unifier(a(X1),b(X2))|f(g(X1))!=f(X2)), inference(fof_simplification,[status(thm)],[ax1])).\n",
      "cnf(c_0_2, plain, (unifier(a(X1),b(X2))|f(g(X1))!=f(X2)), c_0_1, ['final']).\n",
      "cnf(c_0_3, plain, (unifier(a(X1),b(g(X1)))), inference(er,[status(thm)],[c_0_2]), ['final']).\n",
      "# SZS output end Saturation\n",
      "# Processed positive unit clauses:\n",
      "cnf(c_0_3, plain, (unifier(a(X1),b(g(X1))))).\n",
      "\n",
      "# Processed negative unit clauses:\n",
      "\n",
      "# Processed non-unit clauses:\n",
      "cnf(c_0_9, plain, (unifier(a(X1),b(X2))|f(g(X1))!=f(X2))).\n",
      "\n",
      "# Unprocessed positive unit clauses:\n",
      "\n",
      "# Unprocessed negative unit clauses:\n",
      "\n",
      "# Unprocessed non-unit clauses:\n",
      "\n",
      "\n",
      "# Parsed axioms                        : 1\n",
      "# Removed by relevancy pruning/SinE    : 0\n",
      "# Initial clauses                      : 1\n",
      "# Removed in clause preprocessing      : 0\n",
      "# Initial clauses in saturation        : 1\n",
      "# Processed clauses                    : 2\n",
      "# ...of these trivial                  : 0\n",
      "# ...subsumed                          : 0\n",
      "# ...remaining for further processing  : 2\n",
      "# Other redundant clauses eliminated   : 0\n",
      "# Clauses deleted for lack of memory   : 0\n",
      "# Backward-subsumed                    : 0\n",
      "# Backward-rewritten                   : 0\n",
      "# Generated clauses                    : 1\n",
      "# ...of the previous two non-redundant : 1\n",
      "# ...aggressively subsumed             : 0\n",
      "# Contextual simplify-reflections      : 0\n",
      "# Paramodulations                      : 0\n",
      "# Factorizations                       : 0\n",
      "# NegExts                              : 0\n",
      "# Equation resolutions                 : 1\n",
      "# Disequality decompositions           : 0\n",
      "# Total rewrite steps                  : 0\n",
      "# ...of those cached                   : 0\n",
      "# Propositional unsat checks           : 0\n",
      "#    Propositional check models        : 0\n",
      "#    Propositional check unsatisfiable : 0\n",
      "#    Propositional clauses             : 0\n",
      "#    Propositional clauses after purity: 0\n",
      "#    Propositional unsat core size     : 0\n",
      "#    Propositional preprocessing time  : 0.000\n",
      "#    Propositional encoding time       : 0.000\n",
      "#    Propositional solver time         : 0.000\n",
      "#    Success case prop preproc time    : 0.000\n",
      "#    Success case prop encoding time   : 0.000\n",
      "#    Success case prop solver time     : 0.000\n",
      "# Current number of processed clauses  : 2\n",
      "#    Positive orientable unit clauses  : 1\n",
      "#    Positive unorientable unit clauses: 0\n",
      "#    Negative unit clauses             : 0\n",
      "#    Non-unit-clauses                  : 1\n",
      "# Current number of unprocessed clauses: 0\n",
      "# ...number of literals in the above   : 0\n",
      "# Current number of archived formulas  : 0\n",
      "# Current number of archived clauses   : 0\n",
      "# Clause-clause subsumption calls (NU) : 0\n",
      "# Rec. Clause-clause subsumption calls : 0\n",
      "# Non-unit clause-clause subsumptions  : 0\n",
      "# Unit Clause-clause subsumption calls : 0\n",
      "# Rewrite failures with RHS unbound    : 0\n",
      "# BW rewrite match attempts            : 0\n",
      "# BW rewrite match successes           : 0\n",
      "# Condensation attempts                : 0\n",
      "# Condensation successes               : 0\n",
      "# Termbank termtop insertions          : 53\n",
      "# Search garbage collected termcells   : 3\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --print-saturated --output-level=6 --literal-selection-strategy=\"SelectLargestNegLit\" --proof-object /tmp/unify.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also E-unification and lambda unification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/eq.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/eq.p\n",
    "cnf(assoc, axiom, mul(X,mul(Y,Z)) = mul(mul(X,Y),Z)).\n",
    "cnf(com, axiom, mul(Y,X) = mul(X,Y)).\n",
    "%fof(mul_e, conjecture, ?[X,Y] : mul(mul(a,Y), X) = mul(X,mul(a,X))).\n",
    "%fof(mul_e, conjecture, ?[X,Y,Z] : mul(mul(Z,Y), X) = mul(X,mul(Z,X))).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnf(assoc, axiom, (mul(X1,mul(X2,X3))=mul(mul(X1,X2),X3)), file('/tmp/eq.p', assoc)).\n",
      "cnf(com, axiom, (mul(X1,X2)=mul(X2,X1)), file('/tmp/eq.p', com)).\n",
      "# Initializing proof state\n",
      "cnf(c_0_3, plain, (mul(X1,X2)=mul(X2,X1)), c_0_-9223372036854775802,['eval']).\n",
      "cnf(c_0_4, plain, (mul(mul(X1,X2),X3)=mul(X1,mul(X2,X3))), c_0_-9223372036854775803,['eval']).\n",
      "# Scanning for AC axioms\n",
      "# mul is AC\n",
      "# AC handling enabled\n",
      "cnf(c_0_5, plain, (mul(X1,X2)=mul(X2,X1)), c_0_3,['new_given']).\n",
      "cnf(c_0_6, plain, (mul(mul(X1,X2),X3)=mul(X1,mul(X2,X3))), c_0_4,['new_given']).\n",
      "cnf(c_0_7, plain, (mul(X1,mul(X2,X3))=mul(X3,mul(X1,X2))),inference(pm,[status(thm)],[c_0_5,c_0_6])).\n",
      "cnf(c_0_8, plain, (mul(mul(X1,mul(X2,X3)),X4)=mul(mul(X1,X2),mul(X3,X4))),inference(pm,[status(thm)],[c_0_6,c_0_6])).\n",
      "cnf(c_0_9, plain, (mul(X2,mul(X3,X1))=mul(X1,mul(X2,X3))),inference(pm,[status(thm)],[c_0_5,c_0_6])).\n",
      "cnf(c_0_10, plain, (mul(mul(X2,X1),X3)=mul(X1,mul(X2,X3))),inference(pm,[status(thm)],[c_0_6,c_0_5])).\n",
      "cnf(c_0_11, plain, (mul(mul(X2,X1),X3)=mul(X1,mul(X2,X3))),inference(pm,[status(thm)],[c_0_6,c_0_5])).\n",
      "cnf(c_0_12, plain, (mul(X1,mul(X2,mul(X3,X4)))=mul(mul(X1,X2),mul(X3,X4))),inference(rw, [status(thm)],[inference(rw, [status(thm)],[c_0_8,c_0_6]),c_0_6])).\n",
      "cnf(c_0_13, plain, (mul(X1,mul(X2,mul(X3,X4)))=mul(X1,mul(X2,mul(X3,X4)))),inference(rw, [status(thm)],[c_0_12,c_0_6])).\n",
      "cnf(c_0_14, plain, (mul(X2,mul(X1,X3))=mul(X1,mul(X2,X3))),inference(rw, [status(thm)],[c_0_10,c_0_6])).\n",
      "cnf(c_0_15, plain, (mul(X2,mul(X1,X3))=mul(X1,mul(X2,X3))),inference(rw, [status(thm)],[c_0_11,c_0_6])).\n",
      "cnf(c_0_16, plain, (mul(X1,mul(X2,X3))=mul(X3,mul(X1,X2))), c_0_7,['eval']).\n",
      "cnf(c_0_17, plain, (mul(X2,mul(X3,X1))=mul(X1,mul(X2,X3))), c_0_9,['eval']).\n",
      "cnf(c_0_18, plain, (mul(X2,mul(X1,X3))=mul(X1,mul(X2,X3))), c_0_14,['eval']).\n",
      "cnf(c_0_19, plain, (mul(X2,mul(X1,X3))=mul(X1,mul(X2,X3))), c_0_15,['eval']).\n",
      "cnf(c_0_20, plain, (mul(X1,mul(X2,X3))=mul(X3,mul(X1,X2))), c_0_16,['new_given']).\n",
      "cnf(c_0_21, plain, (mul(X3,mul(X4,mul(X1,X2)))=mul(X1,mul(X2,mul(X3,X4)))),inference(pm,[status(thm)],[c_0_6,c_0_20])).\n",
      "cnf(c_0_22, plain, (mul(X1,mul(X3,mul(X4,X2)))=mul(mul(X3,X4),mul(X1,X2))),inference(pm,[status(thm)],[c_0_20,c_0_20])).\n",
      "cnf(c_0_23, plain, (mul(X2,mul(X3,X1))=mul(mul(X2,X3),X1)),inference(pm,[status(thm)],[c_0_5,c_0_20])).\n",
      "cnf(c_0_24, plain, (mul(mul(X2,mul(X3,X1)),X4)=mul(X1,mul(mul(X2,X3),X4))),inference(pm,[status(thm)],[c_0_6,c_0_20])).\n",
      "cnf(c_0_25, plain, (mul(X4,mul(X2,mul(X3,X1)))=mul(X1,mul(mul(X2,X3),X4))),inference(pm,[status(thm)],[c_0_20,c_0_20])).\n",
      "cnf(c_0_26, plain, (mul(X1,mul(X2,X3))=mul(mul(X1,X2),X3)),inference(pm,[status(thm)],[c_0_5,c_0_20])).\n",
      "cnf(c_0_27, plain, (mul(X2,mul(X3,X1))=mul(X3,mul(X1,X2))),inference(pm,[status(thm)],[c_0_20,c_0_20])).\n",
      "cnf(c_0_28, plain, (mul(X4,mul(mul(X1,X2),X3))=mul(X1,mul(X2,mul(X3,X4)))),inference(pm,[status(thm)],[c_0_6,c_0_20])).\n",
      "cnf(c_0_29, plain, (mul(X1,mul(X4,mul(X2,X3)))=mul(mul(X3,X4),mul(X1,X2))),inference(pm,[status(thm)],[c_0_20,c_0_20])).\n",
      "cnf(c_0_30, plain, (mul(X3,mul(X1,X2))=mul(mul(X2,X3),X1)),inference(pm,[status(thm)],[c_0_5,c_0_20])).\n",
      "cnf(c_0_31, plain, (mul(mul(X3,mul(X1,X2)),X4)=mul(X1,mul(mul(X2,X3),X4))),inference(pm,[status(thm)],[c_0_6,c_0_20])).\n",
      "cnf(c_0_32, plain, (mul(X4,mul(X3,mul(X1,X2)))=mul(X1,mul(mul(X2,X3),X4))),inference(pm,[status(thm)],[c_0_20,c_0_20])).\n",
      "cnf(c_0_33, plain, (mul(X2,mul(X3,X1))=mul(mul(X1,X2),X3)),inference(pm,[status(thm)],[c_0_5,c_0_20])).\n",
      "cnf(c_0_34, plain, (mul(X2,mul(X3,X1))=mul(X1,mul(X2,X3))),inference(pm,[status(thm)],[c_0_20,c_0_20])).\n",
      "cnf(c_0_35, plain, (mul(X4,mul(X1,mul(X2,X3)))=mul(mul(X1,X2),mul(X3,X4))),inference(pm,[status(thm)],[c_0_20,c_0_6])).\n",
      "cnf(c_0_36, plain, (mul(X3,mul(X2,X1))=mul(X1,mul(X2,X3))),inference(pm,[status(thm)],[c_0_20,c_0_5])).\n",
      "cnf(c_0_37, plain, (mul(X3,mul(X2,X1))=mul(X1,mul(X2,X3))),inference(pm,[status(thm)],[c_0_20,c_0_5])).\n",
      "cnf(c_0_38, plain, (mul(X1,mul(X2,mul(X3,X4)))=mul(X4,mul(X1,mul(X2,X3)))),inference(pm,[status(thm)],[c_0_20,c_0_6])).\n",
      "cnf(c_0_39, plain, (mul(X1,mul(X3,X2))=mul(X3,mul(X1,X2))),inference(pm,[status(thm)],[c_0_20,c_0_5])).\n",
      "cnf(c_0_40, plain, (mul(X1,mul(X3,X2))=mul(X3,mul(X1,X2))),inference(pm,[status(thm)],[c_0_20,c_0_5])).\n",
      "cnf(c_0_41, plain, (mul(X1,mul(X3,mul(X4,X2)))=mul(X3,mul(X4,mul(X1,X2)))),inference(rw, [status(thm)],[c_0_22,c_0_6])).\n",
      "cnf(c_0_42, plain, (mul(X2,mul(X3,X1))=mul(X2,mul(X3,X1))),inference(rw, [status(thm)],[c_0_23,c_0_6])).\n",
      "cnf(c_0_43, plain, (mul(X2,mul(X3,mul(X1,X4)))=mul(X1,mul(mul(X2,X3),X4))),inference(rw, [status(thm)],[inference(rw, [status(thm)],[c_0_24,c_0_6]),c_0_6])).\n",
      "cnf(c_0_44, plain, (mul(X2,mul(X3,mul(X1,X4)))=mul(X1,mul(X2,mul(X3,X4)))),inference(rw, [status(thm)],[c_0_43,c_0_6])).\n",
      "cnf(c_0_45, plain, (mul(X4,mul(X2,mul(X3,X1)))=mul(X1,mul(X2,mul(X3,X4)))),inference(rw, [status(thm)],[c_0_25,c_0_6])).\n",
      "cnf(c_0_46, plain, (mul(X1,mul(X2,X3))=mul(X1,mul(X2,X3))),inference(rw, [status(thm)],[c_0_26,c_0_6])).\n",
      "cnf(c_0_47, plain, (mul(X4,mul(X1,mul(X2,X3)))=mul(X1,mul(X2,mul(X3,X4)))),inference(rw, [status(thm)],[c_0_28,c_0_6])).\n",
      "cnf(c_0_48, plain, (mul(X1,mul(X4,mul(X2,X3)))=mul(X3,mul(X4,mul(X1,X2)))),inference(rw, [status(thm)],[c_0_29,c_0_6])).\n",
      "cnf(c_0_49, plain, (mul(X3,mul(X1,X2))=mul(X2,mul(X3,X1))),inference(rw, [status(thm)],[c_0_30,c_0_6])).\n",
      "cnf(c_0_50, plain, (mul(X3,mul(X1,mul(X2,X4)))=mul(X1,mul(mul(X2,X3),X4))),inference(rw, [status(thm)],[inference(rw, [status(thm)],[c_0_31,c_0_6]),c_0_6])).\n",
      "cnf(c_0_51, plain, (mul(X3,mul(X1,mul(X2,X4)))=mul(X1,mul(X2,mul(X3,X4)))),inference(rw, [status(thm)],[c_0_50,c_0_6])).\n",
      "cnf(c_0_52, plain, (mul(X4,mul(X3,mul(X1,X2)))=mul(X1,mul(X2,mul(X3,X4)))),inference(rw, [status(thm)],[c_0_32,c_0_6])).\n",
      "cnf(c_0_53, plain, (mul(X2,mul(X3,X1))=mul(X1,mul(X2,X3))),inference(rw, [status(thm)],[c_0_33,c_0_6])).\n",
      "cnf(c_0_54, plain, (mul(X4,mul(X1,mul(X2,X3)))=mul(X1,mul(X2,mul(X3,X4)))),inference(rw, [status(thm)],[c_0_35,c_0_6])).\n",
      "cnf(c_0_55, plain, (mul(X3,mul(X4,mul(X1,X2)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_21,['eval']).\n",
      "cnf(c_0_56, plain, (mul(X1,mul(X3,mul(X4,X2)))=mul(X3,mul(X4,mul(X1,X2)))), c_0_41,['eval']).\n",
      "cnf(c_0_57, plain, (mul(X2,mul(X3,mul(X1,X4)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_44,['eval']).\n",
      "cnf(c_0_58, plain, (mul(X4,mul(X2,mul(X3,X1)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_45,['eval']).\n",
      "cnf(c_0_59, plain, (mul(X2,mul(X3,X1))=mul(X3,mul(X1,X2))), c_0_27,['eval']).\n",
      "cnf(c_0_60, plain, (mul(X4,mul(X1,mul(X2,X3)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_47,['eval']).\n",
      "cnf(c_0_61, plain, (mul(X1,mul(X4,mul(X2,X3)))=mul(X3,mul(X4,mul(X1,X2)))), c_0_48,['eval']).\n",
      "cnf(c_0_62, plain, (mul(X3,mul(X1,X2))=mul(X2,mul(X3,X1))), c_0_49,['eval']).\n",
      "cnf(c_0_63, plain, (mul(X3,mul(X1,mul(X2,X4)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_51,['eval']).\n",
      "cnf(c_0_64, plain, (mul(X4,mul(X3,mul(X1,X2)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_52,['eval']).\n",
      "cnf(c_0_65, plain, (mul(X2,mul(X3,X1))=mul(X1,mul(X2,X3))), c_0_53,['eval']).\n",
      "cnf(c_0_66, plain, (mul(X2,mul(X3,X1))=mul(X1,mul(X2,X3))), c_0_34,['eval']).\n",
      "cnf(c_0_67, plain, (mul(X4,mul(X1,mul(X2,X3)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_54,['eval']).\n",
      "cnf(c_0_68, plain, (mul(X3,mul(X2,X1))=mul(X1,mul(X2,X3))), c_0_36,['eval']).\n",
      "cnf(c_0_69, plain, (mul(X3,mul(X2,X1))=mul(X1,mul(X2,X3))), c_0_37,['eval']).\n",
      "cnf(c_0_70, plain, (mul(X1,mul(X2,mul(X3,X4)))=mul(X4,mul(X1,mul(X2,X3)))), c_0_38,['eval']).\n",
      "cnf(c_0_71, plain, (mul(X1,mul(X3,X2))=mul(X3,mul(X1,X2))), c_0_39,['eval']).\n",
      "cnf(c_0_72, plain, (mul(X1,mul(X3,X2))=mul(X3,mul(X1,X2))), c_0_40,['eval']).\n",
      "cnf(c_0_73, plain, (mul(X2,mul(X3,X1))=mul(X1,mul(X2,X3))), c_0_17,['subsumed(c_0_20)']).\n",
      "cnf(c_0_74, plain, (mul(X2,mul(X1,X3))=mul(X1,mul(X2,X3))), c_0_18,['new_given']).\n",
      "cnf(c_0_75, plain, (mul(X3,mul(mul(X1,X2),X4))=mul(X1,mul(X2,mul(X3,X4)))),inference(pm,[status(thm)],[c_0_6,c_0_74])).\n",
      "cnf(c_0_76, plain, (mul(X1,mul(X3,mul(X2,X4)))=mul(mul(X3,X4),mul(X1,X2))),inference(pm,[status(thm)],[c_0_20,c_0_74])).\n",
      "cnf(c_0_77, plain, (mul(X1,mul(X3,mul(X2,X4)))=mul(X2,mul(X1,mul(X3,X4)))),inference(pm,[status(thm)],[c_0_74,c_0_74])).\n",
      "cnf(c_0_78, plain, (mul(X2,mul(X1,X3))=mul(mul(X2,X3),X1)),inference(pm,[status(thm)],[c_0_5,c_0_74])).\n",
      "cnf(c_0_79, plain, (mul(mul(X2,mul(X1,X3)),X4)=mul(X1,mul(mul(X2,X3),X4))),inference(pm,[status(thm)],[c_0_6,c_0_74])).\n",
      "cnf(c_0_80, plain, (mul(X4,mul(X2,mul(X1,X3)))=mul(X1,mul(mul(X2,X3),X4))),inference(pm,[status(thm)],[c_0_20,c_0_74])).\n",
      "cnf(c_0_81, plain, (mul(X1,mul(X3,X2))=mul(mul(X1,X2),X3)),inference(pm,[status(thm)],[c_0_5,c_0_74])).\n",
      "cnf(c_0_82, plain, (mul(X2,mul(X3,mul(X1,X4)))=mul(X1,mul(X2,mul(X3,X4)))),inference(pm,[status(thm)],[c_0_74,c_0_74])).\n",
      "cnf(c_0_83, plain, (mul(X2,mul(X1,X3))=mul(X3,mul(X1,X2))),inference(pm,[status(thm)],[c_0_20,c_0_74])).\n",
      "cnf(c_0_84, plain, (mul(X1,mul(X3,X2))=mul(X1,mul(X2,X3))),inference(pm,[status(thm)],[c_0_20,c_0_74])).\n",
      "cnf(c_0_85, plain, (mul(X3,mul(mul(X1,X2),X4))=mul(X1,mul(X2,mul(X3,X4)))),inference(pm,[status(thm)],[c_0_6,c_0_74])).\n",
      "cnf(c_0_86, plain, (mul(X1,mul(X3,mul(X2,X4)))=mul(mul(X3,X4),mul(X1,X2))),inference(pm,[status(thm)],[c_0_20,c_0_74])).\n",
      "cnf(c_0_87, plain, (mul(X1,mul(X3,mul(X2,X4)))=mul(X2,mul(X1,mul(X3,X4)))),inference(pm,[status(thm)],[c_0_74,c_0_74])).\n",
      "cnf(c_0_88, plain, (mul(X2,mul(X1,X3))=mul(mul(X2,X3),X1)),inference(pm,[status(thm)],[c_0_5,c_0_74])).\n",
      "cnf(c_0_89, plain, (mul(mul(X2,mul(X1,X3)),X4)=mul(X1,mul(mul(X2,X3),X4))),inference(pm,[status(thm)],[c_0_6,c_0_74])).\n",
      "cnf(c_0_90, plain, (mul(X4,mul(X2,mul(X1,X3)))=mul(X1,mul(mul(X2,X3),X4))),inference(pm,[status(thm)],[c_0_20,c_0_74])).\n",
      "cnf(c_0_91, plain, (mul(X1,mul(X3,X2))=mul(mul(X1,X2),X3)),inference(pm,[status(thm)],[c_0_5,c_0_74])).\n",
      "cnf(c_0_92, plain, (mul(X2,mul(X3,mul(X1,X4)))=mul(X1,mul(X2,mul(X3,X4)))),inference(pm,[status(thm)],[c_0_74,c_0_74])).\n",
      "cnf(c_0_93, plain, (mul(X2,mul(X1,X3))=mul(X3,mul(X1,X2))),inference(pm,[status(thm)],[c_0_20,c_0_74])).\n",
      "cnf(c_0_94, plain, (mul(X1,mul(X3,X2))=mul(X1,mul(X2,X3))),inference(pm,[status(thm)],[c_0_20,c_0_74])).\n",
      "cnf(c_0_95, plain, (mul(X3,mul(X1,mul(X2,X4)))=mul(mul(X1,X2),mul(X3,X4))),inference(pm,[status(thm)],[c_0_74,c_0_6])).\n",
      "cnf(c_0_96, plain, (mul(X2,mul(X4,mul(X1,X3)))=mul(X1,mul(X2,mul(X3,X4)))),inference(pm,[status(thm)],[c_0_74,c_0_20])).\n",
      "cnf(c_0_97, plain, (mul(X2,mul(X3,mul(X4,X1)))=mul(X1,mul(X2,mul(X3,X4)))),inference(pm,[status(thm)],[c_0_74,c_0_20])).\n",
      "cnf(c_0_98, plain, (mul(X2,mul(X3,X1))=mul(X1,mul(X2,X3))),inference(pm,[status(thm)],[c_0_74,c_0_5])).\n",
      "cnf(c_0_99, plain, (mul(X2,mul(X3,X1))=mul(X1,mul(X2,X3))),inference(pm,[status(thm)],[c_0_74,c_0_5])).\n",
      "cnf(c_0_100, plain, (mul(X1,mul(X2,mul(X3,X4)))=mul(mul(X2,X3),mul(X1,X4))),inference(pm,[status(thm)],[c_0_74,c_0_6])).\n",
      "cnf(c_0_101, plain, (mul(X1,mul(X4,mul(X2,X3)))=mul(X2,mul(X1,mul(X3,X4)))),inference(pm,[status(thm)],[c_0_74,c_0_20])).\n",
      "cnf(c_0_102, plain, (mul(X1,mul(X3,mul(X4,X2)))=mul(X2,mul(X1,mul(X3,X4)))),inference(pm,[status(thm)],[c_0_74,c_0_20])).\n",
      "cnf(c_0_103, plain, (mul(X1,mul(X3,X2))=mul(X2,mul(X1,X3))),inference(pm,[status(thm)],[c_0_74,c_0_5])).\n",
      "cnf(c_0_104, plain, (mul(X1,mul(X3,X2))=mul(X2,mul(X1,X3))),inference(pm,[status(thm)],[c_0_74,c_0_5])).\n",
      "cnf(c_0_105, plain, (mul(X3,mul(X1,mul(X2,X4)))=mul(X1,mul(X2,mul(X3,X4)))),inference(rw, [status(thm)],[c_0_75,c_0_6])).\n",
      "cnf(c_0_106, plain, (mul(X1,mul(X3,mul(X2,X4)))=mul(X3,mul(X4,mul(X1,X2)))),inference(rw, [status(thm)],[c_0_76,c_0_6])).\n",
      "cnf(c_0_107, plain, (mul(X2,mul(X1,X3))=mul(X2,mul(X3,X1))),inference(rw, [status(thm)],[c_0_78,c_0_6])).\n",
      "cnf(c_0_108, plain, (mul(X2,mul(X1,mul(X3,X4)))=mul(X1,mul(mul(X2,X3),X4))),inference(rw, [status(thm)],[inference(rw, [status(thm)],[c_0_79,c_0_6]),c_0_6])).\n",
      "cnf(c_0_109, plain, (mul(X2,mul(X1,mul(X3,X4)))=mul(X1,mul(X2,mul(X3,X4)))),inference(rw, [status(thm)],[c_0_108,c_0_6])).\n",
      "cnf(c_0_110, plain, (mul(X4,mul(X2,mul(X1,X3)))=mul(X1,mul(X2,mul(X3,X4)))),inference(rw, [status(thm)],[c_0_80,c_0_6])).\n",
      "cnf(c_0_111, plain, (mul(X1,mul(X3,X2))=mul(X1,mul(X2,X3))),inference(rw, [status(thm)],[c_0_81,c_0_6])).\n",
      "cnf(c_0_112, plain, (mul(X3,mul(X1,mul(X2,X4)))=mul(X1,mul(X2,mul(X3,X4)))),inference(rw, [status(thm)],[c_0_85,c_0_6])).\n",
      "cnf(c_0_113, plain, (mul(X1,mul(X3,mul(X2,X4)))=mul(X3,mul(X4,mul(X1,X2)))),inference(rw, [status(thm)],[c_0_86,c_0_6])).\n",
      "cnf(c_0_114, plain, (mul(X2,mul(X1,X3))=mul(X2,mul(X3,X1))),inference(rw, [status(thm)],[c_0_88,c_0_6])).\n",
      "cnf(c_0_115, plain, (mul(X2,mul(X1,mul(X3,X4)))=mul(X1,mul(mul(X2,X3),X4))),inference(rw, [status(thm)],[inference(rw, [status(thm)],[c_0_89,c_0_6]),c_0_6])).\n",
      "cnf(c_0_116, plain, (mul(X2,mul(X1,mul(X3,X4)))=mul(X1,mul(X2,mul(X3,X4)))),inference(rw, [status(thm)],[c_0_115,c_0_6])).\n",
      "cnf(c_0_117, plain, (mul(X4,mul(X2,mul(X1,X3)))=mul(X1,mul(X2,mul(X3,X4)))),inference(rw, [status(thm)],[c_0_90,c_0_6])).\n",
      "cnf(c_0_118, plain, (mul(X1,mul(X3,X2))=mul(X1,mul(X2,X3))),inference(rw, [status(thm)],[c_0_91,c_0_6])).\n",
      "cnf(c_0_119, plain, (mul(X3,mul(X1,mul(X2,X4)))=mul(X1,mul(X2,mul(X3,X4)))),inference(rw, [status(thm)],[c_0_95,c_0_6])).\n",
      "cnf(c_0_120, plain, (mul(X1,mul(X2,mul(X3,X4)))=mul(X2,mul(X3,mul(X1,X4)))),inference(rw, [status(thm)],[c_0_100,c_0_6])).\n",
      "cnf(c_0_121, plain, (mul(X3,mul(X1,mul(X2,X4)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_105,['eval']).\n",
      "cnf(c_0_122, plain, (mul(X1,mul(X3,mul(X2,X4)))=mul(X3,mul(X4,mul(X1,X2)))), c_0_106,['eval']).\n",
      "cnf(c_0_123, plain, (mul(X1,mul(X3,mul(X2,X4)))=mul(X2,mul(X1,mul(X3,X4)))), c_0_77,['eval']).\n",
      "cnf(c_0_124, plain, (mul(X2,mul(X1,X3))=mul(X2,mul(X3,X1))), c_0_107,['eval']).\n",
      "cnf(c_0_125, plain, (mul(X2,mul(X1,mul(X3,X4)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_109,['eval']).\n",
      "cnf(c_0_126, plain, (mul(X4,mul(X2,mul(X1,X3)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_110,['eval']).\n",
      "cnf(c_0_127, plain, (mul(X1,mul(X3,X2))=mul(X1,mul(X2,X3))), c_0_111,['eval']).\n",
      "cnf(c_0_128, plain, (mul(X2,mul(X3,mul(X1,X4)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_82,['eval']).\n",
      "cnf(c_0_129, plain, (mul(X2,mul(X1,X3))=mul(X3,mul(X1,X2))), c_0_83,['eval']).\n",
      "cnf(c_0_130, plain, (mul(X1,mul(X3,X2))=mul(X1,mul(X2,X3))), c_0_84,['eval']).\n",
      "cnf(c_0_131, plain, (mul(X3,mul(X1,mul(X2,X4)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_112,['eval']).\n",
      "cnf(c_0_132, plain, (mul(X1,mul(X3,mul(X2,X4)))=mul(X3,mul(X4,mul(X1,X2)))), c_0_113,['eval']).\n",
      "cnf(c_0_133, plain, (mul(X1,mul(X3,mul(X2,X4)))=mul(X2,mul(X1,mul(X3,X4)))), c_0_87,['eval']).\n",
      "cnf(c_0_134, plain, (mul(X2,mul(X1,X3))=mul(X2,mul(X3,X1))), c_0_114,['eval']).\n",
      "cnf(c_0_135, plain, (mul(X2,mul(X1,mul(X3,X4)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_116,['eval']).\n",
      "cnf(c_0_136, plain, (mul(X4,mul(X2,mul(X1,X3)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_117,['eval']).\n",
      "cnf(c_0_137, plain, (mul(X1,mul(X3,X2))=mul(X1,mul(X2,X3))), c_0_118,['eval']).\n",
      "cnf(c_0_138, plain, (mul(X2,mul(X3,mul(X1,X4)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_92,['eval']).\n",
      "cnf(c_0_139, plain, (mul(X2,mul(X1,X3))=mul(X3,mul(X1,X2))), c_0_93,['eval']).\n",
      "cnf(c_0_140, plain, (mul(X1,mul(X3,X2))=mul(X1,mul(X2,X3))), c_0_94,['eval']).\n",
      "cnf(c_0_141, plain, (mul(X3,mul(X1,mul(X2,X4)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_119,['eval']).\n",
      "cnf(c_0_142, plain, (mul(X2,mul(X4,mul(X1,X3)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_96,['eval']).\n",
      "cnf(c_0_143, plain, (mul(X2,mul(X3,mul(X4,X1)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_97,['eval']).\n",
      "cnf(c_0_144, plain, (mul(X2,mul(X3,X1))=mul(X1,mul(X2,X3))), c_0_98,['eval']).\n",
      "cnf(c_0_145, plain, (mul(X2,mul(X3,X1))=mul(X1,mul(X2,X3))), c_0_99,['eval']).\n",
      "cnf(c_0_146, plain, (mul(X1,mul(X2,mul(X3,X4)))=mul(X2,mul(X3,mul(X1,X4)))), c_0_120,['eval']).\n",
      "cnf(c_0_147, plain, (mul(X1,mul(X4,mul(X2,X3)))=mul(X2,mul(X1,mul(X3,X4)))), c_0_101,['eval']).\n",
      "cnf(c_0_148, plain, (mul(X1,mul(X3,mul(X4,X2)))=mul(X2,mul(X1,mul(X3,X4)))), c_0_102,['eval']).\n",
      "cnf(c_0_149, plain, (mul(X1,mul(X3,X2))=mul(X2,mul(X1,X3))), c_0_103,['eval']).\n",
      "cnf(c_0_150, plain, (mul(X1,mul(X3,X2))=mul(X2,mul(X1,X3))), c_0_104,['eval']).\n",
      "cnf(c_0_151, plain, (mul(X2,mul(X1,X3))=mul(X1,mul(X2,X3))), c_0_19,['subsumed(c_0_74)']).\n",
      "cnf(c_0_152, plain, (mul(X2,mul(X3,X1))=mul(X3,mul(X1,X2))), c_0_59,['subsumed(c_0_20)']).\n",
      "cnf(c_0_153, plain, (mul(X3,mul(X1,X2))=mul(X2,mul(X3,X1))), c_0_62,['subsumed(c_0_20)']).\n",
      "cnf(c_0_154, plain, (mul(X2,mul(X3,X1))=mul(X1,mul(X2,X3))), c_0_65,['subsumed(c_0_20)']).\n",
      "cnf(c_0_155, plain, (mul(X2,mul(X3,X1))=mul(X1,mul(X2,X3))), c_0_66,['subsumed(c_0_20)']).\n",
      "cnf(c_0_156, plain, (mul(X3,mul(X2,X1))=mul(X1,mul(X2,X3))), c_0_68,['new_given']).\n",
      "cnf(c_0_157, plain, (mul(X4,mul(X3,mul(X1,X2)))=mul(X1,mul(X2,mul(X3,X4)))),inference(pm,[status(thm)],[c_0_6,c_0_156])).\n",
      "cnf(c_0_158, plain, (mul(X1,mul(X4,mul(X3,X2)))=mul(mul(X3,X4),mul(X1,X2))),inference(pm,[status(thm)],[c_0_20,c_0_156])).\n",
      "cnf(c_0_159, plain, (mul(X1,mul(X4,mul(X3,X2)))=mul(X2,mul(X1,mul(X3,X4)))),inference(pm,[status(thm)],[c_0_74,c_0_156])).\n",
      "cnf(c_0_160, plain, (mul(X1,mul(X4,mul(X3,X2)))=mul(mul(X3,X4),mul(X2,X1))),inference(pm,[status(thm)],[c_0_156,c_0_156])).\n",
      "cnf(c_0_161, plain, (mul(X3,mul(X2,X1))=mul(mul(X2,X3),X1)),inference(pm,[status(thm)],[c_0_5,c_0_156])).\n",
      "cnf(c_0_162, plain, (mul(mul(X3,mul(X2,X1)),X4)=mul(X1,mul(mul(X2,X3),X4))),inference(pm,[status(thm)],[c_0_6,c_0_156])).\n",
      "cnf(c_0_163, plain, (mul(X4,mul(X3,mul(X2,X1)))=mul(X1,mul(mul(X2,X3),X4))),inference(pm,[status(thm)],[c_0_20,c_0_156])).\n",
      "cnf(c_0_164, plain, (mul(X2,mul(X1,X3))=mul(mul(X1,X2),X3)),inference(pm,[status(thm)],[c_0_5,c_0_156])).\n",
      "cnf(c_0_165, plain, (mul(X4,mul(X2,mul(X1,X3)))=mul(mul(X1,X2),mul(X3,X4))),inference(pm,[status(thm)],[c_0_156,c_0_156])).\n",
      "cnf(c_0_166, plain, (mul(X2,mul(X4,mul(X3,X1)))=mul(X1,mul(X2,mul(X3,X4)))),inference(pm,[status(thm)],[c_0_74,c_0_156])).\n",
      "cnf(c_0_167, plain, (mul(X3,mul(X2,X1))=mul(X3,mul(X1,X2))),inference(pm,[status(thm)],[c_0_20,c_0_156])).\n",
      "cnf(c_0_168, plain, (mul(X3,mul(X2,X1))=mul(X2,mul(X1,X3))),inference(pm,[status(thm)],[c_0_74,c_0_156])).\n",
      "cnf(c_0_169, plain, (mul(X2,mul(X1,X3))=mul(X1,mul(X2,X3))),inference(pm,[status(thm)],[c_0_20,c_0_156])).\n",
      "cnf(c_0_170, plain, (mul(X3,mul(X1,X2))=mul(X1,mul(X2,X3))),inference(pm,[status(thm)],[c_0_74,c_0_156])).\n",
      "cnf(c_0_171, plain, (mul(X4,mul(X3,mul(X1,X2)))=mul(X1,mul(X2,mul(X3,X4)))),inference(pm,[status(thm)],[c_0_6,c_0_156])).\n",
      "cnf(c_0_172, plain, (mul(X1,mul(X4,mul(X3,X2)))=mul(mul(X3,X4),mul(X1,X2))),inference(pm,[status(thm)],[c_0_20,c_0_156])).\n",
      "cnf(c_0_173, plain, (mul(X1,mul(X4,mul(X3,X2)))=mul(X2,mul(X1,mul(X3,X4)))),inference(pm,[status(thm)],[c_0_74,c_0_156])).\n",
      "cnf(c_0_174, plain, (mul(X1,mul(X4,mul(X3,X2)))=mul(mul(X3,X4),mul(X2,X1))),inference(pm,[status(thm)],[c_0_156,c_0_156])).\n",
      "cnf(c_0_175, plain, (mul(X3,mul(X2,X1))=mul(mul(X2,X3),X1)),inference(pm,[status(thm)],[c_0_5,c_0_156])).\n",
      "cnf(c_0_176, plain, (mul(mul(X3,mul(X2,X1)),X4)=mul(X1,mul(mul(X2,X3),X4))),inference(pm,[status(thm)],[c_0_6,c_0_156])).\n",
      "cnf(c_0_177, plain, (mul(X4,mul(X3,mul(X2,X1)))=mul(X1,mul(mul(X2,X3),X4))),inference(pm,[status(thm)],[c_0_20,c_0_156])).\n",
      "cnf(c_0_178, plain, (mul(X2,mul(X1,X3))=mul(mul(X1,X2),X3)),inference(pm,[status(thm)],[c_0_5,c_0_156])).\n",
      "cnf(c_0_179, plain, (mul(X4,mul(X2,mul(X1,X3)))=mul(mul(X1,X2),mul(X3,X4))),inference(pm,[status(thm)],[c_0_156,c_0_156])).\n",
      "cnf(c_0_180, plain, (mul(X2,mul(X4,mul(X3,X1)))=mul(X1,mul(X2,mul(X3,X4)))),inference(pm,[status(thm)],[c_0_74,c_0_156])).\n",
      "cnf(c_0_181, plain, (mul(X3,mul(X2,X1))=mul(X3,mul(X1,X2))),inference(pm,[status(thm)],[c_0_20,c_0_156])).\n",
      "cnf(c_0_182, plain, (mul(X3,mul(X2,X1))=mul(X2,mul(X1,X3))),inference(pm,[status(thm)],[c_0_74,c_0_156])).\n",
      "cnf(c_0_183, plain, (mul(X2,mul(X1,X3))=mul(X1,mul(X2,X3))),inference(pm,[status(thm)],[c_0_20,c_0_156])).\n",
      "cnf(c_0_184, plain, (mul(X3,mul(X1,X2))=mul(X1,mul(X2,X3))),inference(pm,[status(thm)],[c_0_74,c_0_156])).\n",
      "cnf(c_0_185, plain, (mul(X4,mul(X2,mul(X3,X1)))=mul(X1,mul(mul(X2,X3),X4))),inference(pm,[status(thm)],[c_0_156,c_0_6])).\n",
      "cnf(c_0_186, plain, (mul(X4,mul(X2,mul(X3,X1)))=mul(mul(X1,X2),mul(X3,X4))),inference(pm,[status(thm)],[c_0_156,c_0_20])).\n",
      "cnf(c_0_187, plain, (mul(X4,mul(X1,mul(X3,X2)))=mul(mul(X1,X2),mul(X3,X4))),inference(pm,[status(thm)],[c_0_156,c_0_74])).\n",
      "cnf(c_0_188, plain, (mul(X4,mul(X1,mul(X2,X3)))=mul(mul(X1,X2),mul(X3,X4))),inference(pm,[status(thm)],[c_0_156,c_0_20])).\n",
      "cnf(c_0_189, plain, (mul(X4,mul(X1,mul(X3,X2)))=mul(mul(X1,X2),mul(X3,X4))),inference(pm,[status(thm)],[c_0_156,c_0_74])).\n",
      "cnf(c_0_190, plain, (mul(X3,mul(X1,X2))=mul(X1,mul(X2,X3))),inference(pm,[status(thm)],[c_0_156,c_0_5])).\n",
      "cnf(c_0_191, plain, (mul(X3,mul(X1,X2))=mul(X1,mul(X2,X3))),inference(pm,[status(thm)],[c_0_156,c_0_5])).\n",
      "cnf(c_0_192, plain, (mul(X1,mul(X2,mul(X3,X4)))=mul(X4,mul(mul(X2,X3),X1))),inference(pm,[status(thm)],[c_0_156,c_0_6])).\n",
      "cnf(c_0_193, plain, (mul(X1,mul(X4,mul(X2,X3)))=mul(mul(X3,X4),mul(X2,X1))),inference(pm,[status(thm)],[c_0_156,c_0_20])).\n",
      "cnf(c_0_194, plain, (mul(X1,mul(X3,mul(X2,X4)))=mul(mul(X3,X4),mul(X2,X1))),inference(pm,[status(thm)],[c_0_156,c_0_74])).\n",
      "cnf(c_0_195, plain, (mul(X1,mul(X3,mul(X4,X2)))=mul(mul(X3,X4),mul(X2,X1))),inference(pm,[status(thm)],[c_0_156,c_0_20])).\n",
      "cnf(c_0_196, plain, (mul(X1,mul(X3,mul(X2,X4)))=mul(mul(X3,X4),mul(X2,X1))),inference(pm,[status(thm)],[c_0_156,c_0_74])).\n",
      "cnf(c_0_197, plain, (mul(X1,mul(X3,X2))=mul(X3,mul(X2,X1))),inference(pm,[status(thm)],[c_0_156,c_0_5])).\n",
      "cnf(c_0_198, plain, (mul(X1,mul(X3,X2))=mul(X3,mul(X2,X1))),inference(pm,[status(thm)],[c_0_156,c_0_5])).\n",
      "cnf(c_0_199, plain, (mul(X1,mul(X4,mul(X3,X2)))=mul(X3,mul(X4,mul(X1,X2)))),inference(rw, [status(thm)],[c_0_158,c_0_6])).\n",
      "cnf(c_0_200, plain, (mul(X1,mul(X4,mul(X3,X2)))=mul(X3,mul(X4,mul(X2,X1)))),inference(rw, [status(thm)],[c_0_160,c_0_6])).\n",
      "cnf(c_0_201, plain, (mul(X3,mul(X2,X1))=mul(X2,mul(X3,X1))),inference(rw, [status(thm)],[c_0_161,c_0_6])).\n",
      "cnf(c_0_202, plain, (mul(X3,mul(X2,mul(X1,X4)))=mul(X1,mul(mul(X2,X3),X4))),inference(rw, [status(thm)],[inference(rw, [status(thm)],[c_0_162,c_0_6]),c_0_6])).\n",
      "cnf(c_0_203, plain, (mul(X3,mul(X2,mul(X1,X4)))=mul(X1,mul(X2,mul(X3,X4)))),inference(rw, [status(thm)],[c_0_202,c_0_6])).\n",
      "cnf(c_0_204, plain, (mul(X4,mul(X3,mul(X2,X1)))=mul(X1,mul(X2,mul(X3,X4)))),inference(rw, [status(thm)],[c_0_163,c_0_6])).\n",
      "cnf(c_0_205, plain, (mul(X2,mul(X1,X3))=mul(X1,mul(X2,X3))),inference(rw, [status(thm)],[c_0_164,c_0_6])).\n",
      "cnf(c_0_206, plain, (mul(X4,mul(X2,mul(X1,X3)))=mul(X1,mul(X2,mul(X3,X4)))),inference(rw, [status(thm)],[c_0_165,c_0_6])).\n",
      "cnf(c_0_207, plain, (mul(X1,mul(X4,mul(X3,X2)))=mul(X3,mul(X4,mul(X1,X2)))),inference(rw, [status(thm)],[c_0_172,c_0_6])).\n",
      "cnf(c_0_208, plain, (mul(X1,mul(X4,mul(X3,X2)))=mul(X3,mul(X4,mul(X2,X1)))),inference(rw, [status(thm)],[c_0_174,c_0_6])).\n",
      "cnf(c_0_209, plain, (mul(X3,mul(X2,X1))=mul(X2,mul(X3,X1))),inference(rw, [status(thm)],[c_0_175,c_0_6])).\n",
      "cnf(c_0_210, plain, (mul(X3,mul(X2,mul(X1,X4)))=mul(X1,mul(mul(X2,X3),X4))),inference(rw, [status(thm)],[inference(rw, [status(thm)],[c_0_176,c_0_6]),c_0_6])).\n",
      "cnf(c_0_211, plain, (mul(X3,mul(X2,mul(X1,X4)))=mul(X1,mul(X2,mul(X3,X4)))),inference(rw, [status(thm)],[c_0_210,c_0_6])).\n",
      "cnf(c_0_212, plain, (mul(X4,mul(X3,mul(X2,X1)))=mul(X1,mul(X2,mul(X3,X4)))),inference(rw, [status(thm)],[c_0_177,c_0_6])).\n",
      "cnf(c_0_213, plain, (mul(X2,mul(X1,X3))=mul(X1,mul(X2,X3))),inference(rw, [status(thm)],[c_0_178,c_0_6])).\n",
      "cnf(c_0_214, plain, (mul(X4,mul(X2,mul(X1,X3)))=mul(X1,mul(X2,mul(X3,X4)))),inference(rw, [status(thm)],[c_0_179,c_0_6])).\n",
      "cnf(c_0_215, plain, (mul(X4,mul(X2,mul(X3,X1)))=mul(X1,mul(X2,mul(X3,X4)))),inference(rw, [status(thm)],[c_0_185,c_0_6])).\n",
      "cnf(c_0_216, plain, (mul(X4,mul(X2,mul(X3,X1)))=mul(X1,mul(X2,mul(X3,X4)))),inference(rw, [status(thm)],[c_0_186,c_0_6])).\n",
      "cnf(c_0_217, plain, (mul(X4,mul(X1,mul(X3,X2)))=mul(X1,mul(X2,mul(X3,X4)))),inference(rw, [status(thm)],[c_0_187,c_0_6])).\n",
      "cnf(c_0_218, plain, (mul(X4,mul(X1,mul(X2,X3)))=mul(X1,mul(X2,mul(X3,X4)))),inference(rw, [status(thm)],[c_0_188,c_0_6])).\n",
      "cnf(c_0_219, plain, (mul(X4,mul(X1,mul(X3,X2)))=mul(X1,mul(X2,mul(X3,X4)))),inference(rw, [status(thm)],[c_0_189,c_0_6])).\n",
      "cnf(c_0_220, plain, (mul(X1,mul(X2,mul(X3,X4)))=mul(X4,mul(X2,mul(X3,X1)))),inference(rw, [status(thm)],[c_0_192,c_0_6])).\n",
      "cnf(c_0_221, plain, (mul(X1,mul(X4,mul(X2,X3)))=mul(X3,mul(X4,mul(X2,X1)))),inference(rw, [status(thm)],[c_0_193,c_0_6])).\n",
      "cnf(c_0_222, plain, (mul(X1,mul(X3,mul(X2,X4)))=mul(X3,mul(X4,mul(X2,X1)))),inference(rw, [status(thm)],[c_0_194,c_0_6])).\n",
      "cnf(c_0_223, plain, (mul(X1,mul(X3,mul(X4,X2)))=mul(X3,mul(X4,mul(X2,X1)))),inference(rw, [status(thm)],[c_0_195,c_0_6])).\n",
      "cnf(c_0_224, plain, (mul(X1,mul(X3,mul(X2,X4)))=mul(X3,mul(X4,mul(X2,X1)))),inference(rw, [status(thm)],[c_0_196,c_0_6])).\n",
      "cnf(c_0_225, plain, (mul(X4,mul(X3,mul(X1,X2)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_157,['eval']).\n",
      "cnf(c_0_226, plain, (mul(X1,mul(X4,mul(X3,X2)))=mul(X3,mul(X4,mul(X1,X2)))), c_0_199,['eval']).\n",
      "cnf(c_0_227, plain, (mul(X1,mul(X4,mul(X3,X2)))=mul(X2,mul(X1,mul(X3,X4)))), c_0_159,['eval']).\n",
      "cnf(c_0_228, plain, (mul(X1,mul(X4,mul(X3,X2)))=mul(X3,mul(X4,mul(X2,X1)))), c_0_200,['eval']).\n",
      "cnf(c_0_229, plain, (mul(X3,mul(X2,X1))=mul(X2,mul(X3,X1))), c_0_201,['eval']).\n",
      "cnf(c_0_230, plain, (mul(X3,mul(X2,mul(X1,X4)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_203,['eval']).\n",
      "cnf(c_0_231, plain, (mul(X4,mul(X3,mul(X2,X1)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_204,['eval']).\n",
      "cnf(c_0_232, plain, (mul(X2,mul(X1,X3))=mul(X1,mul(X2,X3))), c_0_205,['eval']).\n",
      "cnf(c_0_233, plain, (mul(X4,mul(X2,mul(X1,X3)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_206,['eval']).\n",
      "cnf(c_0_234, plain, (mul(X2,mul(X4,mul(X3,X1)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_166,['eval']).\n",
      "cnf(c_0_235, plain, (mul(X3,mul(X2,X1))=mul(X3,mul(X1,X2))), c_0_167,['eval']).\n",
      "cnf(c_0_236, plain, (mul(X3,mul(X2,X1))=mul(X2,mul(X1,X3))), c_0_168,['eval']).\n",
      "cnf(c_0_237, plain, (mul(X2,mul(X1,X3))=mul(X1,mul(X2,X3))), c_0_169,['eval']).\n",
      "cnf(c_0_238, plain, (mul(X3,mul(X1,X2))=mul(X1,mul(X2,X3))), c_0_170,['eval']).\n",
      "cnf(c_0_239, plain, (mul(X4,mul(X3,mul(X1,X2)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_171,['eval']).\n",
      "cnf(c_0_240, plain, (mul(X1,mul(X4,mul(X3,X2)))=mul(X3,mul(X4,mul(X1,X2)))), c_0_207,['eval']).\n",
      "cnf(c_0_241, plain, (mul(X1,mul(X4,mul(X3,X2)))=mul(X2,mul(X1,mul(X3,X4)))), c_0_173,['eval']).\n",
      "cnf(c_0_242, plain, (mul(X1,mul(X4,mul(X3,X2)))=mul(X3,mul(X4,mul(X2,X1)))), c_0_208,['eval']).\n",
      "cnf(c_0_243, plain, (mul(X3,mul(X2,X1))=mul(X2,mul(X3,X1))), c_0_209,['eval']).\n",
      "cnf(c_0_244, plain, (mul(X3,mul(X2,mul(X1,X4)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_211,['eval']).\n",
      "cnf(c_0_245, plain, (mul(X4,mul(X3,mul(X2,X1)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_212,['eval']).\n",
      "cnf(c_0_246, plain, (mul(X2,mul(X1,X3))=mul(X1,mul(X2,X3))), c_0_213,['eval']).\n",
      "cnf(c_0_247, plain, (mul(X4,mul(X2,mul(X1,X3)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_214,['eval']).\n",
      "cnf(c_0_248, plain, (mul(X2,mul(X4,mul(X3,X1)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_180,['eval']).\n",
      "cnf(c_0_249, plain, (mul(X3,mul(X2,X1))=mul(X3,mul(X1,X2))), c_0_181,['eval']).\n",
      "cnf(c_0_250, plain, (mul(X3,mul(X2,X1))=mul(X2,mul(X1,X3))), c_0_182,['eval']).\n",
      "cnf(c_0_251, plain, (mul(X2,mul(X1,X3))=mul(X1,mul(X2,X3))), c_0_183,['eval']).\n",
      "cnf(c_0_252, plain, (mul(X3,mul(X1,X2))=mul(X1,mul(X2,X3))), c_0_184,['eval']).\n",
      "cnf(c_0_253, plain, (mul(X4,mul(X2,mul(X3,X1)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_215,['eval']).\n",
      "cnf(c_0_254, plain, (mul(X4,mul(X2,mul(X3,X1)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_216,['eval']).\n",
      "cnf(c_0_255, plain, (mul(X4,mul(X1,mul(X3,X2)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_217,['eval']).\n",
      "cnf(c_0_256, plain, (mul(X4,mul(X1,mul(X2,X3)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_218,['eval']).\n",
      "cnf(c_0_257, plain, (mul(X4,mul(X1,mul(X3,X2)))=mul(X1,mul(X2,mul(X3,X4)))), c_0_219,['eval']).\n",
      "cnf(c_0_258, plain, (mul(X3,mul(X1,X2))=mul(X1,mul(X2,X3))), c_0_190,['eval']).\n",
      "cnf(c_0_259, plain, (mul(X3,mul(X1,X2))=mul(X1,mul(X2,X3))), c_0_191,['eval']).\n",
      "cnf(c_0_260, plain, (mul(X1,mul(X2,mul(X3,X4)))=mul(X4,mul(X2,mul(X3,X1)))), c_0_220,['eval']).\n",
      "cnf(c_0_261, plain, (mul(X1,mul(X4,mul(X2,X3)))=mul(X3,mul(X4,mul(X2,X1)))), c_0_221,['eval']).\n",
      "cnf(c_0_262, plain, (mul(X1,mul(X3,mul(X2,X4)))=mul(X3,mul(X4,mul(X2,X1)))), c_0_222,['eval']).\n",
      "cnf(c_0_263, plain, (mul(X1,mul(X3,mul(X4,X2)))=mul(X3,mul(X4,mul(X2,X1)))), c_0_223,['eval']).\n",
      "cnf(c_0_264, plain, (mul(X1,mul(X3,mul(X2,X4)))=mul(X3,mul(X4,mul(X2,X1)))), c_0_224,['eval']).\n",
      "cnf(c_0_265, plain, (mul(X1,mul(X3,X2))=mul(X3,mul(X2,X1))), c_0_197,['eval']).\n",
      "cnf(c_0_266, plain, (mul(X1,mul(X3,X2))=mul(X3,mul(X2,X1))), c_0_198,['eval']).\n",
      "cnf(c_0_267, plain, (mul(X3,mul(X2,X1))=mul(X1,mul(X2,X3))), c_0_69,['subsumed(c_0_156)']).\n",
      "cnf(c_0_268, plain, (mul(X1,mul(X3,X2))=mul(X3,mul(X1,X2))), c_0_71,['subsumed(c_0_74)']).\n",
      "cnf(c_0_269, plain, (mul(X1,mul(X3,X2))=mul(X3,mul(X1,X2))), c_0_72,['subsumed(c_0_74)']).\n",
      "cnf(c_0_270, plain, (mul(X2,mul(X1,X3))=mul(X2,mul(X3,X1))), c_0_124,['subsumed(c_0_5)']).\n",
      "cnf(c_0_271, plain, (mul(X1,mul(X3,X2))=mul(X1,mul(X2,X3))), c_0_127,['subsumed(c_0_5)']).\n",
      "cnf(c_0_272, plain, (mul(X2,mul(X1,X3))=mul(X3,mul(X1,X2))), c_0_129,['subsumed(c_0_156)']).\n",
      "cnf(c_0_273, plain, (mul(X1,mul(X3,X2))=mul(X1,mul(X2,X3))), c_0_130,['subsumed(c_0_5)']).\n",
      "cnf(c_0_274, plain, (mul(X2,mul(X1,X3))=mul(X2,mul(X3,X1))), c_0_134,['subsumed(c_0_5)']).\n",
      "cnf(c_0_275, plain, (mul(X1,mul(X3,X2))=mul(X1,mul(X2,X3))), c_0_137,['subsumed(c_0_5)']).\n",
      "cnf(c_0_276, plain, (mul(X2,mul(X1,X3))=mul(X3,mul(X1,X2))), c_0_139,['subsumed(c_0_156)']).\n",
      "cnf(c_0_277, plain, (mul(X1,mul(X3,X2))=mul(X1,mul(X2,X3))), c_0_140,['subsumed(c_0_5)']).\n",
      "cnf(c_0_278, plain, (mul(X2,mul(X3,X1))=mul(X1,mul(X2,X3))), c_0_144,['subsumed(c_0_20)']).\n",
      "cnf(c_0_279, plain, (mul(X2,mul(X3,X1))=mul(X1,mul(X2,X3))), c_0_145,['subsumed(c_0_20)']).\n",
      "cnf(c_0_280, plain, (mul(X1,mul(X3,X2))=mul(X2,mul(X1,X3))), c_0_149,['subsumed(c_0_20)']).\n",
      "cnf(c_0_281, plain, (mul(X1,mul(X3,X2))=mul(X2,mul(X1,X3))), c_0_150,['subsumed(c_0_20)']).\n",
      "cnf(c_0_282, plain, (mul(X3,mul(X2,X1))=mul(X2,mul(X3,X1))), c_0_229,['subsumed(c_0_74)']).\n",
      "cnf(c_0_283, plain, (mul(X2,mul(X1,X3))=mul(X1,mul(X2,X3))), c_0_232,['subsumed(c_0_74)']).\n",
      "cnf(c_0_284, plain, (mul(X3,mul(X2,X1))=mul(X3,mul(X1,X2))), c_0_235,['subsumed(c_0_5)']).\n",
      "cnf(c_0_285, plain, (mul(X3,mul(X2,X1))=mul(X2,mul(X1,X3))), c_0_236,['subsumed(c_0_20)']).\n",
      "cnf(c_0_286, plain, (mul(X2,mul(X1,X3))=mul(X1,mul(X2,X3))), c_0_237,['subsumed(c_0_74)']).\n",
      "cnf(c_0_287, plain, (mul(X3,mul(X1,X2))=mul(X1,mul(X2,X3))), c_0_238,['subsumed(c_0_20)']).\n",
      "cnf(c_0_288, plain, (mul(X3,mul(X2,X1))=mul(X2,mul(X3,X1))), c_0_243,['subsumed(c_0_74)']).\n",
      "cnf(c_0_289, plain, (mul(X2,mul(X1,X3))=mul(X1,mul(X2,X3))), c_0_246,['subsumed(c_0_74)']).\n",
      "cnf(c_0_290, plain, (mul(X3,mul(X2,X1))=mul(X3,mul(X1,X2))), c_0_249,['subsumed(c_0_5)']).\n",
      "cnf(c_0_291, plain, (mul(X3,mul(X2,X1))=mul(X2,mul(X1,X3))), c_0_250,['subsumed(c_0_20)']).\n",
      "cnf(c_0_292, plain, (mul(X2,mul(X1,X3))=mul(X1,mul(X2,X3))), c_0_251,['subsumed(c_0_74)']).\n",
      "cnf(c_0_293, plain, (mul(X3,mul(X1,X2))=mul(X1,mul(X2,X3))), c_0_252,['subsumed(c_0_20)']).\n",
      "cnf(c_0_294, plain, (mul(X3,mul(X1,X2))=mul(X1,mul(X2,X3))), c_0_258,['subsumed(c_0_20)']).\n",
      "cnf(c_0_295, plain, (mul(X3,mul(X1,X2))=mul(X1,mul(X2,X3))), c_0_259,['subsumed(c_0_20)']).\n",
      "cnf(c_0_296, plain, (mul(X1,mul(X3,X2))=mul(X3,mul(X2,X1))), c_0_265,['subsumed(c_0_20)']).\n",
      "cnf(c_0_297, plain, (mul(X1,mul(X3,X2))=mul(X3,mul(X2,X1))), c_0_266,['subsumed(c_0_20)']).\n",
      "cnf(c_0_298, plain, (mul(mul(X1,X2),X3)=mul(X1,mul(X2,X3))), c_0_6,['final']).\n",
      "cnf(c_0_299, plain, (mul(X1,X2)=mul(X2,X1)), c_0_5,['final']).\n",
      "cnf(c_0_300, plain, (mul(X1,mul(X2,X3))=mul(X3,mul(X1,X2))), c_0_20,['final']).\n",
      "cnf(c_0_301, plain, (mul(X1,mul(X2,X3))=mul(X2,mul(X1,X3))), c_0_74,['final']).\n",
      "cnf(c_0_302, plain, (mul(X1,mul(X2,X3))=mul(X3,mul(X2,X1))), c_0_156,['final']).\n",
      "\n",
      "# No proof found!\n",
      "# SZS status Satisfiable\n",
      "# Processed positive unit clauses:\n",
      "cnf(c_0_298, plain, (mul(mul(X1,X2),X3)=mul(X1,mul(X2,X3)))).\n",
      "cnf(c_0_299, plain, (mul(X1,X2)=mul(X2,X1))).\n",
      "cnf(c_0_300, plain, (mul(X1,mul(X2,X3))=mul(X3,mul(X1,X2)))).\n",
      "cnf(c_0_301, plain, (mul(X1,mul(X2,X3))=mul(X2,mul(X1,X3)))).\n",
      "cnf(c_0_302, plain, (mul(X1,mul(X2,X3))=mul(X3,mul(X2,X1)))).\n",
      "\n",
      "# Processed negative unit clauses:\n",
      "\n",
      "# Processed non-unit clauses:\n",
      "\n",
      "# Unprocessed positive unit clauses:\n",
      "\n",
      "# Unprocessed negative unit clauses:\n",
      "\n",
      "# Unprocessed non-unit clauses:\n",
      "\n",
      "\n",
      "# Parsed axioms                        : 2\n",
      "# Removed by relevancy pruning/SinE    : 0\n",
      "# Initial clauses                      : 2\n",
      "# Removed in clause preprocessing      : 0\n",
      "# Initial clauses in saturation        : 2\n",
      "# Processed clauses                    : 96\n",
      "# ...of these trivial                  : 54\n",
      "# ...subsumed                          : 37\n",
      "# ...remaining for further processing  : 5\n",
      "# Other redundant clauses eliminated   : 0\n",
      "# Clauses deleted for lack of memory   : 0\n",
      "# Backward-subsumed                    : 0\n",
      "# Backward-rewritten                   : 0\n",
      "# Generated clauses                    : 97\n",
      "# ...of the previous two non-redundant : 94\n",
      "# ...aggressively subsumed             : 0\n",
      "# Contextual simplify-reflections      : 0\n",
      "# Paramodulations                      : 97\n",
      "# Factorizations                       : 0\n",
      "# NegExts                              : 0\n",
      "# Equation resolutions                 : 0\n",
      "# Disequality decompositions           : 0\n",
      "# Total rewrite steps                  : 67\n",
      "# ...of those cached                   : 50\n",
      "# Propositional unsat checks           : 0\n",
      "#    Propositional check models        : 0\n",
      "#    Propositional check unsatisfiable : 0\n",
      "#    Propositional clauses             : 0\n",
      "#    Propositional clauses after purity: 0\n",
      "#    Propositional unsat core size     : 0\n",
      "#    Propositional preprocessing time  : 0.000\n",
      "#    Propositional encoding time       : 0.000\n",
      "#    Propositional solver time         : 0.000\n",
      "#    Success case prop preproc time    : 0.000\n",
      "#    Success case prop encoding time   : 0.000\n",
      "#    Success case prop solver time     : 0.000\n",
      "# Current number of processed clauses  : 5\n",
      "#    Positive orientable unit clauses  : 1\n",
      "#    Positive unorientable unit clauses: 4\n",
      "#    Negative unit clauses             : 0\n",
      "#    Non-unit-clauses                  : 0\n",
      "# Current number of unprocessed clauses: 0\n",
      "# ...number of literals in the above   : 0\n",
      "# Current number of archived formulas  : 0\n",
      "# Current number of archived clauses   : 0\n",
      "# Clause-clause subsumption calls (NU) : 0\n",
      "# Rec. Clause-clause subsumption calls : 0\n",
      "# Non-unit clause-clause subsumptions  : 0\n",
      "# Unit Clause-clause subsumption calls : 6\n",
      "# Rewrite failures with RHS unbound    : 0\n",
      "# BW rewrite match attempts            : 12\n",
      "# BW rewrite match successes           : 12\n",
      "# Condensation attempts                : 0\n",
      "# Condensation successes               : 0\n",
      "# Termbank termtop insertions          : 662\n",
      "# Search garbage collected termcells   : 0\n"
     ]
    }
   ],
   "source": [
    "!eprover-ho --print-saturated --output-level=6 --literal-selection-strategy=\"SelectLargestNegLit\"  /tmp/eq.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Initializing proof state\n",
      "# Scanning for AC axioms\n",
      "# mul is AC\n",
      "# AC handling enabled\n",
      "#\n",
      "#cnf(i_0_4, plain, (mul(X1,X2)=mul(X2,X1))).\n",
      "#\n",
      "#cnf(i_0_3, plain, (mul(mul(X1,X2),X3)=mul(X1,mul(X2,X3)))).\n",
      "#\n",
      "#cnf(i_0_6, plain, (mul(X1,mul(X2,X3))=mul(X3,mul(X1,X2)))).\n",
      "##\n",
      "#cnf(i_0_9, plain, (mul(X2,mul(X1,X3))=mul(X1,mul(X2,X3)))).\n",
      "######\n",
      "#cnf(i_0_26, plain, (mul(X3,mul(X2,X1))=mul(X1,mul(X2,X3)))).\n",
      "################################\n",
      "#cnf(i_0_5, negated_conjecture, ($answer(esk1_3(X3,X2,X1))|mul(X1,mul(X2,X3))!=mul(X3,mul(X1,X3)))).\n",
      "## SZS status Theorem\n",
      "# SZS answers Tuple [[X1, X1, X1]|_]\n",
      "\n",
      "#cnf(i_0_103, negated_conjecture, ($answer(esk1_3(X1,X1,X1)))).\n",
      "#\n",
      "#cnf(i_0_111, negated_conjecture, ($answer(esk1_3(X1,X2,X3))|mul(X1,mul(X1,X3))!=mul(X3,mul(X2,X1)))).\n",
      "##\n",
      "#cnf(i_0_114, negated_conjecture, ($answer(esk1_3(X1,X2,X3))|mul(X3,mul(X1,X1))!=mul(X3,mul(X2,X1)))).\n",
      "## SZS answers Tuple [[X1, X1, X2]|_]\n",
      "\n",
      "#cnf(i_0_173, negated_conjecture, ($answer(esk1_3(X1,X1,X2)))).\n",
      "#######\n",
      "#cnf(i_0_127, negated_conjecture, ($answer(esk1_3(X1,X2,X3))|mul(X3,mul(X1,X2))!=mul(X1,mul(X3,X1)))).\n",
      "###\n",
      "#cnf(i_0_130, negated_conjecture, ($answer(esk1_3(X1,X2,X3))|mul(X2,mul(X1,X3))!=mul(X1,mul(X3,X1)))).\n",
      "####\n",
      "#cnf(i_0_133, negated_conjecture, ($answer(esk1_3(X1,X2,X3))|mul(X1,mul(X3,X2))!=mul(X1,mul(X3,X1)))).\n",
      "#\n",
      "#cnf(i_0_134, negated_conjecture, ($answer(esk1_3(X1,X2,X3))|mul(X2,mul(X3,X1))!=mul(X1,mul(X3,X1)))).\n",
      "##\n",
      "#cnf(i_0_135, negated_conjecture, ($answer(esk1_3(X1,X2,X3))|mul(X1,mul(X2,X3))!=mul(X1,mul(X3,X1)))).\n",
      "####\n",
      "#cnf(i_0_146, negated_conjecture, ($answer(esk1_3(X1,X2,X3))|mul(X3,mul(X1,X2))!=mul(X1,mul(X1,X3)))).\n",
      "##\n",
      "#cnf(i_0_149, negated_conjecture, ($answer(esk1_3(X1,X2,X3))|mul(X2,mul(X1,X3))!=mul(X1,mul(X1,X3)))).\n",
      "####\n",
      "#cnf(i_0_152, negated_conjecture, ($answer(esk1_3(X1,X2,X3))|mul(X1,mul(X3,X2))!=mul(X1,mul(X1,X3)))).\n",
      "##\n",
      "#cnf(i_0_153, negated_conjecture, ($answer(esk1_3(X1,X2,X3))|mul(X2,mul(X3,X1))!=mul(X1,mul(X1,X3)))).\n",
      "#\n",
      "#cnf(i_0_154, negated_conjecture, ($answer(esk1_3(X1,X2,X3))|mul(X1,mul(X2,X3))!=mul(X1,mul(X1,X3)))).\n",
      "###############\n",
      "#cnf(i_0_181, negated_conjecture, ($answer(esk1_3(X1,X2,X3))|mul(X3,mul(X1,X2))!=mul(X3,mul(X1,X1)))).\n",
      "##\n",
      "#cnf(i_0_184, negated_conjecture, ($answer(esk1_3(X1,X2,X3))|mul(X2,mul(X1,X3))!=mul(X3,mul(X1,X1)))).\n",
      "####\n",
      "#cnf(i_0_187, negated_conjecture, ($answer(esk1_3(X1,X2,X3))|mul(X1,mul(X3,X2))!=mul(X3,mul(X1,X1)))).\n",
      "##\n",
      "#cnf(i_0_188, negated_conjecture, ($answer(esk1_3(X1,X2,X3))|mul(X2,mul(X3,X1))!=mul(X3,mul(X1,X1)))).\n",
      "#\n",
      "#cnf(i_0_189, negated_conjecture, ($answer(esk1_3(X1,X2,X3))|mul(X1,mul(X2,X3))!=mul(X3,mul(X1,X1)))).\n",
      "##############################################################################################################################################################################################################################################################################################################################################\n",
      "#cnf(i_0_120, negated_conjecture, ($answer(esk1_3(X1,mul(X2,X3),X4))|mul(X4,mul(X2,mul(X3,X1)))!=mul(X1,mul(X4,X1)))).\n",
      "#\n",
      "#cnf(i_0_139, negated_conjecture, ($answer(esk1_3(X1,mul(X2,X3),X4))|mul(X4,mul(X2,mul(X3,X1)))!=mul(X1,mul(X1,X4)))).\n",
      "#\n",
      "#cnf(i_0_174, negated_conjecture, ($answer(esk1_3(X1,mul(X2,X3),X4))|mul(X4,mul(X2,mul(X3,X1)))!=mul(X4,mul(X1,X1)))).\n",
      "##\n",
      "#cnf(i_0_229, negated_conjecture, ($answer(esk1_3(X1,mul(X2,X3),X4))|mul(X4,mul(X3,mul(X1,X2)))!=mul(X1,mul(X4,X1)))).\n",
      "#\n",
      "#cnf(i_0_230, negated_conjecture, ($answer(esk1_3(X1,mul(X2,X3),X4))|mul(X4,mul(X2,mul(X1,X3)))!=mul(X1,mul(X4,X1)))).\n",
      "#\n",
      "#cnf(i_0_231, negated_conjecture, ($answer(esk1_3(X1,mul(X2,X3),X4))|mul(X4,mul(X3,mul(X2,X1)))!=mul(X1,mul(X4,X1)))).\n",
      "###\n",
      "#cnf(i_0_271, negated_conjecture, ($answer(esk1_3(X1,mul(X2,X3),X4))|mul(X2,mul(X3,mul(X1,X4)))!=mul(X1,mul(X4,X1)))).\n",
      "#\n",
      "#cnf(i_0_298, negated_conjecture, ($answer(esk1_3(X1,mul(X2,X3),X4))|mul(X1,mul(X2,mul(X3,X4)))!=mul(X1,mul(X4,X1)))).\n",
      "## SZS answers Tuple [[mul(X1,X2), mul(X2,X1), X2]|_]\n",
      "\n",
      "#cnf(i_0_1048, negated_conjecture, ($answer(esk1_3(mul(X1,X2),mul(X2,X1),X2)))).\n",
      "## SZS answers Tuple [[mul(X1,mul(X2,X3)), mul(X2,mul(X3,X1)), X3]|_]\n",
      "\n",
      "#cnf(i_0_1094, negated_conjecture, ($answer(esk1_3(mul(X1,mul(X2,X3)),mul(X2,mul(X3,X1)),X3)))).\n",
      "## SZS answers Tuple [[mul(X1,mul(X2,X3)), mul(X1,mul(X3,X2)), X3]|_]\n",
      "\n",
      "#cnf(i_0_1095, negated_conjecture, ($answer(esk1_3(mul(X1,mul(X2,X3)),mul(X1,mul(X3,X2)),X3)))).\n",
      "## SZS answers Tuple [[mul(X1,mul(X2,X3)), mul(X2,mul(X1,X3)), X3]|_]\n",
      "\n",
      "#cnf(i_0_1096, negated_conjecture, ($answer(esk1_3(mul(X1,mul(X2,X3)),mul(X2,mul(X1,X3)),X3)))).\n",
      "#### SZS answers Tuple [[mul(X1,mul(X2,X3)), mul(X3,mul(X1,X2)), X3]|_]\n",
      "\n",
      "#cnf(i_0_1101, negated_conjecture, ($answer(esk1_3(mul(X1,mul(X2,X3)),mul(X3,mul(X1,X2)),X3)))).\n",
      "####### SZS answers Tuple [[mul(X1,mul(X2,X3)), mul(X3,mul(X2,X1)), X3]|_]\n",
      "\n",
      "#cnf(i_0_1124, negated_conjecture, ($answer(esk1_3(mul(X1,mul(X2,X3)),mul(X3,mul(X2,X1)),X3)))).\n",
      "##### SZS answers Tuple [[mul(X1,mul(X3,X2)), mul(X2,mul(X3,X1)), X3]|_]\n",
      "\n",
      "#cnf(i_0_1135, negated_conjecture, ($answer(esk1_3(mul(X1,mul(X3,X2)),mul(X2,mul(X3,X1)),X3)))).\n",
      "### SZS answers Tuple [[mul(X3,mul(X1,X2)), mul(X2,mul(X3,X1)), X3]|_]\n",
      "\n",
      "# Proof found!\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --answers=10 --term-ordering=KBO6 --literal-selection-strategy=\"SelectLargestNegLit\" --conjectures-are-questions /tmp/eq.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prolog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /tmp/prolog.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/prolog.p\n",
    "\n",
    "cnf(add_succ, axiom, add(s(X),Y,s(Z)) | ~add(X, Y, Z)).\n",
    "cnf(add_z, axiom, add(z, Y, Y)).\n",
    "fof(add_g, conjecture, ?[X,Y]: add(X,Y,s(s(z)))).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnf(add_succ, axiom, (add(s(X1),X2,s(X3))|~add(X1,X2,X3)), file('/tmp/prolog.p', add_succ)).\n",
      "cnf(add_z, axiom, (add(z,X1,X1)), file('/tmp/prolog.p', add_z)).\n",
      "fof(add_g, conjecture, ?[X2, X1]:(add(X2,X1,s(s(z)))), file('/tmp/prolog.p', add_g)).\n",
      "fof(c_0_4, negated_conjecture, ~(?[X2, X1]:(add(X2,X1,s(s(z))))),inference(assume_negation, [status(cth)],[c_0_3])).\n",
      "cnf(c_0_5, plain, (add(s(X1),X2,s(X3))|~add(X1,X2,X3)),inference(fof_simplification, [status(thm)],[c_0_1])).\n",
      "fof(c_0_6, negated_conjecture, ![X2, X1]:(~add(X2,X1,s(s(z)))),inference(fof_nnf, [status(thm)],[c_0_4])).\n",
      "fof(c_0_7, negated_conjecture, ![X4, X5]:(~add(X4,X5,s(s(z)))),inference(variable_rename, [status(thm)],[c_0_6])).\n",
      "fof(c_0_8, negated_conjecture, ![X4, X5]:(~add(X4,X5,s(s(z)))),inference(fof_nnf, [status(thm)],[c_0_7])).\n",
      "cnf(c_0_9, negated_conjecture, (~add(X1,X2,s(s(z)))),inference(split_conjunct, [status(thm)],[c_0_8])).\n",
      "# Initializing proof state\n",
      "cnf(c_0_10, plain, (add(z,X1,X1)), c_0_-9223372036854775801,['eval']).\n",
      "cnf(c_0_11, negated_conjecture, (~add(X1,X2,s(s(z)))), c_0_9,['eval']).\n",
      "cnf(c_0_12, plain, (add(s(X1),X2,s(X3))|~add(X1,X2,X3)), c_0_-9223372036854775802,['eval']).\n",
      "# Scanning for AC axioms\n",
      "cnf(c_0_13, plain, (add(z,X1,X1)), c_0_10,['new_given']).\n",
      "cnf(c_0_14, plain, (add(s(X1),X2,s(X3))|~add(X1,X2,X3)), c_0_12,['new_given']).\n",
      "cnf(c_0_15, negated_conjecture, (~add(X1,X2,s(s(z)))), c_0_11,['new_given']).\n",
      "cnf(c_0_16, negated_conjecture, ($false),inference(pm,[status(thm)],[c_0_15,c_0_13])).\n",
      "cnf(c_0_17, negated_conjecture, (~add(X1,X2,s(z))),inference(pm,[status(thm)],[c_0_15,c_0_14])).\n",
      "cnf(c_0_18, negated_conjecture, ($false), c_0_16,['proof']).\n",
      "\n",
      "# Proof found!\n",
      "# SZS status Theorem\n",
      "# Parsed axioms                        : 3\n",
      "# Removed by relevancy pruning/SinE    : 0\n",
      "# Initial clauses                      : 3\n",
      "# Removed in clause preprocessing      : 0\n",
      "# Initial clauses in saturation        : 3\n",
      "# Processed clauses                    : 3\n",
      "# ...of these trivial                  : 0\n",
      "# ...subsumed                          : 0\n",
      "# ...remaining for further processing  : 3\n",
      "# Other redundant clauses eliminated   : 0\n",
      "# Clauses deleted for lack of memory   : 0\n",
      "# Backward-subsumed                    : 0\n",
      "# Backward-rewritten                   : 0\n",
      "# Generated clauses                    : 2\n",
      "# ...of the previous two non-redundant : 0\n",
      "# ...aggressively subsumed             : 0\n",
      "# Contextual simplify-reflections      : 0\n",
      "# Paramodulations                      : 2\n",
      "# Factorizations                       : 0\n",
      "# NegExts                              : 0\n",
      "# Equation resolutions                 : 0\n",
      "# Disequality decompositions           : 0\n",
      "# Total rewrite steps                  : 0\n",
      "# ...of those cached                   : 0\n",
      "# Propositional unsat checks           : 0\n",
      "#    Propositional check models        : 0\n",
      "#    Propositional check unsatisfiable : 0\n",
      "#    Propositional clauses             : 0\n",
      "#    Propositional clauses after purity: 0\n",
      "#    Propositional unsat core size     : 0\n",
      "#    Propositional preprocessing time  : 0.000\n",
      "#    Propositional encoding time       : 0.000\n",
      "#    Propositional solver time         : 0.000\n",
      "#    Success case prop preproc time    : 0.000\n",
      "#    Success case prop encoding time   : 0.000\n",
      "#    Success case prop solver time     : 0.000\n",
      "# Current number of processed clauses  : 3\n",
      "#    Positive orientable unit clauses  : 1\n",
      "#    Positive unorientable unit clauses: 0\n",
      "#    Negative unit clauses             : 1\n",
      "#    Non-unit-clauses                  : 1\n",
      "# Current number of unprocessed clauses: 0\n",
      "# ...number of literals in the above   : 0\n",
      "# Current number of archived formulas  : 0\n",
      "# Current number of archived clauses   : 0\n",
      "# Clause-clause subsumption calls (NU) : 0\n",
      "# Rec. Clause-clause subsumption calls : 0\n",
      "# Non-unit clause-clause subsumptions  : 0\n",
      "# Unit Clause-clause subsumption calls : 0\n",
      "# Rewrite failures with RHS unbound    : 0\n",
      "# BW rewrite match attempts            : 0\n",
      "# BW rewrite match successes           : 0\n",
      "# Condensation attempts                : 0\n",
      "# Condensation successes               : 0\n",
      "# Termbank termtop insertions          : 111\n",
      "# Search garbage collected termcells   : 14\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --output-level=6 /tmp/prolog.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Initializing proof state\n",
      "# Scanning for AC axioms\n",
      "#\n",
      "#cnf(i_0_4, plain, (add(z,X1,X1))).\n",
      "#\n",
      "#cnf(i_0_3, plain, (add(s(X1),X2,s(X3))|~add(X1,X2,X3))).\n",
      "#\n",
      "#cnf(i_0_5, negated_conjecture, ($answer(esk1_2(X1,X2))|~add(X1,X2,s(s(z))))).\n",
      "## SZS status Theorem\n",
      "# SZS answers Tuple [[z, s(s(z))]|_]\n",
      "\n",
      "#cnf(i_0_6, negated_conjecture, ($answer(esk1_2(z,s(s(z)))))).\n",
      "#\n",
      "#cnf(i_0_7, negated_conjecture, ($answer(esk1_2(s(X1),X2))|~add(X1,X2,s(z)))).\n",
      "## SZS answers Tuple [[s(z), s(z)]|_]\n",
      "\n",
      "#cnf(i_0_8, negated_conjecture, ($answer(esk1_2(s(z),s(z))))).\n",
      "#\n",
      "#cnf(i_0_9, negated_conjecture, ($answer(esk1_2(s(s(X1)),X2))|~add(X1,X2,z))).\n",
      "## SZS answers Tuple [[s(s(z)), z]|_]\n",
      "\n",
      "# Proof found!\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --conjectures-are-questions  --answers=3 /tmp/prolog.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplifier\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/simp.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/simp.p\n",
    "cnf(mul_zero, axiom, mul(X,zero) = zero).\n",
    "cnf(mul_comm, axiom, mul(X,Y) = mul(Y,X)).\n",
    "cnf(mul_assoc, axiom, mul(X,mul(Y,Z)) = mul(mul(X,Y),Z)).\n",
    "cnf(add_comm, axiom, add(X,Y) = add(Y,X)).\n",
    "cnf(add_assoc, axiom, add(X,add(Y,Z)) = add(add(X,Y),Z)).\n",
    "cnf(add_zero, axiom, add(X,zero) = X).\n",
    "cnf(abc, axiom, add(a,b) = c).\n",
    "\n",
    "cnf(goal_expr, axiom, t = add(add(a, mul(a,zero)), add(zero, b))).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " --processed-clauses-limit=100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! eprover-ho --print-saturated --unprocessed-limit=100 --output-level=6 /tmp/simp.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional programs.\n",
    "\n",
    "Constructors should come less in the precendence.\n",
    "LPO is more like functional programming.\n",
    "KBO is more like simplification\n",
    "\n",
    "\n",
    "Without the precendence annotations, eprover is not terminating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /tmp/add.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/add.p\n",
    "\n",
    "cnf(add_succ, axiom, add(s(X),Y) = s(add(X,Y))).\n",
    "cnf(add_z, axiom, add(z, Y) = Y).\n",
    "cnf(addn, axiom, add())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! eprover-ho --print-saturated  /tmp/add.p % non terminating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "auto is not better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Preprocessing class: FSSSSMSSSSSNFFN.\n",
      "# Scheduled 1 strats onto 1 cores with 300 seconds (300 total)\n",
      "# Starting G-E--_302_C18_F1_URBAN_RG_S04BN with 300s (1) cores\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --print-saturated --auto-schedule /tmp/add.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Initializing proof state\n",
      "# Scanning for AC axioms\n",
      "#\n",
      "#cnf(i_0_4, plain, (add(z,X1)=X1)).\n",
      "#\n",
      "#cnf(i_0_3, plain, (add(s(X1),X2)=s(add(X1,X2)))).\n",
      "\n",
      "# No proof found!\n",
      "# SZS status Satisfiable\n",
      "# Processed positive unit clauses:\n",
      "cnf(i_0_4, plain, (add(z,X1)=X1)).\n",
      "cnf(i_0_3, plain, (add(s(X1),X2)=s(add(X1,X2)))).\n",
      "\n",
      "# Processed negative unit clauses:\n",
      "\n",
      "# Processed non-unit clauses:\n",
      "\n",
      "# Unprocessed positive unit clauses:\n",
      "\n",
      "# Unprocessed negative unit clauses:\n",
      "\n",
      "# Unprocessed non-unit clauses:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! eprover-ho --print-saturated --term-ordering=LPO4 --precedence=\"add>s>z\" /tmp/add.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Older notes\n",
    "E prover\n",
    "enormalizer is an interesting sounding program. Give it a pile of unit equalities and it will normalize with respect to thm EPR grounder to DIMACS The e calculus is a bit puzzling. I haven’t seen the analog for vampire\n",
    "\n",
    "2.6 manual It’s also in the github repo if you make doc\n",
    "\n",
    "I like how –answer mode works a little better for e.\n",
    "\n",
    "Database printing feature -S. Doesn’t print stuff I would expect though? Kind of prints everything by default right? Early stopping conditions clause size\n",
    "\n",
    "eprover --help | less\n",
    "--watchlist - “constructive” proofs that aren’t seeded by refuation training - you can train it if you have a database of indicative theorems. This might be useful if you have a sequence of increasingly hard theorems, or if you are making a tool that spits out formula. -S print saturated clause set -W literaeelection stretagory NoGeneration will inhibit all generating instances “Each of the strategies that do actually select negative literals has a corresponding counterpart starting with P that additionally allows paramodulation into maximal positive literals”\n",
    "\n",
    "echo \"\n",
    "fof(ground, axiom,\n",
    "    edge(a,b) & edge(b,c)\n",
    ").\n",
    "fof(path1, axiom,\n",
    "    ![X,Y]: (edge(X,Y) => path(X,Y))\n",
    ").\n",
    "fof(path2, axiom,\n",
    "    ![X,Y,Z]:  ((edge(X,Y) & path(Y,Z)) => path(X,Z))\n",
    ").\n",
    "\" | eprover  --literal-selection-strategy=SelectNegativeLiterals\n",
    "--generated-limit=100 Ok this basically did what i wanted. I’m not sure what it is though?\n",
    "\n",
    "“The most natural clause representation for E is probably a literal disjunction: a=\n",
    "true;c!=$true.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Equality Saturation\n",
    "Somewhat like datalog, but it's worse here. The ordering is really important to get fair search.\n",
    "\n",
    "We want the goal term in immediately.\n",
    "\n",
    "\n",
    "%%file /tmp/eq.p\n",
    "cnf(goalterm, axiom, t = div(mul(a, two), two)).\n",
    "cnf(mulcomm, axiom, mul(X,Y) = mul(Y,X)).\n",
    "cnf(mulassoc, axiom, mul(X,mul(Y,Z)) = mul(mul(X,Y),Z)).\n",
    "cnf(mulunit, axiom, mul(X, one) = X).\n",
    "cnf(mulinv, axiom, div(mul(X,Y), Y) = X | Y = zero).\n",
    "cnf(shiftmul, axiom, mul(X, two) = shift(X, one))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vampire\n",
    "\n",
    "Maybe I should play with these.\n",
    "--memory\n",
    "--cores\n",
    "\n",
    "--selection (-s)\n",
    "        Selection methods 2,3,4,10,11 are complete by virtue of extending Maximal \n",
    "        i.e. they select the best among maximal. Methods 1002,1003,1004,1010,1011 \n",
    "        relax this restriction and are therefore not complete.\n",
    "         0     - Total (select everything)\n",
    "         1     - Maximal\n",
    "         2     - ColoredFirst, MaximalSize then Lexicographical\n",
    "         3     - ColoredFirst, NoPositiveEquality, LeastTopLevelVariables,\n",
    "                  LeastDistinctVariables then Lexicographical\n",
    "         4     - ColoredFirst, NoPositiveEquality, LeastTopLevelVariables,\n",
    "                  LeastVariables, MaximalSize then Lexicographical\n",
    "         10    - ColoredFirst, NegativeEquality, MaximalSize, Negative then Lexicographical\n",
    "         11    - Lookahead\n",
    "         666   - Random\n",
    "         1002  - Incomplete version of 2\n",
    "         1003  - Incomplete version of 3\n",
    "         1004  - Incomplete version of 4\n",
    "         1010  - Incomplete version of 10\n",
    "         1011  - Incomplete version of 11\n",
    "         1666  - Incomplete version of 666\n",
    "        Or negated, which means that reversePolarity is true i.e. for selection \n",
    "        we treat all negative non-equality literals as positive and vice versa \n",
    "        (can only apply to non-equality literals).\n",
    "        \n",
    "        default: 10\n",
    "\n",
    "--symbol_precedence (-sp)\n",
    "        Vampire uses term orderings which require a precedence relation between \n",
    "        symbols.\n",
    "        Arity orders symbols by their arity (and reverse_arity takes the reverse \n",
    "        of this) and occurrence orders symbols by the order they appear in the \n",
    "        problem. Then we have a few precedence generating schemes adopted from \n",
    "        E: frequency - sort by frequency making rare symbols large, reverse does \n",
    "        the opposite, (For the weighted versions, each symbol occurrence counts \n",
    "        as many times as is the length of the clause in which it occurs.) unary_first \n",
    "        is like arity, except that unary symbols are maximal (and ties are broken \n",
    "        by frequency), unary_frequency is like frequency, except that unary symbols \n",
    "        are maximal, const_max makes constants the largest, then falls back to \n",
    "        arity, const_min makes constants the smallest, then falls back to reverse_arity, \n",
    "        const_frequency makes constants the smallest, then falls back to frequency.\n",
    "        default: arity\n",
    "        values: arity,occurrence,reverse_arity,unary_first,const_max,const_min,scramble,\n",
    "                frequency,unary_frequency,const_frequency,reverse_frequency,\n",
    "                weighted_frequency,reverse_weighted_frequency\n",
    "--term-rdering kbo lpo\n",
    "--induction = none, stuct, int,both\n",
    "\n",
    "default on rules\n",
    "\n",
    "--backward_demodulation (-bd)\n",
    "        Oriented rewriting of kept clauses by newly derived unit equalities\n",
    "        s = t     L[sθ] \\/ C\n",
    "        ---------------------   where sθ > tθ (replaces RHS)\n",
    "         L[tθ] \\/ C\n",
    "        \n",
    "        default: all\n",
    "        values: all,off,preordered\n",
    "--binary_resolution (-br)\n",
    "        Standard binary resolution i.e.\n",
    "        C \\/ t     D \\/ s\n",
    "        ---------------------\n",
    "        (C \\/ D)θ\n",
    "        where θ = mgu(t,-s) and t selected\n",
    "        default: on\n",
    "--demodulation_redundancy_check (-drc)\n",
    "        The following cases of backward and forward demodulation do not preserve \n",
    "        completeness:\n",
    "        s = t     s = t1 \\/ C    s = t     s != t1 \\/ C\n",
    "        ---------------------    ---------------------\n",
    "        t = t1 \\/ C              t != t1 \\/ C\n",
    "        where t > t1 and s = t > C (RHS replaced)\n",
    "        With `on`, we check this condition and don't demodulate if we could violate \n",
    "        completeness.\n",
    "        With `encompass`, we treat demodulations (both forward and backward) as \n",
    "        encompassment demodulations (as defined by Duarte and Korovin in 2022's \n",
    "        IJCAR paper).\n",
    "        With `off`, we skip the checks, save time, but become incomplete.\n",
    "        default: on\n",
    "        values: off,encompass,on\n",
    "    --forward_demodulation (-fd)\n",
    "        Oriented rewriting of newly derived clauses by kept unit equalities\n",
    "        s = t     L[sθ] \\/ C\n",
    "        ---------------------  where sθ > tθ\n",
    "         L[tθ] \\/ C\n",
    "        If 'preordered' is set, only equalities s = t where s > t are used for \n",
    "        rewriting.\n",
    "        default: all\n",
    "        values: all,off,preordered\n",
    "--forward_subsumption (-fs)\n",
    "        Perform forward subsumption deletion.\n",
    "        default: on\n",
    "--forward_subsumption_resolution (-fsr)\n",
    "        Perform forward subsumption resolution.\n",
    "        default: on\n",
    "--simultaneous_superposition (-sims)\n",
    "        Rewrite the whole RHS clause during superposition, not just the target \n",
    "        literal.\n",
    "        default: on\n",
    "--superposition (-sup)\n",
    "        Control superposition. Turning off this core inference leads to an incomplete \n",
    "        calculus on equational problems.\n",
    "        default: on\n",
    "--superposition_from_variables (-sfv)\n",
    "        Perform superposition from variables.\n",
    "        default: on\n",
    "\n",
    "--unit_resulting_resolution (-urr)\n",
    "        Uses unit resulting resolution only to derive empty clauses (may be useful \n",
    "        for splitting). 'ec_only' only derives empty clauses, 'on' does everything \n",
    "        (but implements a heuristic to skip deriving more than one empty clause), \n",
    "        'full' ignores this heuristic and is thus complete also under AVATAR.\n",
    "        default: off\n",
    "        values: ec_only,off,on,full\n",
    "\n",
    "--show_ordering\n",
    "--show_induction\n",
    "--manual_cs clause select manually\n",
    "--show_everything\n",
    "\n",
    "\n",
    "Pretty interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! vampire --show_everything on --manual_cs on /tmp/path.p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
