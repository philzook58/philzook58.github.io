{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Proof Objects I Have Loved\n",
    "date: 2025-04-28\n",
    "---\n",
    "\n",
    "That proofs are _things_ is a cool meta awareness that is one of the payoffs of studying mathematical logic.\n",
    "\n",
    "The curry Howard correspondence has produced an awareness in the right circles of the programming or CS world  that simply typed lambda terms are proofs objects of natural deduction for propositional intuitionistic logic or that that dependently typed terms are proofs objects of a more complex logic. For example `lam x : A. x`  is a proof object of the proposition `A -> A`. These are not the only proof objects in the world, nor the simplest ones IMO and not all reasonable ways to think about proofs fit in the Curry Howard paradigm. Curry Howard does not _own_ the concept of proof even if the system is flexible enough. Turn off your dependent typed brain if you have one or you will miss the intent with which I write this.\n",
    "\n",
    "Some of my favorite examples of proof objects are\n",
    "\n",
    "# Paths are Proofs of Connectedness in a Graph\n",
    "\n",
    "For small graphs, connectedness does not seemingly require proof, since it is a topic in algorithms class on how to efficiently compute connectivity in polynomial time. Even in this case, it is easier to check a path than to find it.\n",
    "\n",
    "However if you consider big big graphs, it can be impossible to completely examine all the edges.\n",
    "\n",
    "A equational reasoning system can be modelled as a giant graph of terms with an edge between each term that can be rewritten by applying an equation. The vertices of this graph are all the terms. We can produce a computable edge predicate `Term -> Term -> Bool` or `Term -> [Term]` that tells us all the axiom equations that may apply to a particular node, but \n",
    "\n",
    "# The two divisor is a witness of evenness\n",
    "\n",
    "If you give me the number that I need to multiply by 2 to get `x`, that is a bit easier in my mind than figuring out how to divide a number by two. According the the BHK interpretation https://en.wikipedia.org/wiki/Brouwer%E2%80%93Heyting%E2%80%93Kolmogorov_interpretation , we should associate witness information like this with existential statements like `even(x) := exists y, 2*y = x`  . The BHK interpretation is the thing that the Curry Howard correspondence bakes in so thoroughly it is hard to understand the general concept.\n",
    "\n",
    "# Proofs of linear equations.\n",
    "\n",
    "We can add together linear equations like `3x + 4y = 7` to get new equations. We learn this as a form of Gaussian elimination.\n",
    "\n",
    "What this means is that a possible proof object is a vector over the basis of equation axioms. If we can combine the axioms equations %E$ to get some goal equations $G$ like $a_1 E_1 + a_2 E_2 + ... = a^T \\cdot E = G$ then the vector $\\vec{a}$ is a proof object. I dare you to tell me that a vector is not a valid mathematical object.\n",
    "\n",
    "# Proofs of linear Inequations\n",
    "\n",
    "In linear programming, dual vectors are proof objects / certificates of optimality. \n",
    "\n",
    "You again can linearly combine inequalities only using positive coefficients. A negative number flips the direction of the inequality `-2 * (42 >= 4) ---> -84 <= -8`. An optimal dual vector `l^T` combines the linear inequalities to get the cost vector `c` on one side and the cost of the found primal solution`V` on the other   `l^T (A x <= b) ---> c^T x <= V`.\n",
    "\n",
    "You do not need to see how the dual vector was found in order to check it.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Dual_linear_program\n",
    "\n",
    "# Polynomial combinations of polynomials\n",
    "\n",
    "Similarly to the two above if you want to show that `p(x,y,z)` is zero under the assumption `q1, q2, q3,... = 0`, a polynomial combination of them does show this (although it isn't a complete proof procedure depending on what you want. I can't derive `(x - 2)` from `(x -2)**2`). This is a vector of polynomials. These polynomials themselves may be redundant like how linear equations were redundant. These redundancies are called syzygies https://en.wikipedia.org/wiki/Linear_relation\n",
    "\n",
    "\n",
    "# A Bool is a proof object\n",
    "\n",
    "If I say that a correct automated theorem proving procedure found a proof, then just saying that is a proof object at the extreme. All proofs require varying degrees of reconstruction. We usually erase all sorts of little things that are easily reconstructed on the other side. Once I know that the theorem is proven, I can just run the ATP again the reconstruct the proof.\n",
    "\n",
    "# Traces are Proof objects.\n",
    "\n",
    "Many many proof objects are traces of theorem proving systems. If you believe you somehow built a theorem prover, the substeps of this theorem prover.\n",
    "\n",
    "This is a viewpoint useful for SAT solvers, MIP solvers, datalog provenance, etc.\n",
    "\n",
    "UNSAT certificates basically traces of useful learned clauses in a SAT solver. The learned clauses are combinations of previous clauses using resolution. \n",
    "\n",
    "Datalog/prolog provenance basically carries an extra tracing parameter in every predicate. Traces of a prolog solve are proof objects.\n",
    "https://www.philipzucker.com/metamath-datalog-provenenance/\n",
    "\n",
    "\n",
    "MIP certificates are a tree of dual vectors (assuming branch and cut).\n",
    "\n",
    "https://cs.paperswithcode.com/paper/verifying-milp-certificates-with-smt-solvers\n",
    "VIPR certificates\n",
    "https://arxiv.org/abs/2312.10420 Satisfiability modulo theories for verifying MILP certificates\n",
    "\n",
    "https://github.com/ambros-gleixner/VIPR so SCIP can output this stuff? Huh.\n",
    "\n",
    "https://github.com/ambros-gleixner/MIPcc23 mip reoptimization\n",
    "\n",
    "# Rewrite Proofs\n",
    "Rewrite proofs have a couple different formats. See also what egg outputs.\n",
    "\n",
    "- A sequence of terms with position (how to get to subterm applied at) and eqaation used information tagged in between each\n",
    "- Congruence style. A `cong` node that takes in subproofs of all children equations and lifts them. Since rewrite proofs have a categorical flavor (has id and can be composed) the cong nodes have the flavor of a monoidal product functor. This gives some algebra of proofs. One can ask how to normalize proofs (See Terese). Congruence is the fancier version of grade school's \"do the same thing to both sides of an equation\".\n",
    "\n",
    "![](/assets/congruence.png)\n",
    "\n",
    "# Sequent and Natural Deduction proofs\n",
    "They are for serious trees you can write down in a programming language. It is important to not be confused about the different between the judgement the proof is for and the proof itself. These are kind of easy to get confused for some reason. The judgement is a tuple or set of formulas or something. The proof is this massive recursive tree with judgements at every node. You don't have to use lambda calculus verbiage. Sequent calculus has proof terms in the curry howard style in the lambda mu mubar calculus https://en.wikipedia.org/wiki/Lambda-mu_calculus\n",
    "\n",
    "Operations like Cut-elimination, negation normal form, cnf, dnf are for serious algoritms for transforming or using these proof tree data structures\n",
    "\n",
    "# UNSAT cores\n",
    "A lighter weight proof object is unsat cores, which at least prune for relevancy.\n",
    "\n",
    "# Good Rewrite Rules\n",
    "A good rewrite rule system is a good compressed proof object if you can guarantee I can run it and it will work. Each rewrite rule needs to be dignified from the axiom equations. Knuth bendix produces systems like this.\n",
    "\n",
    "# Bits and Bobbles\n",
    "\n",
    "Hello from Paris!\n",
    "\n",
    "https://en.wikipedia.org/wiki/Van_Kampen_diagram Van Kampen Diagrams are a visual proof object for the word problem of finitely presented groups. ![](https://upload.wikimedia.org/wikipedia/commons/8/81/Abelian.jpg)\n",
    "\n",
    "The stuff output by provers like vampire etc are kind of like \n",
    "\n",
    "I've never really understand the industry of SMT proof objects, but it's out there.\n",
    "https://microsoft.github.io/z3guide/programming/Proof%20Logs/\n",
    "https://github.com/Z3Prover/z3/discussions/4881\n",
    "https://cvc5.github.io/docs/cvc5-1.0.0/proofs/proofs.html\n",
    "Alethe\n",
    "LFSC\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "What is your cutoff of Proof vs Not? Is Bool a proof object? Do proofs need to reduce from undecidable to undecidable? Do they need to reduce complexity? \n",
    "\n",
    "Decidability vs undecidable. If we take decidability of theorems as meaning they don't need proof, then we ignore sat certificates all sorts of stuff\n",
    "Complexity arguments. https://en.wikipedia.org/wiki/Proof_complexity#Proofs_of_polynomial_size_and_the_NP_versus_coNP_problem Probably there is no polnoymiasl bounded positional system.\n",
    "\n",
    "But how do you defend against garbage with no relevant information context as a proof object?\n",
    "\n",
    "automatable proofs\n",
    "https://knowledge.uchicago.edu/record/12840?ln=en&v=pdf\n",
    "https://www.youtube.com/watch?v=gIsNV-o3MgY&ab_channel=SimonsInstitute a sruvey of automatilbity. algorithm that given taut outputs an proof in a time polynomial in the length of the shortest proof available\n",
    "https://www.youtube.com/watch?v=SZ6TWaNt5LQ&ab_channel=SimonsInstitute\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "I have had debates with Graham and others about what should count as a proof object.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Proofs are actions or things that convince someone about the truth of something.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paths in infinite graphs, even functional a path seems less straightforward. Indeed all proof search (in the sense of seeking an eumerable finite chceckable object) can be encoded in a graph search with richer vertices. It's reachability kind of.\n",
    "\n",
    "Vertices are sets of proven formula is one version. Kripke model of intuiotnsitc logic. But why?\n",
    "\n",
    "type Graph = V -> V -> bool\n",
    "\n",
    "type Graph = Stream (V,V)\n",
    "\n",
    "\n",
    "There is such a strng proof calculus that it normalizes.\n",
    "Could also have Tree like nor\n",
    "Which proofs are the \"same\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Proof(): ...\n",
    "class AddEq(): ...\n",
    "class MulEq(): ...\n",
    "\n",
    "# could eveb make MulEq as synpy Expr\n",
    "#class MulEq(Add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "\n",
    "x,y = symbols('x y')\n",
    "\n",
    "Eq(3*x + 8*x, 34)\n",
    "\n",
    "class LinProof():\n",
    "    pf : list[tuple[float, Equality]] # or dict[Equality, Real]\n",
    "    fm : Equality\n",
    "    def __add__(self, other):\n",
    "        if isinstance(other, LinProof):\n",
    "            return LinProof(self.pf + other.pf, Eq(self.fm.lhs + other.fm.lhs, self.fm.rhs + other.fm.rhs))\n",
    "    def __mul__(self, other):\n",
    "\n",
    "\n",
    "def flatten(pf: Proof) -> LinProof:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ineqaulity proofs\n",
    "Polynomial proofs\n",
    "\n",
    "p1,p2,p3 |- p\n",
    "\n",
    "multiplation is kind of an or.\n",
    "\n",
    "(x - 2)(x - 4) |- x - 2, x - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewriteStep():\n",
    "    position : list[int]\n",
    "    rule :\n",
    "    vs :  \n",
    "    t1 : \n",
    "    t2 : \n",
    "\n",
    "RewriteProof = list[RewriteStep]\n",
    "\n",
    "\n",
    "class RewriteProof2():\n",
    "\n",
    "\n",
    "\n",
    "class Cong():\n",
    "    f : Function\n",
    "\n",
    "class Conf():\n",
    "    f : smt.FuncDeclRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class \n",
    "class Trans():\n",
    "    a: V ; b : V;  pf: PathProof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# like drat\n",
    "class ResProof():\n",
    "    pfpos : \n",
    "    lit : \n",
    "    clause : frozenset[smt.BoolRef]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@dataclass(immutable=True)\n",
    "class Sequent():\n",
    "    hyps : frozenset[smt.BoolRef]\n",
    "    concs : frozenset[smt.BoolRef]\n",
    "class Proof():\n",
    "    seq: Sequent\n",
    "    fm: smt.BoolRef\n",
    "class Proof1(Proof):\n",
    "    pf : Proof\n",
    "class Proof2(Proof):\n",
    "    pfA : Proof\n",
    "    pfB : Proof\n",
    "class Rand(Proof2): ...\n",
    "class RAnd(Proof2): ...\n",
    "\n",
    "class RAnd(): pfA : Proof; pfB; Proof; fm : smt.BoolRef; seq : Sequent\n",
    "class ROr(): pfA : Proof; fm : smt.BoolRef; seq : Sequent\n",
    "class LOr(): pfA : Proof; pfB : Proof; fm : smt.BoolRef; seq : Sequent\n",
    "\n",
    "def check(Proof):\n",
    "    match pf:\n",
    "        case RAnd(pfA, pfB, fm, seq):\n",
    "            assert fm == And(pfA.fm, pfB.fm)\n",
    "            assert pfA.seq == pfB.seq\n",
    "            assert pfA.seq.hyps == pfB.seq.hyps\n",
    "            assert pfA.seq.concs == pfB.seq.concs\n",
    "            assert pfA.seq.hyps == seq.hyps\n",
    "            assert pfA.seq.concs == seq.concs\n",
    "        case ROr(pfA, fm, seq):\n",
    "            assert fm == Or(pfA.fm)\n",
    "            assert pfA.seq == seq\n",
    "        case RImplies():\n",
    "        case RNot()\n",
    "\n",
    "\n",
    "\n",
    "# atctic\n",
    "def rand(fm, seq): -> tuple[tuple[Sequent, Sequent], Callable[tuple[Proof, Proof, Proof]]]\n",
    "def ror(): ...\n",
    "\n",
    "# tactic. It's a lens.\n",
    "def nnf(fm): ...\n",
    "def cnf(fm) -> tuple[Sequent, Callable[Proof, Proof]: ...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def resolve(seq : Sequent) -> Proof: ...\n",
    "\n",
    "\n",
    "def cut_elim(): ...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NDJudge():\n",
    "    ctx : list[smt.BoolRef]\n",
    "    fm : smt.BoolRef\n",
    "class NDProof():\n",
    "    judge : NDJudge\n",
    "class AndIntro(NDProof): pfA : NDProof; pfB : NDProof\n",
    "class AndElim1(NDProof): pfAB : NDProof\n",
    "class AndElim2(NDProof): pfAB : NDProof\n",
    "class OrIntro1(NDProof): pfA : NDProof\n",
    "class OrIntro2(NDProof): pfB : NDProof\n",
    "class Weaken():\n",
    "class Var(NDProof):\n",
    "\n",
    "def check(pf: NDProof):\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lambda mu style proof terms.\n",
    "Translation to and from ND\n",
    "If we used smt.Sort as formula objects could use z3 lambdas as proof terms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HilbProof(): ...\n",
    "class Modus(HilbProof):\n",
    "    ab : HilbProof\n",
    "    a : HilbProof\n",
    "    fm : smt.BoolRef\n",
    "\n",
    "def check(HilbProof):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# proof transformations\n",
    "\n",
    "There are a number of transformations in logic and automated reasoning that are described as transformations on formulas that carry along semanticsa somehow (equisastifiability). The issue with this from my perspective is that this semantics is somewhat ethereal if you are inside a programming language. You don't really have a great way of talking about abstract infinite sets.\n",
    "\n",
    "Almost every introduction to logic starts with propositional truth tables.\n",
    "\n",
    "This comes about somewhat because what proof objects even are is vague. Once we have a concrete notion of proof object.\n",
    "\n",
    "negation normal form, disjunctive normal form, conjubctive normal form, skolemization, cut elimination\n",
    "\n",
    "\n",
    "subformula property\n",
    "\n",
    "\n",
    "natural -> hilbert is analgous to compiling to combinators\n",
    "natural <-> sequent\n",
    "\n",
    "https://www.cs.cmu.edu/~fp/courses/atp/schedule.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple, Optional\n",
    "class Proof(NamedTuple): judge: object; subproofs: list[\"Proof\"]\n",
    "class Proof(NamedTuple): rule: str; thm\n",
    "class Proof(NamedTuple): data: object; subproofs: list[\"Proof\"]\n",
    "# We can do a style where we have one constructor per proof rule, or a style of a generic Proof object\n",
    "# Thisi s very analous to trhe situation in terms with a Fn(str,args) version vs a one constructor per fn symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proofs are traces\n",
    "Big principle. Proofs are traces.\n",
    "\n",
    "There are many proof methods. There are many traces and hence many proof formats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## truth tables\n",
    "Are truth tables proof objects?\n",
    "They kind of suck. They are so huge that it is much worse to process the table than to regenerate it.\n",
    "\n",
    "A propositional formula is decidable, so by some standards doesn't nmeed proof objects? Thats silly though.\n",
    "\n",
    "It offers no complexity improvement to have the certificate. May as well have the certificate be junk or not exist\n",
    "\n",
    "They also have semantic smell.\n",
    "\n",
    "A proof object of \n",
    "\n",
    "forall M, (M |= A)\n",
    "\n",
    "\n",
    "This proof object is a tree (a list) of all the rows. n |= A is a metalogical side condition.\n",
    "`all _ < _ |= _`  `all M |= A` are two different judgements.\n",
    "\n",
    "```\n",
    "\n",
    "all M < n |= A   n |= A\n",
    "-----------------------\n",
    "   all M < n+1 |= A  \n",
    "\n",
    "\n",
    "   all M < n |= A    2**maxvar(A) = n \n",
    "--------------------------\n",
    "       all M |= A\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "truth tables for non classical logics.\n",
    "Kripke: enumerate number of worlds. generate all accessibility relations.\n",
    "Derive some bound from the formula. That's the confusing part. Probably some kind of modal depth.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rewrite proofs\n",
    "\n",
    "rewrite proofs.\n",
    "rw(t, rule) = s\n",
    "\n",
    "cnf(r1, axiom, rw(f(f(X)), r1) = X).\n",
    "cnf(r1, axiom, ~(rw(T, R) = T1) | rw(f(T), cong(R)) = f(T1)). \n",
    "\n",
    "% relational form\n",
    "cnf(r1,axiom, eq(f(f(X)), X, r1)).\n",
    "\n",
    "\n",
    "tff( , type, pf : $tType)\n",
    "tff(   type, syn : $tType)\n",
    "tff(    type, sem : $tType)\n",
    "tff( type,  start : pf > syn)  % dom\n",
    " (end : pf > syn)   % cod\n",
    "tff  eval : syn > sem)\n",
    "tff( reflect : sem > syn)\n",
    "tff( type,  end : pf > )\n",
    "\n",
    "tff( canon, syn > syn )\n",
    "canon(T) = reflect(eval(T))\n",
    "\n",
    "refl : syn > pf\n",
    "symm : pf > pf\n",
    "comp : pf * pf > pf\n",
    "congf \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "direct conversion of proof stustures seems more conceptually straightrforward to me than some hand waving about herbrand interpretations.\n",
    "\n",
    "https://dl.acm.org/doi/10.1145/174652.174655  Equational inference, canonical proofs, and proof orderings\n",
    "\n",
    "rewrite proofs are a sequence of (position, axiom) tuples interspersed with terms. On the edges and vertices. \n",
    "`[([0,1,0] ,r1), ([0,1], r2), ([0], r3)]`\n",
    "\n",
    "Redundancies. Some rewrites can be reordered. So a sequence is perhaps silly. The cong rules let you factor into the independent parts. Kind of a \"par\" parallel rule.\n",
    "\n",
    "More implicit is to erase the position. Or erase the rule and position and just list a sequence of terms. \"equality with transtivity is decidable\" add it to the conversion rules.\n",
    "\n",
    "Any rewrite system that works for the particular question is a proof. It is a compact way with a little bit of algorotihmic content. You could pick a particular imperative strategy even if not confluent on your starting point. The completed rewrite system is a proof for all pairs.\n",
    "Or it can just be a big step subroutine. (normlize into cnf, then yada yada). Compaction and big step proof discovery via anti unification?\n",
    "\n",
    "Is the knuth bendix rule kind of like extensionality.\n",
    "\n",
    "\n",
    "\n",
    "Or its a proof tree, which kind of refactors this data\n",
    "congf(refl, r1) : f(a, b) = f(a, c)\n",
    "\n",
    "reminsecent of matrix korncker rules. Fusion rules. Monoidal categoiry rules.\n",
    "comp(congf(A,B) , congf(C,D))  =  congf(comp(A,C), comp(B,D))\n",
    "comp(symm(R), R) = refl\n",
    "comp((comp(F,G)), H) = comp(F, comp(G,H))\n",
    "symm(symm(R)) = R\n",
    "symm(refl(T)) = refl(T)\n",
    "symm(congf(A,B)) = congf(symm(A),symm(B))\n",
    "\n",
    "symm is like inverse matrix.\n",
    "\n",
    "univalence?\n",
    "(comp(f,g) = refl(T)) & comp(g,f) = refl(T1) <-> f = g\n",
    "term1(comp(f,g)) = term1(refl(T)) <->  f = g\n",
    "T1 = T2 as terms?\n",
    "\n",
    "I'm seeking a way to turn only _some_ proofs into intensional proofs.\n",
    "This is maybe related to quotienting out in sequence. Or having systems of E baked in.  Is E-modulo and the homotopy thing related? Their quest is also about baking in. Huh. baking in casting. Baking in isomorphisms\n",
    "\n",
    "exists([F,G],  forall(T, term1(comp(F,G)) = T)) \n",
    "\n",
    "proof irrelevance.\n",
    "term1(P) = term1(Q) & term2(P) = term2(Q) <-> P = Q\n",
    "\n",
    "extensionality. But this makes the terms equal?\n",
    "exists(P, term1(P) = T1, term2(P) = T2) <-> T1 = T2\n",
    "\n",
    "ismorphism in the model?\n",
    "\n",
    "simplical sets?\n",
    "\n",
    "Yes, this is like A |- B as a category. comp, id\n",
    "\n",
    "These cong combinators are indexed krons. That reminds me of anyons.\n",
    "\n",
    "call it refl or id. It should be indexed by the term it is being applied at.\n",
    "comp(refl(T), F) = F. This is problematic for the usual reasons. T actually has to be the term.\n",
    "terms are like objects?\n",
    "\n",
    "Hmm. Could I revisit using eprover? https://www.philipzucker.com/theorem-proving-for-catlab-2-lets-try-z3-this-time-nope/\n",
    "There was this idea of using knuckeldragger to show its ok to delete junk in my axioms.\n",
    "\n",
    "an indexed version of otimes.\n",
    "congf = \\otimes_f\n",
    "\n",
    "proof orders says\n",
    "\n",
    "The proof tree can be flattened in different ways.\n",
    "\n",
    "traces of proving processes are proof objects. We are making trace data structures of the proving process. Subtrees kind of factor, which is the mariaculous character of terms.\n",
    "\n",
    "https://link.springer.com/chapter/10.1007/3-540-18508-9_23  Foundations of equational deduction: A categorical treatment of equational proofs and unification algorithms\n",
    "\n",
    "https://www.mi.fu-berlin.de/inf/groups/ag-ki/publications/free-logic/article-20.pdf  Automating Free Logic in HOL, with an Experimental Application in Category Theory\n",
    "\n",
    "What does egg output. Egglog.\n",
    "Eprover\n",
    "twee\n",
    "jbob / nqthm\n",
    "maude?\n",
    "z3 proof objects.\n",
    "cvc5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "syzygies s polynomials\n",
    "S(g1,g2) = sum an * gn\n",
    "\n",
    "There is a rewrite proof connecting all critical pairs. Sure.\n",
    "\n",
    "a*gi = 0 is syzygies.\n",
    "p[.. s] = q[... t] is set of term equations \n",
    "\n",
    "New generating constants?  a,b,c, f() --> p,q,g(X) \n",
    "\n",
    "idea: sorted lists can be converted into instrinsically sorted lists by considering differences.\n",
    "\n",
    "\n",
    "Using my string rewriting thing when z3 knuith bendix might be interesting.\n",
    "Kind of reminscient of K's store thing. contexts\n",
    "\n",
    "In a curious way, I guess the quest in DTT is also about equations modulo. But like equations modulo isomorphisms or equations modulo casting\n",
    "\n",
    "\n",
    "permutation equivalence.\n",
    "standardization\n",
    "https://www.ti.inf.uni-due.de/publications/bruggink/thesis.pdf\n",
    "Terese chapter 8\n",
    "\n",
    "rewriting logic\n",
    "\n",
    "mellies\n",
    "\n",
    "https://ncatlab.org/nlab/show/Tietze+transformation#tietzes_theorem\n",
    "https://en.wikipedia.org/wiki/Group_isomorphism_problem\n",
    "https://docs.gap-system.org/doc/ref/chap48.html#X782985197BE809BF I don't know what the lesson here is\n",
    "\n",
    "https://en.wikipedia.org/wiki/Module_homomorphism\n",
    "isomorphisms of rings?\n",
    "\n",
    "https://en.wikipedia.org/wiki/Nielsen_transformation\n",
    "\n",
    "\n",
    "Combinatorial group theory\n",
    "https://projecteuclid.org/journalArticle/Download?urlid=bams%2F1183548590  the word problem and the isomorphism problem for groups ... stillwell\n",
    "\n",
    "cancellative semigroups rather than groups is sufficient for egraph?\n",
    "\n",
    "\n",
    "ground proof theory is possibly ok too?\n",
    "Maybe any good groundness, linear, grobner, multiset etc proof theory is also good? \n",
    "\n",
    "https://docs.rs/egg/latest/egg/struct.Explanation.html \n",
    "```\n",
    "(+ 1 (- a (* (- 2 1) a)))\n",
    "(+ 1 (- a (* (Rewrite=> constant_fold 1) a)))\n",
    "(+ 1 (- a (Rewrite=> comm-mul (* a 1))))\n",
    "(+ 1 (- a (Rewrite<= mul-one a)))\n",
    "(+ 1 (Rewrite=> cancel-sub 0))\n",
    "(Rewrite=> constant_fold 1)\n",
    "```\n",
    "Interesting. rw(t, rule) form\n",
    "rw(t, id) = t\n",
    "rw(rw(t), r1), r2)\n",
    "\n",
    "```\n",
    "(+ 1 (- a (* (- 2 1) a)))\n",
    "(+\n",
    "   1\n",
    "   (Explanation\n",
    "     (- a (* (- 2 1) a))\n",
    "     (-\n",
    "       a\n",
    "       (Explanation\n",
    "         (* (- 2 1) a)\n",
    "         (* (Explanation (- 2 1) (Rewrite=> constant_fold 1)) a)\n",
    "         (Rewrite=> comm-mul (* a 1))\n",
    "         (Rewrite<= mul-one a)))\n",
    "     (Rewrite=> cancel-sub 0)))\n",
    "(Rewrite=> constant_fold 1)\n",
    "```\n",
    "\n",
    "eq(t1,t2,r) = canon(t1) = canon(t2)\n",
    "\n",
    "\n",
    "\n",
    "homo(H) = ( H(f(X.Y)) = f(H(X), H(Y))  & ...)\n",
    "H @ (f @ Y) = f @ (H @ Y)\n",
    "iso(G,H) = H @ G @ X = X  &  G @ H @ Y = Y\n",
    "could this enumerate?\n",
    "\n",
    "graph isomorphism\n",
    "\n",
    "succ(X) <=>  b1(b0(X))\n",
    "double1(succ(X)) = succ(succ(double1(X)))\n",
    "\n",
    "zero = zero\n",
    "b1(X) = succ(double(X))\n",
    "b0(X) = double(X)\n",
    "\n",
    "succ(zero) = bsucc(bzero) =  b1(bzero)\n",
    "\n",
    "carry(bzero) = b1(bzero)\n",
    "carry()\n",
    "\n",
    "succ(b0(X))\n",
    "\n",
    "iso(iso(F,G), eq(X,Y,p) \n",
    "Can I even confirm this is an iso via eprover?\n",
    "\n",
    "We could prefer b0,b1 over succ for sure. Is the point a john major like equality where you can transfer over and come back?\n",
    "\n",
    "If I did want to have group isomorphism lifted to =. To show that my triangulted thing = the canonical form of the group\n",
    "\n",
    "\n",
    "Proof objects are sometimes internally storeed in the same ast data structures. Because why implement another thing? This is the same moitvation of mathemticians. Why have a theory for two things if they can be unified\n",
    "\n",
    "Geometric group theory. van kampen diagrmax\n",
    "\n",
    "dehn functions - bound size of van kamep nfiagram\n",
    "\n",
    "term metrics https://www.itu.dk/~paba/pubs/files/bahr11rta-slides%20(handout).pdf\n",
    "\n",
    "https://link.springer.com/chapter/10.1007/978-3-031-63501-4_20 solving quantitative equations. hmmm. Useful for taylor O(x^n) equal or epsilon error equal? \"Context\" ?\n",
    "https://link.springer.com/chapter/10.1007/978-3-031-63501-4_20  Elements of Quantitative Rewriting\n",
    "Plotkin quantiative equational https://www.cambridge.org/core/books/foundations-of-probabilistic-programming/quantitative-equational-reasoning/4B76BCCD4D6A3A37459C35ED2CE5FF93  mkarov decision precorsses equational\n",
    "https://www.cambridge.org/core/books/foundations-of-probabilistic-programming/819623B1B5B33836476618AC0621F0EE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old 07/24\n",
    "\n",
    "What is a proof?\n",
    "\n",
    "I think a lot of clarity is gained by examining a couple of cases where there is a reasonable notion of proof\n",
    "\n",
    "There is a mushy boundary between things requiring proof\n",
    "\n",
    "- paths in a graph are proof of connectivity. Silly right? Computing a path is so easy. Algos 101. Well, if the graph is exponentially large or infinite, not so clear.\n",
    "- Satisfying assignments. \n",
    "- Dual vectors. For linear equations can show unsolvability. For inequalities can show minimality or unsolvability. For polynomial systems, can show unsolvability. This is Nullstullensatz (?) https://en.wikipedia.org/wiki/Hilbert%27s_Nullstellensatz https://terrytao.wordpress.com/2007/11/26/hilberts-nullstellensatz/\n",
    "- UNSAT certificates. Traces / Transcripts\n",
    "- \n",
    "\n",
    "- Trees\n",
    "\n",
    "Termination certificates.\n",
    "\n",
    "Proof normalization - Why?\n",
    "Cut elimination - why? It's a way of leaving \n",
    "\n",
    "\n",
    "There is some machine phi(x,p). Computing phi(x,p) given p is presumably easier than guessing p. Perhaps phi may be poly time, or at terminating. If given p, phi is possibly still nonterminating, that is saying proof checking is undecidable, something that comes up in extensional type theory for example.\n",
    "\n",
    "if phi(x,_) is N^3 and phi(x,p) is N, is that not a proof object?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mip proofs\n",
    "NotMin is a SAT-like NP problem. Give me a better solution and that certifies that mine is NOTMIN\n",
    "\n",
    "MIN is an UNSAT-like co-NP problem. Somehow show me there is no better solution.\n",
    "\n",
    "So minimization of producing is something akin to the intersection of NP and co-NP\n",
    "\n",
    "Linear programming is beautiful because of the duality principle, where te dual vector is a proof certificate deomsntrating the minimality of your solution (or infeasibility)\n",
    "\n",
    "MILP uses LP as a subroutine for solving relaxed problems. It also uses cuts and brach and bound. So there is a search tree.\n",
    "\n",
    "\n",
    "https://cs.paperswithcode.com/paper/verifying-milp-certificates-with-smt-solvers\n",
    "VIPR certificates\n",
    "https://arxiv.org/abs/2312.10420 Satisfiability modulo theories for verifying MILP certificates\n",
    "\n",
    "https://github.com/ambros-gleixner/VIPR so SCIP can output this stuff? Huh.\n",
    "\n",
    "https://github.com/ambros-gleixner/MIPcc23 mip reoptimization\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
