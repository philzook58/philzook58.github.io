{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Gauss and Groebner Egraphs: Intrinsic Linear and Polynomial Equations\"\n",
    "date: 2024-07-15\n",
    "---\n",
    "\n",
    "It is a paradoxical bummer that associativity and commutativity are two hard to orient rules (the point of the egraph approach) but also highly explosive for what feels like administrative manipulations.\n",
    "\n",
    "In particular, associativity and commutativity are properties of multiplication and addition of familiar ordinary numbers. \n",
    "\n",
    "Linear and polynomials expressions have pretty good special methods for them. Using general term rewriting or egraph techniques to solve linear equations feels like insanity. \n",
    "\n",
    "Humanity is so good at linear equations. It's kind of one of the few mathematical things we can do at scale. So, is there an intrinsic way of bolting linear equality and polynomial equality reasoning into egraph equality saturation?\n",
    "\n",
    "Yeah, I think so.\n",
    "\n",
    "In short, replace the union find by reduced row echelon form / groebner basis and use bottom up e-matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are Union Finds?\n",
    "Union finds \"solve\" equations of the form `x0 = x1, x1 = x2, x1 = x2, x3 = x4`\n",
    "\n",
    "A union find is a forest of equivalence classes. Each tree in the forest is one equivalence class. The children point up to the parents for a fast `find` operation to get a canonical member (the root) of each eq class.\n",
    "\n",
    "This might result in a union find that looks like\n",
    "\n",
    "`x0 -> x2`\n",
    "\n",
    "`x1 -> x2`\n",
    "\n",
    "`x3 -> x4`\n",
    "\n",
    "![union find](/assets/uf.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"206pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 206.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-112 202,-112 202,4 -4,4\"/>\n",
       "<!-- x0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">x0</text>\n",
       "</g>\n",
       "<!-- x2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>x2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">x2</text>\n",
       "</g>\n",
       "<!-- x0&#45;&gt;x2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x0&#45;&gt;x2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M35.35,-72.76C39.71,-64.28 45.15,-53.71 50.04,-44.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.23,-45.64 54.7,-35.15 47.01,-42.44 53.23,-45.64\"/>\n",
       "</g>\n",
       "<!-- x1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>x1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">x1</text>\n",
       "</g>\n",
       "<!-- x1&#45;&gt;x2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>x1&#45;&gt;x2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M90.65,-72.76C86.29,-64.28 80.85,-53.71 75.96,-44.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"78.99,-42.44 71.3,-35.15 72.77,-45.64 78.99,-42.44\"/>\n",
       "</g>\n",
       "<!-- x3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>x3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"171\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">x3</text>\n",
       "</g>\n",
       "<!-- x4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>x4</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"171\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">x4</text>\n",
       "</g>\n",
       "<!-- x3&#45;&gt;x4 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>x3&#45;&gt;x4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M171,-71.7C171,-63.98 171,-54.71 171,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"174.5,-46.1 171,-36.1 167.5,-46.1 174.5,-46.1\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x739db756ff70>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "\n",
    "dot = Digraph()\n",
    "\n",
    "uf = [(\"x0\", \"x2\"), (\"x1\", \"x2\"), (\"x3\", \"x4\")]\n",
    "for edge in uf:\n",
    "    dot.edge(edge[0], edge[1])\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algebra and Unions Finds\n",
    "These equations can also be interpreted as a linear equations though.\n",
    "\n",
    "We can rewrite the simple equations `x0 = x2` as `x0 - x2 = 0`. This can be seen as dot product `(1 0 -1 ...) . (x0 x1 x2 ...) = 0`\n",
    "\n",
    "When we have multiple equations, these each become a row in a constraint matrix `Ax = 0`.\n",
    "\n",
    "For example, the equations `x0 = x1, x1 = x2, x1 = x2, x3 = x4` becomes the rows of the matrix R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⎡1  -1  0   0  0 ⎤\n",
      "⎢                ⎥\n",
      "⎢0  1   -1  0  0 ⎥\n",
      "⎢                ⎥\n",
      "⎢0  1   -1  0  0 ⎥\n",
      "⎢                ⎥\n",
      "⎣0  0   0   1  -1⎦\n"
     ]
    }
   ],
   "source": [
    "import sympy as sp\n",
    "A =   sp.Matrix([\n",
    "    [1,-1, 0,0, 0],  # x0 = x1\n",
    "    [0, 1,-1,0, 0],  # x1 = x2\n",
    "    [0, 1, -1, 0,0], # x1 = x2\n",
    "    [0, 0, 0,1,-1],  # x3 = x4\n",
    "   # [0, 1, 0,0,-1],\n",
    "    ])\n",
    "sp.pprint(A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the reduced row echelon form. This is using row additions turn turn the leading coefficients to 1 and clear out that coefficient from the lower rows.\n",
    "https://en.wikipedia.org/wiki/Row_echelon_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⎡1  0  -1  0  0 ⎤\n",
      "⎢               ⎥\n",
      "⎢0  1  -1  0  0 ⎥\n",
      "⎢               ⎥\n",
      "⎢0  0  0   1  -1⎥\n",
      "⎢               ⎥\n",
      "⎣0  0  0   0  0 ⎦\n"
     ]
    }
   ],
   "source": [
    "# reduced row echelon form\n",
    "sp.pprint(A.rref()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The row echelon form gives us a notion of normalizing a linear expression.\n",
    "\n",
    "Each nonzero row of this matrix can be interpreted as a normalizing rewrite system.\n",
    "`x0 -> x2`\n",
    "`x1 -> x2`\n",
    "`x3 -> x4`\n",
    "\n",
    "Such a rewrite system can also be seen as a forest of equivalence classes, aka the union find. The rhs are the roots of the tree and the lhs are the children of the roots.\n",
    "\n",
    "Any linear expression we write down can be put into a canonical form by running these rules. I'm not exactly sure how to express this elegantly in linear algebraic language, but it is obviously imperatively doable. Take your input vector, go down each row and use it to replace that column. This is similar to inverting? Let's just move on to groebner bases where it's more obvious.\n",
    "\n",
    "As an alternative motivation for the connection between union finds and linear algebra, note that union finds are useful for finding connected components in a graph. Adjacency matrices are also an encoding of the graph and connected component (or interestingly approximate connected component) information can be extracted via linear algebraic or spectral means. So there is similar junk in there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Elimination and Groebner Bases\n",
    "It turns out that it will be easiest to immediately use the generalization of these considerations, [Groebner bases](https://en.wikipedia.org/wiki/Gr%C3%B6bner_basis). This is a good tutorial https://mattpap.github.io/masters-thesis/html/src/groebner.html\n",
    "\n",
    "Groebner bases are a canonical form for a set of multinomial equations with good behavior with respect to polynomial division. \n",
    "\n",
    "This directly generalizes the reduced row echelon form above. The grobner basis for linear polynomials `x0 - x1 = 0` etc will be in exactly the same form as the reduced row echelon form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\operatorname{GroebnerBasis}\\left(\\left( x_{0} - x_{2}, \\  x_{1} - x_{2}, \\  x_{3} - x_{4}\\right), \\left( x_{0}, \\  x_{1}, \\  x_{2}, \\  x_{3}, \\  x_{4}\\right)\\right)$"
      ],
      "text/plain": [
       "GroebnerBasis([x0 - x2, x1 - x2, x3 - x4], x0, x1, x2, x3, x4, domain='ZZ', order='lex')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sympy as sp\n",
    "xs = sp.symbols('x0 x1 x2 x3 x4')\n",
    "x0, x1, x2, x3, x4 = xs\n",
    "eqs = [\n",
    "    x0 - x1,\n",
    "    x1 - x2,\n",
    "    x1 - x2,\n",
    "    x3 - x4,\n",
    "]\n",
    "G = sp.groebner(eqs, xs, order='lex')\n",
    "G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have a grobner basis in hand, we can reduced a polynomial expression to a canonical form via a process of multinomial division. `sympy` implements this is [`sympy.redcued`](https://docs.sympy.org/latest/modules/polys/reference.html#sympy.polys.polytools.reduced)\n",
    "\n",
    "Here we see `x0` reduces to the canonical `x2`, the same as the above union find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 0, 0], x2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first is coefficients of the grobner basis, the second is the remainder aka canonical terms\n",
    "sp.reduced(x0, G) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More examples of canonical forms coming from this system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sp.reduced(x0, G)=([1, 0, 0], x2)\n",
      "sp.reduced(x1, G)=([0, 1, 0], x2)\n",
      "sp.reduced(x2, G)=([0, 0, 0], x2)\n",
      "sp.reduced(x3, G)=([0, 0, 1], x4)\n",
      "sp.reduced(x4, G)=([0, 0, 0], x4)\n",
      "sp.reduced(x0+2*x2 + 17*x3, G)=([1, 0, 17], 3*x2 + 17*x4)\n",
      "sp.reduced(3*x0 + 25*x4 - 8*x3, G)=([3, 0, -8], 3*x2 + 17*x4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{sp.reduced(x0, G)=}\")\n",
    "print(f\"{sp.reduced(x1, G)=}\")\n",
    "print(f\"{sp.reduced(x2, G)=}\")\n",
    "print(f\"{sp.reduced(x3, G)=}\")\n",
    "print(f\"{sp.reduced(x4, G)=}\")\n",
    "print(f\"{sp.reduced(x0+2*x2 + 17*x3, G)=}\")\n",
    "print(f\"{sp.reduced(3*x0 + 25*x4 - 8*x3, G)=}\") # another way of writing same linear combination under these assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Egraphing it\n",
    "\n",
    "Ok, an egraph is basically some kind of node table associating eclasses to enodes + a union find.\n",
    "\n",
    "We will use sympy symbols `ei` to rerpesent our eclasses and the stock sympy groebner basis routines to do the union find action. The point of the union find is you can add new equalities and you can normalize an eclass by calling find.\n",
    "\n",
    "| union find | groebner |\n",
    "|------------|----------|\n",
    "| union      | add eq   |\n",
    "| find       | reduce   |\n",
    "\n",
    "\n",
    "Curiously and interestingly now, you can multiply and add eclasses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "EClass = sp.Symbol\n",
    "ENode = tuple[str,...]\n",
    "# helper functions to turn integers into sympy symbols\n",
    "def sympy_eclass(n):\n",
    "    return sp.symbols('e' + str(n))\n",
    "def eclass_of_sympy(eclass):\n",
    "    return int(eclass.name[1:])\n",
    "\n",
    "@dataclass\n",
    "class EGraph:\n",
    "    poly_eqs : list[sp.Expr]\n",
    "    hashcons : dict[ENode, EClass]\n",
    "    eclasses : list[EClass]\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.poly_eqs = []\n",
    "        self.hashcons : Dict[ENode, EClass] = {}\n",
    "        self.eclasses = []\n",
    "    def find(self, x : EClass) -> EClass:\n",
    "        return sp.reduced(x, self.poly_eqs, self.eclasses)[1]\n",
    "    def union(self, x : EClass,y : EClass) -> EClass:\n",
    "        x = self.find(x)\n",
    "        y = self.find(y)\n",
    "        if x != y:\n",
    "            self.poly_eqs.append(x - y)\n",
    "    def makeset(self):\n",
    "        x = sympy_eclass(len(self.eclasses))\n",
    "        self.eclasses.append(x)\n",
    "        return x\n",
    "    def make(self, t : ENode) -> EClass:\n",
    "        t1 = self.hashcons.get(t)\n",
    "        if t1 == None:\n",
    "            v = self.makeset()\n",
    "            self.hashcons[t] = v\n",
    "            return v\n",
    "        else:\n",
    "            return t1\n",
    "    def rebuild(self):\n",
    "        # simple naive dumb rebuild step. Could be optimized signifcantly\n",
    "        while True:\n",
    "            #rebuild \"union find\"\n",
    "            self.poly_eqs = list(sp.groebner(self.poly_eqs, *self.eclasses))\n",
    "\n",
    "            # rebuild hashcons\"\n",
    "            newhashcons = {}\n",
    "            for k,v in self.hashcons.items():\n",
    "                (f,*args) = k\n",
    "                args = map(self.find,args) # normalize argument eclasses\n",
    "                enode = (f,*args)\n",
    "                eclass = self.hashcons.get(enode)\n",
    "                if eclass != None:\n",
    "                    self.union(v,eclass)\n",
    "                newhashcons[enode] = self.find(v)\n",
    "            if self.hashcons == newhashcons:\n",
    "                return\n",
    "            self.hashcons = newhashcons   \n",
    "    def add_term(self, t):\n",
    "        if isinstance(t, sp.Expr): # allow partial terms that contain eclasses\n",
    "            return t\n",
    "        f, *args = t\n",
    "        args = map(self.add_term,args)\n",
    "        return self.make_enode((f,*args))\n",
    "    def check_term(self, t):\n",
    "        if isinstance(t, sp.Expr): # allow partial terms that contain eclasses\n",
    "            return t\n",
    "        f, *args = t\n",
    "        map(self.check_term,args)\n",
    "        return (f,*args)\n",
    "    def make_enode(self, enode):\n",
    "        eclass = self.hashcons.get(enode)\n",
    "        if eclass == None:\n",
    "            eclass = self.makeset() \n",
    "            self.hashcons[enode] = eclass\n",
    "        return eclass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fooling around a little with a toy egraph example. We can do algebra on eclasses because they are sympy variables. Here I assert $bar^2 = foo(bar)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EGraph(poly_eqs=[], hashcons={('bar',): e0, ('foo', e0): e1, ('foo', e1): e2}, eclasses=[e0, e1, e2])\n",
      "EGraph(poly_eqs=[e0 - e2], hashcons={('bar',): e2, ('foo', e2): e1, ('foo', e1): e2}, eclasses=[e0, e1, e2])\n",
      "EGraph(poly_eqs=[e0 - e2, e2**2 - e2], hashcons={('bar',): e2, ('foo', e2): e1, ('foo', e1): e2}, eclasses=[e0, e1, e2])\n"
     ]
    }
   ],
   "source": [
    "E = EGraph()\n",
    "foobar = E.add_term((\"foo\", (\"foo\", (\"bar\",))))\n",
    "bar = E.add_term((\"bar\",))\n",
    "print(E)\n",
    "E.union(foobar, bar)\n",
    "E.rebuild()\n",
    "print(E)\n",
    "E.union(bar*bar, foobar)\n",
    "E.rebuild()\n",
    "print(E)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example asserting $\\sin(bar)^2 + \\cos(bar)^2 = 1$ and $bar = biz$, which simplifies $\\sin(bar)^2 + \\cos(biz)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EGraph(poly_eqs=[], hashcons={('bar',): e0, ('sin', e0): e1, ('biz',): e2, ('cos', e2): e3, ('cos', e0): e4}, eclasses=[e0, e1, e2, e3, e4])\n",
      "sin(bar)**2 + cos(bar)**2 == e1**2 + e4**2\n",
      "EGraph(poly_eqs=[e1**2 + e4**2 - 1], hashcons={('bar',): e0, ('sin', e0): e1, ('biz',): e2, ('cos', e2): e3, ('cos', e0): e4}, eclasses=[e0, e1, e2, e3, e4])\n",
      "EGraph(poly_eqs=[e0 - e2, e1**2 + e4**2 - 1, e3 - e4], hashcons={('bar',): e2, ('sin', e2): e1, ('biz',): e2, ('cos', e2): e4}, eclasses=[e0, e1, e2, e3, e4])\n"
     ]
    }
   ],
   "source": [
    "E = EGraph()\n",
    "sinbar = E.add_term((\"sin\", (\"bar\",)))\n",
    "cosbiz = E.add_term((\"cos\", (\"biz\",)))\n",
    "cosbar = E.add_term((\"cos\", (\"bar\",)))\n",
    "t1 = E.add_term(sinbar*sinbar + cosbiz*cosbiz)\n",
    "t2 = E.add_term(sinbar*sinbar + cosbar*cosbar)\n",
    "print(E)\n",
    "print(f\"sin(bar)**2 + cos(bar)**2 == {t2}\")\n",
    "E.union(t2, 1)\n",
    "E.rebuild()\n",
    "print(E)\n",
    "bar = E.add_term((\"bar\",))\n",
    "biz = E.add_term((\"biz\",))\n",
    "E.union(biz,bar)\n",
    "E.rebuild()\n",
    "print(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bottom Up E-matching\n",
    "\n",
    "Again, I think bottom up ematching is the way to go when you need to integrate theories into egraph rewriting. Bottom up e-matching guesses what goes into the pattern variables. You can maintain some explicit set of variable guess terms (every term you've explicitly mentioned previously) or similarly just throw in all the eclasses. Then you can normalize them with respect to the egraph and permit the rule to fire if the lhs falls in some heuristic set. The set is commonly the set of terms held in the egraph. Here I just always allow the rule to fire. This is probably more eager than you'd like.\n",
    "\n",
    "Which linear combinations you should initiate the variables with is not obvious and there is an infinite number of choices. At least naively speaking, it seems you're screwed in terms of completeness. E-graph rewriting was never complete. This is pragmatic mix of what seems readily at hand and doable. Completeness is overrated, but also it feels like complete methods are the only ones that survive, since everyone has their own preferred heuristics. Me dunno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def rw(self, n, f):\n",
    "    for eclasses in itertools.product(self.eclasses, repeat=n):\n",
    "        lhs, rhs = f(*eclasses)\n",
    "        # whatever\n",
    "        lhs = self.add_term(lhs)\n",
    "        rhs = self.add_term(rhs)\n",
    "        self.union(lhs, rhs)\n",
    "EGraph.rw = rw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EGraph(poly_eqs=[], hashcons={('bar',): e0, ('foo', e0): e1, ('foo', e1): e2}, eclasses=[e0, e1, e2])\n",
      "EGraph(poly_eqs=[-2*e0 + e1, -2*e1 + e2, -2*e2 + e3], hashcons={('bar',): e0, ('foo', e0): e1, ('foo', e1): e2, ('foo', e2): e3}, eclasses=[e0, e1, e2, e3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EGraph(poly_eqs=[8*e0 - e3, 4*e1 - e3, 2*e2 - e3], hashcons={('bar',): e3/8, ('foo', e3/8): e3/4, ('foo', e3/4): e3/2, ('foo', e3/2): e3}, eclasses=[e0, e1, e2, e3])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = EGraph()\n",
    "foobar = E.add_term((\"foo\", (\"foo\", (\"bar\",))))\n",
    "print(E)\n",
    "#E.rw(1, lambda x: ((\"foo\", x), x))\n",
    "E.rw(1, lambda x: ((\"foo\", x), 2*x))\n",
    "#E.rw(1, lambda x: ((\"foo\", 2*x), x))\n",
    "print(E)\n",
    "E.rebuild()\n",
    "E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bits and Bobbles\n",
    "\n",
    "Fully normalizing the to the grobner basis may be overkill. It tends to be a property of egraphs that they are self healing in the face of incomplete canonicalization / hash consing. They can recover later. https://en.wikipedia.org/wiki/Wu%27s_method_of_characteristic_set My impression of Wu's method is that it very successful but slightly more ad hoc method for doing geoemtric theorem proving while still using the same basic idea of polynomial division that grobner bases do.\n",
    "\n",
    "lex monomial ordering is typically not the best performing one to my understanding. It is the easiest to interpret though. I think other orders ought to work fine.\n",
    "\n",
    "There was this idea of \"symbolic\" lattices in egglog. If we defined a lattice using egraph equations for join the \"merge\" annotation for the table could refer to this insitead of to a primitive lattice like i64-min.\n",
    "\n",
    "Semiring semantics. Is this getting close to an interesting intertwined notion of semiring semantics? Instead of an a priori quotient ring we could discover what ring we're in and normalize all truth valuers via the grobner. Hmm.\n",
    "\n",
    "A represntation that is \"off by 1\" from the above is polynomials as just another kind of container. Containers have a theory specific notion of rebuilding. Sets for example deduplicate and sort on rebuilding (they may have discovered new equations, so sets could shrink). Polynomials are just another container for eclasses. Enodes are just an ordered fixed size array container. https://www.philipzucker.com/bottom_up/\n",
    "\n",
    "\"Proof producing\" row echelon form is working with the augmented matrix (stacking on an identity matrix) https://en.wikipedia.org/wiki/Augmented_matrix. `E * [R | I] = [E*R | E] = S`. There was something similar you can do for groebner bases I mentioned here. https://www.philipzucker.com/computing-syzygy-modules-in-sympy/ extra variables to track how you derived the grobner basis from your original equations. One new variable per equation `f`. I barely understand what I'm talking about here. A lesson for the future to write better? Or just evidence my mind changes.\n",
    "\n",
    "I basically never implement extraction. Does anything fishy happen? I don't think so.\n",
    "\n",
    "maybe there is a way to bootstrap off of the sympy simplify rules like I could off of z3's. I'm not actually sure I have to opaquify to sympy in the from of the `ei`. Maybe sympy is happy doing groebner bases over compound terms? Then I could take the GRS strategy. This is the analog of what I did for z3 here https://www.philipzucker.com/ext_z3_egraph/\n",
    "I have noticed in the past it is quite hard to stop sympy from doing simplification when you construct terms. `evaluate=False` didn't seem like a panacea\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0], foo(bar()))\n",
      "([-1], foo(bar()))\n",
      "([0, -1, 0], foo(e1))\n",
      "GroebnerBasis([e1 - foo(e1), e2 - foo(e1), bar() - foo(e1)], e1, e2, bar(), foo(e1), domain='ZZ', order='lex')\n",
      "([0], foo(biz()))\n",
      "([0], foo(bar()))\n"
     ]
    }
   ],
   "source": [
    "# yeah, seems like I didn't need the node table. I could just use sympy terms.\n",
    "# but ultimately I want to also bolt in other stuff?\n",
    "foo = sp.Function(\"foo\")\n",
    "bar = sp.Function(\"bar\")\n",
    "biz = sp.Function(\"biz\")\n",
    "eq = [foo(bar()) - bar()]\n",
    "print(sp.reduced(foo(bar()), eq))\n",
    "print(sp.reduced(bar(), eq))\n",
    "e1,e2 = sp.symbols(\"e1 e2\")\n",
    "eq = [e1 - e2, foo(e1) - e2, bar() - e1]\n",
    "print(sp.reduced(e2, eq))\n",
    "\n",
    "print(sp.groebner(eq)) #nice\n",
    "\n",
    "# ok but it doesn't do inner stuff, so we shouyld traverse manually.\n",
    "print(sp.reduced(foo(biz()), [bar() - biz()]))\n",
    "print(sp.reduced(foo(bar()), [bar() - biz()]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo(biz())\n",
      "foo(biz())\n"
     ]
    }
   ],
   "source": [
    "def rec_reduced(t, eqs):\n",
    "    args = map(lambda arg: rec_reduced(arg,eqs), t.args)\n",
    "    return sp.reduced(t.func(*args), eqs)[1]\n",
    "print(rec_reduced(foo(bar()), [bar() - biz()]))\n",
    "print(rec_reduced(foo(biz()), [bar() - biz()]))\n",
    "\n",
    "# https://www.philipzucker.com/ext_z3_egraph/\n",
    "class EGraph1():\n",
    "    T : set[sp.Expr]\n",
    "    eqs : list[sp.Expr] # R\n",
    "    def find(self, t):\n",
    "        return rec_reduced(t, self.eqs)\n",
    "    def add_term(self, t):\n",
    "        self.T.add(t)\n",
    "        for arg in t.args:\n",
    "            self.add_term(arg)\n",
    "    def union(self, t1, t2):\n",
    "        self.eqs.append(t1 - t2)\n",
    "    def rebuild(self):\n",
    "        self.eqs = list(sp.groebner(self.eqs))\n",
    "        self.T = set(map(lambda t: self.find(t), self.T))\n",
    "    def rw(self, n, f, add_term=True):\n",
    "        for ts in itertools.product(self.T, repeat=n):\n",
    "            lhs, rhs = f(*ts)\n",
    "            lhs = self.find(lhs)\n",
    "            if lhs in self.T:\n",
    "                rhs = self.find(rhs)\n",
    "                if add_term:\n",
    "                    self.T.add(rhs)\n",
    "                self.union(lhs, rhs)\n",
    "    def sympy_simp(self):\n",
    "        # reuse sympy rules\n",
    "        for t in self.T:\n",
    "            self.union(t, sp.simplify(t))\n",
    "        self.rebuild()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quine Mclusky https://en.wikipedia.org/wiki/Quine%E2%80%93McCluskey_algorithm might be a good replacement for grobner in boolean theories. Not sure what it is though\n",
    "\n",
    "Faster grobner. msolve https://msolve.lip6.fr/ . singular\n",
    "\n",
    "Intermixing with non real valued teories. No problem. Use regular union find for those sorts.\n",
    "\n",
    "Linear inequalities seem to fit better into egraph modulo theories just mirroring into an smt solver for guards.\n",
    "\n",
    "graver basis for integer linear https://en.wikipedia.org/wiki/Graver_basis . simple two monomial equations.\n",
    "\n",
    "The Shostak method to the best I understand it is combining theories by using the theories to eliminate variables rather than just propagate equations.\n",
    "Linear arithemtic knows how to isolate variables. Sweet. Do that, assert that variable to the egraph. There are piles of papers on shostak's method. Decrypting them is a project on its own. One wonders what the point of writing is when reading is so hard. I dunno. All these theory papers don't illuminate for my taste really. I seek a mall intuitive kernel, like a sentence or two, some hokey pseudo code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Egraphs are Ground Completion, Grobner is Knuth Bendix\n",
    "\n",
    "I'll note that associativity added into ground equations makes knuth bendix completion undecidable.\n",
    "\n",
    "Adding in enough ring equations to bring us back \n",
    "\n",
    "It's complicated.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If you do this process with some arbitrary collection of polynomials, you can still do it, it is just not guaranteed to be unique. \n",
    "\n",
    "If this canonical form is 0, then we know that the set of polynomial equational constraints imply the target expression is always zero. If it's nonzero, well, that is just a canonical expression with respect to that groebner basis.\n",
    "\n",
    "It is this canonicalization property which let's us generalize\n",
    "# Linear Algebra and union finds and spectral thinking\n",
    "\n",
    "Unions find \n",
    "What are they for? Well, one use case is to find the [connected components](https://en.wikipedia.org/wiki/Component_(graph_theory)) in an undirected graph. This is used as part of Kruskal's algorithm https://en.wikipedia.org/wiki/Kruskal%27s_algorithm for finding minimum spanning forests of a graph. You consider the edges in weight order greedily and add it to the spanning tree if it doesn't connect two thing already connected. The union find gives a fast check for already connected.\n",
    "\n",
    "The \"proof\" that two edges are connected is the path between them.\n",
    "\n",
    "There are other approaches though. You might \n",
    "\n",
    "One way of representing graphs that is very fruitful is the perspective of adjacency matrices https://en.wikipedia.org/wiki/Adjacency_matrix . Multiplication of the matrices can correspond to taking steps or finding paths in the graph. Using min-plus arithemtic, you can find the mininum cost path in this way\n",
    "\n",
    "A different, kind of crazy, way of finding connected components of a graph might be spectral method. You could take the eigenvectors of the graph laplacian. There ought to be one . So the linear algebraic \n",
    "\n",
    "I'm not saying any of these considerations directly apply in what we're doing here, but I am noting that linear algebra methods and union finds are in the same ball park.\n",
    " \n",
    "If you only assert equations of the form `x - y = 0` aka have rows in your matrix of only a single `1` and `-1`, then the reduced row echelon form will tell you exactly wich variables are equal to a canonical vairable.\n",
    "\n",
    "If our graph was a bunch of points connected by springs, these eigvenctors are normal mods that correspond to an entire connected chunk translating uniformly. Or you could think of the graph as a circuit and the edges as resistors in which case it corresponds to the shifting of an entire chunk by a uniform Voltage, and no current flows.\n",
    "\n",
    "One of the cool things about spectral graph theory https://en.wikipedia.org/wiki/Spectral_graph_theory is that it tells you an approximation of the min cut\n",
    "\n",
    "However, you are free to use more complicated linear combinations.\n",
    "\n",
    "# Misc\n",
    "\n",
    "\n",
    "Egraphs modulo theories EMT = SMT - Sat\n",
    "But a focus on ematching and simplification rather than sat solving\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Subsumption is a terminology for a redundant fact\n",
    "\n",
    "Forward subsumption  is deleting new redundant inferences. We need to compare a new fact and see if it is made redundant by our large database of old facts\n",
    "\n",
    "Backward subsumption is the opposite. We want to see which pieces of our old big datbase are made redunant by our new fact\n",
    "\n",
    "If I knew x > 0 and then derive x > -1, this new fact is redundant.\n",
    "If I knew x > 0 and derive x > 1, then the old fact x > 0 is made redundant. The new fact is strictly stronger.\n",
    "\n",
    "Some common notions of subsumption\n",
    "- conditional facts with weaker assumtions. `A /\\ B => C` is strictly weaker than `A => C` \n",
    "- intervals\n",
    "- Unification patterns. `forall A, f(A)= g(A)` is stronger than `f(1) = g(1)`. Likewise `forall A B, g(A,B) = 7` is stronger than `forall A, g(A,A) = 7` \n",
    "- Linear equations\n",
    "- Linear Inequalities\n",
    "- Polynomial equations\n",
    "- Boolean formulas. \n",
    "\n",
    "Forward subsumption of linear inequalities is answerable via linear programming. Given the database `Ax >= b`, is `cx >= d` redundant? Well the answer to `min cx s.t. Ax >= b` will tell you. If the min was already greater than d, it is redundant, and the dual vector tells you how to derive this fact\n",
    "\n",
    "Forward Subsumption of boolean variables can be asked via a SAT query. We can have a big database and push and pop small queries on.\n",
    "\n",
    "It is less clear to me how to do backward subsumption.\n",
    "\n",
    "We can normalize\n",
    "\n",
    "\n",
    "Grobner bases and guassian elimination\n",
    "Duplicating inside z3.\n",
    "\n",
    "$Ax=b$ This represents some affine subspace\n",
    "Does this hyperplane\n",
    "$cx=d$\n",
    "lie inside the subspace?\n",
    "\n",
    "$l(Ax - b) = cx - d$\n",
    "\n",
    "The dual problem\n",
    "$ lb=d $\n",
    "$ lA=c $\n",
    "\n",
    "So we could solve this via a stack matrix $l(A|b) = (c|d)$\n",
    "Or we could do a block LU.\n",
    "\n",
    "What are my options for decompositions. LU, QR, eigen, svd\n",
    "\n",
    "\n",
    "https://github.com/vprover/vampire/pull/546 vampire pull request about using SAT for subsumption. Paper references\n",
    "- 2022: \"First-Order Subsumption via SAT Solving.\" by Jakob Rath, Armin Biere and Laura Kovács\n",
    "- 2023: \"SAT-Based Subsumption Resolution\" by Robin Coutelier, Jakob Rath, Michael Rawson and Laura Kovács\n",
    "- 2024: \"SAT Solving for Variants of First-Order Subsumption\" by Robin Coutelier, Jakob Rath, Michael Rawson, Armin Biere and Laura Kovács\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "A \"soft egraph\" which tries to take low rank views?\n",
    "eivenvectors\n",
    "could use svd or qr?\n",
    "That x - y kiund of looks like a finite difference, anything to do with that? homology, homotopty, equality, ideations. Encoding higher equalities linear using mesh curl stuff?\n",
    "Can we make any sense of an occurs check in this linear form?\n",
    "\n",
    "Semiring considerations?\n",
    "\n",
    "\n",
    "Union finds are used for connected components. You could use linear algebraic / spectral methods for connected components, although it would be ludicrous overkill. We are in some sense building things akin to the graph laplacian / differentiation operators. The adjacency matrix of the graph.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EGraph():\n",
    "    nodes\n",
    "    uf\n",
    "    T\n",
    "    def __init__(self):\n",
    "        self.nodes = []\n",
    "        self.R = []\n",
    "        self.t = []\n",
    "    def add_term(self, t):\n",
    "\n",
    "    def canon()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos(sin(x)**2)**2 + sin(1 - cos(x)**2)**2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QRResult(Q=array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]]), R=array([[ 1., -1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1., -1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1., -1.]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "R = np.array([\n",
    "    [1,-1,0,0,0],\n",
    "    [0,1,-1,0,0],\n",
    "    [0,0,0,1,-1]\n",
    "])\n",
    "np.linalg.svd(R)\n",
    "np.linalg.qr(R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}1 & 0 & -1 & 0 & 0 & 1 & 0 & 1 & 0\\\\0 & 1 & -1 & 0 & 0 & 0 & 0 & 1 & 0\\\\0 & 0 & 0 & 1 & -1 & 0 & 0 & 0 & 1\\\\0 & 0 & 0 & 0 & 0 & 0 & 1 & -1 & 0\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[1, 0, -1, 0,  0, 1, 0,  1, 0],\n",
       "[0, 1, -1, 0,  0, 0, 0,  1, 0],\n",
       "[0, 0,  0, 1, -1, 0, 0,  0, 1],\n",
       "[0, 0,  0, 0,  0, 0, 1, -1, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}1 & 0 & 1 & 0\\\\0 & 0 & 1 & 0\\\\0 & 0 & 0 & 1\\\\0 & 1 & -1 & 0\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[1, 0,  1, 0],\n",
       "[0, 0,  1, 0],\n",
       "[0, 0,  0, 1],\n",
       "[0, 1, -1, 0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S[:,5:] # This is directly the row manipulation matrix. It tells us how to get the row normalized form from R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wyaso f looking at matrix multiplication. Row times column, sure, but also a vectior can be seen as a column sum of a matrix. A row vector on the right is a row sum.\n",
    "\n",
    "RA = row manipulations / linear row sums of A. Each row of R is a Row sum recipe.  \n",
    "\n",
    "\n",
    "`E * [R | I] = [E*R | E] = S`\n",
    "\n",
    "We want to know how .\n",
    "Can I produce a spanning tree from this? Well, I can get a subset of the edges needed.\n",
    "\n",
    "\n",
    "Each row of the reduced row echelon can be seen as a rewrite rule. The leading 1 should rewrite to the negative of the rest of that row.\n",
    "`[1 0 -1 -1]` is seen as `x_0 -> x_2 + x_3`. The term ordering of the variable of the obvious one.\n",
    "\n",
    "Polynomials (and many mathemtical expressions) can be seen in two different lights. \n",
    "- `1 + 2a + b*b`  `a` and `b` have particular values in a model. They are points. They are ground. They can perhaps be solved for.  R^2 -> P\n",
    "- `1 + 2*A + B*B`  A thing you're suppose to subsitute in for variables A,B. This is a mapping to a scalar and a pluggable formula for it. \"Solving\" an equation would be finding a surface. In particular you may want a parametrization of the surface. P -> R. Or is this R^2 -> R?\n",
    "\n",
    "Is grobner basis finding ground completion? Yes, I think so.\n",
    "\n",
    "Creating S polynomials is creating critical pairs. But we aren't doing unification of monomials. We are doing sub term finding (?). Well possibly subterm into an even bigger thing. What if we restricted grobner to strict monominal subterm S polynomials (one of the monomial coefficients has to be 1)?  x^{m} - p x^{n}\n",
    "\n",
    "\n",
    "Quine Mclucskey is also completion? How does that one work?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomials are just another container.\n",
    "bottom up ematching still seems ok\n",
    "polynomials are ground from the term reqwriting perspective.\n",
    "grobner guaranteed to terminate?\n",
    "Also linear equalities\n",
    "\n",
    "We can also do SMT guarded patterns.\n",
    "\n",
    "\n",
    "\n",
    "linear inequalities?\n",
    "\n",
    "Knuth bendix and grobner\n",
    "https://leodemoura.github.io/files/synasc.pdf passmore de moura Superfluous S-polynomials in Strategy-Independent\n",
    "Gr¨obner Bases\n",
    "https://www.sciencedirect.com/science/article/pii/S0747717199902626  A Categorical Critical-pair Completion Algorithm\n",
    "https://dl.acm.org/doi/pdf/10.1145/74540.74548  Knuth-Bendix procedure and Buchberger algorithm: a synthesis\n",
    "https://link.springer.com/chapter/10.1007/978-3-0348-8800-4_9 Normalized Rewriting: A Unified View of Knuth-Bendix Completion and Gröbner Bases Computation\n",
    "https://arxiv.org/abs/math/9812097  Applications of Rewriting Systems and Groebner Bases to Computing Kan Extensions and Identities Among Relations\n",
    "\n",
    "\n",
    "https://jingnanshi.com/blog/groebner_basis.html\n",
    "https://colab.research.google.com/github/bernalde/QuIP/blob/master/notebooks/Notebook%202%20-%20Groebner%20basis.ipynb hmm. quantum integer programming?\n",
    "https://github.com/sumiya11/Groebner.jl?tab=readme-ov-file\n",
    "msolve\n",
    "https://www.philipzucker.com/computing-syzygy-modules-in-sympy/\n",
    "\n",
    "\n",
    "Also polynomial factoring. Normalization of the poly could involve slapping the factors in the egraph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://docs.sympy.org/latest/modules/polys/reference.html\n",
    "import sympy as sp\n",
    "\n",
    "from sympy import poly\n",
    "from sympy.abc import x,y,z\n",
    "from sympy import groebner\n",
    "poly(x*(x**2 + x - 1)**2)\n",
    "\n",
    "F = [x*y - 2*y, 2*y**2 - x**2]\n",
    "groebner(F, x, y, order='lex')\n",
    "\n",
    "\n",
    "def sympy_eclass(n):\n",
    "    return sp.symbols('e' + str(n))\n",
    "def eclass_of_sympy(eclass):\n",
    "    return int(eclass.name[1:])\n",
    "\n",
    "eclass_of_sympy(sympy_eclass(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable Mul object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m G \u001b[38;5;241m=\u001b[39m groebner(F, x, y, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlex\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m _, p \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mreduced(x\u001b[38;5;241m*\u001b[39my, G)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x,v \u001b[38;5;129;01min\u001b[39;00m foo:\n\u001b[1;32m      8\u001b[0m     foo[sp\u001b[38;5;241m.\u001b[39mreduced(x,G)] \u001b[38;5;241m=\u001b[39m v\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable Mul object"
     ]
    }
   ],
   "source": [
    "foo = {}\n",
    "foo[x*y] = 10\n",
    "\n",
    "F = [x*y - 2*y, 2*y**2 - x**2]\n",
    "G = groebner(F, x, y, order='lex')\n",
    "_, p = sp.reduced(x*y, G)\n",
    "for x,v in foo:\n",
    "    foo[sp.reduced(x,G)] = v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a grobner basis over linear equations is guassian elimuination.\n",
    "But also a grobner basis over linear equations of the form `p = q` is sufficient to make a union find.\n",
    "Hence we can use grobner instead of our union find. \n",
    "\n",
    "\n",
    "A Grobner Union Find\n",
    "It is interesting that completion\n",
    "\n",
    "\n",
    "Triangular substitutions a la minkanren for unification. Triangular is reminiscent of LU decomposition. There are incremental guassian elimination algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sympy.core.symbol.Symbol"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy.abc import a,b,c,d,e,f,g,h\n",
    "groebner([a - b, b - c, d - e, d - c, f-g])\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2*x, 1], x**2 + y**2 + y)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(poly(x*(x**2 + x - 1)**2))\n",
    "# https://docs.sympy.org/latest/modules/polys/reference.html#sympy.polys.polytools.reduced\n",
    "# not sure how complete reduced is? Naive repeated polynimal division?\n",
    "reduced(2*x**4 + y**2 - x**2 + y**3, [x**3 - x, y**3 - y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolyNode(sympy.polys.polytools.Poly):\n",
    "    def rebuild(self):\n",
    "        return PolyNode(reduced(self, egraph.poly_eqs))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnionFind():\n",
    "    def __init__(self):\n",
    "        self.uf = []\n",
    "    def makeset(self):\n",
    "        uf = self.uf\n",
    "        uf.append(len(uf))\n",
    "        return len(uf) - 1\n",
    "    def find(self,x):\n",
    "        while self.uf[x] != x:\n",
    "            x = self.uf[x]\n",
    "        return x\n",
    "    def union(self,x,y):\n",
    "        x = self.find(x)\n",
    "        y = self.find(y)\n",
    "        self.uf[x] = y\n",
    "        return y\n",
    "    def __len__(self):\n",
    "        return len(self.uf)\n",
    "    def __repr__(self):\n",
    "        return \"UnionFind({})\".format(self.uf)\n",
    "\n",
    "EClass = int\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Lit():\n",
    "    data: Any\n",
    "    def rebuild(self):\n",
    "        return self\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ENode():\n",
    "    head: Any\n",
    "    args : tuple[EClass]\n",
    "    def rebuild(self):\n",
    "        return ENode(self.head, tuple(map(egraph.uf.find, self.args)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EGraph:\n",
    "    def __init__(self):\n",
    "        self.uf = UnionFind()\n",
    "        self.hashcons : Dict[Any, EClass] = {}\n",
    "    def __getitem__(self, key):\n",
    "        return self.hashcons[key]\n",
    "    def union(self, x : EClass,y : EClass) -> EClass:\n",
    "        return self.uf.union(x,y)\n",
    "    def make(self, t : Any) -> EClass:\n",
    "        t1 = self.hashcons.get(t)\n",
    "        if t1 == None:\n",
    "            v = self.uf.makeset()\n",
    "            self.hashcons[t] = v\n",
    "            return v\n",
    "        else:\n",
    "            return t1\n",
    "    def __getitem__(self, key):\n",
    "        return self.hashcons[key]\n",
    "    def __iter__(self):\n",
    "        return iter(range(len(self.uf.uf))) \n",
    "    def __repr__(self):\n",
    "        return f\"EGraph(uf={self.uf},hashcons={self.hashcons})\"\n",
    "    def rebuild(self):\n",
    "        # simple naive dumb rebuild step\n",
    "        for k,v in self.hashcons.items():\n",
    "            v = self.uf.find(v)\n",
    "            self.hashcons[k] = v\n",
    "            v1 = self.make(k.rebuild()) \n",
    "            self.union(v,v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EGraph():\n",
    "    uf:UnionFind\n",
    "    nodes:list[object]\n",
    "    z3_solver: SolverRef\n",
    "    poly_eqs: list[Poly]\n",
    "\n",
    "    def canon(self):\n",
    "    def assert_z3(self, constr):\n",
    "        # or maybe just let it rip.\n",
    "        self.solver.push()\n",
    "        # subsumption check\n",
    "        self.solver.add(Not(constr))\n",
    "        res = self.solver.check()\n",
    "        # mayube store models for fast path subsumtion\n",
    "        self.solver.pop()\n",
    "        if res == sat: # this constrain is not redunddant.\n",
    "            self.solver.add(constr)\n",
    "    def norm_linear(self, lexpr):\n",
    "        # project into current subspace basically. No. because lexpr is describing linear function of vectotrs.\n",
    "    def assert_lineq():\n",
    "        # also maybe inform z3.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "&not;(x = y) &or; z = Store(a, y, 0)[x]"
      ],
      "text/plain": [
       "Or(Not(x == y), z == Store(a, y, 0)[x])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contextual simplification\n",
    "from z3 import *\n",
    "#ArraySort(IntSort(), IntSort())\n",
    "x, y, z = Ints(\"x y z\")\n",
    "a = Array(\"a\", IntSort(), IntSort())\n",
    "z3.simplify(y / (y * x))\n",
    "z3.simplify(Select(Store(a, y, IntVal(0)), x))\n",
    "#z3.simplify(Implies(x == y, ))\n",
    "e = Select(Store(a, y, IntVal(0)), x)\n",
    "z3.simplify(e)\n",
    "z3.simplify(Implies(x == y, z == e)) # nope Ok, well it was an idea\n",
    "\n",
    "# z3 mirroring. Do quantifier instan outside z3. Is this of any relation to avatar?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://servus.math.su.se/bergman/\n",
    "\n",
    "ocaml-alg\n",
    "msolve\n",
    "\n",
    "https://github.com/joshrule/term-rewriting-rs there isn't a kb in here?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
